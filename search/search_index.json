{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ASF HyP3 \u00b6 Alaska Satellite Facility's Hybrid Pluggable Processing Pipeline HyP3 is a service for processing Synthetic Aperture Radar (SAR) imagery that addresses many common issues for users of SAR data: Most SAR datasets require at least some processing to remove distortions before they are analysis-ready SAR processing is computing-intensive Software for SAR processing is complicated to use and/or prohibitively expensive Producing analysis-ready SAR data has a steep learning curve that acts as a barrier to entry HyP3 solves these problems by providing a free service where people can request SAR processing on-demand. These processing requests are picked up by automated systems, which handle the complexity of SAR processing on behalf of the user. HyP3 doesn't require users to have a lot of knowledge of SAR processing before getting started; users only need to submit the input data and set a few optional parameters if desired. With HyP3, analysis-ready products are just a few clicks away. Getting started \u00b6 Using Vertex \u00b6 Vertex , ASF's data search portal, is the easiest way to use HyP3. Vertex provides a friendly interface to request jobs and review previous jobs. Visit On Demand Processing in Vertex to learn more. Using the Python SDK \u00b6 The HyP3 SDK is a Python library for using HyP3 programmatically. It is available on both conda-forge and PyPI , and can be installed with either: conda install -c conda-forge hyp3_sdk or python -m pip install hyp3_sdk Visit Using HyP3: SDK to learn more. Using the API \u00b6 The HyP3 web API is the backbone behind Vertex and the SDK. You may also use the API directly. Visit Using HyP3: API to learn more. Contact Us \u00b6 Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? open an issue General questions? Suggestions? Or just want to talk to the team? chat with us on gitter","title":"Home"},{"location":"#asf-hyp3","text":"Alaska Satellite Facility's Hybrid Pluggable Processing Pipeline HyP3 is a service for processing Synthetic Aperture Radar (SAR) imagery that addresses many common issues for users of SAR data: Most SAR datasets require at least some processing to remove distortions before they are analysis-ready SAR processing is computing-intensive Software for SAR processing is complicated to use and/or prohibitively expensive Producing analysis-ready SAR data has a steep learning curve that acts as a barrier to entry HyP3 solves these problems by providing a free service where people can request SAR processing on-demand. These processing requests are picked up by automated systems, which handle the complexity of SAR processing on behalf of the user. HyP3 doesn't require users to have a lot of knowledge of SAR processing before getting started; users only need to submit the input data and set a few optional parameters if desired. With HyP3, analysis-ready products are just a few clicks away.","title":"ASF HyP3"},{"location":"#getting-started","text":"","title":"Getting started"},{"location":"#using-vertex","text":"Vertex , ASF's data search portal, is the easiest way to use HyP3. Vertex provides a friendly interface to request jobs and review previous jobs. Visit On Demand Processing in Vertex to learn more.","title":"Using Vertex"},{"location":"#using-the-python-sdk","text":"The HyP3 SDK is a Python library for using HyP3 programmatically. It is available on both conda-forge and PyPI , and can be installed with either: conda install -c conda-forge hyp3_sdk or python -m pip install hyp3_sdk Visit Using HyP3: SDK to learn more.","title":"Using the Python SDK"},{"location":"#using-the-api","text":"The HyP3 web API is the backbone behind Vertex and the SDK. You may also use the API directly. Visit Using HyP3: API to learn more.","title":"Using the API"},{"location":"#contact-us","text":"Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? open an issue General questions? Suggestions? Or just want to talk to the team? chat with us on gitter","title":"Contact Us"},{"location":"CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct \u00b6 Our Pledge \u00b6 We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards \u00b6 Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities \u00b6 Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope \u00b6 This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement \u00b6 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement by emailing the ASF APD/Tools team at UAF-asf-apd@alaska.edu . All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines \u00b6 Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction \u00b6 Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning \u00b6 Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban \u00b6 Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban \u00b6 Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution \u00b6 This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Code of Conduct"},{"location":"CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement by emailing the ASF APD/Tools team at UAF-asf-apd@alaska.edu . All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"contributing/","text":"Contributing \u00b6 Thank you for your interest in helping make custom on-demand SAR processing accessible! We're excited you would like to contribute to HyP3! Whether you're finding bugs, adding new features, fixing anything broken, or improving documentation, get started by submitting an issue or pull request! Please read our Code of Conduct before contributing. Issues and Pull Requests are welcome \u00b6 If you have any questions or ideas, or notice any problems or bugs, and want to open an issue, great! We recommend first searching our open issues to see if the issue has already been submitted (we may already be working on it!). If you think your issue is new, you're welcome to create a new issue in our general issues tracker. If you know the specific repository that your issue pertains to, you can use its issues tracker (see our repositories list below). Found a typo, know how to fix a bug, want to update the docs, want to add a new feature? Even better! The smaller the PR, the easier it is to review and test and the more likely it is to be successful. For major contributions, consider opening an issue describing the contribution so we can help guide and breakup the work into digestible pieces. Pull Request Guidelines \u00b6 We ask that you follow these guidelines with your contributions Style \u00b6 We generally follow python community standards ( PEP8 ), except we allow line lengths up to 120 characters. We recommend trying to keep lines 80--100 characters long, but allow up to 120 when it improves readability. Documentation \u00b6 We are working to improve our documentation! For all public-facing functions/methods (not marked internal use ), please include type hints (when reasonable) and a docstring formatted Google style . Tests \u00b6 All of the automated tests for the project need to pass before your submission will be accepted. If you add new functionality, please consider adding tests for that functionality as well. Commits \u00b6 Make small commits that show the individual changes you are making Write descriptive commit messages that explain your changes Example of a good commit message: Improve contributing guidelines. Fixes #10 Improve contributing docs and consolidate them in the standard location https://help.github.com/articles/setting-guidelines-for-repository-contributors/","title":"Contributing"},{"location":"contributing/#contributing","text":"Thank you for your interest in helping make custom on-demand SAR processing accessible! We're excited you would like to contribute to HyP3! Whether you're finding bugs, adding new features, fixing anything broken, or improving documentation, get started by submitting an issue or pull request! Please read our Code of Conduct before contributing.","title":"Contributing"},{"location":"contributing/#issues-and-pull-requests-are-welcome","text":"If you have any questions or ideas, or notice any problems or bugs, and want to open an issue, great! We recommend first searching our open issues to see if the issue has already been submitted (we may already be working on it!). If you think your issue is new, you're welcome to create a new issue in our general issues tracker. If you know the specific repository that your issue pertains to, you can use its issues tracker (see our repositories list below). Found a typo, know how to fix a bug, want to update the docs, want to add a new feature? Even better! The smaller the PR, the easier it is to review and test and the more likely it is to be successful. For major contributions, consider opening an issue describing the contribution so we can help guide and breakup the work into digestible pieces.","title":"Issues and Pull Requests are welcome"},{"location":"contributing/#pull-request-guidelines","text":"We ask that you follow these guidelines with your contributions","title":"Pull Request Guidelines"},{"location":"dems/","text":"Digital Elevation Models \u00b6 The quality of the terrain corrections are directly related to the quality of the digital elevation models (DEMs) used in the process of geometrically and radiometrically correcting the SAR imagery. We use DEMs that are publicly available and have wide-ranging coverage. In the past, ASF maintained a collection of DEMs that were pre-processed as appropriate for SAR workflows, and applied a preference hierarchy so that the best available DEM in any given area would be automatically selected for processing. With the public release of the GLO-30 Copernicus DEM, we are changing our default DEM strategy to leverage a cloud-hosted copy of the global Copernicus DEM. Copernicus DEM GLO-30 Public Coming Soon We are in the process of adding the Copernicus DEM GLO-30 Public dataset as our default DEM for RTC processing. The legacy DEM is still the default for On-Demand RTC in Vertex and using the API , but Copernicus DEM is now the default when using the newest version of the SDK . It will soon be the default DEM for the API and Vertex as well. Stay tuned! Table 1 summarizes ASF's DEM sources. Note that in each case, the DEM is resampled to RTC spacing and reprojected to a UTM Zone (WGS84), and a geoid correction is applied before being used for RTC processing. Resolution DEM Vertical Datum Area Posting Priority Medium GLO-30 EGM2008 Global 1 arc second Default High NED13 NAVD88 CONUS, Hawaii, parts of Alaska 1/3 arc seconds 1 Medium SRTMGL1 EGM96 60 N to 57 S latitude 1 arc second 2 Medium NED1 NAVD88 Canada 1 arc second 3 Low NED2 NAVD88 Parts of Alaska 2 arc seconds 4 Table 1: DEMs used for RTC processing. Note that the Copernicus 30 m DEM is the default, while the other four DEMs are only used if the legacy option is invoked. When ordering On-Demand RTC products, you can choose to include a copy of the DEM used for RTC processing in the RTC product package. This DEM copy is converted to 16-bit signed integer format, but is otherwise the same as the DEM used in the RTC process. Note that the height values will differ from the original source DEM in all cases, due to the geoid correction applied to prepare the DEM for use in RTC processing. Copernicus DEM : Coming Soon \u00b6 The GLO-30 Copernicus DEM provides global coverage (with the current exception of an area covering Armenia and Azerbaijan, see Figure 3) at 30-m pixel spacing. When an RTC job is requested, we download the required DEM tiles from the Copernicus Digital Elevation Model (DEM) GLO-30 Public dataset available in the Registry of Open Data on AWS , managed by Sinergise . We mosaic the tiles and reproject them to the appropriate UTM Zone for the location of the SAR granule to be processed, resampling them to match the pixel spacing and alignment of the RTC product. A geoid correction is applied before it is used for RTC processing. Figure 1 shows the coverage of the Copernicus DEM GLO-30 Public dataset, and figure 2 details the land area currently not covered. Figure 1: Copernicus DEM GLO-30 coverage map Figure 2: Detail of area currently not covered by Copernicus DEM GLO-30 Legacy DEMs \u00b6 The legacy DEMs were pre-processed by ASF to a consistent raster format (GeoTIFF) from the original source formats: height (*.hgt), ESRI ArcGrid (*.adf), etc. Many of the NASA-provided DEMs were provided as orthometric heights with EGM96 vertical datum. These were converted by ASF to ellipsoid heights using the ASF MapReady tool named geoid_adjust . The pixel reference varied from the center (pixel as point) to a corner (pixel as area). The GAMMA software, used to generate the terrain corrected products, uses pixel as area and adjusts DEM coordinates as needed. These processed DEM collections are stored by ASF in AWS. When an RTC job is requested, the best-available DEM covering the SAR granule is selected, and the necessary tiles are reprojected to a mosaic in the UTM Zone appropriate for the granule location. If legacy DEM processing is selected, one of the following DEMs will be used: The National Elevation Dataset (NED) \u2153 arc second (about 10 m resolution) DEM covers the continental U.S. (CONUS), Hawaii, and parts of Alaska. Shuttle Radar Topography Mission (SRTM) GL1 data at 30 m resolution is used where NED 13 is not available. 1 arc second NED gives coverage of Canada at about 30 m resolution. 2 arc second NED (about 60 m) covers the remaining parts of Alaska above 60 degrees northern latitude. Since more than one DEM may be available in legacy processing, DEMs are selected in priority order as listed in Table 1. DEM coverage of at least 20% from a single DEM source is required for legacy processing to proceed. In no case will the DEM selected be from more than one source; only the single best source of terrain height values is used for a given scene. Figure 3 shows the coverage of the various legacy DEM sources. Figure 3: Coverage of the various legacy DEM sources used for terrain correction Special Use DEMs \u00b6 AutoRIFT , a process developed by the NASA MEaSUREs ITS_LIVE project, processes use a custom Greenland and Antarctica DEM with a 240 m resolution. The DEM, associated process input files, and their details are available on the ITS_LIVE project website.","title":"Digital Elevation Models"},{"location":"dems/#digital-elevation-models","text":"The quality of the terrain corrections are directly related to the quality of the digital elevation models (DEMs) used in the process of geometrically and radiometrically correcting the SAR imagery. We use DEMs that are publicly available and have wide-ranging coverage. In the past, ASF maintained a collection of DEMs that were pre-processed as appropriate for SAR workflows, and applied a preference hierarchy so that the best available DEM in any given area would be automatically selected for processing. With the public release of the GLO-30 Copernicus DEM, we are changing our default DEM strategy to leverage a cloud-hosted copy of the global Copernicus DEM. Copernicus DEM GLO-30 Public Coming Soon We are in the process of adding the Copernicus DEM GLO-30 Public dataset as our default DEM for RTC processing. The legacy DEM is still the default for On-Demand RTC in Vertex and using the API , but Copernicus DEM is now the default when using the newest version of the SDK . It will soon be the default DEM for the API and Vertex as well. Stay tuned! Table 1 summarizes ASF's DEM sources. Note that in each case, the DEM is resampled to RTC spacing and reprojected to a UTM Zone (WGS84), and a geoid correction is applied before being used for RTC processing. Resolution DEM Vertical Datum Area Posting Priority Medium GLO-30 EGM2008 Global 1 arc second Default High NED13 NAVD88 CONUS, Hawaii, parts of Alaska 1/3 arc seconds 1 Medium SRTMGL1 EGM96 60 N to 57 S latitude 1 arc second 2 Medium NED1 NAVD88 Canada 1 arc second 3 Low NED2 NAVD88 Parts of Alaska 2 arc seconds 4 Table 1: DEMs used for RTC processing. Note that the Copernicus 30 m DEM is the default, while the other four DEMs are only used if the legacy option is invoked. When ordering On-Demand RTC products, you can choose to include a copy of the DEM used for RTC processing in the RTC product package. This DEM copy is converted to 16-bit signed integer format, but is otherwise the same as the DEM used in the RTC process. Note that the height values will differ from the original source DEM in all cases, due to the geoid correction applied to prepare the DEM for use in RTC processing.","title":"Digital Elevation Models"},{"location":"dems/#copernicus-dem-coming-soon","text":"The GLO-30 Copernicus DEM provides global coverage (with the current exception of an area covering Armenia and Azerbaijan, see Figure 3) at 30-m pixel spacing. When an RTC job is requested, we download the required DEM tiles from the Copernicus Digital Elevation Model (DEM) GLO-30 Public dataset available in the Registry of Open Data on AWS , managed by Sinergise . We mosaic the tiles and reproject them to the appropriate UTM Zone for the location of the SAR granule to be processed, resampling them to match the pixel spacing and alignment of the RTC product. A geoid correction is applied before it is used for RTC processing. Figure 1 shows the coverage of the Copernicus DEM GLO-30 Public dataset, and figure 2 details the land area currently not covered. Figure 1: Copernicus DEM GLO-30 coverage map Figure 2: Detail of area currently not covered by Copernicus DEM GLO-30","title":"Copernicus DEM : Coming Soon"},{"location":"dems/#legacy-dems","text":"The legacy DEMs were pre-processed by ASF to a consistent raster format (GeoTIFF) from the original source formats: height (*.hgt), ESRI ArcGrid (*.adf), etc. Many of the NASA-provided DEMs were provided as orthometric heights with EGM96 vertical datum. These were converted by ASF to ellipsoid heights using the ASF MapReady tool named geoid_adjust . The pixel reference varied from the center (pixel as point) to a corner (pixel as area). The GAMMA software, used to generate the terrain corrected products, uses pixel as area and adjusts DEM coordinates as needed. These processed DEM collections are stored by ASF in AWS. When an RTC job is requested, the best-available DEM covering the SAR granule is selected, and the necessary tiles are reprojected to a mosaic in the UTM Zone appropriate for the granule location. If legacy DEM processing is selected, one of the following DEMs will be used: The National Elevation Dataset (NED) \u2153 arc second (about 10 m resolution) DEM covers the continental U.S. (CONUS), Hawaii, and parts of Alaska. Shuttle Radar Topography Mission (SRTM) GL1 data at 30 m resolution is used where NED 13 is not available. 1 arc second NED gives coverage of Canada at about 30 m resolution. 2 arc second NED (about 60 m) covers the remaining parts of Alaska above 60 degrees northern latitude. Since more than one DEM may be available in legacy processing, DEMs are selected in priority order as listed in Table 1. DEM coverage of at least 20% from a single DEM source is required for legacy processing to proceed. In no case will the DEM selected be from more than one source; only the single best source of terrain height values is used for a given scene. Figure 3 shows the coverage of the various legacy DEM sources. Figure 3: Coverage of the various legacy DEM sources used for terrain correction","title":"Legacy DEMs"},{"location":"dems/#special-use-dems","text":"AutoRIFT , a process developed by the NASA MEaSUREs ITS_LIVE project, processes use a custom Greenland and Antarctica DEM with a 240 m resolution. The DEM, associated process input files, and their details are available on the ITS_LIVE project website.","title":"Special Use DEMs"},{"location":"how_it_works/","text":"How it Works \u00b6 HyP3 is built around three core concepts: Platform, Plugins, and Products. Platform \u00b6 The HyP3 platform makes it easy for users to request processing, monitor their requests, and download processed products. The platform delegates each processing request to a plugin on the user's behalf. A deployment of the HyP3 platform can be integrated with any number of plugins. Plugins \u00b6 Plugins are the workhorses of HyP3. Each plugin implements a particular processing workflow and produces a product. At their most basic level, HyP3 plugins are Docker containers that handle the entire processing workflow for a single product, including: Marshaling the required input data performing any needed transformations and computations on the data creating the final product uploading the product to an AWS S3 bucket for distribution Plugins only need to define a simple interface (entrypoint) that HyP3 understands and is used to run the container. By encapsulating the entire workflow for generating a single product, HyP3 can arbitrarily scale to meet user need. Products \u00b6 Products are the end result of processing, typically one or more data files. For more information about our current products, see our products page .","title":"How it works"},{"location":"how_it_works/#how-it-works","text":"HyP3 is built around three core concepts: Platform, Plugins, and Products.","title":"How it Works"},{"location":"how_it_works/#platform","text":"The HyP3 platform makes it easy for users to request processing, monitor their requests, and download processed products. The platform delegates each processing request to a plugin on the user's behalf. A deployment of the HyP3 platform can be integrated with any number of plugins.","title":"Platform"},{"location":"how_it_works/#plugins","text":"Plugins are the workhorses of HyP3. Each plugin implements a particular processing workflow and produces a product. At their most basic level, HyP3 plugins are Docker containers that handle the entire processing workflow for a single product, including: Marshaling the required input data performing any needed transformations and computations on the data creating the final product uploading the product to an AWS S3 bucket for distribution Plugins only need to define a simple interface (entrypoint) that HyP3 understands and is used to run the container. By encapsulating the entire workflow for generating a single product, HyP3 can arbitrarily scale to meet user need.","title":"Plugins"},{"location":"how_it_works/#products","text":"Products are the end result of processing, typically one or more data files. For more information about our current products, see our products page .","title":"Products"},{"location":"plugins/","text":"Plugins \u00b6 Plugins are the science backbone of HyP3; they do all of the data processing and product generation. Plugins can be added to HyP3 to generate new science products, or support different tools/software/algorithms/options/etc that are not currently supported by HyP3. How plugins work \u00b6 At their most basic level, HyP3 plugins are Docker containers with an interface (entrypoint) HyP3 understands. Plugins handle the entire processing workflow for a single product, including: Marshaling the required input data performing any needed transformations and computations on the data creating the final product uploading the product to an AWS S3 bucket for distribution By encapsulating the entire workflow for generating a single product, HyP3 can arbitrarily scale to meet user need. Developing a plugin \u00b6 To create a new HyP3 plugin, we recommend starting from a Minimal Working Example (MWE) of generating the product you're plugin will generate. Importantly, the MWE should be entirely self contained, and include all the necessary data to generate the product. Once a MWE is developed, it's important to define your plugin's interface -- this is where HyP3 connects the product generation and users. When designing the interface, you may find it helpful to ask yourself: what options do I want to provide to users? what's the minimal set information I need to gather from users? is this information easily input by users? is this information serializable? For example, can the information be written in a JSON file? could I define this information more simply? Once a MWE is developed and an interface is defined, you can use our HyP3 plugin cookiecuter to help you build a plugin that conforms to the plugin requirements. Plugin requirements \u00b6 In order to be supported by HyP3, a plugin must meet a few requirements: the plugin must be a Docker image that is hosted in a repository where HyP3 will be able to pull it the plugin's entrypoint must minimally accept the following arguments --bucket BUCKET-NAME where BUCKET-NAME is the name of an AWS S3 bucket that output products will be uploaded to --bucket-prefix BUCKET-PREFIX where BUCKET-PREFIX is a string appended to the key of any file uploaded to AWS S3 (this is effectively a subfolder in AWS S3) --username USER where USER is the username used to authenticate to EarthData Login --password PASSWORD where PASSWORD is the password used to authenticate to EarthData Login any necessary user input should be able to be provided through entrypoint arguments when uploading files to the S3 Bucket products files must be tagged with filetype: product if you wish to upload thumbnails or browse images, they must be tagged filetype: thumbnail or filetype: browse respectively Note: the aws subpackage of hyp3lib provides helper functions for tagging and uploading files Add the plugin to HyP3 \u00b6 Once the plugin itself is created, it can be added to the HyP3 system by... TBD.","title":"Plugins"},{"location":"plugins/#plugins","text":"Plugins are the science backbone of HyP3; they do all of the data processing and product generation. Plugins can be added to HyP3 to generate new science products, or support different tools/software/algorithms/options/etc that are not currently supported by HyP3.","title":"Plugins"},{"location":"plugins/#how-plugins-work","text":"At their most basic level, HyP3 plugins are Docker containers with an interface (entrypoint) HyP3 understands. Plugins handle the entire processing workflow for a single product, including: Marshaling the required input data performing any needed transformations and computations on the data creating the final product uploading the product to an AWS S3 bucket for distribution By encapsulating the entire workflow for generating a single product, HyP3 can arbitrarily scale to meet user need.","title":"How plugins work"},{"location":"plugins/#developing-a-plugin","text":"To create a new HyP3 plugin, we recommend starting from a Minimal Working Example (MWE) of generating the product you're plugin will generate. Importantly, the MWE should be entirely self contained, and include all the necessary data to generate the product. Once a MWE is developed, it's important to define your plugin's interface -- this is where HyP3 connects the product generation and users. When designing the interface, you may find it helpful to ask yourself: what options do I want to provide to users? what's the minimal set information I need to gather from users? is this information easily input by users? is this information serializable? For example, can the information be written in a JSON file? could I define this information more simply? Once a MWE is developed and an interface is defined, you can use our HyP3 plugin cookiecuter to help you build a plugin that conforms to the plugin requirements.","title":"Developing a plugin"},{"location":"plugins/#plugin-requirements","text":"In order to be supported by HyP3, a plugin must meet a few requirements: the plugin must be a Docker image that is hosted in a repository where HyP3 will be able to pull it the plugin's entrypoint must minimally accept the following arguments --bucket BUCKET-NAME where BUCKET-NAME is the name of an AWS S3 bucket that output products will be uploaded to --bucket-prefix BUCKET-PREFIX where BUCKET-PREFIX is a string appended to the key of any file uploaded to AWS S3 (this is effectively a subfolder in AWS S3) --username USER where USER is the username used to authenticate to EarthData Login --password PASSWORD where PASSWORD is the password used to authenticate to EarthData Login any necessary user input should be able to be provided through entrypoint arguments when uploading files to the S3 Bucket products files must be tagged with filetype: product if you wish to upload thumbnails or browse images, they must be tagged filetype: thumbnail or filetype: browse respectively Note: the aws subpackage of hyp3lib provides helper functions for tagging and uploading files","title":"Plugin requirements"},{"location":"plugins/#add-the-plugin-to-hyp3","text":"Once the plugin itself is created, it can be added to the HyP3 system by... TBD.","title":"Add the plugin to HyP3"},{"location":"products/","text":"Available HyP3 Products \u00b6 RTC \u00b6 SAR datasets inherently contain geometric and radiometric distortions due to terrain being imaged by a side-looking instrument. Radiometric terrain correction (RTC) removes these distortions and creates analysis-ready data suitable for use in GIS applications. RTC processing is a required first step for many amplitude-based SAR applications. Sentinel-1 RTC products are generated leveraging GAMMA Software. Products are distributed as UTM-projected GeoTIFFs with a pixel spacing of 30 meters. To learn more, visit the ASF Sentinel-1 RTC Product Guide . A Digital Elevation Model (DEM) is required for processing RTC. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, visit Digital Elevation Models . InSAR \u00b6 Interferometric SAR (InSAR) uses the phase differences from repeat passes over the same area to identify regions where the distance between the sensor and the Earth's surface has changed. This allows for the detection and quantification of deformation or movement. Use caution when generating interferograms for areas with extensive/dense vegetation cover. Because Sentinel-1 is a C-band sensor, the waves will not penetrate very deeply into vegetation. Imagery of densely vegetated areas likely represents the top of the canopy rather than the actual terrain. In addition, vegetated areas tend to have low coherence, because plants can grow or move from one acquisition to the next. A Digital Elevation Model (DEM) is required for processing InSAR. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, visit Digital Elevation Models . autoRIFT \u00b6 AutoRIFT produces a velocity map from observed motion using a feature tracking algorithm developed as part of the NASA MEaSUREs ITS_LIVE project. To learn more, visit the ITS_LIVE project website. A Digital Elevation Model (DEM) is required for autoRIFT processing. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, visit Digital Elevation Models . Product usage guidelines \u00b6 When using this data in a publication or presentation, we ask that you include the acknowledgement provided with each product. DOIs are also provided for citation when discussing the HyP3 software or plugins. For multi-file products, the acknowledgement and relevant DOIs are included in the *.README.md.txt file. For netCDF products, the acknowledgement is included in the source global attribute and the DOIs are included in the references global attribute.","title":"Products"},{"location":"products/#available-hyp3-products","text":"","title":"Available HyP3 Products"},{"location":"products/#rtc","text":"SAR datasets inherently contain geometric and radiometric distortions due to terrain being imaged by a side-looking instrument. Radiometric terrain correction (RTC) removes these distortions and creates analysis-ready data suitable for use in GIS applications. RTC processing is a required first step for many amplitude-based SAR applications. Sentinel-1 RTC products are generated leveraging GAMMA Software. Products are distributed as UTM-projected GeoTIFFs with a pixel spacing of 30 meters. To learn more, visit the ASF Sentinel-1 RTC Product Guide . A Digital Elevation Model (DEM) is required for processing RTC. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, visit Digital Elevation Models .","title":"RTC"},{"location":"products/#insar","text":"Interferometric SAR (InSAR) uses the phase differences from repeat passes over the same area to identify regions where the distance between the sensor and the Earth's surface has changed. This allows for the detection and quantification of deformation or movement. Use caution when generating interferograms for areas with extensive/dense vegetation cover. Because Sentinel-1 is a C-band sensor, the waves will not penetrate very deeply into vegetation. Imagery of densely vegetated areas likely represents the top of the canopy rather than the actual terrain. In addition, vegetated areas tend to have low coherence, because plants can grow or move from one acquisition to the next. A Digital Elevation Model (DEM) is required for processing InSAR. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, visit Digital Elevation Models .","title":"InSAR"},{"location":"products/#autorift","text":"AutoRIFT produces a velocity map from observed motion using a feature tracking algorithm developed as part of the NASA MEaSUREs ITS_LIVE project. To learn more, visit the ITS_LIVE project website. A Digital Elevation Model (DEM) is required for autoRIFT processing. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, visit Digital Elevation Models .","title":"autoRIFT"},{"location":"products/#product-usage-guidelines","text":"When using this data in a publication or presentation, we ask that you include the acknowledgement provided with each product. DOIs are also provided for citation when discussing the HyP3 software or plugins. For multi-file products, the acknowledgement and relevant DOIs are included in the *.README.md.txt file. For netCDF products, the acknowledgement is included in the source global attribute and the DOIs are included in the references global attribute.","title":"Product usage guidelines"},{"location":"guides/rtc_atbd/","text":"RTC Algorithm Theoretical Basis \u00b6","title":"RTC ATBD"},{"location":"guides/rtc_atbd/#rtc-algorithm-theoretical-basis","text":"","title":"RTC Algorithm Theoretical Basis"},{"location":"guides/rtc_product_guide/","text":"Sentinel-1 RTC Product Guide \u00b6 This document is a guide for users of Radiometrically Terrain Corrected (RTC) Sentinel-1 products generated by the Alaska Satellite Facility (ASF). Users can request RTC products On Demand in ASF's Vertex data portal, or make use of our Python SDK or API . SAR datasets inherently contain geometric and radiometric distortions due to terrain being imaged by a side-looking instrument. Radiometric terrain correction (RTC) corrects these distortions and creates analysis-ready data suitable for use in GIS applications or time-series analysis. RTC processing is a required first step for many amplitude-based SAR applications. ASF's Sentinel-1 On-Demand RTC products are generated using GAMMA Software . Products are distributed as GeoTIFFs (one for each available polarization) projected to the appropriate UTM Zone for the location of the scene. A Digital Elevation Model (DEM) is required for processing RTC. ASF uses the best publicly-available DEM with full coverage of the processing area. For a step-by-step tutorial on ordering On-Demand RTC Products using Vertex, visit our RTC On Demand story map , which also includes links to sample workflows using Sentinel-1 RTC products for GIS applications. Introduction \u00b6 Sentinel-1 Mission \u00b6 The Sentinel-1 mission collects C-band band SAR from a pair of polar-orbiting satellites launched by the European Space Agency (ESA) as part of the Copernicus program . The Sentinel-1A satellite was launched April 3, 2014, and the Sentinel-1B satellite was launched April 25, 2016. The two Sentinel-1 satellites each have a 12-day repeat cycle, but their orbits are offset 180 degrees so that one or the other will pass over the same location on earth every 6 days. Most areas of the earth will still only have imagery collected every 12 days, but Europe and select areas of interest are imaged with a 6-day interval, as described in the mission observation scenario . Because this is a polar-orbiting satellite constellation, areas near the poles may have a number of overlapping paths, resulting in even more frequent acquisitions with similar footprints. The relatively short interval between acquisitions makes this SAR dataset a very useful tool for monitoring rapid or sudden landscape changes. In addition, SAR can image the earth's surface through cloud or smoke cover and does not require sunlight, so valid imagery can be collected on every pass. This is particularly useful for monitoring conditions during natural disasters such as hurricanes or wildfires, or in areas that are prone to frequent cloud cover. SAR Distortions \u00b6 There are a number of distortions inherent to SAR data due to the side-looking nature of the sensor, and these impacts will be more prevalent in areas with rugged terrain. The process of radiometric terrain correction addresses the geometric distortions that lead to geolocation errors in terrain features, and also normalizes the backscatter values based on the actual area contributing returns. This process generates an image that aligns well with other geospatial data and is suitable for GIS applications or time-series analysis. The key distortions present in SAR images are foreshortening, layover and shadow (Figure 1). Figure 1: Distortions induced by side-looking SAR. Ground points a, b, c are \u2018seen\u2019 by radar as points a\u2019, b\u2019, c\u2019 in the slant range. Credit: Franz J. Meyer In the case of foreshortening , the backscatter from the front side of the mountain is compressed, with returns from a large area arriving back to the sensor at about the same time. This results in the front slope being displayed as a narrow, bright band. When layover occurs, returns from the front slope (and potentially even some of the area before the slope starts) are received at the same time as returns from the back slope. Thus, area in the front of the slope is projected onto the back side in the slant range image. In this case, the data from the front slope cannot be extracted from the returns. Another condition that results in missing data is radar shadow . In this case, the angle of the back slope is such that the sensor can not image it at all. These areas with steep back slopes offer no information to the SAR sensor. When RTC is performed, foreshortened areas are corrected based on the DEM. Areas impacted by layover or shadow, however, do not actually have data returns to correct. In this case, the pixels in the resulting RTC image will have a value of No Data. We do not interpolate missing data; users who would like to fill holes with estimated values will need to do so as appropriate for their particular application. The RTC product package includes a Layover-Shadow mask (see Image Files section ) If you find that there are No Data pixels in your image, you can refer to that reference raster to see if the missing pixels are due to layover or shadow effects. Digital Elevation Models \u00b6 The quality of the terrain corrections are directly related to the quality of the digital elevation models (DEMs) used in the process of geometrically and radiometrically correcting the SAR imagery. We use DEMs that are publicly available and have wide-ranging coverage. In the past, ASF maintained a collection of DEMs that were pre-processed as appropriate for SAR workflows, and applied a preference hierarchy so that the best available DEM in any given area would be automatically selected for processing. With the public release of the GLO-30 Copernicus DEM, we are changing our default DEM strategy to leverage a cloud-hosted copy of the global Copernicus DEM. Copernicus DEM GLO-30 Public Coming Soon We are in the process of adding the Copernicus DEM GLO-30 Public dataset as our default DEM for RTC processing. The legacy DEM is still the default for On-Demand RTC in Vertex and using the API , but Copernicus DEM is now the default when using the newest version of the SDK . It will soon be the default DEM for the API and Vertex as well. Stay tuned! Table 1 summarizes ASF's DEM sources. Note that in each case, the DEM is resampled to RTC spacing and reprojected to a UTM Zone (WGS84), and a geoid correction is applied before being used for RTC processing. Resolution DEM Vertical Datum Area Posting Priority Medium GLO-30 EGM2008 Global 1 arc second Default High NED13 NAVD88 CONUS, Hawaii, parts of Alaska 1/3 arc seconds 1 Medium SRTMGL1 EGM96 60 N to 57 S latitude 1 arc second 2 Medium NED1 NAVD88 Canada 1 arc second 3 Low NED2 NAVD88 Parts of Alaska 2 arc seconds 4 Table 1: DEMs used for RTC processing. Note that the Copernicus 30 m DEM is the default, while the other four DEMs are only used if the legacy option is invoked. When ordering On-Demand RTC products, you can choose to include a copy of the DEM used for RTC processing in the RTC product package. This DEM copy is converted to 16-bit signed integer format, but is otherwise the same as the DEM used in the RTC process. Note that the height values will differ from the original source DEM in all cases, due to the geoid correction applied to prepare the DEM for use in RTC processing. Copernicus DEM : Coming Soon \u00b6 The GLO-30 Copernicus DEM provides global coverage (with the current exception of an area covering Armenia and Azerbaijan, see Figure 3) at 30-m pixel spacing. When an RTC job is requested, we download the required DEM tiles from the Copernicus Digital Elevation Model (DEM) GLO-30 Public dataset available in the Registry of Open Data on AWS , managed by Sinergise . We mosaic the tiles and reproject them to the appropriate UTM Zone for the location of the SAR granule to be processed, resampling them to match the pixel spacing and alignment of the RTC product. A geoid correction is applied before it is used for RTC processing. Figure 2 shows the coverage of the Copernicus DEM GLO-30 Public dataset, and figure 3 details the land area currently not covered. Figure 2: Copernicus DEM GLO-30 coverage map Figure 3: Detail of area currently not covered by Copernicus DEM GLO-30 Legacy DEMs \u00b6 The legacy DEMs were pre-processed by ASF to a consistent raster format (GeoTIFF) from the original source formats: height (*.hgt), ESRI ArcGrid (*.adf), etc. Many of the NASA-provided DEMs were provided as orthometric heights with EGM96 vertical datum. These were converted by ASF to ellipsoid heights using the ASF MapReady tool named geoid_adjust . The pixel reference varied from the center (pixel as point) to a corner (pixel as area). The GAMMA software, used to generate the terrain corrected products, uses pixel as area and adjusts DEM coordinates as needed. These processed DEM collections are stored by ASF in AWS. When an RTC job is requested, the best-available DEM covering the SAR granule is selected, and the necessary tiles are reprojected to a mosaic in the UTM Zone appropriate for the granule location. If legacy DEM processing is selected, one of the following DEMs will be used: The National Elevation Dataset (NED) \u2153 arc second (about 10 m resolution) DEM covers the continental U.S. (CONUS), Hawaii, and parts of Alaska. Shuttle Radar Topography Mission (SRTM) GL1 data at 30 m resolution is used where NED 13 is not available. 1 arc second NED gives coverage of Canada at about 30 m resolution. 2 arc second NED (about 60 m) covers the remaining parts of Alaska above 60 degrees northern latitude. Since more than one DEM may be available in legacy processing, DEMs are selected in priority order as listed in Table 1. DEM coverage of at least 20% from a single DEM source is required for legacy processing to proceed. In no case will the DEM selected be from more than one source; only the single best source of terrain height values is used for a given scene. Figure 4 shows the coverage of the various legacy DEM sources. Figure 4: Coverage of the various legacy DEM sources used for terrain correction Radiometric Terrain Correction Workflow \u00b6 Pre-processing \u00b6 The first step of pre-processing is the selection of the best DEM for the terrain correction. The DEM tiles are assembled to ensure sufficient coverage for the terrain correction of the Sentinel-1 granule. The application of the calibration parameters and multi-looking are the only pre-processing steps applied to the SAR image. Terrain Correction \u00b6 The terrain correction is performed in slant range geometry. A mapping function is created, mapping from DEM space into SAR space. The actual mapping of the initial image into projected space is only applied once to mitigate the propagation of any resampling errors. All intermediate steps only update the look-up table used for the mapping. By default, images are not coregistered to the DEM. While RTC results can be improved by matching imagery to a high-quality DEM, different acquisitions over the same area may not always be matched to the DEM in the same way, due in part to the presence of speckle. This can introduce spatial inconsistencies to the dataset, especially when viewing a time-series of RTC images. For consistency, we use the geolocation from the Sentinel-1 state vectors rather than matching the geolocation based on DEM features. When custom-ordering imagery, however, the DEM Matching option is available for selection. In this case, the first step is the co-registration of the SAR image with a simulated SAR image derived from the DEM. An initial offset is first attempted as a single match; if it fails, a larger number of image chips are used to determine an average offset in azimuth and range direction. This initial offset is then refined using strict matching criteria. Matching may fail for three different reasons: (1) no match can be found, (2) the magnitude of the residual offset errors is greater than 2 pixels, or (3) the maximum calculated offset is greater than 50m. In any of these cases, the dead reckoning approach is taken when matching fails. This approach solely relies on the geolocations calculated from state vectors (the same approach used when DEM matching is not selected as an option) - no geolocation refinement is applied. Radiometric Correction \u00b6 During processing, a surface scattering area image for the scene is calculated and saved. This projected area image is used to create the RTC product - the SAR image is multiplied by the ratio of an ellipsoidal scattering image (used during calibration) and this scattering area image. Note that this image is always projected to gamma-nought (\u03b3 0 ). Geocoding \u00b6 In a final step, the RTC product is geocoded into map-projected space. Thus, radiometric terrain correction results in a geocoded radiometrically calibrated multi-looked image with gamma-nought (\u03b3 0 ) power scale values by default, though there are options to process to sigma-nought (\u03c3 0 ) radiometry and amplitude scale. Post-Processing \u00b6 After the terrain correction is completed, the RTC products are exported to GeoTIFF format. If the scene being processed is dual polarization, users have the option to add a full-resolution RGB Decomposition GeoTIFF to the RTC product package. Side products including the DEM, layover shadow map, scattering area map, and incidence angle map are converted into GeoTIFF format. In addition, a README text file, browse images, item-specific ArcGIS-compatible XML metadata files, a log file, and a shapefile indicating the data extent are generated for the product. Product Packaging \u00b6 Naming Convention \u00b6 The naming convention for the RTC products follows this pattern for its base names: S1x_yy_aaaaaaaaTbbbbbb_ppo_RTCzz_u_defklm_ssss Example: S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A Element Definition Example x Mission: A or B A yy Beam Mode IW aaaaaaaa Start Year-Month-Day 20180128 bbbbbb Start Hour-Minute-Second 161201 pp Polarization: Dual-pol (D) vs. Single-pol (S), Primary Polarization (H or V) DV o Orbit Type: Precise (P), Restituted (R), or Original Predicted (O) P zz Terrain Correction Pixel Spacing (m) 30 u Software Package Used: GAMMA (G) G d Gamma-0 (g) or Sigma-0 (s) Output g e Power (p) or Amplitude (a) Output p f Unmasked (u) or Water Masked (w) u k Not Filtered (n) or Filtered (f) n l Entire Area (e) or Clipped Area (c) e m Dead Reckoning (d) or DEM Matching (m) d ssss Product ID FD6A Table 2: Naming convention for RTC products Default Settings \u00b6 The default settings for RTC products are as follows: Setting Default Radiometry Gamma-0 (g) Scale Power (p) Water Mask No water mask applied (u) Speckle Filter Not filtered (n) Clipping Entire extent of input granule (e) DEM Matching No matching; dead reckoning is used (d) Table 3: Default settings for RTC products Image Files \u00b6 All files are stored in a folder named using the above convention, and the base name for each file matches the folder name. Multiple types of image files are present in this folder, and some of the files are optional. Users can choose to exclude the RGB Decomposition GeoTIFF, scattering area map, DEM, and incidence angle map rasters when ordering On-Demand RTC products. Extension Description Example _VV.tif, _VH.tif, _HH.tif, _HV.tif Terrain corrected product stored in separate files for each available polarization in GeoTIFF format S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_VV.tif .png Greyscale browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.png _rgb.png Color browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.png .kmz Zipped Google Earth image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.kmz _rgb.kmz Zipped Google Earth color image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.kmz _rgb.tif Color decomposition in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.tif _area.tif Scattering area map in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_area.tif _dem.tif DEM used for terrain correction in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_dem.tif _inc_map.tif Incidence angle file in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_inc_map.tif _ls_map.tif Layover/shadow mask in GeoTIFF format S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_ls_map.tif Table 4: Image files in product package The RTC products (one for each available polarization) are generated as 32-bit floating-point single-band GeoTIFF files, as are the incidence angle and scattering area maps. The RGB Decomposition is a 3-band unsigned 8-bit GeoTIFF file, the layover/shadow mask is a single-band unsigned 8-bit GeoTIFF, and the DEM is a 16-bit unsigned integer GeoTIFF. The browse images (both grayscale and color) are generated in PNG format, and are each 2048 pixels wide. Finally, KMZ files suitable for viewing in Google Earth are included. Note that colorized products (RGB Decomposition GeoTIFF or color browse PNG) can only be created for dual-polarization (SDV and SDH) granules, not for single-polarization (SSV or SSH). Metadata Files \u00b6 Along with each of the image files, there will be one or more metadata files. Extension Description Example .README.md.txt README file S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.README.md.txt .log Log file of the processing steps S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.log .tif.xml ArcGIS compliant XML metadata S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_VV.tif.xml _rgb.tif.xml ArcGIS compliant XML metadata S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_VV_rgb.tif.xml .png.xml ArcGIS compliant XML metadata S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.png.xml _rgb.png.xml ArcGIS compliant XML metadata S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.png.xml .png.aux.xml Geolocation metadata for greyscale PNG browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.png.aux.xml _rgb.png.aux.xml Geolocation metadata for color PNG browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.png.aux.xml Table 5: Metadata files and their extensions README File \u00b6 The text file with extension .README.md.txt explains the files included in the folder, and is customized to reflect that particular product. Users unfamiliar with RTC products should start by reading this README file, which will give some background on each of the files included in the product folder. ArcGIS-Compatible XML Files \u00b6 There is an ArcGIS-compatible xml file for each raster in the product folder. When ArcGIS Desktop users view any of the rasters in ArcCatalog or the Catalog window in ArcMap, they can open the Item Description to view the contents of the associated xml file. ArcGIS Pro users can access the information from the Metadata tab. These files will not appear as separate items in ArcCatalog, though if you use Windows Explorer to look at the contents of the folder you will see them listed individually. Because each one is named identically to the product it describes (with the addition of the .xml extension), ArcGIS recognizes the appropriate file as the raster\u2019s associated metadata, and integrates the metadata accordingly. ArcGIS users should take care not to change these xml files outside of the ArcGIS environment; changing the filename or content directly may render the files unreadable by ArcGIS. Those not using ArcGIS will still find the contents of these xml files useful, but will have to contend with the xml tagging when viewing the files as text or in a browser. Auxiliary Geolocation Files \u00b6 Geolocation XML files (aux files) are included for each of the PNG browse images to allow for proper display in GIS platforms. Log File \u00b6 A log file detailing the processing parameters and outputs is also included for reference. Shapefile \u00b6 A shapefile indicating the extent of the RTC data coverage is included in the package. Extension Description Example _shape.dbf _shape.prj _shape.shp _shape.shx Shapefile (.shp) and supporting files S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_shape.shp Table 6: Shapefile files and their extensions SAR Scales \u00b6 Power Scale \u00b6 Note that the default output of Sentinel-1 RTC products from HyP3 is in power scale. The values in this scale are generally very close to zero, so the dynamic range of the RTC image can be easily skewed by a few bright scatterers in the image. Power scale is appropriate for statistical analysis of the RTC dataset, but may not always be the best option for data visualization. When viewing an RTC image in power scale in a GIS environment, it may appear mostly or all black, and you may need to adjust the stretch to see features in the image. Often applying a stretch of 2 standard deviations, or setting the Min-Max stretch values to 0 and 0.3, will greatly improve the appearance of the image. You can adjust the stretch as desired to display your image to full advantage. Be aware that this does not change the actual pixel values. In some cases, it may be desirable to convert the actual pixel values to a different scale. Two other scales commonly used for SAR data are amplitude and dB. Amplitude Scale \u00b6 Amplitude scale is the square root of the power scale values. This brightens the darker pixels and darkens the brighter pixels, narrowing the dynamic range of the image. In many cases, amplitude scale presents a pleasing grayscale display of RTC images. Amplitude scale works well for calculating log difference ratios (see Change Detection Using RTC Data ). dB Scale \u00b6 The dB scale is calculated by multiplying 10 times the Log10 of the power scale values. This scale brightens the pixels, allowing for better differentiation among very dark pixels. When identifying water on the landscape, this is often a good scale to use; the water pixels generally remain very dark, while the terrestrial pixels are even brighter (see Identifying Surface Water ). This scale is not always the best choice for general visualization of RTC products, as it can give a washed-out appearance, and because it is in a log scale, it is not appropriate for all types of statistical analyses. RTC Use Examples \u00b6 The RTC products are presented as Cloud-Optimized GeoTIFFs (COGs), a user-friendly format that is GIS compatible. The products include pre-generated overviews, so users will not need to generate pyramids to display the images efficiently in a GIS environment. The following sections present examples of how one might use RTC datasets to identify areas of change and integrate RTC datasets into other datasets for enhanced results. We also present a bibliography of some of the scientific literature making use of Sentinel-1 RTC datasets. Change Detection Using RTC Data \u00b6 There are a number of ways that SAR data sets can be used to identify areas of change. Here are two examples of what you can do in a GIS environment. Seasonal Change \u00b6 Stacking RTC images into a multiband image (Figure 5) allows the user to display different times of year at the same time, using the color bands to highlight areas that differ in radar backscatter values from one month to the next. To generate this type of image, choose three images that capture different seasons or months of interest. These can either be individual RTC images from different times of the year, or rasters displaying the monthly median calculated from multiple RTC images collected in the same month. Combine the three images into a multiband raster and assign each to a different color band. The resulting RGB image highlights areas where there are distinctive differences among the three source image values. Figure 5: Monthly median VH gamma-0 power values for May, July and September, displayed as a multiband RGB (May, July, Sept) image. Contains modified Copernicus Sentinel data 2017, processed by ESA. Quantifying Change over Time \u00b6 A simple and informative approach to change detection is the calculation of the log difference between two RTC datasets from different dates. By calculating Log10(date2/date1) and applying a classified symbology, it is easy to identify areas where change occurred, as well as the direction of the change. Negative values indicate a decrease in radar backscatter over time, while positive values indicate an increase in backscatter. In the example below (Figure 6), RTC images from before and after heavy rains caused a dam breach. The area where the reservoir was located displays a significant increase in backscatter (symbolized in red). This positive change is driven by land that was once covered by standing water, which generally has very low backscatter, now being exposed saturated soil, which generally returns very high backscatter values. In surrounding areas, decreases in radar backscatter (symbolized by blue), are possibly the result of agricultural fields undergoing desiccation/hardening of the surface soil following the heavy rainfall and standing water. Areas with little change in backscatter are displayed in yellow. Figure 6: Log Difference Raster with Classified Symbology. Contains modified Copernicus Sentinel data 2020, processed by ESA. Identifying Surface Water \u00b6 Calm surface water has a very low radar cross section. Most of the signal is reflected off the smooth surface, due to the high dielectric constant of freshwater, so little to none of the signal is returned as backscatter. Because of this, it is often easy to delineate surface water using a simple threshold value, where all pixels below the threshold are assumed to be water. You can easily visualize the water extent using various thresholds by applying a classified symbology with two classes. It is often best to use dB scale datasets for identifying surface water. In many cases, there will be a bimodal distribution of values in an RTC image containing surface water, with the first peak comprised mostly of water values, and the second peak containing all the remaining values. A good first step is to select a break point between those two peaks, then adjust the value as needed to generate a good water mask (Figure 7). Figure 7: Setting the break point to fall between the two peaks of the histogram Once you have determined the appropriate threshold (Figure 8), you can reclassify the RTC image to include only those pixels that fall below the threshold value, providing a water mask that can be used for analysis or to overlay with other imagery to show the water extent. Figure 8: Water Mask. Contains modified Copernicus Sentinel data 2020, processed by ESA. Combination of RTC Image with other Remote Sensing Data \u00b6 One of the main advantages of using RTC imagery with its all weather and day/night capabilities is the combination with other remote sensing data such as optical data. In the example below, the backscatter information of the Sentinel-1 SAR image (Figure 9) is used to enhance the spectral information of the optical Landsat 8 image (Figure 10) in the urban area of Pavia, Italy. Figure 11 shows the image fusion result of an IHS transformation. In this transformation the color channels red, green and blue (RGB) are first converted into a different color representation: intensity, hue and saturation (IHS). In the second step the optical intensity is replaced by the SAR image, before IHS is transformed back to RGB. Figure 9: Sentinel-1 RTC image. Figure 10: False color composite (bands 5, 4, 3) of a Landsat 8 image The color values for the two rivers in the SAR image are far more similar to each other than in the optical image. The vegetated areas (highlighted in red) show up more uniformly in the data fusion result than in the optical false color composite image. Image fusion uses the complementary nature of the different sources to generate an enhanced product. Figure 11: Image fusion result of SAR and optical imagery ArcGIS Toolbox \u00b6 ASF has developed a custom ArcGIS Toolbox for working with RTC datasets in either ArcGIS Desktop or ArcGIS Pro. It includes tools for converting between different SAR scales, calculating the log difference between two images, generating RGB Decomposition (false-color) products, and reclassifying a raster to generate a water mask. For more information and to download the toolbox, visit our website: https://asf.alaska.edu/how-to/data-tools/gis-tools/ . Application Examples in the Literature \u00b6 The following journal articles represent some of the work being done using Radiometric Terrain Corrected Sentinel-1 data sets. Crop Monitoring \u00b6 Clauss, K., Ottinger M. and Kuenzer, C. 2018. Mapping rice areas with Sentinel-1 time series and superpixel segmentation. International Journal of Remote Sensing , 39 (5):1399-1420. DOI: 10.1080/01431161.2017.1404162 Nguyen, D.B., Gruber A. and Wagner, W. 2016. Mapping rice extent and cropping scheme in the Mekong Delta using Sentinel-1A data. Remote Sensing Letters , 7 (12):1209-1218. DOI: 10.1080/2150704X.2016.1225172 Disaster Response \u00b6 Markert, K.N., Chishtie, F., Anderson, E.R., Saah, D., Griffin, R.E. 2018. On the merging of optical and SAR satellite imagery for surface water mapping applications. Results In Physics , 9 :275-277. DOI: 10.1016/j.rinp.2018.02.054 Twele, A., Cao, W., Plank, S. and Martinis, S. 2016. Sentinel-1-based flood mapping: a fully automated processing chain. International Journal of Remote Sensing , 37 (13):2990-3004. DOI: 10.1080/01431161.2016.1192304 Land Classification and Change Detection \u00b6 Muro, J., Canty, M., Conradsen, K., H\u00fcttich, C., Nielsen, A.A., Skriver, H., Remy, F., Strauch, A., Thonfeld, F. and Menz, G. 2016. Short-Term change detection in wetlands using Sentinel-1 time series. Remote Sensing , 8 (10):795. DOI: 10.3390/rs8100795 R\u00fcetschi, M., Schaepman, M.E., Small, D. 2018. Using Multitemporal Sentinel-1 C-band backscatter to monitor phenology and classify deciduous and coniferous forests in Northern Switzerland. Remote Sensing , 10 (1):55. DOI: 10.3390/rs10010055 Data Access \u00b6 To view or download Sentinel-1 RTC products, please see the links below: Vertex: https://search.asf.alaska.edu/ API: https://asf.alaska.edu/api/ For details on accessing data, including other SAR datasets, see ASF\u2019s Get Started guide: https://asf.alaska.edu/how-to/get-started/ To access data recipes, which are step-by-step tutorials for processing and working with SAR data, see ASF\u2019s tutorials page: https://asf.alaska.edu/how-to/data-recipes/data-recipe-tutorials/","title":"RTC Product Guide"},{"location":"guides/rtc_product_guide/#sentinel-1-rtc-product-guide","text":"This document is a guide for users of Radiometrically Terrain Corrected (RTC) Sentinel-1 products generated by the Alaska Satellite Facility (ASF). Users can request RTC products On Demand in ASF's Vertex data portal, or make use of our Python SDK or API . SAR datasets inherently contain geometric and radiometric distortions due to terrain being imaged by a side-looking instrument. Radiometric terrain correction (RTC) corrects these distortions and creates analysis-ready data suitable for use in GIS applications or time-series analysis. RTC processing is a required first step for many amplitude-based SAR applications. ASF's Sentinel-1 On-Demand RTC products are generated using GAMMA Software . Products are distributed as GeoTIFFs (one for each available polarization) projected to the appropriate UTM Zone for the location of the scene. A Digital Elevation Model (DEM) is required for processing RTC. ASF uses the best publicly-available DEM with full coverage of the processing area. For a step-by-step tutorial on ordering On-Demand RTC Products using Vertex, visit our RTC On Demand story map , which also includes links to sample workflows using Sentinel-1 RTC products for GIS applications.","title":"Sentinel-1 RTC Product Guide"},{"location":"guides/rtc_product_guide/#introduction","text":"","title":"Introduction"},{"location":"guides/rtc_product_guide/#sentinel-1-mission","text":"The Sentinel-1 mission collects C-band band SAR from a pair of polar-orbiting satellites launched by the European Space Agency (ESA) as part of the Copernicus program . The Sentinel-1A satellite was launched April 3, 2014, and the Sentinel-1B satellite was launched April 25, 2016. The two Sentinel-1 satellites each have a 12-day repeat cycle, but their orbits are offset 180 degrees so that one or the other will pass over the same location on earth every 6 days. Most areas of the earth will still only have imagery collected every 12 days, but Europe and select areas of interest are imaged with a 6-day interval, as described in the mission observation scenario . Because this is a polar-orbiting satellite constellation, areas near the poles may have a number of overlapping paths, resulting in even more frequent acquisitions with similar footprints. The relatively short interval between acquisitions makes this SAR dataset a very useful tool for monitoring rapid or sudden landscape changes. In addition, SAR can image the earth's surface through cloud or smoke cover and does not require sunlight, so valid imagery can be collected on every pass. This is particularly useful for monitoring conditions during natural disasters such as hurricanes or wildfires, or in areas that are prone to frequent cloud cover.","title":"Sentinel-1 Mission"},{"location":"guides/rtc_product_guide/#sar-distortions","text":"There are a number of distortions inherent to SAR data due to the side-looking nature of the sensor, and these impacts will be more prevalent in areas with rugged terrain. The process of radiometric terrain correction addresses the geometric distortions that lead to geolocation errors in terrain features, and also normalizes the backscatter values based on the actual area contributing returns. This process generates an image that aligns well with other geospatial data and is suitable for GIS applications or time-series analysis. The key distortions present in SAR images are foreshortening, layover and shadow (Figure 1). Figure 1: Distortions induced by side-looking SAR. Ground points a, b, c are \u2018seen\u2019 by radar as points a\u2019, b\u2019, c\u2019 in the slant range. Credit: Franz J. Meyer In the case of foreshortening , the backscatter from the front side of the mountain is compressed, with returns from a large area arriving back to the sensor at about the same time. This results in the front slope being displayed as a narrow, bright band. When layover occurs, returns from the front slope (and potentially even some of the area before the slope starts) are received at the same time as returns from the back slope. Thus, area in the front of the slope is projected onto the back side in the slant range image. In this case, the data from the front slope cannot be extracted from the returns. Another condition that results in missing data is radar shadow . In this case, the angle of the back slope is such that the sensor can not image it at all. These areas with steep back slopes offer no information to the SAR sensor. When RTC is performed, foreshortened areas are corrected based on the DEM. Areas impacted by layover or shadow, however, do not actually have data returns to correct. In this case, the pixels in the resulting RTC image will have a value of No Data. We do not interpolate missing data; users who would like to fill holes with estimated values will need to do so as appropriate for their particular application. The RTC product package includes a Layover-Shadow mask (see Image Files section ) If you find that there are No Data pixels in your image, you can refer to that reference raster to see if the missing pixels are due to layover or shadow effects.","title":"SAR Distortions"},{"location":"guides/rtc_product_guide/#digital-elevation-models","text":"The quality of the terrain corrections are directly related to the quality of the digital elevation models (DEMs) used in the process of geometrically and radiometrically correcting the SAR imagery. We use DEMs that are publicly available and have wide-ranging coverage. In the past, ASF maintained a collection of DEMs that were pre-processed as appropriate for SAR workflows, and applied a preference hierarchy so that the best available DEM in any given area would be automatically selected for processing. With the public release of the GLO-30 Copernicus DEM, we are changing our default DEM strategy to leverage a cloud-hosted copy of the global Copernicus DEM. Copernicus DEM GLO-30 Public Coming Soon We are in the process of adding the Copernicus DEM GLO-30 Public dataset as our default DEM for RTC processing. The legacy DEM is still the default for On-Demand RTC in Vertex and using the API , but Copernicus DEM is now the default when using the newest version of the SDK . It will soon be the default DEM for the API and Vertex as well. Stay tuned! Table 1 summarizes ASF's DEM sources. Note that in each case, the DEM is resampled to RTC spacing and reprojected to a UTM Zone (WGS84), and a geoid correction is applied before being used for RTC processing. Resolution DEM Vertical Datum Area Posting Priority Medium GLO-30 EGM2008 Global 1 arc second Default High NED13 NAVD88 CONUS, Hawaii, parts of Alaska 1/3 arc seconds 1 Medium SRTMGL1 EGM96 60 N to 57 S latitude 1 arc second 2 Medium NED1 NAVD88 Canada 1 arc second 3 Low NED2 NAVD88 Parts of Alaska 2 arc seconds 4 Table 1: DEMs used for RTC processing. Note that the Copernicus 30 m DEM is the default, while the other four DEMs are only used if the legacy option is invoked. When ordering On-Demand RTC products, you can choose to include a copy of the DEM used for RTC processing in the RTC product package. This DEM copy is converted to 16-bit signed integer format, but is otherwise the same as the DEM used in the RTC process. Note that the height values will differ from the original source DEM in all cases, due to the geoid correction applied to prepare the DEM for use in RTC processing.","title":"Digital Elevation Models"},{"location":"guides/rtc_product_guide/#copernicus-dem-coming-soon","text":"The GLO-30 Copernicus DEM provides global coverage (with the current exception of an area covering Armenia and Azerbaijan, see Figure 3) at 30-m pixel spacing. When an RTC job is requested, we download the required DEM tiles from the Copernicus Digital Elevation Model (DEM) GLO-30 Public dataset available in the Registry of Open Data on AWS , managed by Sinergise . We mosaic the tiles and reproject them to the appropriate UTM Zone for the location of the SAR granule to be processed, resampling them to match the pixel spacing and alignment of the RTC product. A geoid correction is applied before it is used for RTC processing. Figure 2 shows the coverage of the Copernicus DEM GLO-30 Public dataset, and figure 3 details the land area currently not covered. Figure 2: Copernicus DEM GLO-30 coverage map Figure 3: Detail of area currently not covered by Copernicus DEM GLO-30","title":"Copernicus DEM : Coming Soon"},{"location":"guides/rtc_product_guide/#legacy-dems","text":"The legacy DEMs were pre-processed by ASF to a consistent raster format (GeoTIFF) from the original source formats: height (*.hgt), ESRI ArcGrid (*.adf), etc. Many of the NASA-provided DEMs were provided as orthometric heights with EGM96 vertical datum. These were converted by ASF to ellipsoid heights using the ASF MapReady tool named geoid_adjust . The pixel reference varied from the center (pixel as point) to a corner (pixel as area). The GAMMA software, used to generate the terrain corrected products, uses pixel as area and adjusts DEM coordinates as needed. These processed DEM collections are stored by ASF in AWS. When an RTC job is requested, the best-available DEM covering the SAR granule is selected, and the necessary tiles are reprojected to a mosaic in the UTM Zone appropriate for the granule location. If legacy DEM processing is selected, one of the following DEMs will be used: The National Elevation Dataset (NED) \u2153 arc second (about 10 m resolution) DEM covers the continental U.S. (CONUS), Hawaii, and parts of Alaska. Shuttle Radar Topography Mission (SRTM) GL1 data at 30 m resolution is used where NED 13 is not available. 1 arc second NED gives coverage of Canada at about 30 m resolution. 2 arc second NED (about 60 m) covers the remaining parts of Alaska above 60 degrees northern latitude. Since more than one DEM may be available in legacy processing, DEMs are selected in priority order as listed in Table 1. DEM coverage of at least 20% from a single DEM source is required for legacy processing to proceed. In no case will the DEM selected be from more than one source; only the single best source of terrain height values is used for a given scene. Figure 4 shows the coverage of the various legacy DEM sources. Figure 4: Coverage of the various legacy DEM sources used for terrain correction","title":"Legacy DEMs"},{"location":"guides/rtc_product_guide/#radiometric-terrain-correction-workflow","text":"","title":"Radiometric Terrain Correction Workflow"},{"location":"guides/rtc_product_guide/#pre-processing","text":"The first step of pre-processing is the selection of the best DEM for the terrain correction. The DEM tiles are assembled to ensure sufficient coverage for the terrain correction of the Sentinel-1 granule. The application of the calibration parameters and multi-looking are the only pre-processing steps applied to the SAR image.","title":"Pre-processing"},{"location":"guides/rtc_product_guide/#terrain-correction","text":"The terrain correction is performed in slant range geometry. A mapping function is created, mapping from DEM space into SAR space. The actual mapping of the initial image into projected space is only applied once to mitigate the propagation of any resampling errors. All intermediate steps only update the look-up table used for the mapping. By default, images are not coregistered to the DEM. While RTC results can be improved by matching imagery to a high-quality DEM, different acquisitions over the same area may not always be matched to the DEM in the same way, due in part to the presence of speckle. This can introduce spatial inconsistencies to the dataset, especially when viewing a time-series of RTC images. For consistency, we use the geolocation from the Sentinel-1 state vectors rather than matching the geolocation based on DEM features. When custom-ordering imagery, however, the DEM Matching option is available for selection. In this case, the first step is the co-registration of the SAR image with a simulated SAR image derived from the DEM. An initial offset is first attempted as a single match; if it fails, a larger number of image chips are used to determine an average offset in azimuth and range direction. This initial offset is then refined using strict matching criteria. Matching may fail for three different reasons: (1) no match can be found, (2) the magnitude of the residual offset errors is greater than 2 pixels, or (3) the maximum calculated offset is greater than 50m. In any of these cases, the dead reckoning approach is taken when matching fails. This approach solely relies on the geolocations calculated from state vectors (the same approach used when DEM matching is not selected as an option) - no geolocation refinement is applied.","title":"Terrain Correction"},{"location":"guides/rtc_product_guide/#radiometric-correction","text":"During processing, a surface scattering area image for the scene is calculated and saved. This projected area image is used to create the RTC product - the SAR image is multiplied by the ratio of an ellipsoidal scattering image (used during calibration) and this scattering area image. Note that this image is always projected to gamma-nought (\u03b3 0 ).","title":"Radiometric Correction"},{"location":"guides/rtc_product_guide/#geocoding","text":"In a final step, the RTC product is geocoded into map-projected space. Thus, radiometric terrain correction results in a geocoded radiometrically calibrated multi-looked image with gamma-nought (\u03b3 0 ) power scale values by default, though there are options to process to sigma-nought (\u03c3 0 ) radiometry and amplitude scale.","title":"Geocoding"},{"location":"guides/rtc_product_guide/#post-processing","text":"After the terrain correction is completed, the RTC products are exported to GeoTIFF format. If the scene being processed is dual polarization, users have the option to add a full-resolution RGB Decomposition GeoTIFF to the RTC product package. Side products including the DEM, layover shadow map, scattering area map, and incidence angle map are converted into GeoTIFF format. In addition, a README text file, browse images, item-specific ArcGIS-compatible XML metadata files, a log file, and a shapefile indicating the data extent are generated for the product.","title":"Post-Processing"},{"location":"guides/rtc_product_guide/#product-packaging","text":"","title":"Product Packaging"},{"location":"guides/rtc_product_guide/#naming-convention","text":"The naming convention for the RTC products follows this pattern for its base names: S1x_yy_aaaaaaaaTbbbbbb_ppo_RTCzz_u_defklm_ssss Example: S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A Element Definition Example x Mission: A or B A yy Beam Mode IW aaaaaaaa Start Year-Month-Day 20180128 bbbbbb Start Hour-Minute-Second 161201 pp Polarization: Dual-pol (D) vs. Single-pol (S), Primary Polarization (H or V) DV o Orbit Type: Precise (P), Restituted (R), or Original Predicted (O) P zz Terrain Correction Pixel Spacing (m) 30 u Software Package Used: GAMMA (G) G d Gamma-0 (g) or Sigma-0 (s) Output g e Power (p) or Amplitude (a) Output p f Unmasked (u) or Water Masked (w) u k Not Filtered (n) or Filtered (f) n l Entire Area (e) or Clipped Area (c) e m Dead Reckoning (d) or DEM Matching (m) d ssss Product ID FD6A Table 2: Naming convention for RTC products","title":"Naming Convention"},{"location":"guides/rtc_product_guide/#default-settings","text":"The default settings for RTC products are as follows: Setting Default Radiometry Gamma-0 (g) Scale Power (p) Water Mask No water mask applied (u) Speckle Filter Not filtered (n) Clipping Entire extent of input granule (e) DEM Matching No matching; dead reckoning is used (d) Table 3: Default settings for RTC products","title":"Default Settings"},{"location":"guides/rtc_product_guide/#image-files","text":"All files are stored in a folder named using the above convention, and the base name for each file matches the folder name. Multiple types of image files are present in this folder, and some of the files are optional. Users can choose to exclude the RGB Decomposition GeoTIFF, scattering area map, DEM, and incidence angle map rasters when ordering On-Demand RTC products. Extension Description Example _VV.tif, _VH.tif, _HH.tif, _HV.tif Terrain corrected product stored in separate files for each available polarization in GeoTIFF format S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_VV.tif .png Greyscale browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.png _rgb.png Color browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.png .kmz Zipped Google Earth image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.kmz _rgb.kmz Zipped Google Earth color image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.kmz _rgb.tif Color decomposition in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.tif _area.tif Scattering area map in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_area.tif _dem.tif DEM used for terrain correction in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_dem.tif _inc_map.tif Incidence angle file in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_inc_map.tif _ls_map.tif Layover/shadow mask in GeoTIFF format S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_ls_map.tif Table 4: Image files in product package The RTC products (one for each available polarization) are generated as 32-bit floating-point single-band GeoTIFF files, as are the incidence angle and scattering area maps. The RGB Decomposition is a 3-band unsigned 8-bit GeoTIFF file, the layover/shadow mask is a single-band unsigned 8-bit GeoTIFF, and the DEM is a 16-bit unsigned integer GeoTIFF. The browse images (both grayscale and color) are generated in PNG format, and are each 2048 pixels wide. Finally, KMZ files suitable for viewing in Google Earth are included. Note that colorized products (RGB Decomposition GeoTIFF or color browse PNG) can only be created for dual-polarization (SDV and SDH) granules, not for single-polarization (SSV or SSH).","title":"Image Files"},{"location":"guides/rtc_product_guide/#metadata-files","text":"Along with each of the image files, there will be one or more metadata files. Extension Description Example .README.md.txt README file S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.README.md.txt .log Log file of the processing steps S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.log .tif.xml ArcGIS compliant XML metadata S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_VV.tif.xml _rgb.tif.xml ArcGIS compliant XML metadata S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_VV_rgb.tif.xml .png.xml ArcGIS compliant XML metadata S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.png.xml _rgb.png.xml ArcGIS compliant XML metadata S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.png.xml .png.aux.xml Geolocation metadata for greyscale PNG browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.png.aux.xml _rgb.png.aux.xml Geolocation metadata for color PNG browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.png.aux.xml Table 5: Metadata files and their extensions","title":"Metadata Files"},{"location":"guides/rtc_product_guide/#shapefile","text":"A shapefile indicating the extent of the RTC data coverage is included in the package. Extension Description Example _shape.dbf _shape.prj _shape.shp _shape.shx Shapefile (.shp) and supporting files S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_shape.shp Table 6: Shapefile files and their extensions","title":"Shapefile"},{"location":"guides/rtc_product_guide/#sar-scales","text":"","title":"SAR Scales"},{"location":"guides/rtc_product_guide/#power-scale","text":"Note that the default output of Sentinel-1 RTC products from HyP3 is in power scale. The values in this scale are generally very close to zero, so the dynamic range of the RTC image can be easily skewed by a few bright scatterers in the image. Power scale is appropriate for statistical analysis of the RTC dataset, but may not always be the best option for data visualization. When viewing an RTC image in power scale in a GIS environment, it may appear mostly or all black, and you may need to adjust the stretch to see features in the image. Often applying a stretch of 2 standard deviations, or setting the Min-Max stretch values to 0 and 0.3, will greatly improve the appearance of the image. You can adjust the stretch as desired to display your image to full advantage. Be aware that this does not change the actual pixel values. In some cases, it may be desirable to convert the actual pixel values to a different scale. Two other scales commonly used for SAR data are amplitude and dB.","title":"Power Scale"},{"location":"guides/rtc_product_guide/#amplitude-scale","text":"Amplitude scale is the square root of the power scale values. This brightens the darker pixels and darkens the brighter pixels, narrowing the dynamic range of the image. In many cases, amplitude scale presents a pleasing grayscale display of RTC images. Amplitude scale works well for calculating log difference ratios (see Change Detection Using RTC Data ).","title":"Amplitude Scale"},{"location":"guides/rtc_product_guide/#db-scale","text":"The dB scale is calculated by multiplying 10 times the Log10 of the power scale values. This scale brightens the pixels, allowing for better differentiation among very dark pixels. When identifying water on the landscape, this is often a good scale to use; the water pixels generally remain very dark, while the terrestrial pixels are even brighter (see Identifying Surface Water ). This scale is not always the best choice for general visualization of RTC products, as it can give a washed-out appearance, and because it is in a log scale, it is not appropriate for all types of statistical analyses.","title":"dB Scale"},{"location":"guides/rtc_product_guide/#rtc-use-examples","text":"The RTC products are presented as Cloud-Optimized GeoTIFFs (COGs), a user-friendly format that is GIS compatible. The products include pre-generated overviews, so users will not need to generate pyramids to display the images efficiently in a GIS environment. The following sections present examples of how one might use RTC datasets to identify areas of change and integrate RTC datasets into other datasets for enhanced results. We also present a bibliography of some of the scientific literature making use of Sentinel-1 RTC datasets.","title":"RTC Use Examples"},{"location":"guides/rtc_product_guide/#change-detection-using-rtc-data","text":"There are a number of ways that SAR data sets can be used to identify areas of change. Here are two examples of what you can do in a GIS environment.","title":"Change Detection Using RTC Data"},{"location":"guides/rtc_product_guide/#identifying-surface-water","text":"Calm surface water has a very low radar cross section. Most of the signal is reflected off the smooth surface, due to the high dielectric constant of freshwater, so little to none of the signal is returned as backscatter. Because of this, it is often easy to delineate surface water using a simple threshold value, where all pixels below the threshold are assumed to be water. You can easily visualize the water extent using various thresholds by applying a classified symbology with two classes. It is often best to use dB scale datasets for identifying surface water. In many cases, there will be a bimodal distribution of values in an RTC image containing surface water, with the first peak comprised mostly of water values, and the second peak containing all the remaining values. A good first step is to select a break point between those two peaks, then adjust the value as needed to generate a good water mask (Figure 7). Figure 7: Setting the break point to fall between the two peaks of the histogram Once you have determined the appropriate threshold (Figure 8), you can reclassify the RTC image to include only those pixels that fall below the threshold value, providing a water mask that can be used for analysis or to overlay with other imagery to show the water extent. Figure 8: Water Mask. Contains modified Copernicus Sentinel data 2020, processed by ESA.","title":"Identifying Surface Water"},{"location":"guides/rtc_product_guide/#combination-of-rtc-image-with-other-remote-sensing-data","text":"One of the main advantages of using RTC imagery with its all weather and day/night capabilities is the combination with other remote sensing data such as optical data. In the example below, the backscatter information of the Sentinel-1 SAR image (Figure 9) is used to enhance the spectral information of the optical Landsat 8 image (Figure 10) in the urban area of Pavia, Italy. Figure 11 shows the image fusion result of an IHS transformation. In this transformation the color channels red, green and blue (RGB) are first converted into a different color representation: intensity, hue and saturation (IHS). In the second step the optical intensity is replaced by the SAR image, before IHS is transformed back to RGB. Figure 9: Sentinel-1 RTC image. Figure 10: False color composite (bands 5, 4, 3) of a Landsat 8 image The color values for the two rivers in the SAR image are far more similar to each other than in the optical image. The vegetated areas (highlighted in red) show up more uniformly in the data fusion result than in the optical false color composite image. Image fusion uses the complementary nature of the different sources to generate an enhanced product. Figure 11: Image fusion result of SAR and optical imagery","title":"Combination of RTC Image with other Remote Sensing Data"},{"location":"guides/rtc_product_guide/#arcgis-toolbox","text":"ASF has developed a custom ArcGIS Toolbox for working with RTC datasets in either ArcGIS Desktop or ArcGIS Pro. It includes tools for converting between different SAR scales, calculating the log difference between two images, generating RGB Decomposition (false-color) products, and reclassifying a raster to generate a water mask. For more information and to download the toolbox, visit our website: https://asf.alaska.edu/how-to/data-tools/gis-tools/ .","title":"ArcGIS Toolbox"},{"location":"guides/rtc_product_guide/#application-examples-in-the-literature","text":"The following journal articles represent some of the work being done using Radiometric Terrain Corrected Sentinel-1 data sets.","title":"Application Examples in the Literature"},{"location":"guides/rtc_product_guide/#crop-monitoring","text":"Clauss, K., Ottinger M. and Kuenzer, C. 2018. Mapping rice areas with Sentinel-1 time series and superpixel segmentation. International Journal of Remote Sensing , 39 (5):1399-1420. DOI: 10.1080/01431161.2017.1404162 Nguyen, D.B., Gruber A. and Wagner, W. 2016. Mapping rice extent and cropping scheme in the Mekong Delta using Sentinel-1A data. Remote Sensing Letters , 7 (12):1209-1218. DOI: 10.1080/2150704X.2016.1225172","title":"Crop Monitoring"},{"location":"guides/rtc_product_guide/#disaster-response","text":"Markert, K.N., Chishtie, F., Anderson, E.R., Saah, D., Griffin, R.E. 2018. On the merging of optical and SAR satellite imagery for surface water mapping applications. Results In Physics , 9 :275-277. DOI: 10.1016/j.rinp.2018.02.054 Twele, A., Cao, W., Plank, S. and Martinis, S. 2016. Sentinel-1-based flood mapping: a fully automated processing chain. International Journal of Remote Sensing , 37 (13):2990-3004. DOI: 10.1080/01431161.2016.1192304","title":"Disaster Response"},{"location":"guides/rtc_product_guide/#land-classification-and-change-detection","text":"Muro, J., Canty, M., Conradsen, K., H\u00fcttich, C., Nielsen, A.A., Skriver, H., Remy, F., Strauch, A., Thonfeld, F. and Menz, G. 2016. Short-Term change detection in wetlands using Sentinel-1 time series. Remote Sensing , 8 (10):795. DOI: 10.3390/rs8100795 R\u00fcetschi, M., Schaepman, M.E., Small, D. 2018. Using Multitemporal Sentinel-1 C-band backscatter to monitor phenology and classify deciduous and coniferous forests in Northern Switzerland. Remote Sensing , 10 (1):55. DOI: 10.3390/rs10010055","title":"Land Classification and Change Detection"},{"location":"guides/rtc_product_guide/#data-access","text":"To view or download Sentinel-1 RTC products, please see the links below: Vertex: https://search.asf.alaska.edu/ API: https://asf.alaska.edu/api/ For details on accessing data, including other SAR datasets, see ASF\u2019s Get Started guide: https://asf.alaska.edu/how-to/get-started/ To access data recipes, which are step-by-step tutorials for processing and working with SAR data, see ASF\u2019s tutorials page: https://asf.alaska.edu/how-to/data-recipes/data-recipe-tutorials/","title":"Data Access"},{"location":"plugins/autoRIFT/","text":"HyP3 autoRIFT Plugin \u00b6","title":"HyP3 autoRIFT Plugin"},{"location":"plugins/autoRIFT/#hyp3-autorift-plugin","text":"","title":"HyP3 autoRIFT Plugin"},{"location":"plugins/gamma/","text":"HyP3 GAMMA Plugin \u00b6","title":"HyP3 GAMMA Plugin"},{"location":"plugins/gamma/#hyp3-gamma-plugin","text":"","title":"HyP3 GAMMA Plugin"},{"location":"tools/arcgis_toolbox/","text":"ArcGIS Toolbox \u00b6 The ASF_Tools ArcGIS Python Toolbox can be used with either ArcGIS Desktop or ArcGIS Pro, and contains tools that perform geoprocessing tasks useful for working with Synthetic Aperture Radar (SAR) data. The tools were designed to be used with Sentinel-1 Radiometric Terrain Corrected (RTC) SAR datasets , such as those available on-demand using ASF's Data Search - Vertex portal, but several of the tools have the potential to be used with a variety of rasters, including non-SAR datasets. The Toolbox is distributed as a zipped archive including the .pyt Toolbox script and associated .xml files. There is an XML file for the toolbox itself and one for each of the tools it contains. These XML files contain the metadata displayed in the item descriptions and tool help windows in ArcGIS, and must be kept in the same directory as the Python Toolbox (.pyt) file, or the information they contain will no longer be accessible. Toolbox Contents \u00b6 Unzip Files Tool \u00b6 This tool assists in file management when downloading .zip files from ASF. It could be used to extract to a specified location any zip files with an additional internal directory containing the individual files. The tool deletes the original zip files once they are extracted, and is especially helpful when dealing with file paths that are so long that they are beyond the maximum allowed in default Windows unzip utilities. Scale Conversion Tool \u00b6 This tool converts pixel values in calibrated SAR datasets (such as RTC rasters) from power or amplitude scale into power, amplitude or dB scale. This is an application specific to SAR data values/scales. Reclassify RTC Tool \u00b6 This tool generates a raster that includes only those pixels below a user-defined threshold value, and is designed for isolating water pixels. While intended for RTC files in dB scale, this tool could be used for any application where the user is interested in generating a spatial mask for values below a given threshold in a single-band raster. Log Difference Tool \u00b6 This tool compares two rasters by calculating the log difference on a pixel-by-pixel basis to identify areas where backscatter values have changed over time. While intended for RTC files in amplitude scale, this tool could be used to compare the pixel values of any two single-band rasters, as long as there are no negative values (NoData values will be returned for pixels with a negative number in either of the datasets). RGB Decomposition Tool \u00b6 This tool generates an RGB image using the co- and cross-polarized datasets from an RTC product. Input datasets can be in either amplitude or power scale, and the primary polarization can be either vertical (VV/VH) or horizontal (HH/HV). Additional documentation is available regarding the calculations used and the interpretation of these false-color images. Prerequisites \u00b6 Users must have either ArcGIS Desktop (ArcMap) or ArcGIS Pro installed and licensed on their computer. The Toolbox has been tested with Desktop versions 10.6.1 and 10.7.1 and Pro versions 2.4.2, 2.5.x and 2.6.1, but it may work with earlier versions as well. Note that several of the tools require the Spatial Analyst extension. Users who do not have licensing for this extension in ArcGIS will not be able to use many of the included tools. To install the Toolbox \u00b6 Download the zip file and extract the contents to any directory accessible by the computer running ArcGIS. Ensure that the Spatial Analyst extension is licensed and enabled. ArcGIS Desktop (ArcMap) \u00b6 Click on the Customize menu in ArcMap and select Extensions\u2026 Check the box next to Spatial Analyst and click the Close button at the bottom of the Extensions window. If you are unable to check this box, you do not have access to the Spatial Analyst extension and will not be able to make use of tools requiring this extension. ArcGIS Pro \u00b6 Click on the Project tab and select the Licensing tab. In the list of Esri Extensions, scroll down to verify that the Spatial Analyst is licensed and enabled. If it is not, an organization administrator will need to enable the extension in your user account. If your organization does not have a license available for you to use, you will not be able to make use of tools requiring this extension. Using the Toolbox \u00b6 In the ArcMap Catalog window or the ArcGIS Pro Catalog pane/view, navigate to the directory containing the toolbox (create a new folder connection if necessary). - To open the Catalog window in ArcMap, click on the Windows menu and select Catalog. - To open the Catalog pane or view in ArcGIS Pro, click the View tab and click on either the Catalog Pane or Catalog View button. Note that if you explore the extracted contents of the zip file outside of the ArcGIS environment, the directory will contain one .pyt file and a number of .xml files. In the ArcGIS Catalog window/pane/view, only the Toolbox is displayed, and when it is expanded, all of the Tools contained in the Toolbox script are displayed. The XML files are automatically referenced when ArcGIS requires the information they contain, and do not appear as additional files in the ArcGIS Catalog environment. The XML files must remain in the same directory as the .pyt file, and their filenames should not be changed. Double-click the ASF_Tools.pyt file to display the Tools (Scripts) included in the toolbox. Double-click on a Tool (displayed with a Script icon) to launch the dialog box or geoprocessing pane, as you would for any other ArcGIS Tool/Script. Enter the parameters as prompted and click the OK button to execute the tool. Note that output products are not automatically added to a project by default. You must navigate to them in the Catalog window/pane/view (or using the Add Data dialog) and add them to your project if desired. Tool Help \u00b6 The XML files included in the zip file are accessed when a user views the metadata for the toolbox, individual tools, or even different fields within the tool dialog. Accessing Help from within the Tool Dialog Box \u00b6 ArcGIS Desktop \u00b6 Click on the Show Help button at the bottom of the tool window to open the help panel. This panel will display information about the tool in general if no field is activated. If the user clicks on any of the parameter fields, information specific to that parameter will be displayed. Click on the Tool Help button at the bottom of the Help pane to open another window that displays most of the information that would be displayed in the tool\u2019s Item Description. ArcGIS Pro \u00b6 When you hover over any of the parameter fields in the tool dialog, a blue i appears. Hover over or click the blue i icon to view helpful tips specific to that parameter. Hover over the blue question mark at the top of the geoprocessing pane to display information about the tool. Click on it to open the full tool description in a browser window. Accessing Help from the Catalog Interface \u00b6 ArcGIS Desktop \u00b6 ArcCatalog displays the information contained in the xml metadata files in the Description tab for the toolbox and each tool. In the ArcMap Catalog window, the Item Description for the toolbox or any of its constituent tools displays the xml content. - Right-click the toolbox or tool in the Catalog window and select Item Description to view the information. ArcGIS Pro \u00b6 The xml metadata is displayed in the Metadata tab in the Catalog view. - Right-click a tool in the Catalog pane and select View Metadata to open the Metadata tab for the item in the Catalog view. OR - Open the Catalog View directly to navigate to the tool and select the Metadata tab.","title":"ArcGIS Toolbox"},{"location":"tools/arcgis_toolbox/#arcgis-toolbox","text":"The ASF_Tools ArcGIS Python Toolbox can be used with either ArcGIS Desktop or ArcGIS Pro, and contains tools that perform geoprocessing tasks useful for working with Synthetic Aperture Radar (SAR) data. The tools were designed to be used with Sentinel-1 Radiometric Terrain Corrected (RTC) SAR datasets , such as those available on-demand using ASF's Data Search - Vertex portal, but several of the tools have the potential to be used with a variety of rasters, including non-SAR datasets. The Toolbox is distributed as a zipped archive including the .pyt Toolbox script and associated .xml files. There is an XML file for the toolbox itself and one for each of the tools it contains. These XML files contain the metadata displayed in the item descriptions and tool help windows in ArcGIS, and must be kept in the same directory as the Python Toolbox (.pyt) file, or the information they contain will no longer be accessible.","title":"ArcGIS Toolbox"},{"location":"tools/arcgis_toolbox/#toolbox-contents","text":"","title":"Toolbox Contents"},{"location":"tools/arcgis_toolbox/#prerequisites","text":"Users must have either ArcGIS Desktop (ArcMap) or ArcGIS Pro installed and licensed on their computer. The Toolbox has been tested with Desktop versions 10.6.1 and 10.7.1 and Pro versions 2.4.2, 2.5.x and 2.6.1, but it may work with earlier versions as well. Note that several of the tools require the Spatial Analyst extension. Users who do not have licensing for this extension in ArcGIS will not be able to use many of the included tools.","title":"Prerequisites"},{"location":"tools/arcgis_toolbox/#to-install-the-toolbox","text":"Download the zip file and extract the contents to any directory accessible by the computer running ArcGIS. Ensure that the Spatial Analyst extension is licensed and enabled.","title":"To install the Toolbox"},{"location":"tools/arcgis_toolbox/#using-the-toolbox","text":"In the ArcMap Catalog window or the ArcGIS Pro Catalog pane/view, navigate to the directory containing the toolbox (create a new folder connection if necessary). - To open the Catalog window in ArcMap, click on the Windows menu and select Catalog. - To open the Catalog pane or view in ArcGIS Pro, click the View tab and click on either the Catalog Pane or Catalog View button. Note that if you explore the extracted contents of the zip file outside of the ArcGIS environment, the directory will contain one .pyt file and a number of .xml files. In the ArcGIS Catalog window/pane/view, only the Toolbox is displayed, and when it is expanded, all of the Tools contained in the Toolbox script are displayed. The XML files are automatically referenced when ArcGIS requires the information they contain, and do not appear as additional files in the ArcGIS Catalog environment. The XML files must remain in the same directory as the .pyt file, and their filenames should not be changed. Double-click the ASF_Tools.pyt file to display the Tools (Scripts) included in the toolbox. Double-click on a Tool (displayed with a Script icon) to launch the dialog box or geoprocessing pane, as you would for any other ArcGIS Tool/Script. Enter the parameters as prompted and click the OK button to execute the tool. Note that output products are not automatically added to a project by default. You must navigate to them in the Catalog window/pane/view (or using the Add Data dialog) and add them to your project if desired.","title":"Using the Toolbox"},{"location":"tools/arcgis_toolbox/#tool-help","text":"The XML files included in the zip file are accessed when a user views the metadata for the toolbox, individual tools, or even different fields within the tool dialog.","title":"Tool Help"},{"location":"tools/asf_tools/","text":"ASF Tools for Python \u00b6 asf_tools is a Python package for working with Synthetic Aperture Radar (SAR) data. It was designed for working with datasets generated by HyP3 , but several of the tools have the potential to be used with a variety of rasters, including non-SAR datasets. Install \u00b6 asf_tools can be installed via Anaconda/Miniconda : conda install -c conda-forge asf_tools Or using pip : python -m pip install asf_tools Quick Usage \u00b6 Local Resolution Weighted Composite \u00b6 The make_composite tool allows you to create a local-resolution-weighted composite from a set of Sentinel-1 RTC products ( D. Small, 2012 ). It is intended to be used with RTC products generated by ASF HyP3 . You will need to request RTC products using the Include Scattering Area option, then download and unzip them into an empty directory. To generate a composite of the co-polarization images, navigate to the directory containing the unzipped RTC products and run: make_composite VV-composite */*VV.tif To generate a composite of the cross-polarization images, navigate to the directory containing the unzipped RTC products and run: make_composite VH-composite */*VH.tif Usage Tip \u00b6 Because the imagery has been radiometrically terrain corrected (RTC), geometric and radiometric distortions have been removed from the files to be composited. One the strong points of LRW composites is that you combine both ascending and descending datatakes into a single product. In this manner no layover or shadow masks are required - what is shadowed on an ascending pass is visible in a descending pass and vice-versa. Thus, not only is it possible to combine ascending and descending, but it is highly encouraged. Using many datatakes from both the ascending and descending satellite passes will make the best composites possible. About Local Resolution Weighting (LRW) \u00b6 In an LRW composite, each satellite pass contributes to creating the output pixels. The amount of this contribution is scaled by the inverse of the scattering area used during terrain correction (thus the need for requesting the area map option of HyP3 RTC). The inverse of the surface scattering area, also referred to as local resolution, is multiplied by each pixel's backscatter value. The results of all of the images covering any single pixel are then summed. This total is then divided by the sum of the weights used to get the output average backscatter.","title":"ASF Tools for Python"},{"location":"tools/asf_tools/#asf-tools-for-python","text":"asf_tools is a Python package for working with Synthetic Aperture Radar (SAR) data. It was designed for working with datasets generated by HyP3 , but several of the tools have the potential to be used with a variety of rasters, including non-SAR datasets.","title":"ASF Tools for Python"},{"location":"tools/asf_tools/#install","text":"asf_tools can be installed via Anaconda/Miniconda : conda install -c conda-forge asf_tools Or using pip : python -m pip install asf_tools","title":"Install"},{"location":"tools/asf_tools/#quick-usage","text":"","title":"Quick Usage"},{"location":"tools/asf_tools/#local-resolution-weighted-composite","text":"The make_composite tool allows you to create a local-resolution-weighted composite from a set of Sentinel-1 RTC products ( D. Small, 2012 ). It is intended to be used with RTC products generated by ASF HyP3 . You will need to request RTC products using the Include Scattering Area option, then download and unzip them into an empty directory. To generate a composite of the co-polarization images, navigate to the directory containing the unzipped RTC products and run: make_composite VV-composite */*VV.tif To generate a composite of the cross-polarization images, navigate to the directory containing the unzipped RTC products and run: make_composite VH-composite */*VH.tif","title":"Local Resolution Weighted Composite"},{"location":"tools/asf_tools_api/","text":"asf_tools API Reference \u00b6 Tools developed by ASF for working with SAR data composite \u00b6 Create a local-resolution-weighted composite from Sentinel-1 RTC products. Create a local-resolution-weighted composite from a set of Sentinel-1 RTC products (D. Small, 2012). The local resolution, defined as the inverse of the local contributing (scattering) area, is used to weight each RTC products' contributions to the composite image on a pixel-by-pixel basis. The composite image is created as a Cloud Optimized GeoTIFF (COG). Additionally, a COG specifying the number of rasters contributing to each composite pixel is created. References David Small, 2012: https://doi.org/10.1109/IGARSS.2012.6350465 epsg_to_wkt ( epsg_code ) \u00b6 Get the WKT representation of a projection from its EPSG code Parameters: Name Type Description Default epsg_code int The integer EPSG code required Returns: Type Description str wkt: The WKT representation of the projection Source code in asf_tools/composite.py def epsg_to_wkt ( epsg_code : int ) -> str : \"\"\"Get the WKT representation of a projection from its EPSG code Args: epsg_code: The integer EPSG code Returns: wkt: The WKT representation of the projection \"\"\" srs = osr . SpatialReference () srs . ImportFromEPSG ( epsg_code ) return srs . ExportToWkt () get_area_raster ( raster ) \u00b6 Determine the path of the area raster for a given backscatter raster based on naming conventions for HyP3 RTC products Parameters: Name Type Description Default raster str path of the backscatter raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_VV.tif required Returns: Type Description str area_raster: path of the area raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_area.tif Source code in asf_tools/composite.py def get_area_raster ( raster : str ) -> str : \"\"\"Determine the path of the area raster for a given backscatter raster based on naming conventions for HyP3 RTC products Args: raster: path of the backscatter raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_VV.tif Returns: area_raster: path of the area raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_area.tif \"\"\" return '_' . join ( raster . split ( '_' )[: - 1 ] + [ 'area.tif' ]) get_epsg_code ( info ) \u00b6 Get the EPSG code from a GDAL Info dictionary Parameters: Name Type Description Default info dict The dictionary returned by a gdal.Info call required Returns: Type Description int epsg_code: The integer EPSG code Source code in asf_tools/composite.py def get_epsg_code ( info : dict ) -> int : \"\"\"Get the EPSG code from a GDAL Info dictionary Args: info: The dictionary returned by a gdal.Info call Returns: epsg_code: The integer EPSG code \"\"\" proj = osr . SpatialReference ( info [ 'coordinateSystem' ][ 'wkt' ]) epsg_code = int ( proj . GetAttrValue ( 'AUTHORITY' , 1 )) return epsg_code get_full_extent ( raster_info ) \u00b6 Determine the corner coordinates and geotransform for the full extent of a set of rasters Parameters: Name Type Description Default raster_info dict A dictionary of gdal.Info results for the set of rasters required Returns: Type Description upper_left The upper left corner of the extent as a tuple upper_right: The lower right corner of the extent as a tuple geotransform: The geotransform of the extent as a list Source code in asf_tools/composite.py def get_full_extent ( raster_info : dict ): \"\"\"Determine the corner coordinates and geotransform for the full extent of a set of rasters Args: raster_info: A dictionary of gdal.Info results for the set of rasters Returns: upper_left: The upper left corner of the extent as a tuple upper_right: The lower right corner of the extent as a tuple geotransform: The geotransform of the extent as a list \"\"\" upper_left_corners = [ info [ 'cornerCoordinates' ][ 'upperLeft' ] for info in raster_info . values ()] lower_right_corners = [ info [ 'cornerCoordinates' ][ 'lowerRight' ] for info in raster_info . values ()] ulx = min ([ ul [ 0 ] for ul in upper_left_corners ]) uly = max ([ ul [ 1 ] for ul in upper_left_corners ]) lrx = max ([ lr [ 0 ] for lr in lower_right_corners ]) lry = min ([ lr [ 1 ] for lr in lower_right_corners ]) log . debug ( f 'Full extent raster upper left: ( { ulx , uly } ); lower right: ( { lrx , lry } )' ) trans = [] for info in raster_info . values (): # Only need info from any one raster trans = info [ 'geoTransform' ] break trans [ 0 ] = ulx trans [ 3 ] = uly return ( ulx , uly ), ( lrx , lry ), trans get_target_epsg_code ( codes ) \u00b6 Determine the target UTM EPSG projection for the output composite Parameters: Name Type Description Default codes List[int] List of UTM EPSG codes required Returns: Type Description int target: UTM EPSG code Source code in asf_tools/composite.py def get_target_epsg_code ( codes : List [ int ]) -> int : \"\"\"Determine the target UTM EPSG projection for the output composite Args: codes: List of UTM EPSG codes Returns: target: UTM EPSG code \"\"\" # use median east/west UTM zone of all files, regardless of hemisphere # UTM EPSG codes for each hemisphere will look like: # North: 326XX # South: 327XX valid_codes = list ( range ( 32601 , 32661 )) + list ( range ( 32701 , 32761 )) if bad_codes := set ( codes ) - set ( valid_codes ): raise ValueError ( f 'Non UTM EPSG code encountered: { bad_codes } ' ) hemispheres = [ c // 100 * 100 for c in codes ] # if even modes, choose lowest (North) target_hemisphere = min ( multimode ( hemispheres )) zones = sorted ([ c % 100 for c in codes ]) # if even length, choose fist of median two target_zone = zones [( len ( zones ) - 1 ) // 2 ] return target_hemisphere + target_zone make_composite ( out_name , rasters , resolution = None ) \u00b6 Creates a local-resolution-weighted composite from Sentinel-1 RTC products Parameters: Name Type Description Default out_name str The base name of the output GeoTIFFs required rasters List[str] A list of file paths of the images to composite required resolution float The pixel size for the output GeoTIFFs None Returns: Type Description out_raster Path to the created composite backscatter GeoTIFF out_counts_raster: Path to the created GeoTIFF with counts of scenes contributing to each pixel Source code in asf_tools/composite.py def make_composite ( out_name : str , rasters : List [ str ], resolution : float = None ): \"\"\"Creates a local-resolution-weighted composite from Sentinel-1 RTC products Args: out_name: The base name of the output GeoTIFFs rasters: A list of file paths of the images to composite resolution: The pixel size for the output GeoTIFFs Returns: out_raster: Path to the created composite backscatter GeoTIFF out_counts_raster: Path to the created GeoTIFF with counts of scenes contributing to each pixel \"\"\" if not rasters : raise ValueError ( 'Must specify at least one raster to composite' ) raster_info = {} for raster in rasters : raster_info [ raster ] = gdal . Info ( raster , format = 'json' ) # make sure gdal can read the area raster gdal . Info ( get_area_raster ( raster )) target_epsg_code = get_target_epsg_code ([ get_epsg_code ( info ) for info in raster_info . values ()]) log . debug ( f 'Composite projection is EPSG: { target_epsg_code } ' ) if resolution is None : resolution = max ([ info [ 'geoTransform' ][ 1 ] for info in raster_info . values ()]) log . debug ( f 'Composite resolution is { resolution } meters' ) # resample rasters to maximum resolution & common UTM zone with TemporaryDirectory ( prefix = 'reprojected_' ) as temp_dir : raster_info = reproject_to_target ( raster_info , target_epsg_code = target_epsg_code , target_resolution = resolution , directory = temp_dir ) # Get extent of union of all images full_ul , full_lr , full_trans = get_full_extent ( raster_info ) nx = int ( abs ( full_ul [ 0 ] - full_lr [ 0 ]) // resolution ) ny = int ( abs ( full_ul [ 1 ] - full_lr [ 1 ]) // resolution ) outputs = np . zeros (( ny , nx )) weights = np . zeros ( outputs . shape ) counts = np . zeros ( outputs . shape , dtype = np . int8 ) for raster , info in raster_info . items (): log . info ( f 'Processing raster { raster } ' ) log . debug ( f \"Raster upper left: { info [ 'cornerCoordinates' ][ 'upperLeft' ] } ; \" f \"lower right: { info [ 'cornerCoordinates' ][ 'lowerRight' ] } \" ) values = read_as_array ( raster ) area_raster = get_area_raster ( raster ) areas = read_as_array ( area_raster ) ulx , uly = info [ 'cornerCoordinates' ][ 'upperLeft' ] y_index_start = int (( full_ul [ 1 ] - uly ) // resolution ) y_index_end = y_index_start + values . shape [ 0 ] x_index_start = int (( ulx - full_ul [ 0 ]) // resolution ) x_index_end = x_index_start + values . shape [ 1 ] log . debug ( f 'Placing values in output grid at { y_index_start } : { y_index_end } and { x_index_start } : { x_index_end } ' ) mask = values == 0 raster_weights = 1.0 / areas raster_weights [ mask ] = 0 outputs [ y_index_start : y_index_end , x_index_start : x_index_end ] += values * raster_weights weights [ y_index_start : y_index_end , x_index_start : x_index_end ] += raster_weights counts [ y_index_start : y_index_end , x_index_start : x_index_end ] += ~ mask del values , areas , mask , raster_weights # Divide by the total weight applied outputs /= weights del weights out_raster = write_cog ( f ' { out_name } .tif' , outputs , full_trans , target_epsg_code , nodata_value = 0 ) del outputs out_counts_raster = write_cog ( f ' { out_name } _counts.tif' , counts , full_trans , target_epsg_code , dtype = gdal . GDT_Int16 ) del counts return out_raster , out_counts_raster read_as_array ( raster , band = 1 ) \u00b6 Reads data from a raster image into memory Parameters: Name Type Description Default raster str The file path to a raster image required band int The raster band to read 1 Returns: Type Description <built-in function array> data: The raster pixel data as a numpy array Source code in asf_tools/composite.py def read_as_array ( raster : str , band : int = 1 ) -> np . array : \"\"\"Reads data from a raster image into memory Args: raster: The file path to a raster image band: The raster band to read Returns: data: The raster pixel data as a numpy array \"\"\" log . debug ( f 'Reading raster values from { raster } ' ) ds = gdal . Open ( raster ) data = ds . GetRasterBand ( band ) . ReadAsArray () del ds # How to close w/ gdal return data reproject_to_target ( raster_info , target_epsg_code , target_resolution , directory ) \u00b6 Reprojects a set of raster images to a common projection and resolution Parameters: Name Type Description Default raster_info dict A dictionary of gdal.Info results for the set of rasters required target_epsg_code int The integer EPSG code for the target projection required target_resolution float The target resolution required directory str The directory in which to create the reprojected files required Returns: Type Description dict target_raster_info: An updated dictionary of gdal.Info results for the reprojected files Source code in asf_tools/composite.py def reproject_to_target ( raster_info : dict , target_epsg_code : int , target_resolution : float , directory : str ) -> dict : \"\"\"Reprojects a set of raster images to a common projection and resolution Args: raster_info: A dictionary of gdal.Info results for the set of rasters target_epsg_code: The integer EPSG code for the target projection target_resolution: The target resolution directory: The directory in which to create the reprojected files Returns: target_raster_info: An updated dictionary of gdal.Info results for the reprojected files \"\"\" target_raster_info = {} for raster , info in raster_info . items (): epsg_code = get_epsg_code ( info ) resolution = info [ 'geoTransform' ][ 1 ] if epsg_code != target_epsg_code or resolution != target_resolution : log . info ( f 'Reprojecting { raster } ' ) reprojected_raster = os . path . join ( directory , os . path . basename ( raster )) gdal . Warp ( reprojected_raster , raster , dstSRS = f 'EPSG: { target_epsg_code } ' , xRes = target_resolution , yRes = target_resolution , targetAlignedPixels = True ) area_raster = get_area_raster ( raster ) log . info ( f 'Reprojecting { area_raster } ' ) reprojected_area_raster = os . path . join ( directory , os . path . basename ( area_raster )) gdal . Warp ( reprojected_area_raster , area_raster , dstSRS = f 'EPSG: { target_epsg_code } ' , xRes = target_resolution , yRes = target_resolution , targetAlignedPixels = True ) target_raster_info [ reprojected_raster ] = gdal . Info ( reprojected_raster , format = 'json' ) else : log . info ( f 'No need to reproject { raster } ' ) target_raster_info [ raster ] = info return target_raster_info write_cog ( file_name , data , transform , epsg_code , dtype = 6 , nodata_value = None ) \u00b6 Creates a Cloud Optimized GeoTIFF Parameters: Name Type Description Default file_name str The output file name required data ndarray The raster data required transform List[float] The geotransform for the output GeoTIFF required epsg_code int The integer EPSG code for the output GeoTIFF projection required dtype The pixel data type for the output GeoTIFF 6 nodata_value The NODATA value for the output Geotiff None Returns: Type Description file_name The output file name Source code in asf_tools/composite.py def write_cog ( file_name : str , data : np . ndarray , transform : List [ float ], epsg_code : int , dtype = gdal . GDT_Float32 , nodata_value = None ): \"\"\"Creates a Cloud Optimized GeoTIFF Args: file_name: The output file name data: The raster data transform: The geotransform for the output GeoTIFF epsg_code: The integer EPSG code for the output GeoTIFF projection dtype: The pixel data type for the output GeoTIFF nodata_value: The NODATA value for the output Geotiff Returns: file_name: The output file name \"\"\" log . info ( f 'Creating { file_name } ' ) with NamedTemporaryFile () as temp_file : driver = gdal . GetDriverByName ( 'GTiff' ) temp_geotiff = driver . Create ( temp_file . name , data . shape [ 1 ], data . shape [ 0 ], 1 , dtype ) temp_geotiff . GetRasterBand ( 1 ) . WriteArray ( data ) if nodata_value is not None : temp_geotiff . GetRasterBand ( 1 ) . SetNoDataValue ( nodata_value ) temp_geotiff . SetGeoTransform ( transform ) temp_geotiff . SetProjection ( epsg_to_wkt ( epsg_code )) driver = gdal . GetDriverByName ( 'COG' ) options = [ 'COMPRESS=LZW' , 'OVERVIEW_RESAMPLING=AVERAGE' , 'NUM_THREADS=ALL_CPUS' , 'BIGTIFF=YES' ] driver . CreateCopy ( file_name , temp_geotiff , options = options ) del temp_geotiff # How to close w/ gdal return file_name","title":"API Reference"},{"location":"tools/asf_tools_api/#asf_tools-api-reference","text":"Tools developed by ASF for working with SAR data","title":"asf_tools API Reference"},{"location":"tools/asf_tools_api/#asf_tools.composite","text":"Create a local-resolution-weighted composite from Sentinel-1 RTC products. Create a local-resolution-weighted composite from a set of Sentinel-1 RTC products (D. Small, 2012). The local resolution, defined as the inverse of the local contributing (scattering) area, is used to weight each RTC products' contributions to the composite image on a pixel-by-pixel basis. The composite image is created as a Cloud Optimized GeoTIFF (COG). Additionally, a COG specifying the number of rasters contributing to each composite pixel is created. References David Small, 2012: https://doi.org/10.1109/IGARSS.2012.6350465","title":"composite"},{"location":"tools/asf_tools_api/#asf_tools.composite.epsg_to_wkt","text":"Get the WKT representation of a projection from its EPSG code Parameters: Name Type Description Default epsg_code int The integer EPSG code required Returns: Type Description str wkt: The WKT representation of the projection Source code in asf_tools/composite.py def epsg_to_wkt ( epsg_code : int ) -> str : \"\"\"Get the WKT representation of a projection from its EPSG code Args: epsg_code: The integer EPSG code Returns: wkt: The WKT representation of the projection \"\"\" srs = osr . SpatialReference () srs . ImportFromEPSG ( epsg_code ) return srs . ExportToWkt ()","title":"epsg_to_wkt()"},{"location":"tools/asf_tools_api/#asf_tools.composite.get_area_raster","text":"Determine the path of the area raster for a given backscatter raster based on naming conventions for HyP3 RTC products Parameters: Name Type Description Default raster str path of the backscatter raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_VV.tif required Returns: Type Description str area_raster: path of the area raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_area.tif Source code in asf_tools/composite.py def get_area_raster ( raster : str ) -> str : \"\"\"Determine the path of the area raster for a given backscatter raster based on naming conventions for HyP3 RTC products Args: raster: path of the backscatter raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_VV.tif Returns: area_raster: path of the area raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_area.tif \"\"\" return '_' . join ( raster . split ( '_' )[: - 1 ] + [ 'area.tif' ])","title":"get_area_raster()"},{"location":"tools/asf_tools_api/#asf_tools.composite.get_epsg_code","text":"Get the EPSG code from a GDAL Info dictionary Parameters: Name Type Description Default info dict The dictionary returned by a gdal.Info call required Returns: Type Description int epsg_code: The integer EPSG code Source code in asf_tools/composite.py def get_epsg_code ( info : dict ) -> int : \"\"\"Get the EPSG code from a GDAL Info dictionary Args: info: The dictionary returned by a gdal.Info call Returns: epsg_code: The integer EPSG code \"\"\" proj = osr . SpatialReference ( info [ 'coordinateSystem' ][ 'wkt' ]) epsg_code = int ( proj . GetAttrValue ( 'AUTHORITY' , 1 )) return epsg_code","title":"get_epsg_code()"},{"location":"tools/asf_tools_api/#asf_tools.composite.get_full_extent","text":"Determine the corner coordinates and geotransform for the full extent of a set of rasters Parameters: Name Type Description Default raster_info dict A dictionary of gdal.Info results for the set of rasters required Returns: Type Description upper_left The upper left corner of the extent as a tuple upper_right: The lower right corner of the extent as a tuple geotransform: The geotransform of the extent as a list Source code in asf_tools/composite.py def get_full_extent ( raster_info : dict ): \"\"\"Determine the corner coordinates and geotransform for the full extent of a set of rasters Args: raster_info: A dictionary of gdal.Info results for the set of rasters Returns: upper_left: The upper left corner of the extent as a tuple upper_right: The lower right corner of the extent as a tuple geotransform: The geotransform of the extent as a list \"\"\" upper_left_corners = [ info [ 'cornerCoordinates' ][ 'upperLeft' ] for info in raster_info . values ()] lower_right_corners = [ info [ 'cornerCoordinates' ][ 'lowerRight' ] for info in raster_info . values ()] ulx = min ([ ul [ 0 ] for ul in upper_left_corners ]) uly = max ([ ul [ 1 ] for ul in upper_left_corners ]) lrx = max ([ lr [ 0 ] for lr in lower_right_corners ]) lry = min ([ lr [ 1 ] for lr in lower_right_corners ]) log . debug ( f 'Full extent raster upper left: ( { ulx , uly } ); lower right: ( { lrx , lry } )' ) trans = [] for info in raster_info . values (): # Only need info from any one raster trans = info [ 'geoTransform' ] break trans [ 0 ] = ulx trans [ 3 ] = uly return ( ulx , uly ), ( lrx , lry ), trans","title":"get_full_extent()"},{"location":"tools/asf_tools_api/#asf_tools.composite.get_target_epsg_code","text":"Determine the target UTM EPSG projection for the output composite Parameters: Name Type Description Default codes List[int] List of UTM EPSG codes required Returns: Type Description int target: UTM EPSG code Source code in asf_tools/composite.py def get_target_epsg_code ( codes : List [ int ]) -> int : \"\"\"Determine the target UTM EPSG projection for the output composite Args: codes: List of UTM EPSG codes Returns: target: UTM EPSG code \"\"\" # use median east/west UTM zone of all files, regardless of hemisphere # UTM EPSG codes for each hemisphere will look like: # North: 326XX # South: 327XX valid_codes = list ( range ( 32601 , 32661 )) + list ( range ( 32701 , 32761 )) if bad_codes := set ( codes ) - set ( valid_codes ): raise ValueError ( f 'Non UTM EPSG code encountered: { bad_codes } ' ) hemispheres = [ c // 100 * 100 for c in codes ] # if even modes, choose lowest (North) target_hemisphere = min ( multimode ( hemispheres )) zones = sorted ([ c % 100 for c in codes ]) # if even length, choose fist of median two target_zone = zones [( len ( zones ) - 1 ) // 2 ] return target_hemisphere + target_zone","title":"get_target_epsg_code()"},{"location":"tools/asf_tools_api/#asf_tools.composite.make_composite","text":"Creates a local-resolution-weighted composite from Sentinel-1 RTC products Parameters: Name Type Description Default out_name str The base name of the output GeoTIFFs required rasters List[str] A list of file paths of the images to composite required resolution float The pixel size for the output GeoTIFFs None Returns: Type Description out_raster Path to the created composite backscatter GeoTIFF out_counts_raster: Path to the created GeoTIFF with counts of scenes contributing to each pixel Source code in asf_tools/composite.py def make_composite ( out_name : str , rasters : List [ str ], resolution : float = None ): \"\"\"Creates a local-resolution-weighted composite from Sentinel-1 RTC products Args: out_name: The base name of the output GeoTIFFs rasters: A list of file paths of the images to composite resolution: The pixel size for the output GeoTIFFs Returns: out_raster: Path to the created composite backscatter GeoTIFF out_counts_raster: Path to the created GeoTIFF with counts of scenes contributing to each pixel \"\"\" if not rasters : raise ValueError ( 'Must specify at least one raster to composite' ) raster_info = {} for raster in rasters : raster_info [ raster ] = gdal . Info ( raster , format = 'json' ) # make sure gdal can read the area raster gdal . Info ( get_area_raster ( raster )) target_epsg_code = get_target_epsg_code ([ get_epsg_code ( info ) for info in raster_info . values ()]) log . debug ( f 'Composite projection is EPSG: { target_epsg_code } ' ) if resolution is None : resolution = max ([ info [ 'geoTransform' ][ 1 ] for info in raster_info . values ()]) log . debug ( f 'Composite resolution is { resolution } meters' ) # resample rasters to maximum resolution & common UTM zone with TemporaryDirectory ( prefix = 'reprojected_' ) as temp_dir : raster_info = reproject_to_target ( raster_info , target_epsg_code = target_epsg_code , target_resolution = resolution , directory = temp_dir ) # Get extent of union of all images full_ul , full_lr , full_trans = get_full_extent ( raster_info ) nx = int ( abs ( full_ul [ 0 ] - full_lr [ 0 ]) // resolution ) ny = int ( abs ( full_ul [ 1 ] - full_lr [ 1 ]) // resolution ) outputs = np . zeros (( ny , nx )) weights = np . zeros ( outputs . shape ) counts = np . zeros ( outputs . shape , dtype = np . int8 ) for raster , info in raster_info . items (): log . info ( f 'Processing raster { raster } ' ) log . debug ( f \"Raster upper left: { info [ 'cornerCoordinates' ][ 'upperLeft' ] } ; \" f \"lower right: { info [ 'cornerCoordinates' ][ 'lowerRight' ] } \" ) values = read_as_array ( raster ) area_raster = get_area_raster ( raster ) areas = read_as_array ( area_raster ) ulx , uly = info [ 'cornerCoordinates' ][ 'upperLeft' ] y_index_start = int (( full_ul [ 1 ] - uly ) // resolution ) y_index_end = y_index_start + values . shape [ 0 ] x_index_start = int (( ulx - full_ul [ 0 ]) // resolution ) x_index_end = x_index_start + values . shape [ 1 ] log . debug ( f 'Placing values in output grid at { y_index_start } : { y_index_end } and { x_index_start } : { x_index_end } ' ) mask = values == 0 raster_weights = 1.0 / areas raster_weights [ mask ] = 0 outputs [ y_index_start : y_index_end , x_index_start : x_index_end ] += values * raster_weights weights [ y_index_start : y_index_end , x_index_start : x_index_end ] += raster_weights counts [ y_index_start : y_index_end , x_index_start : x_index_end ] += ~ mask del values , areas , mask , raster_weights # Divide by the total weight applied outputs /= weights del weights out_raster = write_cog ( f ' { out_name } .tif' , outputs , full_trans , target_epsg_code , nodata_value = 0 ) del outputs out_counts_raster = write_cog ( f ' { out_name } _counts.tif' , counts , full_trans , target_epsg_code , dtype = gdal . GDT_Int16 ) del counts return out_raster , out_counts_raster","title":"make_composite()"},{"location":"tools/asf_tools_api/#asf_tools.composite.read_as_array","text":"Reads data from a raster image into memory Parameters: Name Type Description Default raster str The file path to a raster image required band int The raster band to read 1 Returns: Type Description <built-in function array> data: The raster pixel data as a numpy array Source code in asf_tools/composite.py def read_as_array ( raster : str , band : int = 1 ) -> np . array : \"\"\"Reads data from a raster image into memory Args: raster: The file path to a raster image band: The raster band to read Returns: data: The raster pixel data as a numpy array \"\"\" log . debug ( f 'Reading raster values from { raster } ' ) ds = gdal . Open ( raster ) data = ds . GetRasterBand ( band ) . ReadAsArray () del ds # How to close w/ gdal return data","title":"read_as_array()"},{"location":"tools/asf_tools_api/#asf_tools.composite.reproject_to_target","text":"Reprojects a set of raster images to a common projection and resolution Parameters: Name Type Description Default raster_info dict A dictionary of gdal.Info results for the set of rasters required target_epsg_code int The integer EPSG code for the target projection required target_resolution float The target resolution required directory str The directory in which to create the reprojected files required Returns: Type Description dict target_raster_info: An updated dictionary of gdal.Info results for the reprojected files Source code in asf_tools/composite.py def reproject_to_target ( raster_info : dict , target_epsg_code : int , target_resolution : float , directory : str ) -> dict : \"\"\"Reprojects a set of raster images to a common projection and resolution Args: raster_info: A dictionary of gdal.Info results for the set of rasters target_epsg_code: The integer EPSG code for the target projection target_resolution: The target resolution directory: The directory in which to create the reprojected files Returns: target_raster_info: An updated dictionary of gdal.Info results for the reprojected files \"\"\" target_raster_info = {} for raster , info in raster_info . items (): epsg_code = get_epsg_code ( info ) resolution = info [ 'geoTransform' ][ 1 ] if epsg_code != target_epsg_code or resolution != target_resolution : log . info ( f 'Reprojecting { raster } ' ) reprojected_raster = os . path . join ( directory , os . path . basename ( raster )) gdal . Warp ( reprojected_raster , raster , dstSRS = f 'EPSG: { target_epsg_code } ' , xRes = target_resolution , yRes = target_resolution , targetAlignedPixels = True ) area_raster = get_area_raster ( raster ) log . info ( f 'Reprojecting { area_raster } ' ) reprojected_area_raster = os . path . join ( directory , os . path . basename ( area_raster )) gdal . Warp ( reprojected_area_raster , area_raster , dstSRS = f 'EPSG: { target_epsg_code } ' , xRes = target_resolution , yRes = target_resolution , targetAlignedPixels = True ) target_raster_info [ reprojected_raster ] = gdal . Info ( reprojected_raster , format = 'json' ) else : log . info ( f 'No need to reproject { raster } ' ) target_raster_info [ raster ] = info return target_raster_info","title":"reproject_to_target()"},{"location":"tools/asf_tools_api/#asf_tools.composite.write_cog","text":"Creates a Cloud Optimized GeoTIFF Parameters: Name Type Description Default file_name str The output file name required data ndarray The raster data required transform List[float] The geotransform for the output GeoTIFF required epsg_code int The integer EPSG code for the output GeoTIFF projection required dtype The pixel data type for the output GeoTIFF 6 nodata_value The NODATA value for the output Geotiff None Returns: Type Description file_name The output file name Source code in asf_tools/composite.py def write_cog ( file_name : str , data : np . ndarray , transform : List [ float ], epsg_code : int , dtype = gdal . GDT_Float32 , nodata_value = None ): \"\"\"Creates a Cloud Optimized GeoTIFF Args: file_name: The output file name data: The raster data transform: The geotransform for the output GeoTIFF epsg_code: The integer EPSG code for the output GeoTIFF projection dtype: The pixel data type for the output GeoTIFF nodata_value: The NODATA value for the output Geotiff Returns: file_name: The output file name \"\"\" log . info ( f 'Creating { file_name } ' ) with NamedTemporaryFile () as temp_file : driver = gdal . GetDriverByName ( 'GTiff' ) temp_geotiff = driver . Create ( temp_file . name , data . shape [ 1 ], data . shape [ 0 ], 1 , dtype ) temp_geotiff . GetRasterBand ( 1 ) . WriteArray ( data ) if nodata_value is not None : temp_geotiff . GetRasterBand ( 1 ) . SetNoDataValue ( nodata_value ) temp_geotiff . SetGeoTransform ( transform ) temp_geotiff . SetProjection ( epsg_to_wkt ( epsg_code )) driver = gdal . GetDriverByName ( 'COG' ) options = [ 'COMPRESS=LZW' , 'OVERVIEW_RESAMPLING=AVERAGE' , 'NUM_THREADS=ALL_CPUS' , 'BIGTIFF=YES' ] driver . CreateCopy ( file_name , temp_geotiff , options = options ) del temp_geotiff # How to close w/ gdal return file_name","title":"write_cog()"},{"location":"using/api/","text":"Using the HyP3 API \u00b6 The HyP3 API is built on OpenAPI and Swagger . A friendly interface for exploring the API is available at: https://hyp3-api.asf.alaska.edu/ui/ \u00b6 In order to use the API, you'll need a asf-urs session cookie, which you can get by signing in to Vertex Confirm you are authenticated \u00b6 To confirm you are authenticated, you can run a GET request to our /user endpoint. Select the blue GET button next to /user and click the Try it out button Then, execute the request and look at the response If you get a Code 200 you should see a JSON dictionary of your user information. Authentication Required If you get a 401 response back you need to sign in to Vertex to get the asf-urs session cookie. { \"detail\" : \"No authorization token provided\" , \"status\" : 401 , \"title\" : \"Unauthorized\" , \"type\" : \"about:blank\" } Submitting Sentinel-1 RTC jobs \u00b6 Jobs are submitted through the API by providing a JSON payload with a list of job definitions. Sentinel-1 jobs are submitted using ESA granule IDs . A minimal job list for a single Sentinel-1 RTC job would look like: { \"jobs\" : [ { \"name\" : \"minimal-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_GRDH_1SDV_20210214T154837_20210214T154901_036588_044C54_032E\" ] } } ] } The job list may contain up to 200 job definitions. You can also provide custom RTC options: { \"jobs\" : [ { \"name\" : \"custom-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1B_IW_GRDH_1SDV_20210210T153157_20210210T153222_025546_030B48_2901\" ], \"radiometry\" : \"gamma0\" , \"scale\" : \"power\" , \"dem_matching\" : false , \"include_dem\" : true , \"include_inc_map\" : true , \"include_scattering_area\" : false , \"speckle_filter\" : false } }, { \"name\" : \"custom-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1B_IW_GRDH_1SDV_20210210T153132_20210210T153157_025546_030B48_4E31\" ], \"radiometry\" : \"sigma0\" , \"scale\" : \"amplitude\" , \"dem_matching\" : false , \"include_dem\" : false , \"include_inc_map\" : false , \"include_scattering_area\" : true , \"speckle_filter\" : true } } ] } Submitting Sentinel-1 InSAR jobs \u00b6 You can also submit InSAR jobs for scene pairs using ESA granule IDs . { \"jobs\" : [ { \"name\" : \"minimal-insar-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SDV_20200203T172103_20200203T172122_031091_03929B_3048\" , \"S1A_IW_SLC__1SDV_20200110T172104_20200110T172123_030741_03864E_A996\" ] } }, { \"name\" : \"custom-insar-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SDV_20200527T195012_20200527T195028_032755_03CB56_3D96\" , \"S1A_IW_SLC__1SDV_20200515T195012_20200515T195027_032580_03C609_4EBA\" ], \"looks\" : \"10x2\" , \"include_look_vectors\" : true , \"include_los_displacement\" : true } } ] } Submitting autoRIFT jobs \u00b6 AutoRIFT supports processing Sentinel-1, Sentinel-2, or Landsat-8 Collection 2 pairs. Sentinel-1 jobs are submitted using ESA granule IDs Sentinel-2 jobs can be submitted using ESA granule IDs or Element 84 Earth Search IDs Landsat-8 Collection 2 jobs are submitted using USGS scene IDs To submit an example set of jobs including all supported missions, you could write a job list like: { \"jobs\" : [ { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SSH_20170221T204710_20170221T204737_015387_0193F6_AB07\" , \"S1B_IW_SLC__1SSH_20170227T204628_20170227T204655_004491_007D11_6654\" ] } }, { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"S2B_MSIL1C_20200612T150759_N0209_R025_T22WEB_20200612T184700\" , \"S2A_MSIL1C_20200627T150921_N0209_R025_T22WEB_20200627T170912\" ] } }, { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"S2B_22WEB_20200612_0_L1C\" , \"S2A_22WEB_20200627_0_L1C\" ] } } { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"LC08_L1TP_009011_20200703_20200913_02_T1\" , \"LC08_L1TP_009011_20200820_20200905_02_T1\" ] } } ] } With your JSON jobs definition, you can POST to the /jobs endpoint to submit the jobs. click the green POST button next to /jobs click Try it out on the right paste your jobs definition into the Request body click execute If your jobs were submitted successfully you should see a Code 200 and a JSON response of your job list, with some additional job attributes filled in. Querying jobs \u00b6 You can GET job information from the /jobs endpoint. You may provide query parameters to filter which jobs are returned: For our above examples, you can get the RTC job that was submitted with the default options by searching for name=minimal-rtc-example . If you provide no query parameters, you'll get a JSON response with a jobs list for every job you've submitted. Within the jobs list, a complete job dictionary will look like: { \"jobs\" : [ { \"name\" : \"minimal-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8\" ] }, \"job_id\" : \"20c377be-2511-46a8-b908-e015abd3c24e\" , \"user_id\" : \"MY_EDL_USERNAME\" , \"status_code\" : \"SUCCEEDED\" , \"request_time\" : \"2021-02-24T21:30:45+00:00\" , \"expiration_time\" : \"2021-03-11T00:00:00+00:00\" , \"files\" : [ { \"filename\" : \"S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" , \"s3\" : { \"bucket\" : \"hyp3-contentbucket-fo259f6r6dn6\" , \"key\" : \"20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" }, \"size\" : 28676279 , \"url\" : \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" } ], \"browse_images\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.png\" ], \"thumbnail_images\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA_thumb.png\" ], \"logs\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/20c377be-2511-46a8-b908-e015abd3c24e.log\" ] } ] } Importantly, the files block provides download links for the product files. For large queries results may be truncated. In this case there will be a next key in the response that will contain a url to continue the query (this response may be similarly truncated and include a next key). ```JSON { \"jobs\": [ ... ], \"next\": \"https://hyp3-api.asf.alaska.edu/jobs?start_token=eyJqb2JfaWQiOiAiYzk1MDUzY2ItYWQzNy00ZGFhLTgxZDItYzA0YmQ4NWZiNDhiIiwgInVzZXJfaWQiOiAiamxyaW5lMiIsICJyZXF1ZXN0X3RpbWUiOiAiMjAyMC0xMC0yOVQxOTo0Mzo0NCswMDowMCJ9\" }","title":"API"},{"location":"using/api/#using-the-hyp3-api","text":"The HyP3 API is built on OpenAPI and Swagger . A friendly interface for exploring the API is available at:","title":"Using the HyP3 API"},{"location":"using/api/#confirm-you-are-authenticated","text":"To confirm you are authenticated, you can run a GET request to our /user endpoint. Select the blue GET button next to /user and click the Try it out button Then, execute the request and look at the response If you get a Code 200 you should see a JSON dictionary of your user information. Authentication Required If you get a 401 response back you need to sign in to Vertex to get the asf-urs session cookie. { \"detail\" : \"No authorization token provided\" , \"status\" : 401 , \"title\" : \"Unauthorized\" , \"type\" : \"about:blank\" }","title":"Confirm you are authenticated"},{"location":"using/api/#submitting-sentinel-1-rtc-jobs","text":"Jobs are submitted through the API by providing a JSON payload with a list of job definitions. Sentinel-1 jobs are submitted using ESA granule IDs . A minimal job list for a single Sentinel-1 RTC job would look like: { \"jobs\" : [ { \"name\" : \"minimal-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_GRDH_1SDV_20210214T154837_20210214T154901_036588_044C54_032E\" ] } } ] } The job list may contain up to 200 job definitions. You can also provide custom RTC options: { \"jobs\" : [ { \"name\" : \"custom-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1B_IW_GRDH_1SDV_20210210T153157_20210210T153222_025546_030B48_2901\" ], \"radiometry\" : \"gamma0\" , \"scale\" : \"power\" , \"dem_matching\" : false , \"include_dem\" : true , \"include_inc_map\" : true , \"include_scattering_area\" : false , \"speckle_filter\" : false } }, { \"name\" : \"custom-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1B_IW_GRDH_1SDV_20210210T153132_20210210T153157_025546_030B48_4E31\" ], \"radiometry\" : \"sigma0\" , \"scale\" : \"amplitude\" , \"dem_matching\" : false , \"include_dem\" : false , \"include_inc_map\" : false , \"include_scattering_area\" : true , \"speckle_filter\" : true } } ] }","title":"Submitting Sentinel-1 RTC jobs"},{"location":"using/api/#submitting-sentinel-1-insar-jobs","text":"You can also submit InSAR jobs for scene pairs using ESA granule IDs . { \"jobs\" : [ { \"name\" : \"minimal-insar-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SDV_20200203T172103_20200203T172122_031091_03929B_3048\" , \"S1A_IW_SLC__1SDV_20200110T172104_20200110T172123_030741_03864E_A996\" ] } }, { \"name\" : \"custom-insar-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SDV_20200527T195012_20200527T195028_032755_03CB56_3D96\" , \"S1A_IW_SLC__1SDV_20200515T195012_20200515T195027_032580_03C609_4EBA\" ], \"looks\" : \"10x2\" , \"include_look_vectors\" : true , \"include_los_displacement\" : true } } ] }","title":"Submitting Sentinel-1 InSAR jobs"},{"location":"using/api/#submitting-autorift-jobs","text":"AutoRIFT supports processing Sentinel-1, Sentinel-2, or Landsat-8 Collection 2 pairs. Sentinel-1 jobs are submitted using ESA granule IDs Sentinel-2 jobs can be submitted using ESA granule IDs or Element 84 Earth Search IDs Landsat-8 Collection 2 jobs are submitted using USGS scene IDs To submit an example set of jobs including all supported missions, you could write a job list like: { \"jobs\" : [ { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SSH_20170221T204710_20170221T204737_015387_0193F6_AB07\" , \"S1B_IW_SLC__1SSH_20170227T204628_20170227T204655_004491_007D11_6654\" ] } }, { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"S2B_MSIL1C_20200612T150759_N0209_R025_T22WEB_20200612T184700\" , \"S2A_MSIL1C_20200627T150921_N0209_R025_T22WEB_20200627T170912\" ] } }, { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"S2B_22WEB_20200612_0_L1C\" , \"S2A_22WEB_20200627_0_L1C\" ] } } { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"LC08_L1TP_009011_20200703_20200913_02_T1\" , \"LC08_L1TP_009011_20200820_20200905_02_T1\" ] } } ] } With your JSON jobs definition, you can POST to the /jobs endpoint to submit the jobs. click the green POST button next to /jobs click Try it out on the right paste your jobs definition into the Request body click execute If your jobs were submitted successfully you should see a Code 200 and a JSON response of your job list, with some additional job attributes filled in.","title":"Submitting autoRIFT jobs"},{"location":"using/api/#querying-jobs","text":"You can GET job information from the /jobs endpoint. You may provide query parameters to filter which jobs are returned: For our above examples, you can get the RTC job that was submitted with the default options by searching for name=minimal-rtc-example . If you provide no query parameters, you'll get a JSON response with a jobs list for every job you've submitted. Within the jobs list, a complete job dictionary will look like: { \"jobs\" : [ { \"name\" : \"minimal-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8\" ] }, \"job_id\" : \"20c377be-2511-46a8-b908-e015abd3c24e\" , \"user_id\" : \"MY_EDL_USERNAME\" , \"status_code\" : \"SUCCEEDED\" , \"request_time\" : \"2021-02-24T21:30:45+00:00\" , \"expiration_time\" : \"2021-03-11T00:00:00+00:00\" , \"files\" : [ { \"filename\" : \"S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" , \"s3\" : { \"bucket\" : \"hyp3-contentbucket-fo259f6r6dn6\" , \"key\" : \"20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" }, \"size\" : 28676279 , \"url\" : \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" } ], \"browse_images\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.png\" ], \"thumbnail_images\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA_thumb.png\" ], \"logs\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/20c377be-2511-46a8-b908-e015abd3c24e.log\" ] } ] } Importantly, the files block provides download links for the product files. For large queries results may be truncated. In this case there will be a next key in the response that will contain a url to continue the query (this response may be similarly truncated and include a next key). ```JSON { \"jobs\": [ ... ], \"next\": \"https://hyp3-api.asf.alaska.edu/jobs?start_token=eyJqb2JfaWQiOiAiYzk1MDUzY2ItYWQzNy00ZGFhLTgxZDItYzA0YmQ4NWZiNDhiIiwgInVzZXJfaWQiOiAiamxyaW5lMiIsICJyZXF1ZXN0X3RpbWUiOiAiMjAyMC0xMC0yOVQxOTo0Mzo0NCswMDowMCJ9\" }","title":"Querying jobs"},{"location":"using/sdk/","text":"HyP3 SDK \u00b6 A python wrapper around the HyP3 API >>> from hyp3_sdk import HyP3 >>> hyp3 = HyP3 ( username = 'MyUsername' , password = 'MyPassword' ) >>> granule = 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' >>> job = hyp3 . submit_rtc_job ( granule = granule , name = 'MyNewJob' ) >>> job = hyp3 . watch ( job ) >>> job . download_files () Install \u00b6 In order to easily manage dependencies, we recommend using dedicated project environments via Anaconda/Miniconda . or Python virtual environments . The HyP3 SDK can be installed into a conda environment with conda install -c conda-forge hyp3_sdk or into a virtual environment with python -m pip install hyp3_sdk Quick Usage \u00b6 There are 3 main classes that the SDK exposes: HyP3 to perform HyP3 operations (find jobs, refresh job information, submitting new jobs) Job to perform operations on single jobs (downloading products, check status) Batch to perform operations on multiple jobs at once (downloading products, check status) An instance of the HyP3 class will be needed to interact with the external HyP3 API. >>> from hyp3_sdk import HyP3 >>> hyp3 = HyP3 ( username = 'MyUsername' , password = 'MyPassword' ) >>> granule = 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' >>> job = hyp3 . submit_rtc_job ( granule = granule , name = 'MyNewJob' ) >>> job = hyp3 . watch ( job ) >>> job . download_files () Submitting Jobs \u00b6 hyp3 has member functions for submitting new jobs: rtc_job = hyp3 . submit_rtc_job ( 'granule_id' , 'job_name' ) insar_job = hyp3 . submit_insar_job ( 'reference_granule_id' , 'secondary_granule_id' , 'job_name' ) autorift_job = hyp3 . submit_autorift_job ( 'reference_granule_id' , 'secondary_granule_id' , 'job_name' ) Each of these functions will return an instance of the Job class that represents a new HyP3 job request. Finding Existing Jobs \u00b6 To find HyP3 jobs that were run previously, you can use the hyp3.find_jobs() batch = hyp3 . find_jobs () This will return a Batch instance representing all jobs owned by you. You can also pass parameters to query to a specific set of jobs Operations on Job and Batch \u00b6 If your jobs are not complete you can use the HyP3 instance to update them, and wait from completion batch = hyp3 . find_jobs () if not batch . complete (): # to get updated information batch = hyp3 . refresh ( batch ) # or to wait until completion and get updated information (which will take a fair bit) batch = hyp3 . watch ( batch ) Once you have complete jobs you can download the products to your machine batch . download_files () These operations also work on Job objects job = hyp3 . submit_rtc_job ( 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' , 'MyJobName' ) job = hyp3 . watch ( job ) job . download_files () Documentation \u00b6 For the full SDK API Reference, see the HyP3 documentation Contact Us \u00b6 Want to talk about the HyP3 SDK? We would love to hear from you! Found a bug? Want to request a feature? open an issue General questions? Suggestions? Or just want to talk to the team? chat with us on gitter","title":"SDK"},{"location":"using/sdk/#hyp3-sdk","text":"A python wrapper around the HyP3 API >>> from hyp3_sdk import HyP3 >>> hyp3 = HyP3 ( username = 'MyUsername' , password = 'MyPassword' ) >>> granule = 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' >>> job = hyp3 . submit_rtc_job ( granule = granule , name = 'MyNewJob' ) >>> job = hyp3 . watch ( job ) >>> job . download_files ()","title":"HyP3 SDK"},{"location":"using/sdk/#install","text":"In order to easily manage dependencies, we recommend using dedicated project environments via Anaconda/Miniconda . or Python virtual environments . The HyP3 SDK can be installed into a conda environment with conda install -c conda-forge hyp3_sdk or into a virtual environment with python -m pip install hyp3_sdk","title":"Install"},{"location":"using/sdk/#quick-usage","text":"There are 3 main classes that the SDK exposes: HyP3 to perform HyP3 operations (find jobs, refresh job information, submitting new jobs) Job to perform operations on single jobs (downloading products, check status) Batch to perform operations on multiple jobs at once (downloading products, check status) An instance of the HyP3 class will be needed to interact with the external HyP3 API. >>> from hyp3_sdk import HyP3 >>> hyp3 = HyP3 ( username = 'MyUsername' , password = 'MyPassword' ) >>> granule = 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' >>> job = hyp3 . submit_rtc_job ( granule = granule , name = 'MyNewJob' ) >>> job = hyp3 . watch ( job ) >>> job . download_files ()","title":"Quick Usage"},{"location":"using/sdk/#submitting-jobs","text":"hyp3 has member functions for submitting new jobs: rtc_job = hyp3 . submit_rtc_job ( 'granule_id' , 'job_name' ) insar_job = hyp3 . submit_insar_job ( 'reference_granule_id' , 'secondary_granule_id' , 'job_name' ) autorift_job = hyp3 . submit_autorift_job ( 'reference_granule_id' , 'secondary_granule_id' , 'job_name' ) Each of these functions will return an instance of the Job class that represents a new HyP3 job request.","title":"Submitting Jobs"},{"location":"using/sdk/#finding-existing-jobs","text":"To find HyP3 jobs that were run previously, you can use the hyp3.find_jobs() batch = hyp3 . find_jobs () This will return a Batch instance representing all jobs owned by you. You can also pass parameters to query to a specific set of jobs","title":"Finding Existing Jobs"},{"location":"using/sdk/#operations-on-job-and-batch","text":"If your jobs are not complete you can use the HyP3 instance to update them, and wait from completion batch = hyp3 . find_jobs () if not batch . complete (): # to get updated information batch = hyp3 . refresh ( batch ) # or to wait until completion and get updated information (which will take a fair bit) batch = hyp3 . watch ( batch ) Once you have complete jobs you can download the products to your machine batch . download_files () These operations also work on Job objects job = hyp3 . submit_rtc_job ( 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' , 'MyJobName' ) job = hyp3 . watch ( job ) job . download_files ()","title":"Operations on Job and Batch"},{"location":"using/sdk/#documentation","text":"For the full SDK API Reference, see the HyP3 documentation","title":"Documentation"},{"location":"using/sdk/#contact-us","text":"Want to talk about the HyP3 SDK? We would love to hear from you! Found a bug? Want to request a feature? open an issue General questions? Suggestions? Or just want to talk to the team? chat with us on gitter","title":"Contact Us"},{"location":"using/sdk_api/","text":"hyp3_sdk API Reference \u00b6 A python wrapper around the HyP3 API asf_search \u00b6 get_metadata ( granules ) \u00b6 Get the metadata for a granule or list of granules Parameters: Name Type Description Default granules Union[str, Iterable[str]] granule(s) to lookup metadata for required Returns: Type Description Union[dict, List[dict]] metadata: metadata for the granule(s) Source code in hyp3_sdk/asf_search.py def get_metadata ( granules : Union [ str , Iterable [ str ]]) -> Union [ dict , List [ dict ]]: \"\"\"Get the metadata for a granule or list of granules Args: granules: granule(s) to lookup metadata for Returns: metadata: metadata for the granule(s) \"\"\" if isinstance ( granules , str ): granule_list = granules else : granule_list = ',' . join ( granules ) params = { 'output' : 'jsonlite' , 'granule_list' : granule_list , } response = requests . post ( _SEARCH_API , params = params ) _raise_for_search_status ( response ) metadata = [ result for result in response . json ()[ 'results' ] if not result [ 'productType' ] . startswith ( 'METADATA_' )] if isinstance ( granules , str ): return metadata [ 0 ] return metadata get_nearest_neighbors ( granule , max_neighbors = 2 ) \u00b6 Get a Sentinel-1 granule's nearest neighbors from a temporal stack (backwards in time) Parameters: Name Type Description Default granule str reference granule required max_neighbors int maximum number of neighbors to return 2 Returns: Type Description List[dict] neighbors: a list of neighbors sorted by time Source code in hyp3_sdk/asf_search.py def get_nearest_neighbors ( granule : str , max_neighbors : int = 2 ,) -> List [ dict ]: \"\"\"Get a Sentinel-1 granule's nearest neighbors from a temporal stack (backwards in time) Args: granule: reference granule max_neighbors: maximum number of neighbors to return Returns: neighbors: a list of neighbors sorted by time \"\"\" params = { 'output' : 'json' , # jsonlite doesn't include centerLat/centerLon 'platform' : 'S1' , 'granule_list' : granule , } response = requests . post ( _SEARCH_API , params = params ) _raise_for_search_status ( response ) references = [ r for r in response . json ()[ 0 ] if not r [ 'processingLevel' ] . startswith ( 'METADATA_' )] if not references : raise ASFSearchError ( f 'Reference Sentinel-1 granule { granule } could not be found' ) reference = references [ 0 ] params = { 'output' : 'jsonlite' , 'platform' : 'S1' , 'intersectsWith' : f 'POINT ( { reference [ \"centerLon\" ] } { reference [ \"centerLat\" ] } )' , 'end' : reference [ 'startTime' ], # includes reference scene 'beamMode' : reference [ 'beamMode' ], 'flightDirection' : reference [ 'flightDirection' ], 'processingLevel' : reference [ 'processingLevel' ], 'relativeOrbit' : reference [ 'relativeOrbit' ], 'polarization' : _get_matching_polarizations ( reference [ 'polarization' ]), 'lookDirection' : reference [ 'lookDirection' ], } response = requests . post ( _SEARCH_API , params = params ) _raise_for_search_status ( response ) neighbors = sorted ( response . json ()[ 'results' ], key = lambda x : x [ 'startTime' ], reverse = True ) return neighbors [ 1 : max_neighbors + 1 ] exceptions \u00b6 Errors and exceptions to raise when the SDK runs into problems ASFSearchError \u00b6 Raise for errors when using the ASF Search module AuthenticationError \u00b6 Raise when authentication does not succeed HyP3Error \u00b6 Raise for errors when using the HyP3 module HyP3SDKError \u00b6 Base Exception for the HyP3 SDK ServerError \u00b6 Raise when the HyP3 SDK encounters a server error hyp3 \u00b6 HyP3 \u00b6 A python wrapper around the HyP3 API __init__ ( self , api_url = 'https://hyp3-api.asf.alaska.edu' , username = None , password = None , prompt = False ) special \u00b6 Parameters: Name Type Description Default api_url str Address of the HyP3 API 'https://hyp3-api.asf.alaska.edu' username Optional[str] Username for authenticating to urs.earthdata.nasa.gov . Both username and password must be provided if either is provided. None password Optional[str] Password for authenticating to urs.earthdata.nasa.gov . Both username and password must be provided if either is provided. None prompt bool Prompt for username and/or password interactively when they are not provided as keyword parameters False Source code in hyp3_sdk/hyp3.py def __init__ ( self , api_url : str = HYP3_PROD , username : Optional [ str ] = None , password : Optional [ str ] = None , prompt : bool = False ): \"\"\" Args: api_url: Address of the HyP3 API username: Username for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. password: Password for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. prompt: Prompt for username and/or password interactively when they are not provided as keyword parameters \"\"\" self . url = api_url if username is None and prompt : username = input ( 'NASA Earthdata Login username: ' ) if password is None and prompt : password = getpass ( 'NASA Earthdata Login password: ' ) self . session = get_authenticated_session ( username , password ) self . session . headers . update ({ 'User-Agent' : f ' { hyp3_sdk . __name__ } / { hyp3_sdk . __version__ } ' }) check_quota ( self ) \u00b6 Returns: Type Description int The number of jobs left in your quota Source code in hyp3_sdk/hyp3.py def check_quota ( self ) -> int : \"\"\" Returns: The number of jobs left in your quota \"\"\" info = self . my_info () return info [ 'quota' ][ 'remaining' ] find_jobs ( self , start = None , end = None , status_code = None , name = None , job_type = None ) \u00b6 Gets a Batch of jobs from HyP3 matching the provided search criteria Parameters: Name Type Description Default start Optional[datetime.datetime] only jobs submitted after given time None end Optional[datetime.datetime] only jobs submitted before given time None status_code Optional[str] only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) None name Optional[str] only jobs with this name None job_type Optional[str] only jobs with this job_type None Returns: Type Description Batch A Batch object containing the found jobs Source code in hyp3_sdk/hyp3.py def find_jobs ( self , start : Optional [ datetime ] = None , end : Optional [ datetime ] = None , status_code : Optional [ str ] = None , name : Optional [ str ] = None , job_type : Optional [ str ] = None ) -> Batch : \"\"\"Gets a Batch of jobs from HyP3 matching the provided search criteria Args: start: only jobs submitted after given time end: only jobs submitted before given time status_code: only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) name: only jobs with this name job_type: only jobs with this job_type Returns: A Batch object containing the found jobs \"\"\" params = {} for param_name in ( 'start' , 'end' , 'status' , 'name' , 'job_type' ): param_value = locals () . get ( param_name ) if param_value is not None : if isinstance ( param_value , datetime ): if param_value . tzinfo is None : param_value . replace ( tzinfo = timezone . utc ) param_value = param_value . isoformat ( timespec = 'seconds' ) params [ param_name ] = param_value response = self . session . get ( urljoin ( self . url , '/jobs' ), params = params ) _raise_for_hyp3_status ( response ) jobs = [ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]] while 'next' in response . json (): next_url = response . json ()[ 'next' ] response = self . session . get ( next_url ) _raise_for_hyp3_status ( response ) jobs . extend ([ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]]) if not jobs : warnings . warn ( 'Found zero jobs' , UserWarning ) return Batch ( jobs ) get_job_by_id ( self , job_id ) \u00b6 Get job by job ID Parameters: Name Type Description Default job_id str A job ID required Returns: Type Description Job A Job object Source code in hyp3_sdk/hyp3.py def get_job_by_id ( self , job_id : str ) -> Job : \"\"\"Get job by job ID Args: job_id: A job ID Returns: A Job object \"\"\" response = self . session . get ( urljoin ( self . url , f '/jobs/ { job_id } ' )) _raise_for_hyp3_status ( response ) return Job . from_dict ( response . json ()) my_info ( self ) \u00b6 Returns: Type Description dict Your user information Source code in hyp3_sdk/hyp3.py def my_info ( self ) -> dict : \"\"\" Returns: Your user information \"\"\" response = self . session . get ( urljoin ( self . url , '/user' )) _raise_for_hyp3_status ( response ) return response . json () prepare_autorift_job ( granule1 , granule2 , name = None ) classmethod \u00b6 Submit an autoRIFT job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional[str] A name for the job None Returns: Type Description dict A dictionary containing the prepared autoRIFT job Source code in hyp3_sdk/hyp3.py @classmethod def prepare_autorift_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> dict : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A dictionary containing the prepared autoRIFT job \"\"\" job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ]}, 'job_type' : 'AUTORIFT' , } if name is not None : job_dict [ 'name' ] = name return job_dict prepare_insar_job ( granule1 , granule2 , name = None , include_look_vectors = False , include_los_displacement = False , looks = '20x4' ) classmethod \u00b6 Submit an InSAR job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional[str] A name for the job None include_look_vectors bool Include the look vector theta and phi files in the product package False include_los_displacement bool Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS) False looks Literal['20x4', '10x2'] Number of looks to take in range and azimuth '20x4' Returns: Type Description dict A dictionary containing the prepared InSAR job Source code in hyp3_sdk/hyp3.py @classmethod def prepare_insar_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' ) -> dict : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS) looks: Number of looks to take in range and azimuth Returns: A dictionary containing the prepared InSAR job \"\"\" job_parameters = locals () . copy () for key in [ 'cls' , 'granule1' , 'granule2' , 'name' ]: job_parameters . pop ( key ) job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ], ** job_parameters }, 'job_type' : 'INSAR_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict prepare_rtc_job ( granule , name = None , dem_matching = False , include_dem = False , include_inc_map = False , include_rgb = False , include_scattering_area = False , radiometry = 'gamma0' , resolution = 30 , scale = 'power' , speckle_filter = False , dem_name = 'copernicus' ) classmethod \u00b6 Submit an RTC job Parameters: Name Type Description Default granule str The granule (scene) to use required name Optional[str] A name for the job None dem_matching bool Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files False include_dem bool Include the DEM file in the product package False include_inc_map bool Include the incidence angle map in the product package False include_rgb bool Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) False include_scattering_area bool Include the scattering area in the product package False radiometry Literal['sigma0', 'gamma0'] Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) 'gamma0' resolution Literal[30] Desired output pixel spacing in meters 30 scale Literal['amplitude', 'power'] Scale of output image; either power or amplitude 'power' speckle_filter bool Apply an Enhanced Lee speckle filter False dem_name Literal['copernicus', 'legacy'] Name of the DEM to use for processing. copernicus will use the Copernicus GLO-30 Public DEM, while legacy will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. 'copernicus' Returns: Type Description dict A dictionary containing the prepared RTC job Source code in hyp3_sdk/hyp3.py @classmethod def prepare_rtc_job ( cls , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 30 ] = 30 , scale : Literal [ 'amplitude' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> dict : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; either power or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A dictionary containing the prepared RTC job \"\"\" job_parameters = locals () . copy () for key in [ 'granule' , 'name' , 'cls' ]: job_parameters . pop ( key , None ) job_dict = { 'job_parameters' : { 'granules' : [ granule ], ** job_parameters }, 'job_type' : 'RTC_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict refresh ( self , job_or_batch ) \u00b6 Refresh each jobs' information Parameters: Name Type Description Default job_or_batch Union[hyp3_sdk.jobs.Batch, hyp3_sdk.jobs.Job] A Batch of Job object to refresh required Returns: Type Description Union[hyp3_sdk.jobs.Batch, hyp3_sdk.jobs.Job] A Batch or Job object with refreshed information Source code in hyp3_sdk/hyp3.py @singledispatchmethod def refresh ( self , job_or_batch : Union [ Batch , Job ]) -> Union [ Batch , Job ]: \"\"\"Refresh each jobs' information Args: job_or_batch: A Batch of Job object to refresh Returns: A Batch or Job object with refreshed information \"\"\" raise NotImplementedError ( f 'Cannot refresh { type ( job_or_batch ) } type object' ) submit_autorift_job ( self , granule1 , granule2 , name = None ) \u00b6 Submit an autoRIFT job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional[str] A name for the job None Returns: Type Description Batch A Batch object containing the autoRIFT job Source code in hyp3_sdk/hyp3.py def submit_autorift_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> Batch : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A Batch object containing the autoRIFT job \"\"\" job_dict = self . prepare_autorift_job ( granule1 , granule2 , name = name ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) submit_insar_job ( self , granule1 , granule2 , name = None , include_look_vectors = False , include_los_displacement = False , looks = '20x4' ) \u00b6 Submit an InSAR job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional[str] A name for the job None include_look_vectors bool Include the look vector theta and phi files in the product package False include_los_displacement bool Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS) False looks Literal['20x4', '10x2'] Number of looks to take in range and azimuth '20x4' Returns: Type Description Batch A Batch object containing the InSAR job Source code in hyp3_sdk/hyp3.py def submit_insar_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' ) -> Batch : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS) looks: Number of looks to take in range and azimuth Returns: A Batch object containing the InSAR job \"\"\" arguments = locals () . copy () arguments . pop ( 'self' ) job_dict = self . prepare_insar_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) submit_prepared_jobs ( self , prepared_jobs ) \u00b6 Submit a prepared job dictionary, or list of prepared job dictionaries Parameters: Name Type Description Default prepared_jobs Union[dict, List[dict]] A prepared job dictionary, or list of prepared job dictionaries required Returns: Type Description Batch A Batch object containing the submitted job(s) Source code in hyp3_sdk/hyp3.py def submit_prepared_jobs ( self , prepared_jobs : Union [ dict , List [ dict ]]) -> Batch : \"\"\"Submit a prepared job dictionary, or list of prepared job dictionaries Args: prepared_jobs: A prepared job dictionary, or list of prepared job dictionaries Returns: A Batch object containing the submitted job(s) \"\"\" if isinstance ( prepared_jobs , dict ): payload = { 'jobs' : [ prepared_jobs ]} else : payload = { 'jobs' : prepared_jobs } response = self . session . post ( urljoin ( self . url , '/jobs' ), json = payload ) _raise_for_hyp3_status ( response ) batch = Batch () for job in response . json ()[ 'jobs' ]: batch += Job . from_dict ( job ) return batch submit_rtc_job ( self , granule , name = None , dem_matching = False , include_dem = False , include_inc_map = False , include_rgb = False , include_scattering_area = False , radiometry = 'gamma0' , resolution = 30 , scale = 'power' , speckle_filter = False , dem_name = 'copernicus' ) \u00b6 Submit an RTC job Parameters: Name Type Description Default granule str The granule (scene) to use required name Optional[str] A name for the job None dem_matching bool Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files False include_dem bool Include the DEM file in the product package False include_inc_map bool Include the incidence angle map in the product package False include_rgb bool Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) False include_scattering_area bool Include the scattering area in the product package False radiometry Literal['sigma0', 'gamma0'] Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) 'gamma0' resolution Literal[30] Desired output pixel spacing in meters 30 scale Literal['amplitude', 'power'] Scale of output image; either power or amplitude 'power' speckle_filter bool Apply an Enhanced Lee speckle filter False dem_name Literal['copernicus', 'legacy'] Name of the DEM to use for processing. copernicus will use the Copernicus GLO-30 Public DEM, while legacy will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. 'copernicus' Returns: Type Description Batch A Batch object containing the RTC job Source code in hyp3_sdk/hyp3.py def submit_rtc_job ( self , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 30 ] = 30 , scale : Literal [ 'amplitude' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> Batch : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; either power or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A Batch object containing the RTC job \"\"\" arguments = locals () arguments . pop ( 'self' ) job_dict = self . prepare_rtc_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) watch ( self , job_or_batch , timeout = 10800 , interval = 60 ) \u00b6 Watch jobs until they complete Parameters: Name Type Description Default job_or_batch Union[hyp3_sdk.jobs.Batch, hyp3_sdk.jobs.Job] A Batch or Job object of jobs to watch required timeout int How long to wait until exiting in seconds 10800 interval Union[int, float] How often to check for updates in seconds 60 Returns: Type Description Union[hyp3_sdk.jobs.Batch, hyp3_sdk.jobs.Job] A Batch or Job object with refreshed watched jobs Source code in hyp3_sdk/hyp3.py @singledispatchmethod def watch ( self , job_or_batch : Union [ Batch , Job ], timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Union [ Batch , Job ]: \"\"\"Watch jobs until they complete Args: job_or_batch: A Batch or Job object of jobs to watch timeout: How long to wait until exiting in seconds interval: How often to check for updates in seconds Returns: A Batch or Job object with refreshed watched jobs \"\"\" raise NotImplementedError ( f 'Cannot watch { type ( job_or_batch ) } type object' ) jobs \u00b6 Batch \u00b6 any_expired ( self ) \u00b6 Check succeeded jobs for expiration Source code in hyp3_sdk/jobs.py def any_expired ( self ) -> bool : \"\"\"Check succeeded jobs for expiration\"\"\" for job in self . jobs : try : if job . expired (): return True except HyP3SDKError : continue return False complete ( self ) \u00b6 Returns: True if all jobs are complete, otherwise returns False Source code in hyp3_sdk/jobs.py def complete ( self ) -> bool : \"\"\" Returns: True if all jobs are complete, otherwise returns False \"\"\" for job in self . jobs : if not job . complete (): return False return True download_files ( self , location = '.' , create = True ) \u00b6 Parameters: Name Type Description Default location Union[pathlib.Path, str] Directory location to put files into '.' create bool Create location if it does not point to an existing directory True Returns: list of Path objects to downloaded files Source code in hyp3_sdk/jobs.py def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" downloaded_files = [] for job in tqdm ( self . jobs ): try : downloaded_files . extend ( job . download_files ( location , create )) except HyP3SDKError as e : print ( f 'Warning: { e } . Skipping download for { job } .' ) return downloaded_files filter_jobs ( self , succeeded = True , running = True , failed = False , include_expired = True ) \u00b6 Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Parameters: Name Type Description Default succeeded bool Include all succeeded jobs True running bool Include all running jobs True failed bool Include all failed jobs False include_expired bool Include expired jobs in the result True Returns: Type Description Batch batch: A batch object containing jobs matching all the selected statuses Source code in hyp3_sdk/jobs.py def filter_jobs ( self , succeeded : bool = True , running : bool = True , failed : bool = False , include_expired : bool = True , ) -> 'Batch' : \"\"\"Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Args: succeeded: Include all succeeded jobs running: Include all running jobs failed: Include all failed jobs include_expired: Include expired jobs in the result Returns: batch: A batch object containing jobs matching all the selected statuses \"\"\" filtered_jobs = [] for job in self . jobs : if job . succeeded () and succeeded : if include_expired or not job . expired (): filtered_jobs . append ( job ) elif job . running () and running : filtered_jobs . append ( job ) elif job . failed () and failed : filtered_jobs . append ( job ) return Batch ( filtered_jobs ) succeeded ( self ) \u00b6 Returns: True if all jobs have succeeded, otherwise returns False Source code in hyp3_sdk/jobs.py def succeeded ( self ) -> bool : \"\"\" Returns: True if all jobs have succeeded, otherwise returns False \"\"\" for job in self . jobs : if not job . succeeded (): return False return True Job \u00b6 download_files ( self , location = '.' , create = True ) \u00b6 Parameters: Name Type Description Default location Union[pathlib.Path, str] Directory location to put files into '.' create bool Create location if it does not point to an existing directory True Returns: list of Path objects to downloaded files Source code in hyp3_sdk/jobs.py def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" location = Path ( location ) if not self . succeeded (): raise HyP3SDKError ( f 'Only succeeded jobs can be downloaded; job is { self . status_code } .' ) if self . expired (): raise HyP3SDKError ( f 'Expired jobs cannot be downloaded; ' f 'job expired { self . expiration_time . isoformat ( timespec = \"seconds\" ) } .' ) if create : location . mkdir ( parents = True , exist_ok = True ) elif not location . is_dir (): raise NotADirectoryError ( str ( location )) downloaded_files = [] for file in self . files : download_url = file [ 'url' ] filename = location / file [ 'filename' ] try : downloaded_files . append ( download_file ( download_url , filename , chunk_size = 10485760 )) except HTTPError : raise HyP3SDKError ( f 'Unable to download file: { download_url } ' ) return downloaded_files util \u00b6 Extra utilities for working with HyP3 download_file ( url , filepath , chunk_size = None , retries = 2 , backoff_factor = 1 ) \u00b6 Download a file Parameters: Name Type Description Default url str URL of the file to download required filepath Union[pathlib.Path, str] Location to place file into required chunk_size Size to chunk the download into None retries Number of retries to attempt 2 backoff_factor Factor for calculating time between retries 1 Returns: Type Description Path download_path: The path to the downloaded file Source code in hyp3_sdk/util.py def download_file ( url : str , filepath : Union [ Path , str ], chunk_size = None , retries = 2 , backoff_factor = 1 ) -> Path : \"\"\"Download a file Args: url: URL of the file to download filepath: Location to place file into chunk_size: Size to chunk the download into retries: Number of retries to attempt backoff_factor: Factor for calculating time between retries Returns: download_path: The path to the downloaded file \"\"\" filepath = Path ( filepath ) session = requests . Session () retry_strategy = Retry ( total = retries , backoff_factor = backoff_factor , status_forcelist = [ 429 , 500 , 502 , 503 , 504 ], ) session . mount ( 'https://' , HTTPAdapter ( max_retries = retry_strategy )) session . mount ( 'http://' , HTTPAdapter ( max_retries = retry_strategy )) with session . get ( url , stream = True ) as s : s . raise_for_status () with tqdm . wrapattr ( open ( filepath , \"wb\" ), 'write' , miniters = 1 , desc = filepath . name , total = int ( s . headers . get ( 'content-length' , 0 ))) as f : for chunk in s . iter_content ( chunk_size = chunk_size ): if chunk : f . write ( chunk ) session . close () return filepath get_authenticated_session ( username , password ) \u00b6 Log into HyP3 using credentials for urs.earthdata.nasa.gov from either the provided credentials or a .netrc file. Returns: Type Description Session An authenticated HyP3 Session Source code in hyp3_sdk/util.py def get_authenticated_session ( username : str , password : str ) -> requests . Session : \"\"\"Log into HyP3 using credentials for `urs.earthdata.nasa.gov` from either the provided credentials or a `.netrc` file. Returns: An authenticated HyP3 Session \"\"\" s = requests . Session () if hyp3_sdk . TESTING : return s if username is not None and password is not None : response = s . get ( AUTH_URL , auth = ( username , password )) try : response . raise_for_status () except requests . HTTPError : raise AuthenticationError ( 'Was not able to authenticate with credentials provided \\n ' 'This could be due to invalid credentials or a connection error.' ) else : response = s . get ( AUTH_URL ) try : response . raise_for_status () except requests . HTTPError : raise AuthenticationError ( 'Was not able to authenticate with .netrc file and no credentials provided \\n ' 'This could be due to invalid credentials in .netrc or a connection error.' ) return s","title":"API Reference"},{"location":"using/sdk_api/#hyp3_sdk-api-reference","text":"A python wrapper around the HyP3 API","title":"hyp3_sdk API Reference"},{"location":"using/sdk_api/#hyp3_sdk.asf_search","text":"","title":"asf_search"},{"location":"using/sdk_api/#hyp3_sdk.asf_search.get_metadata","text":"Get the metadata for a granule or list of granules Parameters: Name Type Description Default granules Union[str, Iterable[str]] granule(s) to lookup metadata for required Returns: Type Description Union[dict, List[dict]] metadata: metadata for the granule(s) Source code in hyp3_sdk/asf_search.py def get_metadata ( granules : Union [ str , Iterable [ str ]]) -> Union [ dict , List [ dict ]]: \"\"\"Get the metadata for a granule or list of granules Args: granules: granule(s) to lookup metadata for Returns: metadata: metadata for the granule(s) \"\"\" if isinstance ( granules , str ): granule_list = granules else : granule_list = ',' . join ( granules ) params = { 'output' : 'jsonlite' , 'granule_list' : granule_list , } response = requests . post ( _SEARCH_API , params = params ) _raise_for_search_status ( response ) metadata = [ result for result in response . json ()[ 'results' ] if not result [ 'productType' ] . startswith ( 'METADATA_' )] if isinstance ( granules , str ): return metadata [ 0 ] return metadata","title":"get_metadata()"},{"location":"using/sdk_api/#hyp3_sdk.asf_search.get_nearest_neighbors","text":"Get a Sentinel-1 granule's nearest neighbors from a temporal stack (backwards in time) Parameters: Name Type Description Default granule str reference granule required max_neighbors int maximum number of neighbors to return 2 Returns: Type Description List[dict] neighbors: a list of neighbors sorted by time Source code in hyp3_sdk/asf_search.py def get_nearest_neighbors ( granule : str , max_neighbors : int = 2 ,) -> List [ dict ]: \"\"\"Get a Sentinel-1 granule's nearest neighbors from a temporal stack (backwards in time) Args: granule: reference granule max_neighbors: maximum number of neighbors to return Returns: neighbors: a list of neighbors sorted by time \"\"\" params = { 'output' : 'json' , # jsonlite doesn't include centerLat/centerLon 'platform' : 'S1' , 'granule_list' : granule , } response = requests . post ( _SEARCH_API , params = params ) _raise_for_search_status ( response ) references = [ r for r in response . json ()[ 0 ] if not r [ 'processingLevel' ] . startswith ( 'METADATA_' )] if not references : raise ASFSearchError ( f 'Reference Sentinel-1 granule { granule } could not be found' ) reference = references [ 0 ] params = { 'output' : 'jsonlite' , 'platform' : 'S1' , 'intersectsWith' : f 'POINT ( { reference [ \"centerLon\" ] } { reference [ \"centerLat\" ] } )' , 'end' : reference [ 'startTime' ], # includes reference scene 'beamMode' : reference [ 'beamMode' ], 'flightDirection' : reference [ 'flightDirection' ], 'processingLevel' : reference [ 'processingLevel' ], 'relativeOrbit' : reference [ 'relativeOrbit' ], 'polarization' : _get_matching_polarizations ( reference [ 'polarization' ]), 'lookDirection' : reference [ 'lookDirection' ], } response = requests . post ( _SEARCH_API , params = params ) _raise_for_search_status ( response ) neighbors = sorted ( response . json ()[ 'results' ], key = lambda x : x [ 'startTime' ], reverse = True ) return neighbors [ 1 : max_neighbors + 1 ]","title":"get_nearest_neighbors()"},{"location":"using/sdk_api/#hyp3_sdk.exceptions","text":"Errors and exceptions to raise when the SDK runs into problems","title":"exceptions"},{"location":"using/sdk_api/#hyp3_sdk.exceptions.ASFSearchError","text":"Raise for errors when using the ASF Search module","title":"ASFSearchError"},{"location":"using/sdk_api/#hyp3_sdk.exceptions.AuthenticationError","text":"Raise when authentication does not succeed","title":"AuthenticationError"},{"location":"using/sdk_api/#hyp3_sdk.exceptions.HyP3Error","text":"Raise for errors when using the HyP3 module","title":"HyP3Error"},{"location":"using/sdk_api/#hyp3_sdk.exceptions.HyP3SDKError","text":"Base Exception for the HyP3 SDK","title":"HyP3SDKError"},{"location":"using/sdk_api/#hyp3_sdk.exceptions.ServerError","text":"Raise when the HyP3 SDK encounters a server error","title":"ServerError"},{"location":"using/sdk_api/#hyp3_sdk.hyp3","text":"","title":"hyp3"},{"location":"using/sdk_api/#hyp3_sdk.hyp3.HyP3","text":"A python wrapper around the HyP3 API","title":"HyP3"},{"location":"using/sdk_api/#hyp3_sdk.jobs","text":"","title":"jobs"},{"location":"using/sdk_api/#hyp3_sdk.jobs.Batch","text":"","title":"Batch"},{"location":"using/sdk_api/#hyp3_sdk.jobs.Job","text":"","title":"Job"},{"location":"using/sdk_api/#hyp3_sdk.util","text":"Extra utilities for working with HyP3","title":"util"},{"location":"using/sdk_api/#hyp3_sdk.util.download_file","text":"Download a file Parameters: Name Type Description Default url str URL of the file to download required filepath Union[pathlib.Path, str] Location to place file into required chunk_size Size to chunk the download into None retries Number of retries to attempt 2 backoff_factor Factor for calculating time between retries 1 Returns: Type Description Path download_path: The path to the downloaded file Source code in hyp3_sdk/util.py def download_file ( url : str , filepath : Union [ Path , str ], chunk_size = None , retries = 2 , backoff_factor = 1 ) -> Path : \"\"\"Download a file Args: url: URL of the file to download filepath: Location to place file into chunk_size: Size to chunk the download into retries: Number of retries to attempt backoff_factor: Factor for calculating time between retries Returns: download_path: The path to the downloaded file \"\"\" filepath = Path ( filepath ) session = requests . Session () retry_strategy = Retry ( total = retries , backoff_factor = backoff_factor , status_forcelist = [ 429 , 500 , 502 , 503 , 504 ], ) session . mount ( 'https://' , HTTPAdapter ( max_retries = retry_strategy )) session . mount ( 'http://' , HTTPAdapter ( max_retries = retry_strategy )) with session . get ( url , stream = True ) as s : s . raise_for_status () with tqdm . wrapattr ( open ( filepath , \"wb\" ), 'write' , miniters = 1 , desc = filepath . name , total = int ( s . headers . get ( 'content-length' , 0 ))) as f : for chunk in s . iter_content ( chunk_size = chunk_size ): if chunk : f . write ( chunk ) session . close () return filepath","title":"download_file()"},{"location":"using/sdk_api/#hyp3_sdk.util.get_authenticated_session","text":"Log into HyP3 using credentials for urs.earthdata.nasa.gov from either the provided credentials or a .netrc file. Returns: Type Description Session An authenticated HyP3 Session Source code in hyp3_sdk/util.py def get_authenticated_session ( username : str , password : str ) -> requests . Session : \"\"\"Log into HyP3 using credentials for `urs.earthdata.nasa.gov` from either the provided credentials or a `.netrc` file. Returns: An authenticated HyP3 Session \"\"\" s = requests . Session () if hyp3_sdk . TESTING : return s if username is not None and password is not None : response = s . get ( AUTH_URL , auth = ( username , password )) try : response . raise_for_status () except requests . HTTPError : raise AuthenticationError ( 'Was not able to authenticate with credentials provided \\n ' 'This could be due to invalid credentials or a connection error.' ) else : response = s . get ( AUTH_URL ) try : response . raise_for_status () except requests . HTTPError : raise AuthenticationError ( 'Was not able to authenticate with .netrc file and no credentials provided \\n ' 'This could be due to invalid credentials in .netrc or a connection error.' ) return s","title":"get_authenticated_session()"}]}