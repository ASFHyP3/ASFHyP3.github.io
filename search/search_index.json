{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ASF HyP3 \u00b6 Alaska Satellite Facility's Hybrid Pluggable Processing Pipeline HyP3 (pronounced \"hype\" ) is a service for processing Synthetic Aperture Radar (SAR) imagery that addresses many common issues for users of SAR data: Most SAR datasets require at least some processing to remove distortions before they are analysis-ready SAR processing is computing-intensive Software for SAR processing is complicated to use and/or prohibitively expensive Producing analysis-ready SAR data has a steep learning curve that acts as a barrier to entry HyP3 solves these problems by providing a free service where people can request SAR processing on-demand. These processing requests are picked up by automated systems, which handle the complexity of SAR processing on behalf of the user. HyP3 doesn't require users to have a lot of knowledge of SAR processing before getting started; users only need to submit the input data and set a few optional parameters if desired. With HyP3, analysis-ready products are just a few clicks away. Getting started \u00b6 On Demand products processed by HyP3 can be requested quickly and easily, either by using a web interface or programmatically. These services are currently only available for Sentinel-1 datasets . Web Access \u00b6 ASF's Data Search Vertex portal provides a rich interface to explore Sentinel-1 acquisitions and find images to submit for On Demand processing. It also provides tools for selecting pairs and stacks for InSAR analysis. Vertex Programmatic Access \u00b6 Requesting and downloading On Demand products can also be done programmatically: HyP3 SDK for Python HyP3 REST API Public Visibility of Jobs \u00b6 Warning All jobs submitted to HyP3, whether via web access or programmatic access, are publicly visible. Anyone with access to HyP3 can potentially: View your jobs and associated metadata, including job name and user ID. Download any products generated by your jobs. In particular, do not include any sensitive information in your job names. What's New \u00b6 Follow @ASFHyP3 on Twitter, or check our What's New page to keep up to date on all things HyP3! Contact Us \u00b6 Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? Open an issue General questions? Suggestions? Or just want to talk to the team? Chat with us on Gitter You can also reach us by email through ASF User Services: Email ASF User Services","title":"Home"},{"location":"#asf-hyp3","text":"Alaska Satellite Facility's Hybrid Pluggable Processing Pipeline HyP3 (pronounced \"hype\" ) is a service for processing Synthetic Aperture Radar (SAR) imagery that addresses many common issues for users of SAR data: Most SAR datasets require at least some processing to remove distortions before they are analysis-ready SAR processing is computing-intensive Software for SAR processing is complicated to use and/or prohibitively expensive Producing analysis-ready SAR data has a steep learning curve that acts as a barrier to entry HyP3 solves these problems by providing a free service where people can request SAR processing on-demand. These processing requests are picked up by automated systems, which handle the complexity of SAR processing on behalf of the user. HyP3 doesn't require users to have a lot of knowledge of SAR processing before getting started; users only need to submit the input data and set a few optional parameters if desired. With HyP3, analysis-ready products are just a few clicks away.","title":"ASF HyP3"},{"location":"#getting-started","text":"On Demand products processed by HyP3 can be requested quickly and easily, either by using a web interface or programmatically. These services are currently only available for Sentinel-1 datasets .","title":"Getting started"},{"location":"#web-access","text":"ASF's Data Search Vertex portal provides a rich interface to explore Sentinel-1 acquisitions and find images to submit for On Demand processing. It also provides tools for selecting pairs and stacks for InSAR analysis. Vertex","title":"Web Access"},{"location":"#programmatic-access","text":"Requesting and downloading On Demand products can also be done programmatically: HyP3 SDK for Python HyP3 REST API","title":"Programmatic Access"},{"location":"#public-visibility-of-jobs","text":"Warning All jobs submitted to HyP3, whether via web access or programmatic access, are publicly visible. Anyone with access to HyP3 can potentially: View your jobs and associated metadata, including job name and user ID. Download any products generated by your jobs. In particular, do not include any sensitive information in your job names.","title":"Public Visibility of Jobs"},{"location":"#whats-new","text":"Follow @ASFHyP3 on Twitter, or check our What's New page to keep up to date on all things HyP3!","title":"What's New"},{"location":"#contact-us","text":"Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? Open an issue General questions? Suggestions? Or just want to talk to the team? Chat with us on Gitter You can also reach us by email through ASF User Services: Email ASF User Services","title":"Contact Us"},{"location":"CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct \u00b6 Our Pledge \u00b6 We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socioeconomic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards \u00b6 Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities \u00b6 Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope \u00b6 This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement \u00b6 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement by emailing the ASF APD/Tools team at UAF-asf-apd@alaska.edu . All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines \u00b6 Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction \u00b6 Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning \u00b6 Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban \u00b6 Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban \u00b6 Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution \u00b6 This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Code of Conduct"},{"location":"CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socioeconomic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement by emailing the ASF APD/Tools team at UAF-asf-apd@alaska.edu . All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"citing-snippet/","text":"To reference HyP3 in manuscripts, cite our documentation available at ASF's hyp3-docs GitHub repository : Hogenson, K., Kristenson, H., Kennedy, J., Johnston, A., Rine, J., Logan, T., Zhu, J., Williams, F., Herrmann, J., Smale, J., & Meyer, F. (2020). Hybrid Pluggable Processing Pipeline (HyP3): A cloud-native infrastructure for generic processing of SAR data [Computer software]. https://doi.org/10.5281/zenodo.4646138","title":"Citing snippet"},{"location":"contact-snippet/","text":"Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? Open an issue General questions? Suggestions? Or just want to talk to the team? Chat with us on Gitter You can also reach us by email through ASF User Services: Email ASF User Services","title":"Contact snippet"},{"location":"contact/","text":"Contact Us \u00b6 Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? Open an issue General questions? Suggestions? Or just want to talk to the team? Chat with us on Gitter You can also reach us by email through ASF User Services: Email ASF User Services","title":"Contact Us"},{"location":"contact/#contact-us","text":"Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? Open an issue General questions? Suggestions? Or just want to talk to the team? Chat with us on Gitter You can also reach us by email through ASF User Services: Email ASF User Services","title":"Contact Us"},{"location":"contributing/","text":"Contributing \u00b6 Thank you for your interest in helping make custom on-demand SAR processing accessible! We're excited you would like to contribute to HyP3! Whether you're finding bugs, adding new features, fixing anything broken, or improving documentation, get started by submitting an issue or pull request! Please read our Code of Conduct before contributing. Issues and Pull Requests are welcome \u00b6 If you have any questions or ideas, or notice any problems or bugs, and want to open an issue, great! We recommend first searching our open issues to see if the issue has already been submitted (we may already be working on it!). If you think your issue is new, you're welcome to create a new issue in our general issues tracker. If you know the specific repository that your issue pertains to, you can use its issues tracker. Found a typo, know how to fix a bug, want to update the docs, want to add a new feature? Even better! The smaller the PR, the easier it is to review and test, and the more likely it is to be successful. For major contributions, consider opening an issue describing the contribution, so we can help guide and breakup the work into digestible pieces. Pull Request Guidelines \u00b6 We ask that you follow these guidelines with your contributions Style \u00b6 We generally follow python community standards ( PEP8 ), except we allow line lengths up to 120 characters. We recommend trying to keep lines 80--100 characters long, but allow up to 120 when it improves readability. Documentation \u00b6 We are working to improve our documentation! For all public-facing functions/methods (not marked internal use ), please include type hints (when reasonable) and a docstring formatted Google style . Tests \u00b6 All of the automated tests for the project need to pass before your submission will be accepted. If you add new functionality, please consider adding tests for that functionality as well. Commits \u00b6 Make small commits that show the individual changes you are making Write descriptive commit messages that explain your changes Example of a good commit message: Improve contributing guidelines. Fixes #10 Improve contributing docs and consolidate them in the standard location https://help.github.com/articles/setting-guidelines-for-repository-contributors/","title":"Contributing"},{"location":"contributing/#contributing","text":"Thank you for your interest in helping make custom on-demand SAR processing accessible! We're excited you would like to contribute to HyP3! Whether you're finding bugs, adding new features, fixing anything broken, or improving documentation, get started by submitting an issue or pull request! Please read our Code of Conduct before contributing.","title":"Contributing"},{"location":"contributing/#issues-and-pull-requests-are-welcome","text":"If you have any questions or ideas, or notice any problems or bugs, and want to open an issue, great! We recommend first searching our open issues to see if the issue has already been submitted (we may already be working on it!). If you think your issue is new, you're welcome to create a new issue in our general issues tracker. If you know the specific repository that your issue pertains to, you can use its issues tracker. Found a typo, know how to fix a bug, want to update the docs, want to add a new feature? Even better! The smaller the PR, the easier it is to review and test, and the more likely it is to be successful. For major contributions, consider opening an issue describing the contribution, so we can help guide and breakup the work into digestible pieces.","title":"Issues and Pull Requests are welcome"},{"location":"contributing/#pull-request-guidelines","text":"We ask that you follow these guidelines with your contributions","title":"Pull Request Guidelines"},{"location":"contributing/#style","text":"We generally follow python community standards ( PEP8 ), except we allow line lengths up to 120 characters. We recommend trying to keep lines 80--100 characters long, but allow up to 120 when it improves readability.","title":"Style"},{"location":"contributing/#documentation","text":"We are working to improve our documentation! For all public-facing functions/methods (not marked internal use ), please include type hints (when reasonable) and a docstring formatted Google style .","title":"Documentation"},{"location":"contributing/#tests","text":"All of the automated tests for the project need to pass before your submission will be accepted. If you add new functionality, please consider adding tests for that functionality as well.","title":"Tests"},{"location":"contributing/#commits","text":"Make small commits that show the individual changes you are making Write descriptive commit messages that explain your changes Example of a good commit message: Improve contributing guidelines. Fixes #10 Improve contributing docs and consolidate them in the standard location https://help.github.com/articles/setting-guidelines-for-repository-contributors/","title":"Commits"},{"location":"dems/","text":"Digital Elevation Models \u00b6 Digital Elevation Models are required when processing SAR data to higher-level products, such as the Radiometric Terrain Correction (RTC) and Interferometric SAR (InSAR) products available On Demand from ASF. ASF uses DEMs that are publicly available and have wide-ranging coverage. In the past, ASF maintained a collection of DEMs that were pre-processed as appropriate for SAR workflows, and applied a preference hierarchy so that the best available DEM in any given area would be automatically selected for processing. With the public release of the GLO-30 Copernicus DEM , we have changed our default DEM strategy to leverage a cloud-hosted copy of the global Copernicus DEM. This is now the default DEM for processing RTC products, and the only option available for processing InSAR products. Users still have the option to use the legacy DEMs when processing RTC jobs On Demand in Vertex and when using the API or SDK , but we recommend using the Copernicus DEM whenever possible. Deprecation of Legacy DEMs for RTC Processing We are considering eliminating the option to use our legacy DEM dataset (NED/SRTM) as a HyP3 processing option for RTC. We would value your feedback as we decide if we will make this change. How would you be impacted if the NED/SRTM DEM option was no longer available? Would it affect your current workflows? Please send your feedback to uso@asf.alaska.edu . We use the 2022 Release of the Copernicus GLO-30 Public DEM , available on AWS . For more information, see the 'Releases' section of this article . Coverage gaps in Copernicus DEM GLO-30 filled using GLO-90 The Copernicus DEM GLO-30 dataset does not provide coverage over Armenia and Azerbaijan. In the past, we have not supported On Demand product generation over those areas, due to the lack of DEM coverage. We now use the Copernicus DEM GLO-90 to fill those gaps. The GLO-90 dataset has a pixel spacing of 90 meters, which is not as detailed as the 30-m pixel spacing in the GLO-30 DEM, but it does allow us to provide On Demand products in these regions, where they were previously unavailable. Table 1 summarizes ASF's DEM sources. Note that in all cases the DEM is reprojected to the UTM Zone (WGS84) appropriate for the granule location, and a geoid correction is applied before being used for processing. For RTC processing, the DEM is resampled to the pixel spacing of the output product. The Copernicus DEM is the only option available for InSAR processing, and the DEM is resampled to twice the pixel spacing of the output InSAR product (160 m for 20x4 looks, 80 m for 10x2 looks). Resolution DEM Vertical Datum Area Posting Priority Medium GLO-30 EGM2008 Global 1 arc second Default High NED13 NAVD88 CONUS, Hawaii, parts of Alaska 1/3 arc seconds 1 Medium SRTMGL1 EGM96 60 N to 57 S latitude 1 arc second 2 Medium NED1 NAVD88 Canada 1 arc second 3 Low NED2 NAVD88 Parts of Alaska 2 arc seconds 4 Table 1: DEMs used for On Demand processing. For RTC products, the Copernicus 30 m DEM is the default, while the other four DEMs are only used if the legacy option is invoked. The Copernicus DEM is the only option available when processing InSAR products. When ordering On-Demand products, you can choose to include a copy of the DEM used for processing in the output product package. For RTC products, this DEM copy is converted to 16-bit signed integer format, but is otherwise the same as the DEM used in the RTC process. For InSAR products, the DEM copy is output in 32-bit float format, and is upsampled from the DEM resolution used for processing to match the pixel spacing of the output InSAR products. Note that the height values will differ from the original source DEM in all cases, due to the geoid correction applied to prepare the DEM for use in SAR processing. Copernicus DEM \u00b6 The GLO-30 Copernicus DEM provides global coverage at 30-m pixel spacing (with the current exception of an area covering Armenia and Azerbaijan, see Figure 2). When an On Demand job is requested, we download the required DEM tiles from the Copernicus Digital Elevation Model (DEM) GLO-30 Public dataset available in the Registry of Open Data on AWS , managed by Sinergise . We mosaic the tiles and reproject them to the appropriate UTM Zone for the location of the SAR granule to be processed, resampling them as required for processing. A geoid correction is applied before it is used for On Demand processing. For the area that does not have coverage with the GLO-30 DEM, we use the Copernicus DEM GLO-90 dataset, which provides elevation data at 90-meter pixel spacing. Users ordering products over this area should be aware that a lower-resolution DEM is used for processing. Figure 1 shows the coverage of the Copernicus DEM GLO-30 Public dataset, and Figure 2 details the land area currently only covered by the GLO-30 DEM at 90-m pixel spacing. Figure 1: Copernicus DEM GLO-30 coverage map Figure 2: Detail of area currently not covered by Copernicus DEM GLO-30. On Demand jobs requested over this area will use the Copernicus DEM GLO-90. Legacy DEMs \u00b6 Deprecation of Legacy DEMs for RTC Processing We are considering eliminating the option to use our legacy DEM dataset (NED/SRTM) as a HyP3 processing option for RTC. We would value your feedback as we decide if we will make this change. How would you be impacted if the NED/SRTM DEM option was no longer available? Would it affect your current workflows? Please send your feedback to uso@asf.alaska.edu . The legacy DEMs were pre-processed by ASF to a consistent raster format (GeoTIFF) from the original source formats: height (*.hgt), ESRI ArcGrid (*.adf), etc. Many of the NASA-provided DEMs were provided as orthometric heights with EGM96 vertical datum. These were converted by ASF to ellipsoid heights using the ASF MapReady tool named geoid_adjust . The pixel reference varied from the center (pixel as point) to a corner (pixel as area). The GAMMA software, used to generate the terrain corrected products, uses pixel as area and adjusts DEM coordinates as needed. These processed DEM collections are stored by ASF in AWS. When an On Demand job is requested, the best-available DEM covering the SAR granule is selected, and the necessary tiles are reprojected to a mosaic in the UTM Zone appropriate for the granule location. If legacy DEM processing is selected, one of the following DEMs will be used: The National Elevation Dataset (NED) \u2153 arc second (about 10 m resolution) DEM covers the continental U.S. (CONUS), Hawaii, and parts of Alaska. Shuttle Radar Topography Mission (SRTM) GL1 data at 30 m resolution is used where NED 13 is not available. 1 arc second NED gives coverage of Canada at about 30 m resolution. 2 arc second NED (about 60 m) covers the remaining parts of Alaska above 60 degrees northern latitude. Since more than one DEM may be available in legacy processing, DEMs are selected in priority order as listed in Table 1. DEM coverage of at least 20% from a single DEM source is required for legacy processing to proceed. In no case will the DEM selected be from more than one source; only the single best source of terrain height values is used for a given scene. Figure 3 shows the coverage of the various legacy DEM sources. Figure 3: Coverage of the various legacy DEM sources used for terrain correction Special Use DEMs \u00b6 AutoRIFT , a process developed by the NASA MEaSUREs ITS_LIVE project, uses custom Greenland and Antarctica DEMs with 240-m resolution. The DEM, associated process input files, and their details are available on the ITS_LIVE project website .","title":"Digital Elevation Models"},{"location":"dems/#digital-elevation-models","text":"Digital Elevation Models are required when processing SAR data to higher-level products, such as the Radiometric Terrain Correction (RTC) and Interferometric SAR (InSAR) products available On Demand from ASF. ASF uses DEMs that are publicly available and have wide-ranging coverage. In the past, ASF maintained a collection of DEMs that were pre-processed as appropriate for SAR workflows, and applied a preference hierarchy so that the best available DEM in any given area would be automatically selected for processing. With the public release of the GLO-30 Copernicus DEM , we have changed our default DEM strategy to leverage a cloud-hosted copy of the global Copernicus DEM. This is now the default DEM for processing RTC products, and the only option available for processing InSAR products. Users still have the option to use the legacy DEMs when processing RTC jobs On Demand in Vertex and when using the API or SDK , but we recommend using the Copernicus DEM whenever possible. Deprecation of Legacy DEMs for RTC Processing We are considering eliminating the option to use our legacy DEM dataset (NED/SRTM) as a HyP3 processing option for RTC. We would value your feedback as we decide if we will make this change. How would you be impacted if the NED/SRTM DEM option was no longer available? Would it affect your current workflows? Please send your feedback to uso@asf.alaska.edu . We use the 2022 Release of the Copernicus GLO-30 Public DEM , available on AWS . For more information, see the 'Releases' section of this article . Coverage gaps in Copernicus DEM GLO-30 filled using GLO-90 The Copernicus DEM GLO-30 dataset does not provide coverage over Armenia and Azerbaijan. In the past, we have not supported On Demand product generation over those areas, due to the lack of DEM coverage. We now use the Copernicus DEM GLO-90 to fill those gaps. The GLO-90 dataset has a pixel spacing of 90 meters, which is not as detailed as the 30-m pixel spacing in the GLO-30 DEM, but it does allow us to provide On Demand products in these regions, where they were previously unavailable. Table 1 summarizes ASF's DEM sources. Note that in all cases the DEM is reprojected to the UTM Zone (WGS84) appropriate for the granule location, and a geoid correction is applied before being used for processing. For RTC processing, the DEM is resampled to the pixel spacing of the output product. The Copernicus DEM is the only option available for InSAR processing, and the DEM is resampled to twice the pixel spacing of the output InSAR product (160 m for 20x4 looks, 80 m for 10x2 looks). Resolution DEM Vertical Datum Area Posting Priority Medium GLO-30 EGM2008 Global 1 arc second Default High NED13 NAVD88 CONUS, Hawaii, parts of Alaska 1/3 arc seconds 1 Medium SRTMGL1 EGM96 60 N to 57 S latitude 1 arc second 2 Medium NED1 NAVD88 Canada 1 arc second 3 Low NED2 NAVD88 Parts of Alaska 2 arc seconds 4 Table 1: DEMs used for On Demand processing. For RTC products, the Copernicus 30 m DEM is the default, while the other four DEMs are only used if the legacy option is invoked. The Copernicus DEM is the only option available when processing InSAR products. When ordering On-Demand products, you can choose to include a copy of the DEM used for processing in the output product package. For RTC products, this DEM copy is converted to 16-bit signed integer format, but is otherwise the same as the DEM used in the RTC process. For InSAR products, the DEM copy is output in 32-bit float format, and is upsampled from the DEM resolution used for processing to match the pixel spacing of the output InSAR products. Note that the height values will differ from the original source DEM in all cases, due to the geoid correction applied to prepare the DEM for use in SAR processing.","title":"Digital Elevation Models"},{"location":"dems/#copernicus-dem","text":"The GLO-30 Copernicus DEM provides global coverage at 30-m pixel spacing (with the current exception of an area covering Armenia and Azerbaijan, see Figure 2). When an On Demand job is requested, we download the required DEM tiles from the Copernicus Digital Elevation Model (DEM) GLO-30 Public dataset available in the Registry of Open Data on AWS , managed by Sinergise . We mosaic the tiles and reproject them to the appropriate UTM Zone for the location of the SAR granule to be processed, resampling them as required for processing. A geoid correction is applied before it is used for On Demand processing. For the area that does not have coverage with the GLO-30 DEM, we use the Copernicus DEM GLO-90 dataset, which provides elevation data at 90-meter pixel spacing. Users ordering products over this area should be aware that a lower-resolution DEM is used for processing. Figure 1 shows the coverage of the Copernicus DEM GLO-30 Public dataset, and Figure 2 details the land area currently only covered by the GLO-30 DEM at 90-m pixel spacing. Figure 1: Copernicus DEM GLO-30 coverage map Figure 2: Detail of area currently not covered by Copernicus DEM GLO-30. On Demand jobs requested over this area will use the Copernicus DEM GLO-90.","title":"Copernicus DEM"},{"location":"dems/#legacy-dems","text":"Deprecation of Legacy DEMs for RTC Processing We are considering eliminating the option to use our legacy DEM dataset (NED/SRTM) as a HyP3 processing option for RTC. We would value your feedback as we decide if we will make this change. How would you be impacted if the NED/SRTM DEM option was no longer available? Would it affect your current workflows? Please send your feedback to uso@asf.alaska.edu . The legacy DEMs were pre-processed by ASF to a consistent raster format (GeoTIFF) from the original source formats: height (*.hgt), ESRI ArcGrid (*.adf), etc. Many of the NASA-provided DEMs were provided as orthometric heights with EGM96 vertical datum. These were converted by ASF to ellipsoid heights using the ASF MapReady tool named geoid_adjust . The pixel reference varied from the center (pixel as point) to a corner (pixel as area). The GAMMA software, used to generate the terrain corrected products, uses pixel as area and adjusts DEM coordinates as needed. These processed DEM collections are stored by ASF in AWS. When an On Demand job is requested, the best-available DEM covering the SAR granule is selected, and the necessary tiles are reprojected to a mosaic in the UTM Zone appropriate for the granule location. If legacy DEM processing is selected, one of the following DEMs will be used: The National Elevation Dataset (NED) \u2153 arc second (about 10 m resolution) DEM covers the continental U.S. (CONUS), Hawaii, and parts of Alaska. Shuttle Radar Topography Mission (SRTM) GL1 data at 30 m resolution is used where NED 13 is not available. 1 arc second NED gives coverage of Canada at about 30 m resolution. 2 arc second NED (about 60 m) covers the remaining parts of Alaska above 60 degrees northern latitude. Since more than one DEM may be available in legacy processing, DEMs are selected in priority order as listed in Table 1. DEM coverage of at least 20% from a single DEM source is required for legacy processing to proceed. In no case will the DEM selected be from more than one source; only the single best source of terrain height values is used for a given scene. Figure 3 shows the coverage of the various legacy DEM sources. Figure 3: Coverage of the various legacy DEM sources used for terrain correction","title":"Legacy DEMs"},{"location":"dems/#special-use-dems","text":"AutoRIFT , a process developed by the NASA MEaSUREs ITS_LIVE project, uses custom Greenland and Antarctica DEMs with 240-m resolution. The DEM, associated process input files, and their details are available on the ITS_LIVE project website .","title":"Special Use DEMs"},{"location":"how_it_works/","text":"How it Works \u00b6 HyP3 is built around three core concepts: Platform, Plugins, and Products. Platform \u00b6 The HyP3 platform makes it easy for users to request processing, monitor their requests, and download processed products. The platform delegates each processing request to a plugin on the user's behalf. A deployment of the HyP3 platform can be integrated with any number of plugins. Plugins \u00b6 Plugins are the workhorses of HyP3. Each plugin implements a particular processing workflow and produces a product. At their most basic level, HyP3 plugins are Docker containers that handle the entire processing workflow for a single product, including: Marshaling the required input data performing any needed transformations and computations on the data creating the final product uploading the product to an AWS S3 bucket for distribution Plugins only need to define a simple interface (entrypoint) that HyP3 understands and is used to run the container. By encapsulating the entire workflow for generating a single product, HyP3 can arbitrarily scale to meet user need. Products \u00b6 Products are the end result of processing, typically one or more data files. For more information about our current products, see our products page .","title":"Architecture"},{"location":"how_it_works/#how-it-works","text":"HyP3 is built around three core concepts: Platform, Plugins, and Products.","title":"How it Works"},{"location":"how_it_works/#platform","text":"The HyP3 platform makes it easy for users to request processing, monitor their requests, and download processed products. The platform delegates each processing request to a plugin on the user's behalf. A deployment of the HyP3 platform can be integrated with any number of plugins.","title":"Platform"},{"location":"how_it_works/#plugins","text":"Plugins are the workhorses of HyP3. Each plugin implements a particular processing workflow and produces a product. At their most basic level, HyP3 plugins are Docker containers that handle the entire processing workflow for a single product, including: Marshaling the required input data performing any needed transformations and computations on the data creating the final product uploading the product to an AWS S3 bucket for distribution Plugins only need to define a simple interface (entrypoint) that HyP3 understands and is used to run the container. By encapsulating the entire workflow for generating a single product, HyP3 can arbitrarily scale to meet user need.","title":"Plugins"},{"location":"how_it_works/#products","text":"Products are the end result of processing, typically one or more data files. For more information about our current products, see our products page .","title":"Products"},{"location":"plugins/","text":"Plugins \u00b6 Plugins are the science backbone of HyP3; they do all of the data processing and product generation. Plugins can be added to HyP3 to generate new science products, or support different tools/software/algorithms/options/etc that are not currently supported by HyP3. How plugins work \u00b6 At their most basic level, HyP3 plugins are Docker containers with an interface (entrypoint) HyP3 understands. Plugins handle the entire processing workflow for a single product, including: Marshaling the required input data performing any needed transformations and computations on the data creating the final product uploading the product to an AWS S3 bucket for distribution By encapsulating the entire workflow for generating a single product, HyP3 can arbitrarily scale to meet user need. Developing a plugin \u00b6 To create a new HyP3 plugin, we recommend starting from a Minimal Working Example (MWE) of generating the product you're plugin will generate. Importantly, the MWE should be entirely self contained, and include all the necessary data to generate the product. Once a MWE is developed, it's important to define your plugin's interface -- this is where HyP3 connects the product generation and users. When designing the interface, you may find it helpful to ask yourself: what options do I want to provide to users? what's the minimal set information I need to gather from users? is this information easily input by users? is this information serializable? For example, can the information be written in a JSON file? could I define this information more simply? Once a MWE is developed and an interface is defined, you can use our HyP3 plugin cookiecutter to help you build a plugin that conforms to the plugin requirements. Plugin requirements \u00b6 In order to be supported by HyP3, a plugin must meet a few requirements: the plugin must be a Docker image that is hosted in a repository where HyP3 will be able to pull it the plugin's entrypoint must minimally accept the following arguments --bucket BUCKET-NAME where BUCKET-NAME is the name of an AWS S3 bucket that output products will be uploaded to --bucket-prefix BUCKET-PREFIX where BUCKET-PREFIX is a string appended to the key of any file uploaded to AWS S3 (this is effectively a subfolder in AWS S3) --username USER where USER is the username used to authenticate to Earthdata Login --password PASSWORD where PASSWORD is the password used to authenticate to Earthdata Login any necessary user input should be able to be provided through entrypoint arguments when uploading files to the S3 Bucket products files must be tagged with filetype: product if you wish to upload thumbnails or browse images, they must be tagged filetype: thumbnail or filetype: browse respectively Note: the aws subpackage of hyp3lib provides helper functions for tagging and uploading files Add the plugin to HyP3 \u00b6 Once the plugin itself is created, it can be added to the HyP3 system by... TBD.","title":"Plugins"},{"location":"plugins/#plugins","text":"Plugins are the science backbone of HyP3; they do all of the data processing and product generation. Plugins can be added to HyP3 to generate new science products, or support different tools/software/algorithms/options/etc that are not currently supported by HyP3.","title":"Plugins"},{"location":"plugins/#how-plugins-work","text":"At their most basic level, HyP3 plugins are Docker containers with an interface (entrypoint) HyP3 understands. Plugins handle the entire processing workflow for a single product, including: Marshaling the required input data performing any needed transformations and computations on the data creating the final product uploading the product to an AWS S3 bucket for distribution By encapsulating the entire workflow for generating a single product, HyP3 can arbitrarily scale to meet user need.","title":"How plugins work"},{"location":"plugins/#developing-a-plugin","text":"To create a new HyP3 plugin, we recommend starting from a Minimal Working Example (MWE) of generating the product you're plugin will generate. Importantly, the MWE should be entirely self contained, and include all the necessary data to generate the product. Once a MWE is developed, it's important to define your plugin's interface -- this is where HyP3 connects the product generation and users. When designing the interface, you may find it helpful to ask yourself: what options do I want to provide to users? what's the minimal set information I need to gather from users? is this information easily input by users? is this information serializable? For example, can the information be written in a JSON file? could I define this information more simply? Once a MWE is developed and an interface is defined, you can use our HyP3 plugin cookiecutter to help you build a plugin that conforms to the plugin requirements.","title":"Developing a plugin"},{"location":"plugins/#plugin-requirements","text":"In order to be supported by HyP3, a plugin must meet a few requirements: the plugin must be a Docker image that is hosted in a repository where HyP3 will be able to pull it the plugin's entrypoint must minimally accept the following arguments --bucket BUCKET-NAME where BUCKET-NAME is the name of an AWS S3 bucket that output products will be uploaded to --bucket-prefix BUCKET-PREFIX where BUCKET-PREFIX is a string appended to the key of any file uploaded to AWS S3 (this is effectively a subfolder in AWS S3) --username USER where USER is the username used to authenticate to Earthdata Login --password PASSWORD where PASSWORD is the password used to authenticate to Earthdata Login any necessary user input should be able to be provided through entrypoint arguments when uploading files to the S3 Bucket products files must be tagged with filetype: product if you wish to upload thumbnails or browse images, they must be tagged filetype: thumbnail or filetype: browse respectively Note: the aws subpackage of hyp3lib provides helper functions for tagging and uploading files","title":"Plugin requirements"},{"location":"plugins/#add-the-plugin-to-hyp3","text":"Once the plugin itself is created, it can be added to the HyP3 system by... TBD.","title":"Add the plugin to HyP3"},{"location":"products/","text":"Available HyP3 Products \u00b6 On-demand SAR products generated using HyP3 are currently available for the Sentinel-1 mission only. RTC \u00b6 SAR datasets inherently contain geometric and radiometric distortions due to terrain being imaged by a side-looking instrument. Radiometric Terrain Correction (RTC) removes these distortions and creates analysis-ready data suitable for use in GIS applications. RTC processing is a required first step for many amplitude-based SAR applications. Sentinel-1 RTC products are generated leveraging GAMMA Software. Products are distributed as UTM-projected GeoTIFFs with a pixel spacing of either 10 or 30 meters . To learn more, refer to our ASF Sentinel-1 RTC Product Guide . For step-by-step instructions for searching for, ordering, downloading and using On Demand RTC products, visit our RTC On Demand! tutorial. A Digital Elevation Model (DEM) is required for processing RTC. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, refer to our Digital Elevation Models documentation. InSAR \u00b6 Interferometric SAR (InSAR) uses the phase differences from repeat passes over the same area to identify regions where the distance between the sensor and the Earth's surface has changed. This allows for the detection and quantification of deformation or movement. To learn more, refer to our ASF Sentinel-1 InSAR Product Guide . Use caution when generating interferograms for areas with extensive/dense vegetation cover. Because Sentinel-1 is a C-band sensor, the waves will not penetrate very deeply into vegetation. Imagery of densely vegetated areas likely represents the top of the canopy rather than the actual terrain. In addition, vegetated areas tend to have low coherence, because plants can grow or move from one acquisition to the next. For step-by-step instructions for searching for, ordering and downloading On Demand InSAR products, visit our InSAR On Demand! tutorial. A Digital Elevation Model (DEM) is required for processing InSAR. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, refer to our Digital Elevation Models documentation. autoRIFT \u00b6 AutoRIFT produces a velocity map from observed motion using a feature tracking algorithm developed as part of the NASA MEaSUREs ITS_LIVE project. To learn more, visit the ITS_LIVE project website . A Digital Elevation Model (DEM) is required for autoRIFT processing. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, refer to our Digital Elevation Models documentation.","title":"Products"},{"location":"products/#available-hyp3-products","text":"On-demand SAR products generated using HyP3 are currently available for the Sentinel-1 mission only.","title":"Available HyP3 Products"},{"location":"products/#rtc","text":"SAR datasets inherently contain geometric and radiometric distortions due to terrain being imaged by a side-looking instrument. Radiometric Terrain Correction (RTC) removes these distortions and creates analysis-ready data suitable for use in GIS applications. RTC processing is a required first step for many amplitude-based SAR applications. Sentinel-1 RTC products are generated leveraging GAMMA Software. Products are distributed as UTM-projected GeoTIFFs with a pixel spacing of either 10 or 30 meters . To learn more, refer to our ASF Sentinel-1 RTC Product Guide . For step-by-step instructions for searching for, ordering, downloading and using On Demand RTC products, visit our RTC On Demand! tutorial. A Digital Elevation Model (DEM) is required for processing RTC. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, refer to our Digital Elevation Models documentation.","title":"RTC"},{"location":"products/#insar","text":"Interferometric SAR (InSAR) uses the phase differences from repeat passes over the same area to identify regions where the distance between the sensor and the Earth's surface has changed. This allows for the detection and quantification of deformation or movement. To learn more, refer to our ASF Sentinel-1 InSAR Product Guide . Use caution when generating interferograms for areas with extensive/dense vegetation cover. Because Sentinel-1 is a C-band sensor, the waves will not penetrate very deeply into vegetation. Imagery of densely vegetated areas likely represents the top of the canopy rather than the actual terrain. In addition, vegetated areas tend to have low coherence, because plants can grow or move from one acquisition to the next. For step-by-step instructions for searching for, ordering and downloading On Demand InSAR products, visit our InSAR On Demand! tutorial. A Digital Elevation Model (DEM) is required for processing InSAR. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, refer to our Digital Elevation Models documentation.","title":"InSAR"},{"location":"products/#autorift","text":"AutoRIFT produces a velocity map from observed motion using a feature tracking algorithm developed as part of the NASA MEaSUREs ITS_LIVE project. To learn more, visit the ITS_LIVE project website . A Digital Elevation Model (DEM) is required for autoRIFT processing. ASF uses the best publicly-available DEM with full coverage of the processing area. To learn more, refer to our Digital Elevation Models documentation.","title":"autoRIFT"},{"location":"sentinel1/","text":"Sentinel-1 Mission \u00b6 The Sentinel-1 satellite constellation is part of the Copernicus Earth Observation program, coordinated by the European Space Agency (ESA) on behalf of the European Commission (EC). Sentinel-1 satellites carry C-band Synthetic Aperture Radar (SAR) instruments for global, around-the-clock imagery acquisition, even through cloud cover. More information about the mission is available from the European Space Agency Sentinel-1 Mission website . The Sentinel-1 Constellation \u00b6 The Sentinel-1A satellite was launched April 3, 2014, and the Sentinel-1B satellite was launched April 25, 2016. The satellites each have a 12-day repeat cycle and use the same orbit pattern, but are offset 180 degrees to allow repeat passes every 6 days. While both satellites were actively imaging, most global landmasses were imaged every 12 days. Some areas of particular interest to the EC, including Europe and areas undergoing rapid changes due to uplift or subsidence activity, were imaged every 6 days. Refer to the Sentinel-1 Observation Scenario for more information on the acquisition plan used while both satellites were actively acquiring data. Mission Ends for Sentinel-1B \u00b6 Sentinel-1B no longer acquiring data As of December 23, 2021, Sentinel-1B is no longer able to acquire data. An anomaly related to the power supply cannot be repaired, and the satellite will be decommissioned. Refer to ESA's documentation of the end of the Sentinel-1B mission for more information. While Sentinel-1A is still healthy, the loss of Sentinel-1B has resulted in a significant reduction in the spatial and temporal coverage of the Sentinel-1 mission. Refer to this article by Iain Woodhouse for an illustration of the global impact of the Sentinel-1B failure. The image below illustrates a gap in the acquisitions over Alaska. This area of the Yukon-Kuskokwim Delta did not have a Sentinel-1 acquisition during the summer of 2022 until August 15. The good news is that Sentinel-1C is waiting in the wings, and launch is anticipated in 2023. This satellite will replace Sentinel-1B, but until that is in place, there will continue to be reduced coverage. The gaps in coverage were particularly noticeable the first few months after Sentinel-1B lost power, but there are still some areas with little to no coverage. Keep this in mind as you search for data in your area of interest. If there are fewer results than you would expect, you can download current acquisition plans for the mission from ESA to view the acquisition plan for your area and time period of interest.","title":"Sentinel-1 Mission"},{"location":"sentinel1/#sentinel-1-mission","text":"The Sentinel-1 satellite constellation is part of the Copernicus Earth Observation program, coordinated by the European Space Agency (ESA) on behalf of the European Commission (EC). Sentinel-1 satellites carry C-band Synthetic Aperture Radar (SAR) instruments for global, around-the-clock imagery acquisition, even through cloud cover. More information about the mission is available from the European Space Agency Sentinel-1 Mission website .","title":"Sentinel-1 Mission"},{"location":"sentinel1/#the-sentinel-1-constellation","text":"The Sentinel-1A satellite was launched April 3, 2014, and the Sentinel-1B satellite was launched April 25, 2016. The satellites each have a 12-day repeat cycle and use the same orbit pattern, but are offset 180 degrees to allow repeat passes every 6 days. While both satellites were actively imaging, most global landmasses were imaged every 12 days. Some areas of particular interest to the EC, including Europe and areas undergoing rapid changes due to uplift or subsidence activity, were imaged every 6 days. Refer to the Sentinel-1 Observation Scenario for more information on the acquisition plan used while both satellites were actively acquiring data.","title":"The Sentinel-1 Constellation"},{"location":"sentinel1/#mission-ends-for-sentinel-1b","text":"Sentinel-1B no longer acquiring data As of December 23, 2021, Sentinel-1B is no longer able to acquire data. An anomaly related to the power supply cannot be repaired, and the satellite will be decommissioned. Refer to ESA's documentation of the end of the Sentinel-1B mission for more information. While Sentinel-1A is still healthy, the loss of Sentinel-1B has resulted in a significant reduction in the spatial and temporal coverage of the Sentinel-1 mission. Refer to this article by Iain Woodhouse for an illustration of the global impact of the Sentinel-1B failure. The image below illustrates a gap in the acquisitions over Alaska. This area of the Yukon-Kuskokwim Delta did not have a Sentinel-1 acquisition during the summer of 2022 until August 15. The good news is that Sentinel-1C is waiting in the wings, and launch is anticipated in 2023. This satellite will replace Sentinel-1B, but until that is in place, there will continue to be reduced coverage. The gaps in coverage were particularly noticeable the first few months after Sentinel-1B lost power, but there are still some areas with little to no coverage. Keep this in mind as you search for data in your area of interest. If there are fewer results than you would expect, you can download current acquisition plans for the mission from ESA to view the acquisition plan for your area and time period of interest.","title":"Mission Ends for Sentinel-1B"},{"location":"tutorials/","text":"HyP3 Tutorials \u00b6 Jupyter Notebooks \u00b6 We provide step-by-step tutorials for using HyP3 programmatically via Jupyter Notebooks. Using the HyP3 Python SDK -- This notebook walks through ordering and accessing RTC, InSAR, and autoRIFT products in Python using the HyP3 SDK. Using the HyP3 SDK to search for jobs run by another user -- This notebook walks through using the HyP3 SDK to search for jobs run by another user. Using the HyP3 SDK to process new granules for given search parameters -- These notebooks demonstrate how to process new granules that match particular search parameters, which is particularly useful for ongoing monitoring of a geographic area of interest. Time series analysis with HyP3 and MintPy -- This notebook walks through performing a time-series analysis of the 2019 Ridgecrest, CA earthquake with HyP3 On Demand InSAR products and MintPy. StoryMaps \u00b6 ASF provides a variety of interactive StoryMap tutorials focused on accessing and using Synthetic Aperture Radar (SAR) data available from ASF. They can all be accessed here: StoryMap Tutorials The StoryMap collection includes step-by-step tutorials for ordering and accessing RTC and InSAR products in Vertex.","title":"Tutorials"},{"location":"tutorials/#hyp3-tutorials","text":"","title":"HyP3 Tutorials"},{"location":"tutorials/#jupyter-notebooks","text":"We provide step-by-step tutorials for using HyP3 programmatically via Jupyter Notebooks. Using the HyP3 Python SDK -- This notebook walks through ordering and accessing RTC, InSAR, and autoRIFT products in Python using the HyP3 SDK. Using the HyP3 SDK to search for jobs run by another user -- This notebook walks through using the HyP3 SDK to search for jobs run by another user. Using the HyP3 SDK to process new granules for given search parameters -- These notebooks demonstrate how to process new granules that match particular search parameters, which is particularly useful for ongoing monitoring of a geographic area of interest. Time series analysis with HyP3 and MintPy -- This notebook walks through performing a time-series analysis of the 2019 Ridgecrest, CA earthquake with HyP3 On Demand InSAR products and MintPy.","title":"Jupyter Notebooks"},{"location":"tutorials/#storymaps","text":"ASF provides a variety of interactive StoryMap tutorials focused on accessing and using Synthetic Aperture Radar (SAR) data available from ASF. They can all be accessed here: StoryMap Tutorials The StoryMap collection includes step-by-step tutorials for ordering and accessing RTC and InSAR products in Vertex.","title":"StoryMaps"},{"location":"usage_guidelines/","text":"Product Usage Guidelines \u00b6 When using this data in a publication or presentation, we ask that you include the acknowledgement provided with each product. DOIs are also provided for citation when discussing the HyP3 software or plugins. For multi-file products, the acknowledgement and relevant DOIs are included in the *.README.md.txt file. For netCDF products, the acknowledgement is included in the source global attribute and the DOIs are included in the references global attribute. To reference HyP3 in manuscripts, cite our documentation available at ASF's hyp3-docs GitHub repository : Hogenson, K., Kristenson, H., Kennedy, J., Johnston, A., Rine, J., Logan, T., Zhu, J., Williams, F., Herrmann, J., Smale, J., & Meyer, F. (2020). Hybrid Pluggable Processing Pipeline (HyP3): A cloud-native infrastructure for generic processing of SAR data [Computer software]. https://doi.org/10.5281/zenodo.4646138","title":"Usage Guidelines"},{"location":"usage_guidelines/#product-usage-guidelines","text":"When using this data in a publication or presentation, we ask that you include the acknowledgement provided with each product. DOIs are also provided for citation when discussing the HyP3 software or plugins. For multi-file products, the acknowledgement and relevant DOIs are included in the *.README.md.txt file. For netCDF products, the acknowledgement is included in the source global attribute and the DOIs are included in the references global attribute. To reference HyP3 in manuscripts, cite our documentation available at ASF's hyp3-docs GitHub repository : Hogenson, K., Kristenson, H., Kennedy, J., Johnston, A., Rine, J., Logan, T., Zhu, J., Williams, F., Herrmann, J., Smale, J., & Meyer, F. (2020). Hybrid Pluggable Processing Pipeline (HyP3): A cloud-native infrastructure for generic processing of SAR data [Computer software]. https://doi.org/10.5281/zenodo.4646138","title":"Product Usage Guidelines"},{"location":"using-snippet/","text":"On Demand products processed by HyP3 can be requested quickly and easily, either by using a web interface or programmatically. These services are currently only available for Sentinel-1 datasets . Web Access \u00b6 ASF's Data Search Vertex portal provides a rich interface to explore Sentinel-1 acquisitions and find images to submit for On Demand processing. It also provides tools for selecting pairs and stacks for InSAR analysis. Vertex Programmatic Access \u00b6 Requesting and downloading On Demand products can also be done programmatically: HyP3 SDK for Python HyP3 REST API Public Visibility of Jobs \u00b6 Warning All jobs submitted to HyP3, whether via web access or programmatic access, are publicly visible. Anyone with access to HyP3 can potentially: View your jobs and associated metadata, including job name and user ID. Download any products generated by your jobs. In particular, do not include any sensitive information in your job names.","title":"Using snippet"},{"location":"using-snippet/#web-access","text":"ASF's Data Search Vertex portal provides a rich interface to explore Sentinel-1 acquisitions and find images to submit for On Demand processing. It also provides tools for selecting pairs and stacks for InSAR analysis. Vertex","title":"Web Access"},{"location":"using-snippet/#programmatic-access","text":"Requesting and downloading On Demand products can also be done programmatically: HyP3 SDK for Python HyP3 REST API","title":"Programmatic Access"},{"location":"using-snippet/#public-visibility-of-jobs","text":"Warning All jobs submitted to HyP3, whether via web access or programmatic access, are publicly visible. Anyone with access to HyP3 can potentially: View your jobs and associated metadata, including job name and user ID. Download any products generated by your jobs. In particular, do not include any sensitive information in your job names.","title":"Public Visibility of Jobs"},{"location":"using/","text":"Using ASF HyP3 \u00b6 On Demand products processed by HyP3 can be requested quickly and easily, either by using a web interface or programmatically. These services are currently only available for Sentinel-1 datasets . Web Access \u00b6 ASF's Data Search Vertex portal provides a rich interface to explore Sentinel-1 acquisitions and find images to submit for On Demand processing. It also provides tools for selecting pairs and stacks for InSAR analysis. Vertex Programmatic Access \u00b6 Requesting and downloading On Demand products can also be done programmatically: HyP3 SDK for Python HyP3 REST API Public Visibility of Jobs \u00b6 Warning All jobs submitted to HyP3, whether via web access or programmatic access, are publicly visible. Anyone with access to HyP3 can potentially: View your jobs and associated metadata, including job name and user ID. Download any products generated by your jobs. In particular, do not include any sensitive information in your job names. Citing HyP3 \u00b6 To reference HyP3 in manuscripts, cite our documentation available at ASF's hyp3-docs GitHub repository : Hogenson, K., Kristenson, H., Kennedy, J., Johnston, A., Rine, J., Logan, T., Zhu, J., Williams, F., Herrmann, J., Smale, J., & Meyer, F. (2020). Hybrid Pluggable Processing Pipeline (HyP3): A cloud-native infrastructure for generic processing of SAR data [Computer software]. https://doi.org/10.5281/zenodo.4646138 See the Usage Guidelines section for more information on citing and/or acknowledging On Demand products.","title":"Using HyP3"},{"location":"using/#using-asf-hyp3","text":"On Demand products processed by HyP3 can be requested quickly and easily, either by using a web interface or programmatically. These services are currently only available for Sentinel-1 datasets .","title":"Using ASF HyP3"},{"location":"using/#web-access","text":"ASF's Data Search Vertex portal provides a rich interface to explore Sentinel-1 acquisitions and find images to submit for On Demand processing. It also provides tools for selecting pairs and stacks for InSAR analysis. Vertex","title":"Web Access"},{"location":"using/#programmatic-access","text":"Requesting and downloading On Demand products can also be done programmatically: HyP3 SDK for Python HyP3 REST API","title":"Programmatic Access"},{"location":"using/#public-visibility-of-jobs","text":"Warning All jobs submitted to HyP3, whether via web access or programmatic access, are publicly visible. Anyone with access to HyP3 can potentially: View your jobs and associated metadata, including job name and user ID. Download any products generated by your jobs. In particular, do not include any sensitive information in your job names.","title":"Public Visibility of Jobs"},{"location":"using/#citing-hyp3","text":"To reference HyP3 in manuscripts, cite our documentation available at ASF's hyp3-docs GitHub repository : Hogenson, K., Kristenson, H., Kennedy, J., Johnston, A., Rine, J., Logan, T., Zhu, J., Williams, F., Herrmann, J., Smale, J., & Meyer, F. (2020). Hybrid Pluggable Processing Pipeline (HyP3): A cloud-native infrastructure for generic processing of SAR data [Computer software]. https://doi.org/10.5281/zenodo.4646138 See the Usage Guidelines section for more information on citing and/or acknowledging On Demand products.","title":"Citing HyP3"},{"location":"v2-transition/","text":"Welcome to HyP3 v2 \u00b6 As of September 30, 2021, our beta HyP3 service available at https://hyp3.asf.alaska.edu/ has been retired in favor of our new On Demand service powered by HyP3 version 2 (hereafter, just \"HyP3\"). On Demand processing through HyP3 is now available directly in Vertex , ASF's data search portal. Vertex provides a friendly interface to request processing jobs and review previous jobs. To learn how to request jobs through Vertex, please consult the following resources: Vertex On Demand video tutorial InSAR On Demand! StoryMap tutorial RTC On Demand! StoryMap tutorial For more information, check out our full documentation at https://hyp3-docs.asf.alaska.edu/ . If you have any comments, questions or concerns, please reach out to us! We love feedback. Contact Us \u00b6 Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? Open an issue General questions? Suggestions? Or just want to talk to the team? Chat with us on Gitter You can also reach us by email through ASF User Services: Email ASF User Services","title":"Welcome to HyP3 v2"},{"location":"v2-transition/#welcome-to-hyp3-v2","text":"As of September 30, 2021, our beta HyP3 service available at https://hyp3.asf.alaska.edu/ has been retired in favor of our new On Demand service powered by HyP3 version 2 (hereafter, just \"HyP3\"). On Demand processing through HyP3 is now available directly in Vertex , ASF's data search portal. Vertex provides a friendly interface to request processing jobs and review previous jobs. To learn how to request jobs through Vertex, please consult the following resources: Vertex On Demand video tutorial InSAR On Demand! StoryMap tutorial RTC On Demand! StoryMap tutorial For more information, check out our full documentation at https://hyp3-docs.asf.alaska.edu/ . If you have any comments, questions or concerns, please reach out to us! We love feedback.","title":"Welcome to HyP3 v2"},{"location":"v2-transition/#contact-us","text":"Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? Open an issue General questions? Suggestions? Or just want to talk to the team? Chat with us on Gitter You can also reach us by email through ASF User Services: Email ASF User Services","title":"Contact Us"},{"location":"whats_new/","text":"What's New \u00b6 Follow @ASFHyP3 on Twitter to keep up to date on all things HyP3! Tweets by ASFHyP3","title":"What's New"},{"location":"whats_new/#whats-new","text":"Follow @ASFHyP3 on Twitter to keep up to date on all things HyP3! Tweets by ASFHyP3","title":"What's New"},{"location":"guides/burst_insar_product_guide/","text":"Sentinel-1 Burst InSAR Product Guide \u00b6 This document is a guide for users of Sentinel-1 Burst Interferometric Synthetic Aperture Radar (InSAR) products generated by the Alaska Satellite Facility (ASF). Sentinel-1 Bursts \u00b6 Single Look Complex (SLC) data from the Sentinel-1 mission that is suitable for use in interferometry has historically been packaged into Interferometric Wide (IW) SLC products. These IW SLC products include three sub-swaths, each containing many individual burst SLCs. The framing of the IW SLCs is not consistent through time, so when using IW SLCs as the basis for InSAR, scene pairs do not always fully overlap. In contrast, working at the burst level of the Sentinel-1 SLC data provides a couple key benefits: 1. Bursts are consistently geolocated through time The coverage of a burst is the same for every orbit of the satellite, so you can be confident that every burst with the same Full Burst ID in a stack of acquisitions will cover the same geographic location. 2. Bursts cover a smaller geographic area IW SLC products are extremely large, and in many cases, only a small portion of the image is of interest. You can process only the bursts that cover your specific area of interest, which significantly decreases the time and cost required to generate InSAR products. Refer to the Sentinel-1 Bursts tutorial to learn more about how ASF extracts burst-level products from Sentinel-1 IW and EW SLCs. Burst InSAR Processing \u00b6 The Sentinel-1 Burst InSAR products are generated using the Jet Propulsion Laboratory's ISCE2 software . ASF is committed to transparency in product development, and we are pleased to be able to offer an InSAR product that leverages open-source software for processing. For those who would prefer to work at the scale of a full IW SLC, our original On Demand InSAR products are still available. These products have a larger footprint, and are generated using GAMMA software . Using Sentinel-1 Burst InSAR \u00b6 Users can request Sentinel-1 Burst InSAR products On Demand in ASF's Vertex data portal, or make use of our HyP3 Python SDK or API . Input pair selection in Vertex uses either the Baseline Tool or the SBAS Tool search interfaces. Users are cautioned to read the sections on limitations and error sources in InSAR products before attempting to use InSAR data. For a more complete description of the properties of SAR, see our Introduction to SAR guide. Introduction \u00b6 Interferometric Synthetic Aperture Radar (InSAR) processing uses two SAR images collected over the same area to determine geometric properties of the surface. Missions such as Sentinel-1 are designed for monitoring surface deformation using InSAR, which is optimal when acquisitions are made from a consistent location in space ( short perpendicular baseline ) over regular time intervals. The phase measurements of two SAR images acquired at different times from the same place in orbit are differenced to detect and quantify surface changes, such as deformation caused by earthquakes, volcanoes, or groundwater subsidence. InSAR can also be used to generate digital elevation models, but the optimal mission for DEM generation has the opposite characteristics of the Sentinel-1 mission. Topography is best mapped when the two acquisitions are obtained as close together as possible in time ( short temporal baseline ), but from different vantage points in space (larger perpendicular baseline than would be optimal for deformation mapping). Brief Overview of InSAR \u00b6 SAR is an active sensor that transmits pulses and listens for echoes. These echoes are recorded in phase and amplitude, with the phase being used to determine the distance from the sensor to the target and the amplitude yielding information about the roughness and dielectric constant of that target. Figure 1: Two passes of an imaging SAR taken at time T 0 and T 0 + \u2206t, will give two distances to the ground, R 1 and R 2 . A difference between R 1 and R 2 shows motion on the ground. In this case, a subsidence makes R 2 greater than R 1 . Credit: TRE ALTAMIRA InSAR exploits the phase difference between two SAR images to create an interferogram that shows where the phase and, therefore, the distance to the target has changed from one pass to the next, as illustrated in Figure 1. There are several factors that influence the interferogram, including earth curvature, topographic effects, atmospheric delays, surface motion, and noise. With proper processing, Sentinel-1 InSAR can be used to detect changes in the earth's surface down to the centimeter scale. Applications include volcanic deformation, subsidence, landslide detection, and earthquake assessment. Wavelengths \u00b6 The SAR sensors on the Sentinel-1 satellites transmit C-band signals, with a wavelength of 5.6 cm. The signal wavelength impacts the penetration capability of the signal, so it is important to be aware of the sensor wavelength when working with SAR datasets. C-band SAR will penetrate more deeply into canopy or surfaces than an X-band signal, but not nearly as deep as an L-band SAR signal, which, with a wavelength on the order of 25 cm, is better able to penetrate canopy and return signals from the forest floor. Different wavelengths are also sensitive to different levels of deformation. To detect very small changes over relatively short periods of time, you may require a signal with a smaller wavelength (such as X-band). However, signals with shorter wavelengths are also more prone to decorrelation due to small changes in surface conditions such as vegetation growth. For slower processes that require a longer time interval to detect movement, longer wavelengths (such as L-band) may be necessary. C-band sits in the middle. It can detect fairly small changes over fairly short periods of time, but is not as sensitive to small changes as X-band or as able to monitor surface dynamics under canopy as L-band. Polarizations \u00b6 Polarization refers to the direction of travel of an electromagnetic wave. A horizontal wave is transmitted so that it oscillates in a plane parallel to the surface imaged, while a vertical wave oscillates in a plane perpendicular to the surface imaged. Most modern SAR systems can transmit chirps with either a horizontal or vertical polarization. In addition, some of these sensors can listen for either horizontal or vertical backscatter. This gives rise to 4 different types of returns: HH, HV, VV, and VH, with the first letter indicating the transmission method and the second the receive method. For example, VH is a vertically polarized transmit signal with horizontally polarized echoes recorded. For InSAR applications, processing is generally performed on the co-pol (VV or HH) data and not on the cross-pol (VH or HV) data. Also, each image used in an InSAR pair is required to be the same polarization - two HH images of the same area could form a valid pair, while a single HH with a single VV of the same area would not. Baselines \u00b6 Perpendicular Baseline \u00b6 The term baseline refers to the physical distance between the two vantage points from which images used as an InSAR pair are acquired. The baseline is decomposed into perpendicular (also called normal) and parallel components, as shown in Figure 2. To monitor surface deformation, the perpendicular baseline for the two acquisitions should be very small in order to maximize the coherence of the phase measurements. In order to determine topography, two slightly different vantage points are required. Sensitivity to topography depends on the perpendicular baseline, the sensor wavelength, the distance between the satellite and the ground, and the sensor look angle. Figure 2: Geometry of InSAR baselines. Two satellite passes image the same area on the ground from positions S 1 and S 2 , resulting in a baseline of B, which can be decomposed into perpendicular (B \u27c2 ) and parallel (B \u2225 ) components. Here Y is the direction of travel, referred to as the along-track or azimuth direction, and X is the direction perpendicular to motion, referred to as the cross-track or range direction. Credit: ASF Temporal Baseline \u00b6 In contrast to the (physical) baseline, the temporal baseline refers to the time separation between imaging passes. Along-track interferometry measures motion in the millisecond to second range. This technique can detect ocean currents and rapidly moving objects like boats. Differential interferometry is the standard method used to detect motion in the range of days to years. This is the type of interferometry that is performed by the Sentinel-1 HyP3 InSAR processing algorithm. Table 1 lists different temporal baselines, their common names, and what they can be used to measure. Duration Known as Measurement of ms to sec along-track ocean currents, moving object detection, MTI days differential glacier/ice fields/lava flows, surface water extent, hydrology days to years differential subsidence, seismic events, volcanic activity, crustal displacement Table 1: Temporal baselines and what they measure. Different geophysical phenomena can be detected based upon the temporal baseline. In general, the longer the temporal baseline, the smaller the motion that can be detected. Critical Baseline \u00b6 Large baselines are better than small for topographic mapping. However, as the baseline increases, coherence decreases. At some point, it is impossible to create an interferogram because of baseline decorrelation. The maximum viable baseline per platform, referred to as the critical baseline , is a function of the distance to the ground, the wavelength, and the viewing geometry of the platform. For Sentinel-1, this critical baseline is about 5 km. In practice, if the perpendicular baseline between images is more than 3/4 of the critical baseline, interferogram creation will be problematic due to the level of noise. For deformation mapping, it is best to minimize the perpendicular baseline whenever possible, but there may be tradeoffs in terms of finding suitable temporal baselines. In most cases, however, pairs selected for deformation mapping will have perpendicular baselines much smaller than the critical baseline. Ordering On Demand InSAR Products \u00b6 All of ASF's On Demand InSAR products are generated using ASF's HyP3 platform. Jobs can be submitted for processing using the Vertex data portal, the HyP3 Python SDK or the HyP3 API . Vertex \u00b6 InSAR pairs are selected in Vertex using either the Baseline Search or the SBAS Search interface. The Baseline tool is the best option for selecting specific InSAR pairs. Use the Geographic Search to find an image that covers your time and area of interest, select that item in the results, and click the Baseline button in the center panel. The Baseline tool then displays all of the scenes that could be used to generate an interferogram using the selected image. Scroll through the results to find pairs to add to the On Demand queue, or click on items displayed in the plot to highlight that particular image pair. The SBAS tool is designed for generating time series of InSAR pairs. As with the Baseline search, you can launch the SBAS search from the center panel of a Geographic Search result. It will display all of the valid InSAR pairs through time based on the acquisition location of the input scene. This functionality is designed for processing a series of interferograms to be used in SBAS (Small BAseline Subset) analysis. The results can be adjusted based on baseline criteria (both perpendicular and temporal), and restricted to specific periods of time. Once the list is refined, you have the option to add all of the InSAR pairs displayed in the results to the On Demand queue. HyP3 SDK and API \u00b6 The HyP3 SDK provides support for processing nearest-neighbor interferograms for a selected granule. Specifying nearest-neighbor processing will find the next appropriate scene back in time to use as the reference granule for generating an interferogram with the selected granule. You can specify up to 2 nearest neighbors, which will pair the scene closest in time and next-closest in time to the selected granule for generating InSAR products, as demonstrated in this sample HyP3 SDK Jupyter Notebook . You may still find the Geographic, Baseline and SBAS searches in Vertex useful for finding reference scenes or picking specific pairs to use when submitting InSAR jobs via the SDK or API . Considerations for Selecting an InSAR Pair \u00b6 When selecting an InSAR pair, observe the following required conditions: Images from an identical orbit direction (either ascending or descending) Images with identical incidence angles and beam mode Images with identical resolution and wavelength (usually from the same sensor) Images with the same viewing geometry (same path and frame) Images with identical polarizations (both HH or VV) In addition, the following suggestions may be helpful: Use images from similar seasons/growth/weather conditions For deformation mapping: limited spatial separation of acquisition locations (small physical baseline) For topographic mapping: limited time separation between images (small temporal baseline) To analyze deformation caused by a single discrete event, such as an earthquake, select images that bracket the event as closely in time as possible. Keeping the window narrowly focused on the time of the event will reduce the impacts of other processes that may mask the signal of the event of interest. Processing Options \u00b6 There are several options users can set when ordering Burst InSAR On Demand products: The number of looks drives the resolution and pixel spacing of the output products: Looks Resolution Pixel Spacing 20x4 160 m 80 m 10x2 80 m 40 m 5x1 40 m 20 m Products generated with 10x2 looks have a file size roughly 4 times that of 20x4-look products. Similarly, 5x1-look products have a file size roughly 4 times that of 10x2-look products (or 16 times that of 20x4-look products). The default is 20x4 looks. There is an option to apply a water mask after phase unwrapping. This mask includes coastal waters and large inland waterbodies. A GeoTIFF of the water mask is always included with the InSAR product package, but when this option is selected, the water mask will be applied to the wrapped interferogram, the unwrapped interferogram, and the browse image. Water masking is turned off by default. Refer to the Apply Water Mask section for more information about the water mask and how it is used. Burst InSAR Workflow \u00b6 The Burst InSAR workflow used in HyP3 was developed by ASF using ISCE2 software. The steps include pre-processing, interferogram preparation, and product creation. Once these steps are performed, an output product package is created. See product packaging for details on the individual files included in the package. Pre-Processing \u00b6 Pre-processing steps prepare the SAR images to be used in interferometry. The pre-processing steps include downloading the burst granules, downloading the DEM file, and downloading the orbit and auxiliary data files. Download Bursts \u00b6 The burst InSAR workflow accepts as input two Interferometric Wide swath Single Look Complex (IW SLC) burst granules with the same burst ID. The bursts are downloaded using ASF's Sentinel-1 Burst Extractor . Download the DEM File \u00b6 In order to create differential InSAR products that show motion on the ground, one must subtract the topographic phase from the interferogram. The topographic phase, in this case, is replicated by using an existing DEM to calculate the actual topographic phase. This phase is then removed from the interferogram leaving just the motion or deformation signal (plus atmospheric delays and noise). The DEM that is used for HyP3 InSAR processing is the 2021 Release of the Copernicus GLO-30 Public DEM dataset publicly available on AWS , which provides global coverage at 30-m pixel spacing (except for an area over Armenia and Azerbaijan, which only has 90-m coverage). For more information about the 2021 updates, see the 'Releases' section of this article . The portion of the DEM that covers the input bursts is downloaded. Download Orbit Files and Calibration Auxiliary Data Files \u00b6 For Sentinel-1 InSAR processing, ISCE2 requires additional satellite orbit and calibration metadata files. The orbit files are downloaded from the Copernicus Sentinels POD Data Hub . The calibration auxiliary data files are downloaded from the Sentinel-1 Mission Performance Center . InSAR Processing \u00b6 The ISCE2 InSAR processing this product uses follows the workflow in topsApp.py from steps startup through geocode . These steps perform the following processing: Extract the orbits, Instrument Processing Facility (IPF) version, burst data, and antenna pattern if it is necessary. Calculate the perpendicular and parallel baselines. Map the DEM into the radar coordinates of the reference image. This generates the longitude, latitude, height and LOS angles on a pixel by pixel grid for each burst. Estimate the azimuth offsets between the input SLC bursts. The Enhanced Spectral Diversity (ESD) method is not used. Estimate the range offsets between the input SLC bursts. Co-register the secondary SLC burst by applying the estimated range and azimuth offsets. Produce the wrapped phase interferogram. Apply the Goldstein-Werner power spectral filter with a dampening factor of 0.5. Unwrap the wrapped phase interferogram using SNAPHU 's minimum cost flow (MCF) unwrapping algorithm to produce the unwrapped phase interferogram. Geocode the output products. Post-Processing \u00b6 Apply Water Mask \u00b6 A water mask identifying coastal waters and major inland waterbodies is generated using the Global Self-consistent, Hierarchical, High-resolution Geography Database (GSHHG) dataset. This water mask raster is always included with the Burst InSAR products for reference, but is not applied to the interferometry products by default. Users can optionally choose to apply the water mask to output products, which affects the wrapped interferogram, the unwrapped interferogram, and the browse image. Areas covered by the water mask in these output images are set to NoData. Applying a water mask to an interferogram is only supported after phase unwrapping. Note that applying the mask after phase unwrapping does not prevent unwrapping errors caused by the inclusion of water pixels as valid data during the phase unwrapping process. When phase unwrapping occurs over large expanses of water, it can lead to unexpected deformation signals or phase jumps in the unwrapped outputs, and the current masking approach does not correct for these impacts. Product Creation \u00b6 Image files are exported into the widely-used GeoTIFF format in a Universal Transverse Mercator (UTM) projection. Images are resampled to a pixel size that reflects the resolution of output image based on the requested number of looks: 80 meters for 20x4 looks, 40 meters for 10x2 looks, and 20 meters for 5x1 looks. Supporting metadata files are created, as well as a quick-look browse image. Product Packaging \u00b6 HyP3 Burst InSAR output is a zip file containing various files, including GeoTIFFs, a PNG browse image, a metadata file, and a README file. Naming Convention \u00b6 The Burst InSAR product names are packed with information pertaining to the processing of the data, presented in the following order, as illustrated in Figure 3. The imaging platform name, always S1 for Sentinel-1. Relative burst ID values assigned by ESA. Each value identifies a consistent burst footprint; relative burst ID values differ from one sub-swath to the next. The imaging mode, currently only IW is supported. The swath number, either 1, 2, or 3, indicating which sub-swath the burst is located in. The acquisition dates of the reference (older) scene and the secondary (newer) scene The polarizations for the pair, either HH or VV. The product type (always INT for InSAR) and the pixel spacing, which will be either 80, 40, or 20, based upon the number of looks selected when the job was submitted for processing The filename ends with the ASF product ID, a 4 digit hexadecimal number Figure 3: Breakdown of ASF Burst InSAR naming scheme. Image Files \u00b6 All of the main InSAR product files are 32-bit floating-point single-band GeoTIFFs. The exceptions to this are the connected components and the water mask, which are both 8-bit unsigned-integer single-band GeoTIFFs. The coherence file pixel values range from 0.0 to 1.0, with 0.0 being completely non-coherent and 1.0 being perfectly coherent. The unwrapped phase file shows the results of the phase unwrapping process. Negative values indicate movement towards the sensor, and positive values indicate movement away from the sensor. This is the main interferogram output. The wrapped phase file indicates the interferogram phase after applying the adaptive filter immediately before unwrapping. Values range from negative pi to positive pi. The connected components file delineates regions unwrapped as contiguous units by the SNAPHU unwrapping algorithm. The look vectors theta (\u03b8) and phi (\u03c6) describe the elevation and orientation angles of the look vector in radians. The look vectors refer to the look direction back towards the sensor. The lv_theta (\u03b8) file indicates the SAR look vector elevation angle (in radians) at each pixel, ranging from -\u03c0/2 (down) to \u03c0/2 (up). The look vector elevation angle is defined as the angle between the horizontal surface and the look vector with positive angles indicating sensor positions above the surface. The lv_phi (\u03c6) file indicates the SAR look vector orientation angle (in radians) at each pixel. The look vector orientation angle is defined as the angle between the East direction and the projection of the look vector on the horizontal surface plane. The orientation angle increases towards north, with the North direction corresponding to \u03c0/2 (and south to -\u03c0/2). The orientation angle range is -\u03c0 to \u03c0. The DEM file gives the local terrain heights in meters, with a geoid correction applied. The water mask file indicates coastal waters and large inland waterbodies. Pixel values of 1 indicate land and 0 indicate water. This file is in 8-bit unsigned integer format. If the water mask option is selected, the water mask is applied after phase unwrapping to exclude water pixels from the output. The water mask is generated using the GSHHG dataset. To compile the reference shapefile, the full-resolution L1 dataset (boundary between land and ocean) and L5 dataset (boundary between Antarctic ice and ocean) were combined. The L3 dataset (boundary between islands and the lakes they are within) was removed from the L2 dataset (boundary between lakes and land), and this combined dataset was removed from the combined L1/L5 dataset. The GSHHG dataset was last updated in 2017, so there may be discrepancies where shorelines have changed. A browse image is included for the unwrapped (unw_phase) phase file, which is in PNG format and is 2048 pixels wide. The tags and extensions used and example file names for each raster are listed in Table 2 below. Extension Description Example _conncomp.tif Connected Components S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _conncomp.tif _corr.tif Normalized coherence file S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _corr.tif _unw_phase.tif Unwrapped geocoded interferogram S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _unw_phase.tif _wrapped_phase.tif Wrapped geocoded interferogram S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _wrapped_phase.tif _lv_phi.tif Look vector \u03c6 (orientation) S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _lv_phi.tif _lv_theta.tif Look vector \u03b8 (elevation) S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _lv_theta.tif _dem.tif Digital elevation model S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _dem.tif _water_mask.tif Water mask S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _water_mask.tif _unw_phase.png Unwrapped phase browse image S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _unw_phase.png Table 2: Image files in product package Metadata Files \u00b6 The product package also includes a number of metadata files. Extension Description Example .README.md.txt Main README file for Burst InSAR products S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 .README.md.txt .txt Parameters and metadata for the InSAR pair S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 .txt Table 3: Metadata files in product package README File \u00b6 The text file with extension .README.md.txt explains the files included in the folder, and is customized to reflect that particular product. Users unfamiliar with InSAR products should start by reading this README file, which will give some background on each of the files included in the product folder. InSAR Parameter File \u00b6 The text file with extension .txt includes processing parameters used to generate the InSAR product as well as metadata attributes for the InSAR pair. These are detailed in Table 4. Name Description Possible Value Reference Granule Granule name for reference burst (of the two scenes in the pair, the dataset with the oldest timestamp) S1 _136231 _IW2 _20200604T022312 _VV _7C85-BURST Secondary Granule Granule name for secondary burst (of the two scenes in the pair, the dataset with the newest timestamp) S1 _136231 _IW2 _20200616T022313 _VV _5D11-BURST Reference Pass Direction Orbit direction of the reference scene DESCENDING Reference Orbit Number Absolute orbit number of the reference scene 30741 Secondary Pass Direction Orbit direction of the reference scene DESCENDING Secondary Orbit Number Absolute orbit number of the secondary scene 31091 Baseline Perpendicular baseline in meters 58.3898 UTCTime Time in the UTC time zone in seconds 12360.691361 Heading Spacecraft heading measured in degrees clockwise from north 193.2939317 Spacecraft height Height in meters of the spacecraft above nadir point 700618.6318999995 Earth radius at nadir Ellipsoidal earth radius in meters at the point directly below the satellite 6370250.0667 Slant range near Distance in meters from satellite to nearest point imaged 799517.4338 Slant range center Distance in meters from satellite to the center point imaged 879794.1404 Slant range far Distance in meters from satellite to farthest point imaged 960070.8469 Range looks Number of looks taken in the range direction 20 Azimuth looks Number of looks taken in the azimuth direction 4 InSAR phase filter Name of the phase filter used yes Phase filter parameter Dampening factor 0.5 Range bandpass filter Range bandpass filter applied no Azimuth bandpass filter Azimuth bandpass filter applied no DEM source DEM used in processing GLO-30 DEM resolution Pixel spacing in meters for DEM used to process this scene 30 Unwrapping type Phase unwrapping algorithm used snaphu_mcf Speckle filter Speckle filter applied yes Table 4: List of InSAR parameters included in the parameter text file Limitations \u00b6 Baseline Calculation \u00b6 The baseline is defined as the difference of the platform positions when a given area is imaged. HyP3 baselines are calculated using the best state vectors available. If precise orbits are not yet available for the input granules, restituted orbits will be used. The original predicted orbits are not used for InSAR processing in HyP3. If no restituted or precise state vectors are available, the process will not run. Coherence \u00b6 The phase measurements in the two images used in InSAR must be coherent in order to detect change. Random changes in phase from one acquisition to the next can mask actual surface deformation. Vegetation is a common driver of decorrelation, as changes can easily take place in the interval between two acquisitions due to growth, seasonal changes, or wind effects. It will be difficult to generate valid interferograms with C-band data in heavily vegetated regions due to lack of coherence even with fairly short time intervals. Consider seasonality when selecting image pairs. Decorrelation can be particularly high when comparing phase from different seasons. Changes in the condition of vegetation (especially deciduous canopies), snow, moisture, or freeze/thaw state can impact phase measurements. In cases where a temporal baseline is required that spans seasons, it may be better to use an annual interferogram if possible so that the images are more comparable in terms of seasonality. Line-of-Sight Measurements \u00b6 When looking at a single interferogram, the deformation measurements in the line-of-sight orientation of the sensor indicate relative motion towards or away from the sensor. InSAR is not sensitive to motion in the azimuth direction of the satellite, so motion that occurs in the same direction as the satellite's direction of travel will not be detected. A single interferogram cannot be used to determine the relative contributions of vertical and horizontal movement to the line-of-sight displacement measurement. To determine how much of the signal is driven by vertical vs. horizontal movement, you must either use a time series of interferograms, or use reference measurements with known vertical and horizontal components (such as GNSS measurements from the region of deformation) to deconstruct the line-of-sight displacement. Phase Unwrapping Reference Point \u00b6 The reference point for phase unwrapping is set automatically by the topsApp.py script. It may not be an ideal location to use as a reference point for phase unwrapping. If it is located in an area undergoing deformation, or in an area with low coherence, the unwrapping may be of lower quality than if the reference point was in a more suitable location. Even when there are no phase unwrapping errors introduced by phase discontinuities, it is important to be aware that unwrapped phase differences are calculated relative to the reference point. The phase difference value of the reference point is set to 0 during phase unwrapping, so any displacement values will be relative to that benchmark. If you are interested in the amount of displacement in a particular area, you may wish to choose your own reference point. The ideal reference point would be in an area of high coherence beyond where deformation has occurred. The unwrapped phase measurements can be adjusted to be relative to this new reference point. To adjust the values in the unwrapped phase GeoTIFF, simply select a reference point that is optimal for your use case and subtract the unwrapped phase value of that reference point from each pixel in the unwrapped phase raster: \u0394\u03a8 * = \u0394\u03a8 - \u0394\u03c8 ref where \u0394\u03a8 * is the adjusted unwrapped phase, \u0394\u03a8 is the original unwrapped phase, and \u0394\u03c8 ref is the unwrapped phase value at the new reference point. Displacement Values from a Single Interferogram \u00b6 In general, calculating displacement values from a single interferogram is not recommended. It will be more robust to use a time series approach to more accurately determine the pattern of movement. When using SAR time-series software such as MintPy , you have the option to select a specific reference point, and the values of the input rasters will be adjusted accordingly. Error Sources \u00b6 On Demand InSAR products do not currently correct for some common sources of error in interferometry, such as atmospheric effects. Further processing or time series analysis can be performed by the user to identify or reduce the impact of some of these errors when using On Demand InSAR products for analysis. Atmospheric Delay \u00b6 While SAR signals can penetrate clouds, atmospheric conditions can delay the transmission of the signal. This results in phase differences that can look like surface deformation signals but are actually driven by differences in the atmospheric conditions between the pair of acquisitions used to generate the interferogram. In some cases, atmospheric errors can be corrected by using an atmospheric model to remove the impacts of the turbulent delay from the interferogram. Another approach is to use time series analysis to identify outliers. Always doubt your interferogram first! View the interferogram critically, and consider if fringe patterns could potentially be driven by atmospheric effects. In general, it is best to avoid drawing conclusions from the outcome of a single interferogram. Turbulent Delay \u00b6 These delays are generally caused by differences in water vapor distribution from one image to the next. They often manifest as wobbly or sausage-shaped fringes, and can potentially mask the signal of a small earthquake. Stratified Delay \u00b6 This type of delay is driven mostly by pressure and temperature differences or gradients through the atmospheric column, and often correlates with topography. This atmospheric signature can be confused with movement caused by volcanic activity. If there are multiple volcanoes in an image and they all exhibit similar patterns, it is likely being driven by this type of atmospheric delay. DEM Errors \u00b6 A DEM is used to remove topographic phase impacts, but if there are inaccuracies in the DEM, residual impacts of those errors can remain in the interferogram. Orbit Uncertainties \u00b6 This is generally not an issue for Sentinel-1 data, as the orbits are very precise and generally reliable. On Demand InSAR products are only processed once restituted or precise orbits are available. Orbit uncertainties are more problematic when working with datasets from older missions.","title":"Burst insar product guide"},{"location":"guides/burst_insar_product_guide/#sentinel-1-burst-insar-product-guide","text":"This document is a guide for users of Sentinel-1 Burst Interferometric Synthetic Aperture Radar (InSAR) products generated by the Alaska Satellite Facility (ASF).","title":"Sentinel-1 Burst InSAR Product Guide"},{"location":"guides/burst_insar_product_guide/#sentinel-1-bursts","text":"Single Look Complex (SLC) data from the Sentinel-1 mission that is suitable for use in interferometry has historically been packaged into Interferometric Wide (IW) SLC products. These IW SLC products include three sub-swaths, each containing many individual burst SLCs. The framing of the IW SLCs is not consistent through time, so when using IW SLCs as the basis for InSAR, scene pairs do not always fully overlap. In contrast, working at the burst level of the Sentinel-1 SLC data provides a couple key benefits: 1. Bursts are consistently geolocated through time The coverage of a burst is the same for every orbit of the satellite, so you can be confident that every burst with the same Full Burst ID in a stack of acquisitions will cover the same geographic location. 2. Bursts cover a smaller geographic area IW SLC products are extremely large, and in many cases, only a small portion of the image is of interest. You can process only the bursts that cover your specific area of interest, which significantly decreases the time and cost required to generate InSAR products. Refer to the Sentinel-1 Bursts tutorial to learn more about how ASF extracts burst-level products from Sentinel-1 IW and EW SLCs.","title":"Sentinel-1 Bursts"},{"location":"guides/burst_insar_product_guide/#burst-insar-processing","text":"The Sentinel-1 Burst InSAR products are generated using the Jet Propulsion Laboratory's ISCE2 software . ASF is committed to transparency in product development, and we are pleased to be able to offer an InSAR product that leverages open-source software for processing. For those who would prefer to work at the scale of a full IW SLC, our original On Demand InSAR products are still available. These products have a larger footprint, and are generated using GAMMA software .","title":"Burst InSAR Processing"},{"location":"guides/burst_insar_product_guide/#using-sentinel-1-burst-insar","text":"Users can request Sentinel-1 Burst InSAR products On Demand in ASF's Vertex data portal, or make use of our HyP3 Python SDK or API . Input pair selection in Vertex uses either the Baseline Tool or the SBAS Tool search interfaces. Users are cautioned to read the sections on limitations and error sources in InSAR products before attempting to use InSAR data. For a more complete description of the properties of SAR, see our Introduction to SAR guide.","title":"Using Sentinel-1 Burst InSAR"},{"location":"guides/burst_insar_product_guide/#introduction","text":"Interferometric Synthetic Aperture Radar (InSAR) processing uses two SAR images collected over the same area to determine geometric properties of the surface. Missions such as Sentinel-1 are designed for monitoring surface deformation using InSAR, which is optimal when acquisitions are made from a consistent location in space ( short perpendicular baseline ) over regular time intervals. The phase measurements of two SAR images acquired at different times from the same place in orbit are differenced to detect and quantify surface changes, such as deformation caused by earthquakes, volcanoes, or groundwater subsidence. InSAR can also be used to generate digital elevation models, but the optimal mission for DEM generation has the opposite characteristics of the Sentinel-1 mission. Topography is best mapped when the two acquisitions are obtained as close together as possible in time ( short temporal baseline ), but from different vantage points in space (larger perpendicular baseline than would be optimal for deformation mapping).","title":"Introduction"},{"location":"guides/burst_insar_product_guide/#brief-overview-of-insar","text":"SAR is an active sensor that transmits pulses and listens for echoes. These echoes are recorded in phase and amplitude, with the phase being used to determine the distance from the sensor to the target and the amplitude yielding information about the roughness and dielectric constant of that target. Figure 1: Two passes of an imaging SAR taken at time T 0 and T 0 + \u2206t, will give two distances to the ground, R 1 and R 2 . A difference between R 1 and R 2 shows motion on the ground. In this case, a subsidence makes R 2 greater than R 1 . Credit: TRE ALTAMIRA InSAR exploits the phase difference between two SAR images to create an interferogram that shows where the phase and, therefore, the distance to the target has changed from one pass to the next, as illustrated in Figure 1. There are several factors that influence the interferogram, including earth curvature, topographic effects, atmospheric delays, surface motion, and noise. With proper processing, Sentinel-1 InSAR can be used to detect changes in the earth's surface down to the centimeter scale. Applications include volcanic deformation, subsidence, landslide detection, and earthquake assessment.","title":"Brief Overview of InSAR"},{"location":"guides/burst_insar_product_guide/#wavelengths","text":"The SAR sensors on the Sentinel-1 satellites transmit C-band signals, with a wavelength of 5.6 cm. The signal wavelength impacts the penetration capability of the signal, so it is important to be aware of the sensor wavelength when working with SAR datasets. C-band SAR will penetrate more deeply into canopy or surfaces than an X-band signal, but not nearly as deep as an L-band SAR signal, which, with a wavelength on the order of 25 cm, is better able to penetrate canopy and return signals from the forest floor. Different wavelengths are also sensitive to different levels of deformation. To detect very small changes over relatively short periods of time, you may require a signal with a smaller wavelength (such as X-band). However, signals with shorter wavelengths are also more prone to decorrelation due to small changes in surface conditions such as vegetation growth. For slower processes that require a longer time interval to detect movement, longer wavelengths (such as L-band) may be necessary. C-band sits in the middle. It can detect fairly small changes over fairly short periods of time, but is not as sensitive to small changes as X-band or as able to monitor surface dynamics under canopy as L-band.","title":"Wavelengths"},{"location":"guides/burst_insar_product_guide/#polarizations","text":"Polarization refers to the direction of travel of an electromagnetic wave. A horizontal wave is transmitted so that it oscillates in a plane parallel to the surface imaged, while a vertical wave oscillates in a plane perpendicular to the surface imaged. Most modern SAR systems can transmit chirps with either a horizontal or vertical polarization. In addition, some of these sensors can listen for either horizontal or vertical backscatter. This gives rise to 4 different types of returns: HH, HV, VV, and VH, with the first letter indicating the transmission method and the second the receive method. For example, VH is a vertically polarized transmit signal with horizontally polarized echoes recorded. For InSAR applications, processing is generally performed on the co-pol (VV or HH) data and not on the cross-pol (VH or HV) data. Also, each image used in an InSAR pair is required to be the same polarization - two HH images of the same area could form a valid pair, while a single HH with a single VV of the same area would not.","title":"Polarizations"},{"location":"guides/burst_insar_product_guide/#baselines","text":"","title":"Baselines"},{"location":"guides/burst_insar_product_guide/#perpendicular-baseline","text":"The term baseline refers to the physical distance between the two vantage points from which images used as an InSAR pair are acquired. The baseline is decomposed into perpendicular (also called normal) and parallel components, as shown in Figure 2. To monitor surface deformation, the perpendicular baseline for the two acquisitions should be very small in order to maximize the coherence of the phase measurements. In order to determine topography, two slightly different vantage points are required. Sensitivity to topography depends on the perpendicular baseline, the sensor wavelength, the distance between the satellite and the ground, and the sensor look angle. Figure 2: Geometry of InSAR baselines. Two satellite passes image the same area on the ground from positions S 1 and S 2 , resulting in a baseline of B, which can be decomposed into perpendicular (B \u27c2 ) and parallel (B \u2225 ) components. Here Y is the direction of travel, referred to as the along-track or azimuth direction, and X is the direction perpendicular to motion, referred to as the cross-track or range direction. Credit: ASF","title":"Perpendicular Baseline"},{"location":"guides/burst_insar_product_guide/#temporal-baseline","text":"In contrast to the (physical) baseline, the temporal baseline refers to the time separation between imaging passes. Along-track interferometry measures motion in the millisecond to second range. This technique can detect ocean currents and rapidly moving objects like boats. Differential interferometry is the standard method used to detect motion in the range of days to years. This is the type of interferometry that is performed by the Sentinel-1 HyP3 InSAR processing algorithm. Table 1 lists different temporal baselines, their common names, and what they can be used to measure. Duration Known as Measurement of ms to sec along-track ocean currents, moving object detection, MTI days differential glacier/ice fields/lava flows, surface water extent, hydrology days to years differential subsidence, seismic events, volcanic activity, crustal displacement Table 1: Temporal baselines and what they measure. Different geophysical phenomena can be detected based upon the temporal baseline. In general, the longer the temporal baseline, the smaller the motion that can be detected.","title":"Temporal Baseline"},{"location":"guides/burst_insar_product_guide/#critical-baseline","text":"Large baselines are better than small for topographic mapping. However, as the baseline increases, coherence decreases. At some point, it is impossible to create an interferogram because of baseline decorrelation. The maximum viable baseline per platform, referred to as the critical baseline , is a function of the distance to the ground, the wavelength, and the viewing geometry of the platform. For Sentinel-1, this critical baseline is about 5 km. In practice, if the perpendicular baseline between images is more than 3/4 of the critical baseline, interferogram creation will be problematic due to the level of noise. For deformation mapping, it is best to minimize the perpendicular baseline whenever possible, but there may be tradeoffs in terms of finding suitable temporal baselines. In most cases, however, pairs selected for deformation mapping will have perpendicular baselines much smaller than the critical baseline.","title":"Critical Baseline"},{"location":"guides/burst_insar_product_guide/#ordering-on-demand-insar-products","text":"All of ASF's On Demand InSAR products are generated using ASF's HyP3 platform. Jobs can be submitted for processing using the Vertex data portal, the HyP3 Python SDK or the HyP3 API .","title":"Ordering On Demand InSAR Products"},{"location":"guides/burst_insar_product_guide/#vertex","text":"InSAR pairs are selected in Vertex using either the Baseline Search or the SBAS Search interface. The Baseline tool is the best option for selecting specific InSAR pairs. Use the Geographic Search to find an image that covers your time and area of interest, select that item in the results, and click the Baseline button in the center panel. The Baseline tool then displays all of the scenes that could be used to generate an interferogram using the selected image. Scroll through the results to find pairs to add to the On Demand queue, or click on items displayed in the plot to highlight that particular image pair. The SBAS tool is designed for generating time series of InSAR pairs. As with the Baseline search, you can launch the SBAS search from the center panel of a Geographic Search result. It will display all of the valid InSAR pairs through time based on the acquisition location of the input scene. This functionality is designed for processing a series of interferograms to be used in SBAS (Small BAseline Subset) analysis. The results can be adjusted based on baseline criteria (both perpendicular and temporal), and restricted to specific periods of time. Once the list is refined, you have the option to add all of the InSAR pairs displayed in the results to the On Demand queue.","title":"Vertex"},{"location":"guides/burst_insar_product_guide/#hyp3-sdk-and-api","text":"The HyP3 SDK provides support for processing nearest-neighbor interferograms for a selected granule. Specifying nearest-neighbor processing will find the next appropriate scene back in time to use as the reference granule for generating an interferogram with the selected granule. You can specify up to 2 nearest neighbors, which will pair the scene closest in time and next-closest in time to the selected granule for generating InSAR products, as demonstrated in this sample HyP3 SDK Jupyter Notebook . You may still find the Geographic, Baseline and SBAS searches in Vertex useful for finding reference scenes or picking specific pairs to use when submitting InSAR jobs via the SDK or API .","title":"HyP3 SDK and API"},{"location":"guides/burst_insar_product_guide/#considerations-for-selecting-an-insar-pair","text":"When selecting an InSAR pair, observe the following required conditions: Images from an identical orbit direction (either ascending or descending) Images with identical incidence angles and beam mode Images with identical resolution and wavelength (usually from the same sensor) Images with the same viewing geometry (same path and frame) Images with identical polarizations (both HH or VV) In addition, the following suggestions may be helpful: Use images from similar seasons/growth/weather conditions For deformation mapping: limited spatial separation of acquisition locations (small physical baseline) For topographic mapping: limited time separation between images (small temporal baseline) To analyze deformation caused by a single discrete event, such as an earthquake, select images that bracket the event as closely in time as possible. Keeping the window narrowly focused on the time of the event will reduce the impacts of other processes that may mask the signal of the event of interest.","title":"Considerations for Selecting an InSAR Pair"},{"location":"guides/burst_insar_product_guide/#processing-options","text":"There are several options users can set when ordering Burst InSAR On Demand products: The number of looks drives the resolution and pixel spacing of the output products: Looks Resolution Pixel Spacing 20x4 160 m 80 m 10x2 80 m 40 m 5x1 40 m 20 m Products generated with 10x2 looks have a file size roughly 4 times that of 20x4-look products. Similarly, 5x1-look products have a file size roughly 4 times that of 10x2-look products (or 16 times that of 20x4-look products). The default is 20x4 looks. There is an option to apply a water mask after phase unwrapping. This mask includes coastal waters and large inland waterbodies. A GeoTIFF of the water mask is always included with the InSAR product package, but when this option is selected, the water mask will be applied to the wrapped interferogram, the unwrapped interferogram, and the browse image. Water masking is turned off by default. Refer to the Apply Water Mask section for more information about the water mask and how it is used.","title":"Processing Options"},{"location":"guides/burst_insar_product_guide/#burst-insar-workflow","text":"The Burst InSAR workflow used in HyP3 was developed by ASF using ISCE2 software. The steps include pre-processing, interferogram preparation, and product creation. Once these steps are performed, an output product package is created. See product packaging for details on the individual files included in the package.","title":"Burst InSAR Workflow"},{"location":"guides/burst_insar_product_guide/#pre-processing","text":"Pre-processing steps prepare the SAR images to be used in interferometry. The pre-processing steps include downloading the burst granules, downloading the DEM file, and downloading the orbit and auxiliary data files.","title":"Pre-Processing"},{"location":"guides/burst_insar_product_guide/#download-bursts","text":"The burst InSAR workflow accepts as input two Interferometric Wide swath Single Look Complex (IW SLC) burst granules with the same burst ID. The bursts are downloaded using ASF's Sentinel-1 Burst Extractor .","title":"Download Bursts"},{"location":"guides/burst_insar_product_guide/#download-the-dem-file","text":"In order to create differential InSAR products that show motion on the ground, one must subtract the topographic phase from the interferogram. The topographic phase, in this case, is replicated by using an existing DEM to calculate the actual topographic phase. This phase is then removed from the interferogram leaving just the motion or deformation signal (plus atmospheric delays and noise). The DEM that is used for HyP3 InSAR processing is the 2021 Release of the Copernicus GLO-30 Public DEM dataset publicly available on AWS , which provides global coverage at 30-m pixel spacing (except for an area over Armenia and Azerbaijan, which only has 90-m coverage). For more information about the 2021 updates, see the 'Releases' section of this article . The portion of the DEM that covers the input bursts is downloaded.","title":"Download the DEM File"},{"location":"guides/burst_insar_product_guide/#download-orbit-files-and-calibration-auxiliary-data-files","text":"For Sentinel-1 InSAR processing, ISCE2 requires additional satellite orbit and calibration metadata files. The orbit files are downloaded from the Copernicus Sentinels POD Data Hub . The calibration auxiliary data files are downloaded from the Sentinel-1 Mission Performance Center .","title":"Download Orbit Files and Calibration Auxiliary Data Files"},{"location":"guides/burst_insar_product_guide/#insar-processing","text":"The ISCE2 InSAR processing this product uses follows the workflow in topsApp.py from steps startup through geocode . These steps perform the following processing: Extract the orbits, Instrument Processing Facility (IPF) version, burst data, and antenna pattern if it is necessary. Calculate the perpendicular and parallel baselines. Map the DEM into the radar coordinates of the reference image. This generates the longitude, latitude, height and LOS angles on a pixel by pixel grid for each burst. Estimate the azimuth offsets between the input SLC bursts. The Enhanced Spectral Diversity (ESD) method is not used. Estimate the range offsets between the input SLC bursts. Co-register the secondary SLC burst by applying the estimated range and azimuth offsets. Produce the wrapped phase interferogram. Apply the Goldstein-Werner power spectral filter with a dampening factor of 0.5. Unwrap the wrapped phase interferogram using SNAPHU 's minimum cost flow (MCF) unwrapping algorithm to produce the unwrapped phase interferogram. Geocode the output products.","title":"InSAR Processing"},{"location":"guides/burst_insar_product_guide/#post-processing","text":"","title":"Post-Processing"},{"location":"guides/burst_insar_product_guide/#apply-water-mask","text":"A water mask identifying coastal waters and major inland waterbodies is generated using the Global Self-consistent, Hierarchical, High-resolution Geography Database (GSHHG) dataset. This water mask raster is always included with the Burst InSAR products for reference, but is not applied to the interferometry products by default. Users can optionally choose to apply the water mask to output products, which affects the wrapped interferogram, the unwrapped interferogram, and the browse image. Areas covered by the water mask in these output images are set to NoData. Applying a water mask to an interferogram is only supported after phase unwrapping. Note that applying the mask after phase unwrapping does not prevent unwrapping errors caused by the inclusion of water pixels as valid data during the phase unwrapping process. When phase unwrapping occurs over large expanses of water, it can lead to unexpected deformation signals or phase jumps in the unwrapped outputs, and the current masking approach does not correct for these impacts.","title":"Apply Water Mask"},{"location":"guides/burst_insar_product_guide/#product-creation","text":"Image files are exported into the widely-used GeoTIFF format in a Universal Transverse Mercator (UTM) projection. Images are resampled to a pixel size that reflects the resolution of output image based on the requested number of looks: 80 meters for 20x4 looks, 40 meters for 10x2 looks, and 20 meters for 5x1 looks. Supporting metadata files are created, as well as a quick-look browse image.","title":"Product Creation"},{"location":"guides/burst_insar_product_guide/#product-packaging","text":"HyP3 Burst InSAR output is a zip file containing various files, including GeoTIFFs, a PNG browse image, a metadata file, and a README file.","title":"Product Packaging"},{"location":"guides/burst_insar_product_guide/#naming-convention","text":"The Burst InSAR product names are packed with information pertaining to the processing of the data, presented in the following order, as illustrated in Figure 3. The imaging platform name, always S1 for Sentinel-1. Relative burst ID values assigned by ESA. Each value identifies a consistent burst footprint; relative burst ID values differ from one sub-swath to the next. The imaging mode, currently only IW is supported. The swath number, either 1, 2, or 3, indicating which sub-swath the burst is located in. The acquisition dates of the reference (older) scene and the secondary (newer) scene The polarizations for the pair, either HH or VV. The product type (always INT for InSAR) and the pixel spacing, which will be either 80, 40, or 20, based upon the number of looks selected when the job was submitted for processing The filename ends with the ASF product ID, a 4 digit hexadecimal number Figure 3: Breakdown of ASF Burst InSAR naming scheme.","title":"Naming Convention"},{"location":"guides/burst_insar_product_guide/#image-files","text":"All of the main InSAR product files are 32-bit floating-point single-band GeoTIFFs. The exceptions to this are the connected components and the water mask, which are both 8-bit unsigned-integer single-band GeoTIFFs. The coherence file pixel values range from 0.0 to 1.0, with 0.0 being completely non-coherent and 1.0 being perfectly coherent. The unwrapped phase file shows the results of the phase unwrapping process. Negative values indicate movement towards the sensor, and positive values indicate movement away from the sensor. This is the main interferogram output. The wrapped phase file indicates the interferogram phase after applying the adaptive filter immediately before unwrapping. Values range from negative pi to positive pi. The connected components file delineates regions unwrapped as contiguous units by the SNAPHU unwrapping algorithm. The look vectors theta (\u03b8) and phi (\u03c6) describe the elevation and orientation angles of the look vector in radians. The look vectors refer to the look direction back towards the sensor. The lv_theta (\u03b8) file indicates the SAR look vector elevation angle (in radians) at each pixel, ranging from -\u03c0/2 (down) to \u03c0/2 (up). The look vector elevation angle is defined as the angle between the horizontal surface and the look vector with positive angles indicating sensor positions above the surface. The lv_phi (\u03c6) file indicates the SAR look vector orientation angle (in radians) at each pixel. The look vector orientation angle is defined as the angle between the East direction and the projection of the look vector on the horizontal surface plane. The orientation angle increases towards north, with the North direction corresponding to \u03c0/2 (and south to -\u03c0/2). The orientation angle range is -\u03c0 to \u03c0. The DEM file gives the local terrain heights in meters, with a geoid correction applied. The water mask file indicates coastal waters and large inland waterbodies. Pixel values of 1 indicate land and 0 indicate water. This file is in 8-bit unsigned integer format. If the water mask option is selected, the water mask is applied after phase unwrapping to exclude water pixels from the output. The water mask is generated using the GSHHG dataset. To compile the reference shapefile, the full-resolution L1 dataset (boundary between land and ocean) and L5 dataset (boundary between Antarctic ice and ocean) were combined. The L3 dataset (boundary between islands and the lakes they are within) was removed from the L2 dataset (boundary between lakes and land), and this combined dataset was removed from the combined L1/L5 dataset. The GSHHG dataset was last updated in 2017, so there may be discrepancies where shorelines have changed. A browse image is included for the unwrapped (unw_phase) phase file, which is in PNG format and is 2048 pixels wide. The tags and extensions used and example file names for each raster are listed in Table 2 below. Extension Description Example _conncomp.tif Connected Components S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _conncomp.tif _corr.tif Normalized coherence file S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _corr.tif _unw_phase.tif Unwrapped geocoded interferogram S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _unw_phase.tif _wrapped_phase.tif Wrapped geocoded interferogram S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _wrapped_phase.tif _lv_phi.tif Look vector \u03c6 (orientation) S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _lv_phi.tif _lv_theta.tif Look vector \u03b8 (elevation) S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _lv_theta.tif _dem.tif Digital elevation model S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _dem.tif _water_mask.tif Water mask S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _water_mask.tif _unw_phase.png Unwrapped phase browse image S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 _unw_phase.png Table 2: Image files in product package","title":"Image Files"},{"location":"guides/burst_insar_product_guide/#metadata-files","text":"The product package also includes a number of metadata files. Extension Description Example .README.md.txt Main README file for Burst InSAR products S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 .README.md.txt .txt Parameters and metadata for the InSAR pair S1 _136231 _IW2 _20200604 _20200616 _VV _INT80 _12E3 .txt Table 3: Metadata files in product package","title":"Metadata Files"},{"location":"guides/burst_insar_product_guide/#readme-file","text":"The text file with extension .README.md.txt explains the files included in the folder, and is customized to reflect that particular product. Users unfamiliar with InSAR products should start by reading this README file, which will give some background on each of the files included in the product folder.","title":"README File"},{"location":"guides/burst_insar_product_guide/#insar-parameter-file","text":"The text file with extension .txt includes processing parameters used to generate the InSAR product as well as metadata attributes for the InSAR pair. These are detailed in Table 4. Name Description Possible Value Reference Granule Granule name for reference burst (of the two scenes in the pair, the dataset with the oldest timestamp) S1 _136231 _IW2 _20200604T022312 _VV _7C85-BURST Secondary Granule Granule name for secondary burst (of the two scenes in the pair, the dataset with the newest timestamp) S1 _136231 _IW2 _20200616T022313 _VV _5D11-BURST Reference Pass Direction Orbit direction of the reference scene DESCENDING Reference Orbit Number Absolute orbit number of the reference scene 30741 Secondary Pass Direction Orbit direction of the reference scene DESCENDING Secondary Orbit Number Absolute orbit number of the secondary scene 31091 Baseline Perpendicular baseline in meters 58.3898 UTCTime Time in the UTC time zone in seconds 12360.691361 Heading Spacecraft heading measured in degrees clockwise from north 193.2939317 Spacecraft height Height in meters of the spacecraft above nadir point 700618.6318999995 Earth radius at nadir Ellipsoidal earth radius in meters at the point directly below the satellite 6370250.0667 Slant range near Distance in meters from satellite to nearest point imaged 799517.4338 Slant range center Distance in meters from satellite to the center point imaged 879794.1404 Slant range far Distance in meters from satellite to farthest point imaged 960070.8469 Range looks Number of looks taken in the range direction 20 Azimuth looks Number of looks taken in the azimuth direction 4 InSAR phase filter Name of the phase filter used yes Phase filter parameter Dampening factor 0.5 Range bandpass filter Range bandpass filter applied no Azimuth bandpass filter Azimuth bandpass filter applied no DEM source DEM used in processing GLO-30 DEM resolution Pixel spacing in meters for DEM used to process this scene 30 Unwrapping type Phase unwrapping algorithm used snaphu_mcf Speckle filter Speckle filter applied yes Table 4: List of InSAR parameters included in the parameter text file","title":"InSAR Parameter File"},{"location":"guides/burst_insar_product_guide/#limitations","text":"","title":"Limitations"},{"location":"guides/burst_insar_product_guide/#baseline-calculation","text":"The baseline is defined as the difference of the platform positions when a given area is imaged. HyP3 baselines are calculated using the best state vectors available. If precise orbits are not yet available for the input granules, restituted orbits will be used. The original predicted orbits are not used for InSAR processing in HyP3. If no restituted or precise state vectors are available, the process will not run.","title":"Baseline Calculation"},{"location":"guides/burst_insar_product_guide/#coherence","text":"The phase measurements in the two images used in InSAR must be coherent in order to detect change. Random changes in phase from one acquisition to the next can mask actual surface deformation. Vegetation is a common driver of decorrelation, as changes can easily take place in the interval between two acquisitions due to growth, seasonal changes, or wind effects. It will be difficult to generate valid interferograms with C-band data in heavily vegetated regions due to lack of coherence even with fairly short time intervals. Consider seasonality when selecting image pairs. Decorrelation can be particularly high when comparing phase from different seasons. Changes in the condition of vegetation (especially deciduous canopies), snow, moisture, or freeze/thaw state can impact phase measurements. In cases where a temporal baseline is required that spans seasons, it may be better to use an annual interferogram if possible so that the images are more comparable in terms of seasonality.","title":"Coherence"},{"location":"guides/burst_insar_product_guide/#line-of-sight-measurements","text":"When looking at a single interferogram, the deformation measurements in the line-of-sight orientation of the sensor indicate relative motion towards or away from the sensor. InSAR is not sensitive to motion in the azimuth direction of the satellite, so motion that occurs in the same direction as the satellite's direction of travel will not be detected. A single interferogram cannot be used to determine the relative contributions of vertical and horizontal movement to the line-of-sight displacement measurement. To determine how much of the signal is driven by vertical vs. horizontal movement, you must either use a time series of interferograms, or use reference measurements with known vertical and horizontal components (such as GNSS measurements from the region of deformation) to deconstruct the line-of-sight displacement.","title":"Line-of-Sight Measurements"},{"location":"guides/burst_insar_product_guide/#phase-unwrapping-reference-point","text":"The reference point for phase unwrapping is set automatically by the topsApp.py script. It may not be an ideal location to use as a reference point for phase unwrapping. If it is located in an area undergoing deformation, or in an area with low coherence, the unwrapping may be of lower quality than if the reference point was in a more suitable location. Even when there are no phase unwrapping errors introduced by phase discontinuities, it is important to be aware that unwrapped phase differences are calculated relative to the reference point. The phase difference value of the reference point is set to 0 during phase unwrapping, so any displacement values will be relative to that benchmark. If you are interested in the amount of displacement in a particular area, you may wish to choose your own reference point. The ideal reference point would be in an area of high coherence beyond where deformation has occurred. The unwrapped phase measurements can be adjusted to be relative to this new reference point. To adjust the values in the unwrapped phase GeoTIFF, simply select a reference point that is optimal for your use case and subtract the unwrapped phase value of that reference point from each pixel in the unwrapped phase raster: \u0394\u03a8 * = \u0394\u03a8 - \u0394\u03c8 ref where \u0394\u03a8 * is the adjusted unwrapped phase, \u0394\u03a8 is the original unwrapped phase, and \u0394\u03c8 ref is the unwrapped phase value at the new reference point.","title":"Phase Unwrapping Reference Point"},{"location":"guides/burst_insar_product_guide/#displacement-values-from-a-single-interferogram","text":"In general, calculating displacement values from a single interferogram is not recommended. It will be more robust to use a time series approach to more accurately determine the pattern of movement. When using SAR time-series software such as MintPy , you have the option to select a specific reference point, and the values of the input rasters will be adjusted accordingly.","title":"Displacement Values from a Single Interferogram"},{"location":"guides/burst_insar_product_guide/#error-sources","text":"On Demand InSAR products do not currently correct for some common sources of error in interferometry, such as atmospheric effects. Further processing or time series analysis can be performed by the user to identify or reduce the impact of some of these errors when using On Demand InSAR products for analysis.","title":"Error Sources"},{"location":"guides/burst_insar_product_guide/#atmospheric-delay","text":"While SAR signals can penetrate clouds, atmospheric conditions can delay the transmission of the signal. This results in phase differences that can look like surface deformation signals but are actually driven by differences in the atmospheric conditions between the pair of acquisitions used to generate the interferogram. In some cases, atmospheric errors can be corrected by using an atmospheric model to remove the impacts of the turbulent delay from the interferogram. Another approach is to use time series analysis to identify outliers. Always doubt your interferogram first! View the interferogram critically, and consider if fringe patterns could potentially be driven by atmospheric effects. In general, it is best to avoid drawing conclusions from the outcome of a single interferogram.","title":"Atmospheric Delay"},{"location":"guides/burst_insar_product_guide/#turbulent-delay","text":"These delays are generally caused by differences in water vapor distribution from one image to the next. They often manifest as wobbly or sausage-shaped fringes, and can potentially mask the signal of a small earthquake.","title":"Turbulent Delay"},{"location":"guides/burst_insar_product_guide/#stratified-delay","text":"This type of delay is driven mostly by pressure and temperature differences or gradients through the atmospheric column, and often correlates with topography. This atmospheric signature can be confused with movement caused by volcanic activity. If there are multiple volcanoes in an image and they all exhibit similar patterns, it is likely being driven by this type of atmospheric delay.","title":"Stratified Delay"},{"location":"guides/burst_insar_product_guide/#dem-errors","text":"A DEM is used to remove topographic phase impacts, but if there are inaccuracies in the DEM, residual impacts of those errors can remain in the interferogram.","title":"DEM Errors"},{"location":"guides/burst_insar_product_guide/#orbit-uncertainties","text":"This is generally not an issue for Sentinel-1 data, as the orbits are very precise and generally reliable. On Demand InSAR products are only processed once restituted or precise orbits are available. Orbit uncertainties are more problematic when working with datasets from older missions.","title":"Orbit Uncertainties"},{"location":"guides/insar_product_guide/","text":"Sentinel-1 InSAR Product Guide \u00b6 This document is a guide for users of Interferometric Synthetic Aperture Radar (InSAR) Sentinel-1 products generated by the Alaska Satellite Facility (ASF). Users can request InSAR products On Demand in ASF's Vertex data portal, or make use of our HyP3 Python SDK or API . This process requires Sentinel-1 IW SLC products as input. Input pairs can be selected in Vertex using either the Baseline Tool or the SBAS Tool search interfaces. For a step-by-step tutorial on ordering On-Demand InSAR Products using Vertex, visit our InSAR On Demand! StoryMap . To learn more about the files included in the On Demand InSAR product packages and how to work with them, refer to our Exploring Sentinel-1 InSAR StoryMap . InSAR processing requires a Digital Elevation Model (DEM) for the removal of topographic phase. We use the GLO-30 Copernicus DEM when processing our On Demand InSAR products. Refer to the Prepare the DEM File section for more information. Coverage gaps in Copernicus DEM GLO-30 filled using GLO-90 The Copernicus DEM GLO-30 dataset does not provide coverage over Armenia and Azerbaijan. In the past, we have not supported InSAR product generation over those areas, due to the lack of DEM coverage. We now use the Copernicus DEM GLO-90 to fill those gaps. The GLO-90 dataset has a pixel spacing of 90 meters, which is not as detailed as the 30-m pixel spacing in the GLO-30 DEM, but it does allow us to provide InSAR products in these regions, where they were previously unavailable. Users are cautioned to read the sections on limitations and error sources in InSAR products before attempting to use InSAR data. For a more complete description of the properties of SAR, see our Introduction to SAR guide. Introduction \u00b6 Interferometric Synthetic Aperture Radar (InSAR) processing uses two SAR images collected over the same area to determine geometric properties of the surface. Missions such as Sentinel-1 are designed for monitoring surface deformation using InSAR, which is optimal when acquisitions are made from a consistent location in space ( short perpendicular baseline ) over regular time intervals. The phase measurements of two SAR images acquired at different times from the same place in orbit are differenced to detect and quantify surface changes, such as deformation caused by earthquakes, volcanoes, or groundwater subsidence. InSAR can also be used to generate digital elevation models, but the optimal mission for DEM generation has the opposite characteristics of the Sentinel-1 mission. Topography is best mapped when the two acquisitions are obtained as close together as possible in time ( short temporal baseline ), but from different vantage points in space (larger perpendicular baseline than would be optimal for deformation mapping). Brief Overview of InSAR \u00b6 SAR is an active sensor that transmits pulses and listens for echoes. These echoes are recorded in phase and amplitude, with the phase being used to determine the distance from the sensor to the target and the amplitude yielding information about the roughness and dielectric constant of that target. Figure 1: Two passes of an imaging SAR taken at time T 0 and T 0 + \u2206t, will give two distances to the ground, R 1 and R 2 . A difference between R 1 and R 2 shows motion on the ground. In this case, a subsidence makes R 2 greater than R 1 . Credit: TRE ALTAMIRA InSAR exploits the phase difference between two SAR images to create an interferogram that shows where the phase and, therefore, the distance to the target has changed from one pass to the next, as illustrated in Figure 1. There are several factors that influence the interferogram, including earth curvature, topographic effects, atmospheric delays, surface motion, and noise. With proper processing, Sentinel-1 InSAR can be used to detect changes in the earth's surface down to the centimeter scale. Applications include volcanic deformation, subsidence, landslide detection, and earthquake assessment. Wavelengths \u00b6 The SAR sensors on the Sentinel-1 satellites transmit C-band signals, with a wavelength of 5.6 cm. The signal wavelength impacts the penetration capability of the signal, so it is important to be aware of the sensor wavelength when working with SAR datasets. C-band SAR will penetrate more deeply into canopy or surfaces than an X-band signal, but not nearly as deep as an L-band SAR signal, which, with a wavelength on the order of 25 cm, is better able to penetrate canopy and return signals from the forest floor. Different wavelengths are also sensitive to different levels of deformation. To detect very small changes over relatively short periods of time, you may require a signal with a smaller wavelength (such as X-band). However, signals with shorter wavelengths are also more prone to decorrelation due to small changes in surface conditions such as vegetation growth. For slower processes that require a longer time interval to detect movement, longer wavelengths (such as L-band) may be necessary. C-band sits in the middle. It can detect fairly small changes over fairly short periods of time, but is not as sensitive to small changes as X-band or as able to monitor surface dynamics under canopy as L-band. Polarizations \u00b6 Polarization refers to the direction of travel of an electromagnetic wave. A horizontal wave is transmitted so that it oscillates in a plane parallel to the surface imaged, while a vertical wave oscillates in a plane perpendicular to the surface imaged. Most modern SAR systems can transmit chirps with either a horizontal or vertical polarization. In addition, some of these sensors can listen for either horizontal or vertical backscatter. This gives rise to 4 different types of returns: HH, HV, VV, and VH, with the first letter indicating the transmission method and the second the receive method. For example, VH is a vertically polarized transmit signal with horizontally polarized echoes recorded. For InSAR applications, processing is generally performed on the co-pol (VV or HH) data and not on the cross-pol (VH or HV) data. Also, each image used in an InSAR pair is required to be the same polarization - two HH images of the same area could form a valid pair, while a single HH with a single VV of the same area would not. Baselines \u00b6 Perpendicular Baseline \u00b6 The term baseline refers to the physical distance between the two vantage points from which images used as an InSAR pair are acquired. The baseline is decomposed into perpendicular (also called normal) and parallel components, as shown in Figure 2. To monitor surface deformation, the perpendicular baseline for the two acquisitions should be very small in order to maximize the coherence of the phase measurements. In order to determine topography, two slightly different vantage points are required. Sensitivity to topography depends on the perpendicular baseline, the sensor wavelength, the distance between the satellite and the ground, and the sensor look angle. Figure 2: Geometry of InSAR baselines. Two satellite passes image the same area on the ground from positions S 1 and S 2 , resulting in a baseline of B, which can be decomposed into perpendicular (B \u27c2 ) and parallel (B \u2225 ) components. Here Y is the direction of travel, referred to as the along-track or azimuth direction, and X is the direction perpendicular to motion, referred to as the cross-track or range direction. Credit: ASF Temporal Baseline \u00b6 In contrast to the (physical) baseline, the temporal baseline refers to the time separation between imaging passes. Along-track interferometry measures motion in the millisecond to second range. This technique can detect ocean currents and rapidly moving objects like boats. Differential interferometry is the standard method used to detect motion in the range of days to years. This is the type of interferometry that is performed by the Sentinel-1 HyP3 InSAR processing algorithm. Table 1 lists different temporal baselines, their common names, and what they can be used to measure. Duration Known as Measurement of ms to sec along-track ocean currents, moving object detection, MTI days differential glacier/ice fields/lava flows, surface water extent, hydrology days to years differential subsidence, seismic events, volcanic activity, crustal displacement Table 1: Temporal baselines and what they measure. Different geophysical phenomena can be detected based upon the temporal baseline. In general, the longer the temporal baseline, the smaller the motion that can be detected. Critical Baseline \u00b6 Large baselines are better than small for topographic mapping. However, as the baseline increases, coherence decreases. At some point, it is impossible to create an interferogram because of baseline decorrelation. The maximum viable baseline per platform, referred to as the critical baseline , is a function of the distance to the ground, the wavelength, and the viewing geometry of the platform. For Sentinel-1, this critical baseline is about 5 km. In practice, if the perpendicular baseline between images is more than 3/4 of the critical baseline, interferogram creation will be problematic due to the level of noise. For deformation mapping, it is best to minimize the perpendicular baseline whenever possible, but there may be tradeoffs in terms of finding suitable temporal baselines. In most cases, however, pairs selected for deformation mapping will have perpendicular baselines much smaller than the critical baseline. Ordering On Demand InSAR Products \u00b6 All of ASF's On Demand InSAR products are generated using ASF's HyP3 platform. Jobs can be submitted for processing using the Vertex data portal, the HyP3 Python SDK or the HyP3 API . Vertex \u00b6 InSAR pairs are selected in Vertex using either the Baseline Search or the SBAS Search interface. The Baseline tool is the best option for selecting specific InSAR pairs. Use the Geographic Search to find an image that covers your time and area of interest, select that item in the results, and click the Baseline button in the center panel. The Baseline tool then displays all of the scenes that could be used to generate an interferogram using the selected image. Scroll through the results to find pairs to add to the On Demand queue, or click on items displayed in the plot to highlight that particular image pair. The SBAS tool is designed for generating time series of InSAR pairs. As with the Baseline search, you can launch the SBAS search from the center panel of a Geographic Search result. It will display all of the valid InSAR pairs through time based on the acquisition location of the input scene. This functionality is designed for processing a series of interferograms to be used in SBAS (Small BAseline Subset) analysis. The results can be adjusted based on baseline criteria (both perpendicular and temporal), and restricted to specific periods of time. Once the list is refined, you have the option to add all of the InSAR pairs displayed in the results to the On Demand queue. HyP3 SDK and API \u00b6 The HyP3 SDK provides support for processing nearest-neighbor interferograms for a selected granule. Specifying nearest-neighbor processing will find the next appropriate scene back in time to use as the reference granule for generating an interferogram with the selected granule. You can specify up to 2 nearest neighbors, which will pair the scene closest in time and next-closest in time to the selected granule for generating InSAR products, as demonstrated in this sample HyP3 SDK Jupyter Notebook . You may still find the Geographic, Baseline and SBAS searches in Vertex useful for finding reference scenes or picking specific pairs to use when submitting InSAR jobs via the SDK or API . Considerations for Selecting an InSAR Pair \u00b6 When selecting an InSAR pair, observe the following required conditions: Images from an identical orbit direction (either ascending or descending) Images with identical incidence angles and beam mode Images with identical resolution and wavelength (usually from the same sensor) Images with the same viewing geometry (same path and frame) Images with identical polarizations (both HH or VV) In addition, the following suggestions may be helpful: Use images from similar seasons/growth/weather conditions For deformation mapping: limited spatial separation of acquisition locations (small physical baseline) For topographic mapping: limited time separation between images (small temporal baseline) To analyze deformation caused by a single discrete event, such as an earthquake, select images that bracket the event as closely in time as possible. Keeping the window narrowly focused on the time of the event will reduce the impacts of other processes that may mask the signal of the event of interest. Processing Options \u00b6 New Water Masking Approach InSAR products can be phase unwrapped using a water mask. The option to \"Apply water mask\" sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping. This reduces phase unwrapping errors and outputs a less noisy unwrapped interferogram. As of September 27, 2022, the water mask used for this option is no longer buffered. The original water mask had a 3 km buffer on coastlines and a 5 km buffer on the shorelines of inland waterbodies. This was to reduce the chance that valid land pixels would be excluded from phase unwrapping, but it appears that the inclusion of more water pixels is more detrimental to phase unwrapping than the exclusion of some land pixels. Visit our InSAR Water Masking Tutorial for more information. Change in Displacement Map Options There is now a single option for including displacement maps. Both line-of-sight and vertical displacement maps will only be added to the product package if the option to \"Include Displacement Maps\" is selected when submitting On-Demand InSAR jobs. Use caution when referencing the values included in the displacement maps, as the values are calculated relative to an arbitrary reference point. Refer to the Phase Unwrapping Reference Point section for more information. There are several options users can set when ordering InSAR On Demand products. Currently, users can choose the number of looks to take (which drives the resolution and pixel spacing of the products), and which optional products to include in the output package. The options are described below: The number of looks drives the resolution and pixel spacing of the output products. Selecting 10x2 looks will yield larger products with 80 m resolution and pixel spacing of 40 m. Selecting 20x4 looks reduces the resolution to 160 m and reduces the size of the products (roughly 1/4 the size of 10x2 look products), with a pixel spacing of 80 m. The default is 20x4 looks. The look vectors are stored in two files. The look vector refers the look direction back towards the sensor. The lv_theta (\u03b8) indicates the SAR look vector elevation angle at each pixel, ranging from -\u03c0/2 (down) to \u03c0/2 (up). The look vector elevation angle is defined as the angle between the horizontal surface and the look vector with positive angles indicating sensor positions above the surface. The lv_phi (\u03c6) map indicates the SAR look vector orientation angle at each pixel, ranging from -\u03c0 (west) to \u03c0 (west). The look vector orientation angle is defined as the angle between the East direction and the projection of the look vector on the horizontal surface plane. The orientation angle increases towards north, with the North direction corresponding to \u03c0/2 (and south to -\u03c0/2). Both angles are expressed in radians. The default is to not include these files in the output product bundle. The displacement maps convert the phase difference values from the unwrapped interferogram into measurements of ground displacement in meters. The line-of-sight displacement map indicates the amount of movement away from or towards the sensor. The vertical displacement calculates the vertical component of the line-of-sight displacement, using the assumption that all deformation is in the vertical direction. These files are excluded from the product package by default. The wrapped phase GeoTIFF can be included in the output package. The browse version of this GeoTIFF (_color_phase.png) is always included, but the GeoTIFF version is not included by default. The specific color ramp displayed in the png is most valuable for many users, but some may wish to work with the actual wrapped phase values. The incidence angle maps indicate the angle of the radar signal. The local incidence angle is defined as the angle between the incident radar signal and the local surface normal, expressed in radians, while the ellipsoid incidence angle indicates the angle between the incident radar beam and the direction perpendicular to the WGS84 ellipsoid model. These files are excluded from the product package by default. A copy of the DEM used for processing can optionally be included in the product package. The file has been projected to a UTM Zone coordinate system, and pixel values indicate the elevation in meters. The elevation values will differ from the original Copernicus DEM GLO-30 dataset, as a geoid correction has been applied. The source DEM is also downsampled to twice the pixel spacing of the output product to smooth it for use in processing, then resampled again to match the pixel spacing of the InSAR product. The DEM is excluded by default. There is an option to apply a water mask . This mask includes coastal waters and large inland waterbodies. Masking waterbodies can have a significant impact during the phase unwrapping, as water can sometimes exhibit enough coherence between acquisitions to allow for unwrapping to occur over waterbodies, which is invalid. A GeoTIFF of the water mask is always included with the InSAR product package, but when this option is selected, the conditional water mask will be applied along with coherence and intensity thresholds during the phase unwrapping process. Water masking is turned off by default. Visit our InSAR Water Masking Tutorial for more information. InSAR Workflow \u00b6 The InSAR workflow used in HyP3 was developed by ASF using GAMMA software. The steps include pre-processing steps, interferogram preparation, and product creation. Once these steps are performed, an output product package will be created. See product packaging for details on the individual files included in the package. Pre-Processing \u00b6 Pre-processing steps prepare the SAR images to be used in interferometry. The pre-processing steps include image selection, ingest (including calibration), creation of a suitable DEM, and calculation of the burst overlap. Select an InSAR Pair \u00b6 Although it is possible to start from RAW data, Sentinel-1 InSAR processing is typically done using Interferometric Wide swath Single Look Complex (IW SLC) data as the input. This means that the data has been formed into an image through SAR processing, but has not been multi-looked. The SLC pair is defined by the user , either through the Vertex interface, or using the HyP3 API or SDK. To ensure consistency, the older SLC image is always used as the reference image, and the younger SLC image is always used as the secondary image. This means that positive values in the resulting unwrapped interferogram represent movement away from the SAR platform and negative values represent movement towards the SAR platform. However, these values are relative to the reference point of the unwrapped interferogram. See the phase unwrapping section for more details. Ingest SLC data into GAMMA format \u00b6 Once the InSAR pair has been identified, the selected SLC data are ingested into GAMMA internal format. This is performed by the GAMMA program par_s1_slc . GAMMA format has raw data files (only data, no headers or line leaders) with metadata stored in external files with a .par extension. During ingest into GAMMA's internal format, the SLC data is calibrated by applying the calibration coefficients that are supplied with each product. This process puts the SAR backscatter into a known scale where the diffuse volume scattering of the Amazon rainforest is a constant -6.5 dB. Immediately after ingesting the SLC, the state vectors are updated to use the best available state vectors. The state vector types in order of absolute correctness are original predicted (O), restituted (R), and precision (P). In practice, one will never receive an InSAR product that uses the original predicted orbit - only granules for which a restituted or precision orbit is available can be used in HyP3 InSAR processing. The orbit type used for generating the InSAR product is indicated in the product filename, as shown in Figure 3. Figure 3: Position of the orbit type in the HyP3 product name. Prepare the DEM File \u00b6 In order to create differential InSAR products that show motion on the ground, one must subtract the topographic phase from the interferogram. The topographic phase, in this case, is replicated by using an existing DEM to calculate the actual topographic phase. This phase is then removed from the interferogram leaving just the motion or deformation signal (plus atmospheric delays and noise). The DEM that is used for HyP3 InSAR processing is the 2022 Release of the Copernicus GLO-30 Public DEM dataset publicly available on AWS . For more information about the 2022 updates, see the 'Releases' section of this article . The Copernicus DEM provides higher-quality products over a wider area than the older DEMs (SRTM and NED) previously used to generate ASF's On Demand products. Refer to our Digital Elevation Model Documentation for more information. The Copernicus DEM provides global coverage at 30-m pixel spacing, except for areas over Armenia and Azerbaijan . These gaps in coverage are filled with the Copernicus GLO-90 Public DEM, which has 90-m pixel spacing. The DEM tiles necessary to cover the input granules for the InSAR product are downloaded. A geoid correction is applied to the DEM, and it is resampled to match the output resolution of the InSAR product (160 m for 20x4 products, 80 m for 10x2 products) and projected to the appropriate UTM Zone for the granule location. Calculate Overlapping Bursts \u00b6 The IW SLC Sentinel-1 data comes in three sub-swaths. However, a further subdivision is made in the data, wherein bursts occur. Bursts are the fundamental building block for Sentinel-1 imagery. Each one is a portion of the final image, around 1500 lines long and one sub-swath width wide. Thus, the more busts, the longer the file is in length. Each burst is precisely timed to repeat at a given time interval. This consistent repeat combined with precise velocity control gives rise to the fact that the bursts start at the same time on each pass around the globe. For example, a burst images a piece of the Gal\u00e1pagos Islands. The next time that same piece of the island is imaged, the time of day will be the same, to within few milliseconds. Only the frames containing overlapping bursts can be used to perform InSAR processing. This means that if there is no burst overlap in the pair selected as input, the InSAR process will not run . Repeatable burst timing is exploited by HyP3 in order to calculate the bursts that overlap between two scenes. These overlapping bursts are the only ones used in the rest of the InSAR process. The rest are discarded. Interferogram Creation, Co-registration and Refinement \u00b6 Before the interferogram is created, the lookup table that maps from the SLC image space into a ground range image space is created. At this time, the interferogram of the topography is simulated using the previously prepared DEM. Once these steps have been performed, the two SLCs are co-registered to within 0.02 pixels. This is done by iteratively using the following steps: Resample the secondary SLC using previously calculated offset polynomial Match the reference and secondary SLC images using intensity cross-correlation Estimate range and azimuth offset polynomial coefficients from results of matching Create a differential interferogram using the co-registered SLCs and the simulated interferogram Update offset polynomial by adding the current estimates Note that these steps are automatically run 4 times. At that point, if the last offset calculated was more than 0.02 pixels, then the procedure will fail to complete . Provided the images passed the check for convergence, the next co-registration step employs the Enhanced Spectral Diversity (ESD) algorithm to match the two scenes to better than 1/100th of a pixel. This is accomplished by examining the overlap area between subsequent bursts. If there is even a small offset, the phase between the bursts will not match. This phase mismatch is then used to calculate the corresponding azimuth offset. To finish interferogram processing, steps 1 through 4 are run once again, this time with the offsets from the ESD included. The output of this entire process is a wrapped interferogram . Phase Unwrapping \u00b6 All of the phase differences in wrapped interferograms lie between -\u03c0 and \u03c0. Phase unwrapping attempts to assign multiples of 2\u03c0 to add to each pixel in the interferogram to restrict the number of 2\u03c0 jumps in the phase to the regions where they may actually occur. These regions are areas of radar layover or areas of deformation exceeding half a wavelength in the sensor's line of sight. Thermal noise and interferometric decorrelation can also result in these 2\u03c0 phase discontinuities called residues . The phase unwrapping algorithm used for these products is Minimum Cost Flow (MCF) and Triangulation. Refer to this Technical Report from GAMMA Remote Sensing for more information on the MCF phase unwrapping approach. Filtering \u00b6 Before the interferogram can be unwrapped, it must be filtered to remove noise. This is accomplished using an adaptive spectral filtering algorithm. This adaptive interferogram filtering aims to reduce phase noise, increase the accuracy of the interferometric phase, and reduce the number of interferogram residues as an aid to phase unwrapping. In this case, residues are points in the interferogram where the sum of the phase differences between pixels around a closed path is not 0.0, which indicates a jump in phase. Masking \u00b6 Another step before unwrapping is to create a validity mask to guide the phase unwrapping process. This mask is generated by applying thresholds to the coherence and/or amplitude (backscatter intensity) values for an image pair. For On Demand InSAR products, we set the amplitude threshold to be 0.0 (in power scale), so that data is only excluded based on the coherence threshold. Coherence is estimated from the normalized interferogram. The pixel values in this file range from 0.0 (total decorrelation) to 1.0 (perfectly coherent). Any input pixel with a coherence value less than 0.1 is given a validity mask value of zero and not used during unwrapping. Change to Validity Mask Thresholds In the past, we also used an amplitude threshold of 0.2 (in power scale) when generating the validity mask. While this approach tends to mask out inland waters, providing a less noisy interferogram in some cases, it also masks arid regions that have low amplitude values but reasonably high coherence. As of March 2022, we have set the amplitude threshold to 0.0, so that coherence is the only driver of the validity mask. When the water masking option is applied, the validity mask is further amended to apply 0 values to any pixels classified as water in the water mask. In some cases, pixels over water may still meet the coherence and amplitude threshold criteria for inclusion, even though they are not valid for use during phase unwrapping. When processing scenes with extensive coverage by coastal waters or large inland waterbodies, there can be erroneous deformation signals or phase jumps introduced if unwrapping proceeds over water as if it were land. In such cases, choosing the option to apply the water mask can improve the results. Visit our InSAR Water Masking Tutorial for more information. Reference point \u00b6 In order to perform phase unwrapping, a reference point must be selected. The unwrapping will proceed relative to this reference point; the 2\u03c0 integer multiples will be applied to the wrapped phase using this pixel as the starting point. The unwrapped phase value is set to 0 at the reference point. Ideally, the reference point for phase unwrapping would be located in an area with high coherence in a stable region close to an area with surface deformation. Choosing an optimal reference point requires knowledge of the site characteristics and examination of the interferogram, which is not practical in an automated, global workflow. By default, ASF's On Demand InSAR products use the location of the pixel with the highest coherence value as the reference point. The coherence map is examined to determine the maximum value, and all pixels with this value are examined using a 9-pixel window. The pixel with the highest sum of values within its 9-pixel window is selected as the reference point. If more than one pixel has the same 9-pixel sum, the pixel closest to the origin pixel (bottom left corner for ascending scenes, top right corner for descending scenes) is selected. This may be an appropriate reference point location in many cases, as it meets the criteria of having high coherence, and stable areas have higher coherence than areas undergoing significant deformation. If a user wants to set a different location as the phase unwrapping reference point, however, a correction can be applied to the unwrapped interferogram. For more information on the impact of the phase unwrapping reference point location on unwrapped phase and displacement measurements, refer to the Limitations section of this document, which also includes instructions for applying a correction based on a custom reference point. Geocoding and Product Creation \u00b6 After the phase is unwrapped, the final steps are geocoding and product creation. Geocoding \u00b6 Geocoding is the process of reprojecting pixels from SAR slant range space (where all the calculations have been performed) into map-projected ground range space (where analysis of products is simplest). Using the look up table previously computed, this process takes each pixel in the input product and relocates it to the UTM zone of the DEM used in processing. This is accomplished using nearest-neighbor resampling so that original pixel values are preserved. Product Creation \u00b6 Files are next exported from GAMMA internal format into the widely-used GeoTIFF format, complete with geolocation information. GeoTIFFs are created for amplitude, coherence, and unwrapped phase by default, and a water mask GeoTIFF is also included in the product package. Optionally, GeoTIFFs of wrapped phase, look vectors, displacement maps (line-of-sight and vertical), and incidence angle maps can be included, as can a copy of the DEM used for processing. Product Packaging \u00b6 HyP3 InSAR output is a zip file containing various files, including GeoTIFFs, PNG browse images with geolocation information, Google Earth KMZ files, a metadata file, and a README file. Naming Convention \u00b6 The InSAR product names are packed with information pertaining to the processing of the data, presented in the following order, as illustrated in Figure 4. The platform names, either Sentinel-1A or Sentinel-1B, are abbreviated \"A\" or \"B\", indicating the reference and secondary granule's imaging platform The reference start date and time and the secondary start date and time, with the date and time separated by the letter T The polarizations for the pair, either HH or VV, the orbit type, and the days of separation for the pair The product type (always INT for InSAR) and the pixel spacing, which will be either 80 or 40, based upon the number of looks selected when the job was submitted for processing The software package used for processing is always GAMMA for GAMMA InSAR products User-defined options are denoted by three characters indicating whether the product is water masked (w) or not (u), the scene is clipped (e for entire area, c for clipped), and whether a single sub-swath was processed or the entire granule (either 1, 2, 3, or F for full swath) Currently, only the water masking is available as a user-selected option; the products always include the full granule extent with all three sub-swaths The filename ends with the ASF product ID, a 4 digit hexadecimal number Figure 4: Breakdown of ASF InSAR naming scheme. Image Files \u00b6 All of the main InSAR product files are 32-bit floating-point single-band GeoTIFFs. To learn more about the rasters included in the product package, refer to the Exploring Sentinel-1 InSAR StoryMap tutorial. The amplitude image is the calibrated radiometric backscatter from the reference granule in sigma-nought power. The image is terrain corrected using a geometric correction, but not radiometrically corrected. The coherence file pixel values range from 0.0 to 1.0, with 0.0 being completely non-coherent and 1.0 being perfectly coherent. The unwrapped phase file shows the results of the phase unwrapping process. Negative values indicate movement towards the sensor, and positive values indicate movement away from the sensor. This is the main interferogram output. The wrapped phase file indicates the interferogram phase after applying the adaptive filter immediately before unwrapping. Values range from negative pi to positive pi. (optional) The line-of-sight displacement file indicates the displacement in meters along the look direction of the sensor. The sign is opposite to that of the unwrapped phase: positive values indicate motion towards the sensor and negative values indicate motion away from the sensor. (optional) The vertical displacement is generated from the line of sight displacement values, and makes the assumption that deformation only occurs in the vertical direction. Note that this assumption may not hold true in cases where the deformation also has a horizontal component. Positive values indicate uplift, and negative values indicate subsidence. (optional) The look vectors theta (\u03b8) and phi (\u03c6) describe the elevation and orientation angles of the sensor's look direction. (optional) The incidence angle maps indicate the angle between the incident signal and the surface normal of either the terrain (local incidence angle) or the ellipsoid (ellipsoid incidence angle). (optional) The DEM file gives the local terrain heights in meters, with a geoid correction applied. (optional) The water mask file indicates coastal waters and large inland waterbodies. Pixel values of 1 indicate land and 0 indicate water. This file is in 8-bit unsigned integer format. If the water mask option is selected, the water mask is applied prior to phase unwrapping to exclude water pixels from the process. The water mask is generated using the GSHHG dataset. To compile the reference shapefile, the full-resolution L1 dataset (boundary between land and ocean) and L5 dataset (boundary between Antarctic ice and ocean) were combined. The L3 dataset (boundary between islands and the lakes they are within) was removed from the L2 dataset (boundary between lakes and land), and this combined dataset was removed from the combined L1/L5 dataset. The portion of the shapefile covering the scene is converted to a raster for inclusion in the phase unwrapping mask during InSAR processing. The GSHHG dataset was last updated in 2017, so there may be discrepancies where shorelines have changed. Visit our InSAR Water Masking Tutorial for more information about water masking. Browse images are included for the wrapped (color_phase) and unwrapped (unw_phase) phase files, which are in PNG format and are each 2048 pixels wide. The browse images are displayed using a cyclic color ramp to generate fringes. Each fringe in a wrapped (color_phase) browse image represents a 2-pi phase difference, and the line-of-sight displacement for each fringe is equivalent to half the wavelength of the sensor. The wavelength of Sentinel-1 is about 5.6 cm, so each 2-pi fringe represents a line-of-sight displacement of about 2.8 cm. Each fringe in an unwrapped (unw_phase) browse image represents a phase difference of 6 pi. Because each 2-pi difference is equivalent to half the wavelength of the sensor, each 6-pi fringe represents about 8.3 cm of line-of-sight displacement for these Sentinel-1 products. KMZ files are included for the wrapped (color_phase) and unwrapped (unw_phase) phase images, which allow users to view the outputs in Google Earth or other platforms that support kmz files. The tags and extensions used and example file names for each raster are listed in Table 2 below. Extension Description Example _amp.tif Amplitude S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _amp.tif _corr.tif Normalized coherence file S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _corr.tif _unw_phase.tif Unwrapped geocoded interferogram S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _unw_phase.tif _wrapped_phase.tif Wrapped geocoded interferogram S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _wrapped_phase.tif _los_disp.tif Line-of-sight displacement S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _los_disp.tif _vert_disp.tif Vertical displacement S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _vert_disp.tif _lv_phi.tif Look vector \u03c6 (orientation) S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _lv_phi.tif _lv_theta.tif Look vector \u03b8 (elevation) S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _lv_theta.tif _dem.tif Digital elevation model S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _dem.tif _inc_map_ell.tif Ellipsoid incidence angle S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _inc_map_ell.tif _inc_map.tif Local incidence angle S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _inc_map.tif _water_mask.tif Water mask S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _water_mask.tif _color_phase.kmz Wrapped phase kmz file S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _color_phase.kmz _unw_phase.kmz Unwrapped phase kmz file S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _unw_phase.kmz _color_phase.png Wrapped phase browse image S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _color_phase.png _unw_phase.png Unwrapped phase browse image S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _unw_phase.png Table 2: Image files in product package Metadata Files \u00b6 The product package also includes a number of metadata files. Extension Description Example .README.md.txt Main README file for GAMMA InSAR S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 .README.md.txt .txt Parameters and metadata for the InSAR pair S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 .txt .tif.xml ArcGIS compliant XML metadata for GeoTIFF files S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _unw_phase.tif.xml .png.xml ArcGIS compliant XML metadata for PNG files S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _color_phase.png.xml .png.aux.xml Geolocation information for png browse images S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _color_phase.png.aux.xml Table 3: Metadata files in product package README File \u00b6 The text file with extension .README.md.txt explains the files included in the folder, and is customized to reflect that particular product. Users unfamiliar with InSAR products should start by reading this README file, which will give some background on each of the files included in the product folder. InSAR Parameter File \u00b6 The text file with extension .txt includes processing parameters used to generate the InSAR product as well as metadata attributes for the InSAR pair. These are detailed in Table 4. Name Description Possible Value Reference Granule ESA granule name for reference scene (of the two scenes in the pair, the dataset with the oldest timestamp) S1A _IW _SLC __1SDV _20200116T032559 _20200116T032627 _030820 _038928 _F5DC Secondary Granule ESA granule name for secondary scene (of the two scenes in the pair, the dataset with the newest timestamp) S1B _IW _SLC __1SDV _20200128T032559 _20200128T032627 _030995 _038F51 _7D4F Reference Pass Direction Orbit direction of the reference scene DESCENDING Reference Orbit Number Absolute orbit number of the reference scene 30741 Secondary Pass Direction Orbit direction of the reference scene DESCENDING Secondary Orbit Number Absolute orbit number of the secondary scene 31091 Baseline Perpendicular baseline in meters 58.3898 UTCTime Time in the UTC time zone in seconds 12360.691361 Heading Spacecraft heading measured in degrees clockwise from north 193.2939317 Spacecraft height Height in meters of the spacecraft above nadir point 700618.6318999995 Earth radius at nadir Ellipsoidal earth radius in meters at the point directly below the satellite 6370250.0667 Slant range near Distance in meters from satellite to nearest point imaged 799517.4338 Slant range center Distance in meters from satellite to the center point imaged 879794.1404 Slant range far Distance in meters from satellite to farthest point imaged 960070.8469 Range looks Number of looks taken in the range direction 20 Azimuth looks Number of looks taken in the azimuth direction 4 InSAR phase filter Name of the phase filter used adf Phase filter parameter Dampening factor 0.6 Resolution of output (m) Pixel spacing in meters for output products 80 Range bandpass filter Range bandpass filter applied no Azimuth bandpass filter Azimuth bandpass filter applied no DEM source DEM used in processing GLO-30 DEM resolution Pixel spacing in meters for DEM used to process this scene 160 Unwrapping type Phase unwrapping algorithm used mcf Phase at Reference Point Original unwrapped phase value at the reference point (set to 0 in output unwrapped phase raster) -4.21967 Azimuth line of the reference point in SAR space Row number (in SAR space) of the reference point 2737.0 Range pixel of the reference point in SAR space Column number (in SAR space) of the reference point 739.0 Y coordinate of the reference point in the map projection Latitude of the reference point in projected coordinates (UTM Zone - meters) 4112453.3223 X coordinate of the reference point in the map projection Longitude of the reference point in projected coordinates (UTM Zone - meters) 589307.6248 Latitude of the reference point (WGS84) Latitude of the reference point in WGS84 Geographic Coordinate System (degrees) 37.1542125 Longitude of the reference point (WGS84) Longitude of the reference point in WGS84 Geographic Coordinate System (degrees) 40.00574707 Unwrapping threshold Minimum coherence required to unwrap a given pixel none Speckle filter Speckle filter applied no Table 4: List of InSAR parameters included in the parameter text file ArcGIS-Compatible XML Files \u00b6 There is an ArcGIS-compatible XML file for each raster in the product folder. When ArcGIS Desktop users view any of the rasters in ArcCatalog or the Catalog window in ArcMap, they can open the Item Description to view the contents of the associated XML file. ArcGIS Pro users can access the information from the Metadata tab. These files will not appear as separate items in ArcCatalog, though if you use Windows Explorer to look at the contents of the folder you will see them listed individually. Because each one is named identically to the product it describes (with the addition of the .xml extension), ArcGIS recognizes the appropriate file as the raster\u2019s associated metadata, and integrates the metadata accordingly. ArcGIS users should take care not to change these XML files outside of the ArcGIS environment; changing the filename or content directly may render the files unreadable by ArcGIS. Those not using ArcGIS will still find the contents of these XML files useful, but will have to contend with the XML tagging when viewing the files as text or in a browser. Auxiliary Geolocation Files \u00b6 Geolocation XML files (aux files) are included for each of the PNG browse images to allow for proper display in GIS platforms. Limitations \u00b6 Baseline Calculation \u00b6 The baseline is defined as the difference of the platform positions when a given area is imaged. HyP3 baselines are calculated using the best state vectors available. If precise orbits are not yet available for the input granules, restituted orbits will be used. The original predicted orbits are not used for InSAR processing in HyP3. If no restituted or precise state vectors are available, the process will not run. Coherence \u00b6 The phase measurements in the two images used in InSAR must be coherent in order to detect change. Random changes in phase from one acquisition to the next can mask actual surface deformation. Vegetation is a common driver of decorrelation, as changes can easily take place in the interval between two acquisitions due to growth, seasonal changes, or wind effects. It will be difficult to generate valid interferograms with C-band data in heavily vegetated regions due to lack of coherence even with fairly short time intervals. Consider seasonality when selecting image pairs. Decorrelation can be particularly high when comparing phase from different seasons. Changes in the condition of vegetation (especially deciduous canopies), snow, moisture, or freeze/thaw state can impact phase measurements. In cases where a temporal baseline is required that spans seasons, it may be better to use an annual interferogram if possible so that the images are more comparable in terms of seasonality. Line-of-Sight Measurements \u00b6 When looking at a single interferogram, the deformation measurements in the line-of-sight orientation of the sensor indicate relative motion towards or away from the sensor. InSAR is not sensitive to motion in the azimuth direction of the satellite, so motion that occurs in the same direction as the satellite's direction of travel will not be detected. A single interferogram cannot be used to determine the relative contributions of vertical and horizontal movement to the line-of-sight displacement measurement. The vertical displacement map is generated based on the assumption that the movement is entirely in the vertical direction, which may not be realistic for some processes. To determine how much of the signal is driven by vertical vs. horizontal movement, you must either use a time series of interferograms, or use reference measurements with known vertical and horizontal components (such as GNSS measurements from the region of deformation) to deconstruct the line-of-sight displacement. All displacement values are calculated relative to a reference point , which may or may not be an appropriate benchmark for measuring particular areas of displacement within the interferogram. Phase Unwrapping Reference Point \u00b6 The reference point for phase unwrapping is set to be the location of the pixel with the highest coherence value. As described in the phase unwrapping section , this may not always be an ideal location to use as a reference point. If it is located in an area undergoing deformation, or in a patch of coherent pixels that is separated from the area undergoing deformation by a gap of incoherent pixels, the unwrapping may be of lower quality than if the reference point was in a more suitable location. Even when there are not phase unwrapping errors introduced by phase discontinuities, it is important to be aware that unwrapped phase differences and displacement values are all calculated relative to the reference point. The phase difference value of the reference point is set to 0 during phase unwrapping, so any displacement values will be relative to that benchmark. If the location of the default reference point is in the middle of an area that underwent deformation, displacement values may be different than expected. If you are interested in the amount of displacement in a particular area, you may wish to choose your own reference point. The ideal reference point would be in an area of high coherence beyond where deformation has occurred. The unwrapped phase measurements can be adjusted to be relative to this new reference point, and displacement values can be recalculated accordingly. To adjust the values in the unwrapped phase GeoTIFF, simply select a reference point that is optimal for your use case and subtract the unwrapped phase value of that reference point from each pixel in the unwrapped phase raster: \u0394\u03a8 * = \u0394\u03a8 - \u0394\u03c8 ref where \u0394\u03a8 * is the adjusted unwrapped phase, \u0394\u03a8 is the original unwrapped phase, and \u0394\u03c8 ref is the unwrapped phase value at the new reference point. Impacts on Displacement Measurements \u00b6 The measurements in the displacement maps are calculated from the unwrapped phase values, so will similarly be impacted by the location of the reference point. You may wish to recalculate the displacement values relative to a new reference point. The approach for correcting the displacement maps will be different for the line-of-sight and vertical measurements. Correcting Line-of-Sight Displacement Maps \u00b6 If you have already corrected the unwrapped phase raster, you can calculate a new line-of-sight (LOS) displacement map by applying the following calculation on a pixel-by-pixel basis using the unwrapped phase GeoTIFF: \u0394\u03a9 * = - \u0394\u03a8 * \u03bb / 4\u03c0 where \u0394\u03a9 * is the adjusted line-of-sight displacement in meters, \u0394\u03a8 * is the adjusted unwrapped phase , and \u03bb is the wavelength of the sensor in meters (0.055465763 for Sentinel-1). Setting the \u0394\u03a8 * value to be negative reverses the sign so that the difference is relative to the earth rather than the sensor. A positive phase difference value indicates subsidence, which is unintuitive when thinking about movement on the earth's surface. Applying the negative will return positive displacement values for uplift and negative values for subsidence. If you are not interested in adjusted unwrapped phase values, you can also directly correct the LOS Displacement map included optionally in the InSAR product package: \u0394\u03a9 * = \u0394\u03a9 - \u0394\u03c9 ref where \u0394\u03a9 * is the adjusted line-of-sight displacement in meters, \u0394\u03a9 is the original line-of-sight displacement in meters, and \u0394\u03c9 ref is the line-of-sight displacement value at the new reference point. Correcting Vertical Displacement Maps \u00b6 Vertical displacement maps cannot be adjusted directly, and must be recalculated from the adjusted unwrapped phase image. You will also need the \u03b8 look vector map (lv_theta GeoTIFF) for this calculation. The look vector maps are not included in the InSAR product package by default; the option to Include Look Vectors must be selected when ordering the product. To calculate an adjusted vertical displacement raster, calculate the adjusted unwrapped phase , then apply the following: \u0394\u03d2 * = - \u0394\u03a8 * \u03bb cos(\u00bd\u03c0 - LV \u03b8 ) / 4\u03c0 where \u0394\u03d2 * is the adjusted vertical displacement in meters, \u0394\u03a8 * is the adjusted unwrapped phase, \u03bb is the wavelength of the sensor in meters (0.055465763 for Sentinel-1), and LV \u03b8 is the theta look vector (from the lv_theta GeoTIFF). As with the LOS Displacement maps, setting the \u0394\u03a8 * value to be negative reverses the sign so that the difference is relative to the earth rather than the sensor. Applying the negative will return positive displacement values for uplift and negative values for subsidence. Displacement Values from a Single Interferogram \u00b6 In general, calculating displacement values from a single interferogram is not recommended. While the displacement rasters provided with ASF's On Demand InSAR products can be helpful in visualizing changes, we do not recommend that you rely on a single interferogram when coming to conclusions about surface displacement, even if you apply a correction based on a manually selected reference point. It will be more robust to use a time series approach to more accurately determine the pattern of movement. When using SAR time-series software such as MintPy , you have the option to select a specific reference point, and the values of the input rasters will be adjusted accordingly. Error Sources \u00b6 On Demand InSAR products do not currently correct for some common sources of error in interferometry, such as atmospheric effects. Further processing or time series analysis can be performed by the user to identify or reduce the impact of some of these errors when using On Demand InSAR products for analysis. Atmospheric Delay \u00b6 While SAR signals can penetrate clouds, atmospheric conditions can delay the transmission of the signal. This results in phase differences that can look like surface deformation signals but are actually driven by differences in the atmospheric conditions between the pair of acquisitions used to generate the interferogram. In some cases, atmospheric errors can be corrected by using an atmospheric model to remove the impacts of the turbulent delay from the interferogram. Another approach is to use time series analysis to identify outliers. Always doubt your interferogram first! View the interferogram critically, and consider if fringe patterns could potentially be driven by atmospheric effects. In general, it is best to avoid drawing conclusions from the outcome of a single interferogram. Turbulent Delay \u00b6 These delays are generally caused by differences in water vapor distribution from one image to the next. They often manifest as wobbly or sausage-shaped fringes, and can potentially mask the signal of a small earthquake. Stratified Delay \u00b6 This type of delay is driven mostly by pressure and temperature differences or gradients through the atmospheric column, and often correlates with topography. This atmospheric signature can be confused with movement caused by volcanic activity. If there are multiple volcanoes in an image and they all exhibit similar patterns, it is likely being driven by this type of atmospheric delay. DEM Errors \u00b6 A DEM is used to remove topographic phase impacts, but if there are inaccuracies in the DEM, residual impacts of those errors can remain in the interferogram. Orbit Uncertainties \u00b6 This is generally not an issue for Sentinel-1 data, as the orbits are very precise and generally reliable. On Demand InSAR products are only processed once restituted or precise orbits are available. Orbit uncertainties are more problematic when working with datasets from older missions.","title":"Product Guide"},{"location":"guides/insar_product_guide/#sentinel-1-insar-product-guide","text":"This document is a guide for users of Interferometric Synthetic Aperture Radar (InSAR) Sentinel-1 products generated by the Alaska Satellite Facility (ASF). Users can request InSAR products On Demand in ASF's Vertex data portal, or make use of our HyP3 Python SDK or API . This process requires Sentinel-1 IW SLC products as input. Input pairs can be selected in Vertex using either the Baseline Tool or the SBAS Tool search interfaces. For a step-by-step tutorial on ordering On-Demand InSAR Products using Vertex, visit our InSAR On Demand! StoryMap . To learn more about the files included in the On Demand InSAR product packages and how to work with them, refer to our Exploring Sentinel-1 InSAR StoryMap . InSAR processing requires a Digital Elevation Model (DEM) for the removal of topographic phase. We use the GLO-30 Copernicus DEM when processing our On Demand InSAR products. Refer to the Prepare the DEM File section for more information. Coverage gaps in Copernicus DEM GLO-30 filled using GLO-90 The Copernicus DEM GLO-30 dataset does not provide coverage over Armenia and Azerbaijan. In the past, we have not supported InSAR product generation over those areas, due to the lack of DEM coverage. We now use the Copernicus DEM GLO-90 to fill those gaps. The GLO-90 dataset has a pixel spacing of 90 meters, which is not as detailed as the 30-m pixel spacing in the GLO-30 DEM, but it does allow us to provide InSAR products in these regions, where they were previously unavailable. Users are cautioned to read the sections on limitations and error sources in InSAR products before attempting to use InSAR data. For a more complete description of the properties of SAR, see our Introduction to SAR guide.","title":"Sentinel-1 InSAR Product Guide"},{"location":"guides/insar_product_guide/#introduction","text":"Interferometric Synthetic Aperture Radar (InSAR) processing uses two SAR images collected over the same area to determine geometric properties of the surface. Missions such as Sentinel-1 are designed for monitoring surface deformation using InSAR, which is optimal when acquisitions are made from a consistent location in space ( short perpendicular baseline ) over regular time intervals. The phase measurements of two SAR images acquired at different times from the same place in orbit are differenced to detect and quantify surface changes, such as deformation caused by earthquakes, volcanoes, or groundwater subsidence. InSAR can also be used to generate digital elevation models, but the optimal mission for DEM generation has the opposite characteristics of the Sentinel-1 mission. Topography is best mapped when the two acquisitions are obtained as close together as possible in time ( short temporal baseline ), but from different vantage points in space (larger perpendicular baseline than would be optimal for deformation mapping).","title":"Introduction"},{"location":"guides/insar_product_guide/#brief-overview-of-insar","text":"SAR is an active sensor that transmits pulses and listens for echoes. These echoes are recorded in phase and amplitude, with the phase being used to determine the distance from the sensor to the target and the amplitude yielding information about the roughness and dielectric constant of that target. Figure 1: Two passes of an imaging SAR taken at time T 0 and T 0 + \u2206t, will give two distances to the ground, R 1 and R 2 . A difference between R 1 and R 2 shows motion on the ground. In this case, a subsidence makes R 2 greater than R 1 . Credit: TRE ALTAMIRA InSAR exploits the phase difference between two SAR images to create an interferogram that shows where the phase and, therefore, the distance to the target has changed from one pass to the next, as illustrated in Figure 1. There are several factors that influence the interferogram, including earth curvature, topographic effects, atmospheric delays, surface motion, and noise. With proper processing, Sentinel-1 InSAR can be used to detect changes in the earth's surface down to the centimeter scale. Applications include volcanic deformation, subsidence, landslide detection, and earthquake assessment.","title":"Brief Overview of InSAR"},{"location":"guides/insar_product_guide/#wavelengths","text":"The SAR sensors on the Sentinel-1 satellites transmit C-band signals, with a wavelength of 5.6 cm. The signal wavelength impacts the penetration capability of the signal, so it is important to be aware of the sensor wavelength when working with SAR datasets. C-band SAR will penetrate more deeply into canopy or surfaces than an X-band signal, but not nearly as deep as an L-band SAR signal, which, with a wavelength on the order of 25 cm, is better able to penetrate canopy and return signals from the forest floor. Different wavelengths are also sensitive to different levels of deformation. To detect very small changes over relatively short periods of time, you may require a signal with a smaller wavelength (such as X-band). However, signals with shorter wavelengths are also more prone to decorrelation due to small changes in surface conditions such as vegetation growth. For slower processes that require a longer time interval to detect movement, longer wavelengths (such as L-band) may be necessary. C-band sits in the middle. It can detect fairly small changes over fairly short periods of time, but is not as sensitive to small changes as X-band or as able to monitor surface dynamics under canopy as L-band.","title":"Wavelengths"},{"location":"guides/insar_product_guide/#polarizations","text":"Polarization refers to the direction of travel of an electromagnetic wave. A horizontal wave is transmitted so that it oscillates in a plane parallel to the surface imaged, while a vertical wave oscillates in a plane perpendicular to the surface imaged. Most modern SAR systems can transmit chirps with either a horizontal or vertical polarization. In addition, some of these sensors can listen for either horizontal or vertical backscatter. This gives rise to 4 different types of returns: HH, HV, VV, and VH, with the first letter indicating the transmission method and the second the receive method. For example, VH is a vertically polarized transmit signal with horizontally polarized echoes recorded. For InSAR applications, processing is generally performed on the co-pol (VV or HH) data and not on the cross-pol (VH or HV) data. Also, each image used in an InSAR pair is required to be the same polarization - two HH images of the same area could form a valid pair, while a single HH with a single VV of the same area would not.","title":"Polarizations"},{"location":"guides/insar_product_guide/#baselines","text":"","title":"Baselines"},{"location":"guides/insar_product_guide/#perpendicular-baseline","text":"The term baseline refers to the physical distance between the two vantage points from which images used as an InSAR pair are acquired. The baseline is decomposed into perpendicular (also called normal) and parallel components, as shown in Figure 2. To monitor surface deformation, the perpendicular baseline for the two acquisitions should be very small in order to maximize the coherence of the phase measurements. In order to determine topography, two slightly different vantage points are required. Sensitivity to topography depends on the perpendicular baseline, the sensor wavelength, the distance between the satellite and the ground, and the sensor look angle. Figure 2: Geometry of InSAR baselines. Two satellite passes image the same area on the ground from positions S 1 and S 2 , resulting in a baseline of B, which can be decomposed into perpendicular (B \u27c2 ) and parallel (B \u2225 ) components. Here Y is the direction of travel, referred to as the along-track or azimuth direction, and X is the direction perpendicular to motion, referred to as the cross-track or range direction. Credit: ASF","title":"Perpendicular Baseline"},{"location":"guides/insar_product_guide/#temporal-baseline","text":"In contrast to the (physical) baseline, the temporal baseline refers to the time separation between imaging passes. Along-track interferometry measures motion in the millisecond to second range. This technique can detect ocean currents and rapidly moving objects like boats. Differential interferometry is the standard method used to detect motion in the range of days to years. This is the type of interferometry that is performed by the Sentinel-1 HyP3 InSAR processing algorithm. Table 1 lists different temporal baselines, their common names, and what they can be used to measure. Duration Known as Measurement of ms to sec along-track ocean currents, moving object detection, MTI days differential glacier/ice fields/lava flows, surface water extent, hydrology days to years differential subsidence, seismic events, volcanic activity, crustal displacement Table 1: Temporal baselines and what they measure. Different geophysical phenomena can be detected based upon the temporal baseline. In general, the longer the temporal baseline, the smaller the motion that can be detected.","title":"Temporal Baseline"},{"location":"guides/insar_product_guide/#critical-baseline","text":"Large baselines are better than small for topographic mapping. However, as the baseline increases, coherence decreases. At some point, it is impossible to create an interferogram because of baseline decorrelation. The maximum viable baseline per platform, referred to as the critical baseline , is a function of the distance to the ground, the wavelength, and the viewing geometry of the platform. For Sentinel-1, this critical baseline is about 5 km. In practice, if the perpendicular baseline between images is more than 3/4 of the critical baseline, interferogram creation will be problematic due to the level of noise. For deformation mapping, it is best to minimize the perpendicular baseline whenever possible, but there may be tradeoffs in terms of finding suitable temporal baselines. In most cases, however, pairs selected for deformation mapping will have perpendicular baselines much smaller than the critical baseline.","title":"Critical Baseline"},{"location":"guides/insar_product_guide/#ordering-on-demand-insar-products","text":"All of ASF's On Demand InSAR products are generated using ASF's HyP3 platform. Jobs can be submitted for processing using the Vertex data portal, the HyP3 Python SDK or the HyP3 API .","title":"Ordering On Demand InSAR Products"},{"location":"guides/insar_product_guide/#vertex","text":"InSAR pairs are selected in Vertex using either the Baseline Search or the SBAS Search interface. The Baseline tool is the best option for selecting specific InSAR pairs. Use the Geographic Search to find an image that covers your time and area of interest, select that item in the results, and click the Baseline button in the center panel. The Baseline tool then displays all of the scenes that could be used to generate an interferogram using the selected image. Scroll through the results to find pairs to add to the On Demand queue, or click on items displayed in the plot to highlight that particular image pair. The SBAS tool is designed for generating time series of InSAR pairs. As with the Baseline search, you can launch the SBAS search from the center panel of a Geographic Search result. It will display all of the valid InSAR pairs through time based on the acquisition location of the input scene. This functionality is designed for processing a series of interferograms to be used in SBAS (Small BAseline Subset) analysis. The results can be adjusted based on baseline criteria (both perpendicular and temporal), and restricted to specific periods of time. Once the list is refined, you have the option to add all of the InSAR pairs displayed in the results to the On Demand queue.","title":"Vertex"},{"location":"guides/insar_product_guide/#hyp3-sdk-and-api","text":"The HyP3 SDK provides support for processing nearest-neighbor interferograms for a selected granule. Specifying nearest-neighbor processing will find the next appropriate scene back in time to use as the reference granule for generating an interferogram with the selected granule. You can specify up to 2 nearest neighbors, which will pair the scene closest in time and next-closest in time to the selected granule for generating InSAR products, as demonstrated in this sample HyP3 SDK Jupyter Notebook . You may still find the Geographic, Baseline and SBAS searches in Vertex useful for finding reference scenes or picking specific pairs to use when submitting InSAR jobs via the SDK or API .","title":"HyP3 SDK and API"},{"location":"guides/insar_product_guide/#considerations-for-selecting-an-insar-pair","text":"When selecting an InSAR pair, observe the following required conditions: Images from an identical orbit direction (either ascending or descending) Images with identical incidence angles and beam mode Images with identical resolution and wavelength (usually from the same sensor) Images with the same viewing geometry (same path and frame) Images with identical polarizations (both HH or VV) In addition, the following suggestions may be helpful: Use images from similar seasons/growth/weather conditions For deformation mapping: limited spatial separation of acquisition locations (small physical baseline) For topographic mapping: limited time separation between images (small temporal baseline) To analyze deformation caused by a single discrete event, such as an earthquake, select images that bracket the event as closely in time as possible. Keeping the window narrowly focused on the time of the event will reduce the impacts of other processes that may mask the signal of the event of interest.","title":"Considerations for Selecting an InSAR Pair"},{"location":"guides/insar_product_guide/#processing-options","text":"New Water Masking Approach InSAR products can be phase unwrapped using a water mask. The option to \"Apply water mask\" sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping. This reduces phase unwrapping errors and outputs a less noisy unwrapped interferogram. As of September 27, 2022, the water mask used for this option is no longer buffered. The original water mask had a 3 km buffer on coastlines and a 5 km buffer on the shorelines of inland waterbodies. This was to reduce the chance that valid land pixels would be excluded from phase unwrapping, but it appears that the inclusion of more water pixels is more detrimental to phase unwrapping than the exclusion of some land pixels. Visit our InSAR Water Masking Tutorial for more information. Change in Displacement Map Options There is now a single option for including displacement maps. Both line-of-sight and vertical displacement maps will only be added to the product package if the option to \"Include Displacement Maps\" is selected when submitting On-Demand InSAR jobs. Use caution when referencing the values included in the displacement maps, as the values are calculated relative to an arbitrary reference point. Refer to the Phase Unwrapping Reference Point section for more information. There are several options users can set when ordering InSAR On Demand products. Currently, users can choose the number of looks to take (which drives the resolution and pixel spacing of the products), and which optional products to include in the output package. The options are described below: The number of looks drives the resolution and pixel spacing of the output products. Selecting 10x2 looks will yield larger products with 80 m resolution and pixel spacing of 40 m. Selecting 20x4 looks reduces the resolution to 160 m and reduces the size of the products (roughly 1/4 the size of 10x2 look products), with a pixel spacing of 80 m. The default is 20x4 looks. The look vectors are stored in two files. The look vector refers the look direction back towards the sensor. The lv_theta (\u03b8) indicates the SAR look vector elevation angle at each pixel, ranging from -\u03c0/2 (down) to \u03c0/2 (up). The look vector elevation angle is defined as the angle between the horizontal surface and the look vector with positive angles indicating sensor positions above the surface. The lv_phi (\u03c6) map indicates the SAR look vector orientation angle at each pixel, ranging from -\u03c0 (west) to \u03c0 (west). The look vector orientation angle is defined as the angle between the East direction and the projection of the look vector on the horizontal surface plane. The orientation angle increases towards north, with the North direction corresponding to \u03c0/2 (and south to -\u03c0/2). Both angles are expressed in radians. The default is to not include these files in the output product bundle. The displacement maps convert the phase difference values from the unwrapped interferogram into measurements of ground displacement in meters. The line-of-sight displacement map indicates the amount of movement away from or towards the sensor. The vertical displacement calculates the vertical component of the line-of-sight displacement, using the assumption that all deformation is in the vertical direction. These files are excluded from the product package by default. The wrapped phase GeoTIFF can be included in the output package. The browse version of this GeoTIFF (_color_phase.png) is always included, but the GeoTIFF version is not included by default. The specific color ramp displayed in the png is most valuable for many users, but some may wish to work with the actual wrapped phase values. The incidence angle maps indicate the angle of the radar signal. The local incidence angle is defined as the angle between the incident radar signal and the local surface normal, expressed in radians, while the ellipsoid incidence angle indicates the angle between the incident radar beam and the direction perpendicular to the WGS84 ellipsoid model. These files are excluded from the product package by default. A copy of the DEM used for processing can optionally be included in the product package. The file has been projected to a UTM Zone coordinate system, and pixel values indicate the elevation in meters. The elevation values will differ from the original Copernicus DEM GLO-30 dataset, as a geoid correction has been applied. The source DEM is also downsampled to twice the pixel spacing of the output product to smooth it for use in processing, then resampled again to match the pixel spacing of the InSAR product. The DEM is excluded by default. There is an option to apply a water mask . This mask includes coastal waters and large inland waterbodies. Masking waterbodies can have a significant impact during the phase unwrapping, as water can sometimes exhibit enough coherence between acquisitions to allow for unwrapping to occur over waterbodies, which is invalid. A GeoTIFF of the water mask is always included with the InSAR product package, but when this option is selected, the conditional water mask will be applied along with coherence and intensity thresholds during the phase unwrapping process. Water masking is turned off by default. Visit our InSAR Water Masking Tutorial for more information.","title":"Processing Options"},{"location":"guides/insar_product_guide/#insar-workflow","text":"The InSAR workflow used in HyP3 was developed by ASF using GAMMA software. The steps include pre-processing steps, interferogram preparation, and product creation. Once these steps are performed, an output product package will be created. See product packaging for details on the individual files included in the package.","title":"InSAR Workflow"},{"location":"guides/insar_product_guide/#pre-processing","text":"Pre-processing steps prepare the SAR images to be used in interferometry. The pre-processing steps include image selection, ingest (including calibration), creation of a suitable DEM, and calculation of the burst overlap.","title":"Pre-Processing"},{"location":"guides/insar_product_guide/#select-an-insar-pair","text":"Although it is possible to start from RAW data, Sentinel-1 InSAR processing is typically done using Interferometric Wide swath Single Look Complex (IW SLC) data as the input. This means that the data has been formed into an image through SAR processing, but has not been multi-looked. The SLC pair is defined by the user , either through the Vertex interface, or using the HyP3 API or SDK. To ensure consistency, the older SLC image is always used as the reference image, and the younger SLC image is always used as the secondary image. This means that positive values in the resulting unwrapped interferogram represent movement away from the SAR platform and negative values represent movement towards the SAR platform. However, these values are relative to the reference point of the unwrapped interferogram. See the phase unwrapping section for more details.","title":"Select an InSAR Pair"},{"location":"guides/insar_product_guide/#ingest-slc-data-into-gamma-format","text":"Once the InSAR pair has been identified, the selected SLC data are ingested into GAMMA internal format. This is performed by the GAMMA program par_s1_slc . GAMMA format has raw data files (only data, no headers or line leaders) with metadata stored in external files with a .par extension. During ingest into GAMMA's internal format, the SLC data is calibrated by applying the calibration coefficients that are supplied with each product. This process puts the SAR backscatter into a known scale where the diffuse volume scattering of the Amazon rainforest is a constant -6.5 dB. Immediately after ingesting the SLC, the state vectors are updated to use the best available state vectors. The state vector types in order of absolute correctness are original predicted (O), restituted (R), and precision (P). In practice, one will never receive an InSAR product that uses the original predicted orbit - only granules for which a restituted or precision orbit is available can be used in HyP3 InSAR processing. The orbit type used for generating the InSAR product is indicated in the product filename, as shown in Figure 3. Figure 3: Position of the orbit type in the HyP3 product name.","title":"Ingest SLC data into GAMMA format"},{"location":"guides/insar_product_guide/#prepare-the-dem-file","text":"In order to create differential InSAR products that show motion on the ground, one must subtract the topographic phase from the interferogram. The topographic phase, in this case, is replicated by using an existing DEM to calculate the actual topographic phase. This phase is then removed from the interferogram leaving just the motion or deformation signal (plus atmospheric delays and noise). The DEM that is used for HyP3 InSAR processing is the 2022 Release of the Copernicus GLO-30 Public DEM dataset publicly available on AWS . For more information about the 2022 updates, see the 'Releases' section of this article . The Copernicus DEM provides higher-quality products over a wider area than the older DEMs (SRTM and NED) previously used to generate ASF's On Demand products. Refer to our Digital Elevation Model Documentation for more information. The Copernicus DEM provides global coverage at 30-m pixel spacing, except for areas over Armenia and Azerbaijan . These gaps in coverage are filled with the Copernicus GLO-90 Public DEM, which has 90-m pixel spacing. The DEM tiles necessary to cover the input granules for the InSAR product are downloaded. A geoid correction is applied to the DEM, and it is resampled to match the output resolution of the InSAR product (160 m for 20x4 products, 80 m for 10x2 products) and projected to the appropriate UTM Zone for the granule location.","title":"Prepare the DEM File"},{"location":"guides/insar_product_guide/#calculate-overlapping-bursts","text":"The IW SLC Sentinel-1 data comes in three sub-swaths. However, a further subdivision is made in the data, wherein bursts occur. Bursts are the fundamental building block for Sentinel-1 imagery. Each one is a portion of the final image, around 1500 lines long and one sub-swath width wide. Thus, the more busts, the longer the file is in length. Each burst is precisely timed to repeat at a given time interval. This consistent repeat combined with precise velocity control gives rise to the fact that the bursts start at the same time on each pass around the globe. For example, a burst images a piece of the Gal\u00e1pagos Islands. The next time that same piece of the island is imaged, the time of day will be the same, to within few milliseconds. Only the frames containing overlapping bursts can be used to perform InSAR processing. This means that if there is no burst overlap in the pair selected as input, the InSAR process will not run . Repeatable burst timing is exploited by HyP3 in order to calculate the bursts that overlap between two scenes. These overlapping bursts are the only ones used in the rest of the InSAR process. The rest are discarded.","title":"Calculate Overlapping Bursts"},{"location":"guides/insar_product_guide/#interferogram-creation-co-registration-and-refinement","text":"Before the interferogram is created, the lookup table that maps from the SLC image space into a ground range image space is created. At this time, the interferogram of the topography is simulated using the previously prepared DEM. Once these steps have been performed, the two SLCs are co-registered to within 0.02 pixels. This is done by iteratively using the following steps: Resample the secondary SLC using previously calculated offset polynomial Match the reference and secondary SLC images using intensity cross-correlation Estimate range and azimuth offset polynomial coefficients from results of matching Create a differential interferogram using the co-registered SLCs and the simulated interferogram Update offset polynomial by adding the current estimates Note that these steps are automatically run 4 times. At that point, if the last offset calculated was more than 0.02 pixels, then the procedure will fail to complete . Provided the images passed the check for convergence, the next co-registration step employs the Enhanced Spectral Diversity (ESD) algorithm to match the two scenes to better than 1/100th of a pixel. This is accomplished by examining the overlap area between subsequent bursts. If there is even a small offset, the phase between the bursts will not match. This phase mismatch is then used to calculate the corresponding azimuth offset. To finish interferogram processing, steps 1 through 4 are run once again, this time with the offsets from the ESD included. The output of this entire process is a wrapped interferogram .","title":"Interferogram Creation, Co-registration and Refinement"},{"location":"guides/insar_product_guide/#phase-unwrapping","text":"All of the phase differences in wrapped interferograms lie between -\u03c0 and \u03c0. Phase unwrapping attempts to assign multiples of 2\u03c0 to add to each pixel in the interferogram to restrict the number of 2\u03c0 jumps in the phase to the regions where they may actually occur. These regions are areas of radar layover or areas of deformation exceeding half a wavelength in the sensor's line of sight. Thermal noise and interferometric decorrelation can also result in these 2\u03c0 phase discontinuities called residues . The phase unwrapping algorithm used for these products is Minimum Cost Flow (MCF) and Triangulation. Refer to this Technical Report from GAMMA Remote Sensing for more information on the MCF phase unwrapping approach.","title":"Phase Unwrapping"},{"location":"guides/insar_product_guide/#filtering","text":"Before the interferogram can be unwrapped, it must be filtered to remove noise. This is accomplished using an adaptive spectral filtering algorithm. This adaptive interferogram filtering aims to reduce phase noise, increase the accuracy of the interferometric phase, and reduce the number of interferogram residues as an aid to phase unwrapping. In this case, residues are points in the interferogram where the sum of the phase differences between pixels around a closed path is not 0.0, which indicates a jump in phase.","title":"Filtering"},{"location":"guides/insar_product_guide/#masking","text":"Another step before unwrapping is to create a validity mask to guide the phase unwrapping process. This mask is generated by applying thresholds to the coherence and/or amplitude (backscatter intensity) values for an image pair. For On Demand InSAR products, we set the amplitude threshold to be 0.0 (in power scale), so that data is only excluded based on the coherence threshold. Coherence is estimated from the normalized interferogram. The pixel values in this file range from 0.0 (total decorrelation) to 1.0 (perfectly coherent). Any input pixel with a coherence value less than 0.1 is given a validity mask value of zero and not used during unwrapping. Change to Validity Mask Thresholds In the past, we also used an amplitude threshold of 0.2 (in power scale) when generating the validity mask. While this approach tends to mask out inland waters, providing a less noisy interferogram in some cases, it also masks arid regions that have low amplitude values but reasonably high coherence. As of March 2022, we have set the amplitude threshold to 0.0, so that coherence is the only driver of the validity mask. When the water masking option is applied, the validity mask is further amended to apply 0 values to any pixels classified as water in the water mask. In some cases, pixels over water may still meet the coherence and amplitude threshold criteria for inclusion, even though they are not valid for use during phase unwrapping. When processing scenes with extensive coverage by coastal waters or large inland waterbodies, there can be erroneous deformation signals or phase jumps introduced if unwrapping proceeds over water as if it were land. In such cases, choosing the option to apply the water mask can improve the results. Visit our InSAR Water Masking Tutorial for more information.","title":"Masking"},{"location":"guides/insar_product_guide/#reference-point","text":"In order to perform phase unwrapping, a reference point must be selected. The unwrapping will proceed relative to this reference point; the 2\u03c0 integer multiples will be applied to the wrapped phase using this pixel as the starting point. The unwrapped phase value is set to 0 at the reference point. Ideally, the reference point for phase unwrapping would be located in an area with high coherence in a stable region close to an area with surface deformation. Choosing an optimal reference point requires knowledge of the site characteristics and examination of the interferogram, which is not practical in an automated, global workflow. By default, ASF's On Demand InSAR products use the location of the pixel with the highest coherence value as the reference point. The coherence map is examined to determine the maximum value, and all pixels with this value are examined using a 9-pixel window. The pixel with the highest sum of values within its 9-pixel window is selected as the reference point. If more than one pixel has the same 9-pixel sum, the pixel closest to the origin pixel (bottom left corner for ascending scenes, top right corner for descending scenes) is selected. This may be an appropriate reference point location in many cases, as it meets the criteria of having high coherence, and stable areas have higher coherence than areas undergoing significant deformation. If a user wants to set a different location as the phase unwrapping reference point, however, a correction can be applied to the unwrapped interferogram. For more information on the impact of the phase unwrapping reference point location on unwrapped phase and displacement measurements, refer to the Limitations section of this document, which also includes instructions for applying a correction based on a custom reference point.","title":"Reference point"},{"location":"guides/insar_product_guide/#geocoding-and-product-creation","text":"After the phase is unwrapped, the final steps are geocoding and product creation.","title":"Geocoding and Product Creation"},{"location":"guides/insar_product_guide/#geocoding","text":"Geocoding is the process of reprojecting pixels from SAR slant range space (where all the calculations have been performed) into map-projected ground range space (where analysis of products is simplest). Using the look up table previously computed, this process takes each pixel in the input product and relocates it to the UTM zone of the DEM used in processing. This is accomplished using nearest-neighbor resampling so that original pixel values are preserved.","title":"Geocoding"},{"location":"guides/insar_product_guide/#product-creation","text":"Files are next exported from GAMMA internal format into the widely-used GeoTIFF format, complete with geolocation information. GeoTIFFs are created for amplitude, coherence, and unwrapped phase by default, and a water mask GeoTIFF is also included in the product package. Optionally, GeoTIFFs of wrapped phase, look vectors, displacement maps (line-of-sight and vertical), and incidence angle maps can be included, as can a copy of the DEM used for processing.","title":"Product Creation"},{"location":"guides/insar_product_guide/#product-packaging","text":"HyP3 InSAR output is a zip file containing various files, including GeoTIFFs, PNG browse images with geolocation information, Google Earth KMZ files, a metadata file, and a README file.","title":"Product Packaging"},{"location":"guides/insar_product_guide/#naming-convention","text":"The InSAR product names are packed with information pertaining to the processing of the data, presented in the following order, as illustrated in Figure 4. The platform names, either Sentinel-1A or Sentinel-1B, are abbreviated \"A\" or \"B\", indicating the reference and secondary granule's imaging platform The reference start date and time and the secondary start date and time, with the date and time separated by the letter T The polarizations for the pair, either HH or VV, the orbit type, and the days of separation for the pair The product type (always INT for InSAR) and the pixel spacing, which will be either 80 or 40, based upon the number of looks selected when the job was submitted for processing The software package used for processing is always GAMMA for GAMMA InSAR products User-defined options are denoted by three characters indicating whether the product is water masked (w) or not (u), the scene is clipped (e for entire area, c for clipped), and whether a single sub-swath was processed or the entire granule (either 1, 2, 3, or F for full swath) Currently, only the water masking is available as a user-selected option; the products always include the full granule extent with all three sub-swaths The filename ends with the ASF product ID, a 4 digit hexadecimal number Figure 4: Breakdown of ASF InSAR naming scheme.","title":"Naming Convention"},{"location":"guides/insar_product_guide/#image-files","text":"All of the main InSAR product files are 32-bit floating-point single-band GeoTIFFs. To learn more about the rasters included in the product package, refer to the Exploring Sentinel-1 InSAR StoryMap tutorial. The amplitude image is the calibrated radiometric backscatter from the reference granule in sigma-nought power. The image is terrain corrected using a geometric correction, but not radiometrically corrected. The coherence file pixel values range from 0.0 to 1.0, with 0.0 being completely non-coherent and 1.0 being perfectly coherent. The unwrapped phase file shows the results of the phase unwrapping process. Negative values indicate movement towards the sensor, and positive values indicate movement away from the sensor. This is the main interferogram output. The wrapped phase file indicates the interferogram phase after applying the adaptive filter immediately before unwrapping. Values range from negative pi to positive pi. (optional) The line-of-sight displacement file indicates the displacement in meters along the look direction of the sensor. The sign is opposite to that of the unwrapped phase: positive values indicate motion towards the sensor and negative values indicate motion away from the sensor. (optional) The vertical displacement is generated from the line of sight displacement values, and makes the assumption that deformation only occurs in the vertical direction. Note that this assumption may not hold true in cases where the deformation also has a horizontal component. Positive values indicate uplift, and negative values indicate subsidence. (optional) The look vectors theta (\u03b8) and phi (\u03c6) describe the elevation and orientation angles of the sensor's look direction. (optional) The incidence angle maps indicate the angle between the incident signal and the surface normal of either the terrain (local incidence angle) or the ellipsoid (ellipsoid incidence angle). (optional) The DEM file gives the local terrain heights in meters, with a geoid correction applied. (optional) The water mask file indicates coastal waters and large inland waterbodies. Pixel values of 1 indicate land and 0 indicate water. This file is in 8-bit unsigned integer format. If the water mask option is selected, the water mask is applied prior to phase unwrapping to exclude water pixels from the process. The water mask is generated using the GSHHG dataset. To compile the reference shapefile, the full-resolution L1 dataset (boundary between land and ocean) and L5 dataset (boundary between Antarctic ice and ocean) were combined. The L3 dataset (boundary between islands and the lakes they are within) was removed from the L2 dataset (boundary between lakes and land), and this combined dataset was removed from the combined L1/L5 dataset. The portion of the shapefile covering the scene is converted to a raster for inclusion in the phase unwrapping mask during InSAR processing. The GSHHG dataset was last updated in 2017, so there may be discrepancies where shorelines have changed. Visit our InSAR Water Masking Tutorial for more information about water masking. Browse images are included for the wrapped (color_phase) and unwrapped (unw_phase) phase files, which are in PNG format and are each 2048 pixels wide. The browse images are displayed using a cyclic color ramp to generate fringes. Each fringe in a wrapped (color_phase) browse image represents a 2-pi phase difference, and the line-of-sight displacement for each fringe is equivalent to half the wavelength of the sensor. The wavelength of Sentinel-1 is about 5.6 cm, so each 2-pi fringe represents a line-of-sight displacement of about 2.8 cm. Each fringe in an unwrapped (unw_phase) browse image represents a phase difference of 6 pi. Because each 2-pi difference is equivalent to half the wavelength of the sensor, each 6-pi fringe represents about 8.3 cm of line-of-sight displacement for these Sentinel-1 products. KMZ files are included for the wrapped (color_phase) and unwrapped (unw_phase) phase images, which allow users to view the outputs in Google Earth or other platforms that support kmz files. The tags and extensions used and example file names for each raster are listed in Table 2 below. Extension Description Example _amp.tif Amplitude S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _amp.tif _corr.tif Normalized coherence file S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _corr.tif _unw_phase.tif Unwrapped geocoded interferogram S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _unw_phase.tif _wrapped_phase.tif Wrapped geocoded interferogram S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _wrapped_phase.tif _los_disp.tif Line-of-sight displacement S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _los_disp.tif _vert_disp.tif Vertical displacement S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _vert_disp.tif _lv_phi.tif Look vector \u03c6 (orientation) S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _lv_phi.tif _lv_theta.tif Look vector \u03b8 (elevation) S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _lv_theta.tif _dem.tif Digital elevation model S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _dem.tif _inc_map_ell.tif Ellipsoid incidence angle S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _inc_map_ell.tif _inc_map.tif Local incidence angle S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _inc_map.tif _water_mask.tif Water mask S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _water_mask.tif _color_phase.kmz Wrapped phase kmz file S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _color_phase.kmz _unw_phase.kmz Unwrapped phase kmz file S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _unw_phase.kmz _color_phase.png Wrapped phase browse image S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _color_phase.png _unw_phase.png Unwrapped phase browse image S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _unw_phase.png Table 2: Image files in product package","title":"Image Files"},{"location":"guides/insar_product_guide/#metadata-files","text":"The product package also includes a number of metadata files. Extension Description Example .README.md.txt Main README file for GAMMA InSAR S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 .README.md.txt .txt Parameters and metadata for the InSAR pair S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 .txt .tif.xml ArcGIS compliant XML metadata for GeoTIFF files S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _unw_phase.tif.xml .png.xml ArcGIS compliant XML metadata for PNG files S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _color_phase.png.xml .png.aux.xml Geolocation information for png browse images S1AB _20171111T150004 _20171117T145926 _VVP006 _INT80 _G _ueF _4D09 _color_phase.png.aux.xml Table 3: Metadata files in product package","title":"Metadata Files"},{"location":"guides/insar_product_guide/#readme-file","text":"The text file with extension .README.md.txt explains the files included in the folder, and is customized to reflect that particular product. Users unfamiliar with InSAR products should start by reading this README file, which will give some background on each of the files included in the product folder.","title":"README File"},{"location":"guides/insar_product_guide/#insar-parameter-file","text":"The text file with extension .txt includes processing parameters used to generate the InSAR product as well as metadata attributes for the InSAR pair. These are detailed in Table 4. Name Description Possible Value Reference Granule ESA granule name for reference scene (of the two scenes in the pair, the dataset with the oldest timestamp) S1A _IW _SLC __1SDV _20200116T032559 _20200116T032627 _030820 _038928 _F5DC Secondary Granule ESA granule name for secondary scene (of the two scenes in the pair, the dataset with the newest timestamp) S1B _IW _SLC __1SDV _20200128T032559 _20200128T032627 _030995 _038F51 _7D4F Reference Pass Direction Orbit direction of the reference scene DESCENDING Reference Orbit Number Absolute orbit number of the reference scene 30741 Secondary Pass Direction Orbit direction of the reference scene DESCENDING Secondary Orbit Number Absolute orbit number of the secondary scene 31091 Baseline Perpendicular baseline in meters 58.3898 UTCTime Time in the UTC time zone in seconds 12360.691361 Heading Spacecraft heading measured in degrees clockwise from north 193.2939317 Spacecraft height Height in meters of the spacecraft above nadir point 700618.6318999995 Earth radius at nadir Ellipsoidal earth radius in meters at the point directly below the satellite 6370250.0667 Slant range near Distance in meters from satellite to nearest point imaged 799517.4338 Slant range center Distance in meters from satellite to the center point imaged 879794.1404 Slant range far Distance in meters from satellite to farthest point imaged 960070.8469 Range looks Number of looks taken in the range direction 20 Azimuth looks Number of looks taken in the azimuth direction 4 InSAR phase filter Name of the phase filter used adf Phase filter parameter Dampening factor 0.6 Resolution of output (m) Pixel spacing in meters for output products 80 Range bandpass filter Range bandpass filter applied no Azimuth bandpass filter Azimuth bandpass filter applied no DEM source DEM used in processing GLO-30 DEM resolution Pixel spacing in meters for DEM used to process this scene 160 Unwrapping type Phase unwrapping algorithm used mcf Phase at Reference Point Original unwrapped phase value at the reference point (set to 0 in output unwrapped phase raster) -4.21967 Azimuth line of the reference point in SAR space Row number (in SAR space) of the reference point 2737.0 Range pixel of the reference point in SAR space Column number (in SAR space) of the reference point 739.0 Y coordinate of the reference point in the map projection Latitude of the reference point in projected coordinates (UTM Zone - meters) 4112453.3223 X coordinate of the reference point in the map projection Longitude of the reference point in projected coordinates (UTM Zone - meters) 589307.6248 Latitude of the reference point (WGS84) Latitude of the reference point in WGS84 Geographic Coordinate System (degrees) 37.1542125 Longitude of the reference point (WGS84) Longitude of the reference point in WGS84 Geographic Coordinate System (degrees) 40.00574707 Unwrapping threshold Minimum coherence required to unwrap a given pixel none Speckle filter Speckle filter applied no Table 4: List of InSAR parameters included in the parameter text file","title":"InSAR Parameter File"},{"location":"guides/insar_product_guide/#arcgis-compatible-xml-files","text":"There is an ArcGIS-compatible XML file for each raster in the product folder. When ArcGIS Desktop users view any of the rasters in ArcCatalog or the Catalog window in ArcMap, they can open the Item Description to view the contents of the associated XML file. ArcGIS Pro users can access the information from the Metadata tab. These files will not appear as separate items in ArcCatalog, though if you use Windows Explorer to look at the contents of the folder you will see them listed individually. Because each one is named identically to the product it describes (with the addition of the .xml extension), ArcGIS recognizes the appropriate file as the raster\u2019s associated metadata, and integrates the metadata accordingly. ArcGIS users should take care not to change these XML files outside of the ArcGIS environment; changing the filename or content directly may render the files unreadable by ArcGIS. Those not using ArcGIS will still find the contents of these XML files useful, but will have to contend with the XML tagging when viewing the files as text or in a browser.","title":"ArcGIS-Compatible XML Files"},{"location":"guides/insar_product_guide/#auxiliary-geolocation-files","text":"Geolocation XML files (aux files) are included for each of the PNG browse images to allow for proper display in GIS platforms.","title":"Auxiliary Geolocation Files"},{"location":"guides/insar_product_guide/#limitations","text":"","title":"Limitations"},{"location":"guides/insar_product_guide/#baseline-calculation","text":"The baseline is defined as the difference of the platform positions when a given area is imaged. HyP3 baselines are calculated using the best state vectors available. If precise orbits are not yet available for the input granules, restituted orbits will be used. The original predicted orbits are not used for InSAR processing in HyP3. If no restituted or precise state vectors are available, the process will not run.","title":"Baseline Calculation"},{"location":"guides/insar_product_guide/#coherence","text":"The phase measurements in the two images used in InSAR must be coherent in order to detect change. Random changes in phase from one acquisition to the next can mask actual surface deformation. Vegetation is a common driver of decorrelation, as changes can easily take place in the interval between two acquisitions due to growth, seasonal changes, or wind effects. It will be difficult to generate valid interferograms with C-band data in heavily vegetated regions due to lack of coherence even with fairly short time intervals. Consider seasonality when selecting image pairs. Decorrelation can be particularly high when comparing phase from different seasons. Changes in the condition of vegetation (especially deciduous canopies), snow, moisture, or freeze/thaw state can impact phase measurements. In cases where a temporal baseline is required that spans seasons, it may be better to use an annual interferogram if possible so that the images are more comparable in terms of seasonality.","title":"Coherence"},{"location":"guides/insar_product_guide/#line-of-sight-measurements","text":"When looking at a single interferogram, the deformation measurements in the line-of-sight orientation of the sensor indicate relative motion towards or away from the sensor. InSAR is not sensitive to motion in the azimuth direction of the satellite, so motion that occurs in the same direction as the satellite's direction of travel will not be detected. A single interferogram cannot be used to determine the relative contributions of vertical and horizontal movement to the line-of-sight displacement measurement. The vertical displacement map is generated based on the assumption that the movement is entirely in the vertical direction, which may not be realistic for some processes. To determine how much of the signal is driven by vertical vs. horizontal movement, you must either use a time series of interferograms, or use reference measurements with known vertical and horizontal components (such as GNSS measurements from the region of deformation) to deconstruct the line-of-sight displacement. All displacement values are calculated relative to a reference point , which may or may not be an appropriate benchmark for measuring particular areas of displacement within the interferogram.","title":"Line-of-Sight Measurements"},{"location":"guides/insar_product_guide/#phase-unwrapping-reference-point","text":"The reference point for phase unwrapping is set to be the location of the pixel with the highest coherence value. As described in the phase unwrapping section , this may not always be an ideal location to use as a reference point. If it is located in an area undergoing deformation, or in a patch of coherent pixels that is separated from the area undergoing deformation by a gap of incoherent pixels, the unwrapping may be of lower quality than if the reference point was in a more suitable location. Even when there are not phase unwrapping errors introduced by phase discontinuities, it is important to be aware that unwrapped phase differences and displacement values are all calculated relative to the reference point. The phase difference value of the reference point is set to 0 during phase unwrapping, so any displacement values will be relative to that benchmark. If the location of the default reference point is in the middle of an area that underwent deformation, displacement values may be different than expected. If you are interested in the amount of displacement in a particular area, you may wish to choose your own reference point. The ideal reference point would be in an area of high coherence beyond where deformation has occurred. The unwrapped phase measurements can be adjusted to be relative to this new reference point, and displacement values can be recalculated accordingly. To adjust the values in the unwrapped phase GeoTIFF, simply select a reference point that is optimal for your use case and subtract the unwrapped phase value of that reference point from each pixel in the unwrapped phase raster: \u0394\u03a8 * = \u0394\u03a8 - \u0394\u03c8 ref where \u0394\u03a8 * is the adjusted unwrapped phase, \u0394\u03a8 is the original unwrapped phase, and \u0394\u03c8 ref is the unwrapped phase value at the new reference point.","title":"Phase Unwrapping Reference Point"},{"location":"guides/insar_product_guide/#impacts-on-displacement-measurements","text":"The measurements in the displacement maps are calculated from the unwrapped phase values, so will similarly be impacted by the location of the reference point. You may wish to recalculate the displacement values relative to a new reference point. The approach for correcting the displacement maps will be different for the line-of-sight and vertical measurements.","title":"Impacts on Displacement Measurements"},{"location":"guides/insar_product_guide/#displacement-values-from-a-single-interferogram","text":"In general, calculating displacement values from a single interferogram is not recommended. While the displacement rasters provided with ASF's On Demand InSAR products can be helpful in visualizing changes, we do not recommend that you rely on a single interferogram when coming to conclusions about surface displacement, even if you apply a correction based on a manually selected reference point. It will be more robust to use a time series approach to more accurately determine the pattern of movement. When using SAR time-series software such as MintPy , you have the option to select a specific reference point, and the values of the input rasters will be adjusted accordingly.","title":"Displacement Values from a Single Interferogram"},{"location":"guides/insar_product_guide/#error-sources","text":"On Demand InSAR products do not currently correct for some common sources of error in interferometry, such as atmospheric effects. Further processing or time series analysis can be performed by the user to identify or reduce the impact of some of these errors when using On Demand InSAR products for analysis.","title":"Error Sources"},{"location":"guides/insar_product_guide/#atmospheric-delay","text":"While SAR signals can penetrate clouds, atmospheric conditions can delay the transmission of the signal. This results in phase differences that can look like surface deformation signals but are actually driven by differences in the atmospheric conditions between the pair of acquisitions used to generate the interferogram. In some cases, atmospheric errors can be corrected by using an atmospheric model to remove the impacts of the turbulent delay from the interferogram. Another approach is to use time series analysis to identify outliers. Always doubt your interferogram first! View the interferogram critically, and consider if fringe patterns could potentially be driven by atmospheric effects. In general, it is best to avoid drawing conclusions from the outcome of a single interferogram.","title":"Atmospheric Delay"},{"location":"guides/insar_product_guide/#turbulent-delay","text":"These delays are generally caused by differences in water vapor distribution from one image to the next. They often manifest as wobbly or sausage-shaped fringes, and can potentially mask the signal of a small earthquake.","title":"Turbulent Delay"},{"location":"guides/insar_product_guide/#stratified-delay","text":"This type of delay is driven mostly by pressure and temperature differences or gradients through the atmospheric column, and often correlates with topography. This atmospheric signature can be confused with movement caused by volcanic activity. If there are multiple volcanoes in an image and they all exhibit similar patterns, it is likely being driven by this type of atmospheric delay.","title":"Stratified Delay"},{"location":"guides/insar_product_guide/#dem-errors","text":"A DEM is used to remove topographic phase impacts, but if there are inaccuracies in the DEM, residual impacts of those errors can remain in the interferogram.","title":"DEM Errors"},{"location":"guides/insar_product_guide/#orbit-uncertainties","text":"This is generally not an issue for Sentinel-1 data, as the orbits are very precise and generally reliable. On Demand InSAR products are only processed once restituted or precise orbits are available. Orbit uncertainties are more problematic when working with datasets from older missions.","title":"Orbit Uncertainties"},{"location":"guides/insar_product_guide_template/","text":"Introduction \u00b6 Interferometric Synthetic Aperture Radar (InSAR) processing uses two SAR images collected over the same area to determine geometric properties of the surface. Missions such as Sentinel-1 are designed for monitoring surface deformation using InSAR, which is optimal when acquisitions are made from a consistent location in space ( short perpendicular baseline ) over regular time intervals. The phase measurements of two SAR images acquired at different times from the same place in orbit are differenced to detect and quantify surface changes, such as deformation caused by earthquakes, volcanoes, or groundwater subsidence. InSAR can also be used to generate digital elevation models, but the optimal mission for DEM generation has the opposite characteristics of the Sentinel-1 mission. Topography is best mapped when the two acquisitions are obtained as close together as possible in time ( short temporal baseline ), but from different vantage points in space (larger perpendicular baseline than would be optimal for deformation mapping). Brief Overview of InSAR \u00b6 SAR is an active sensor that transmits pulses and listens for echoes. These echoes are recorded in phase and amplitude, with the phase being used to determine the distance from the sensor to the target and the amplitude yielding information about the roughness and dielectric constant of that target. Figure 1: Two passes of an imaging SAR taken at time T 0 and T 0 + \u2206t, will give two distances to the ground, R 1 and R 2 . A difference between R 1 and R 2 shows motion on the ground. In this case, a subsidence makes R 2 greater than R 1 . Credit: TRE ALTAMIRA InSAR exploits the phase difference between two SAR images to create an interferogram that shows where the phase and, therefore, the distance to the target has changed from one pass to the next, as illustrated in Figure 1. There are several factors that influence the interferogram, including earth curvature, topographic effects, atmospheric delays, surface motion, and noise. With proper processing, Sentinel-1 InSAR can be used to detect changes in the earth's surface down to the centimeter scale. Applications include volcanic deformation, subsidence, landslide detection, and earthquake assessment. Wavelengths \u00b6 The SAR sensors on the Sentinel-1 satellites transmit C-band signals, with a wavelength of 5.6 cm. The signal wavelength impacts the penetration capability of the signal, so it is important to be aware of the sensor wavelength when working with SAR datasets. C-band SAR will penetrate more deeply into canopy or surfaces than an X-band signal, but not nearly as deep as an L-band SAR signal, which, with a wavelength on the order of 25 cm, is better able to penetrate canopy and return signals from the forest floor. Different wavelengths are also sensitive to different levels of deformation. To detect very small changes over relatively short periods of time, you may require a signal with a smaller wavelength (such as X-band). However, signals with shorter wavelengths are also more prone to decorrelation due to small changes in surface conditions such as vegetation growth. For slower processes that require a longer time interval to detect movement, longer wavelengths (such as L-band) may be necessary. C-band sits in the middle. It can detect fairly small changes over fairly short periods of time, but is not as sensitive to small changes as X-band or as able to monitor surface dynamics under canopy as L-band. Polarizations \u00b6 Polarization refers to the direction of travel of an electromagnetic wave. A horizontal wave is transmitted so that it oscillates in a plane parallel to the surface imaged, while a vertical wave oscillates in a plane perpendicular to the surface imaged. Most modern SAR systems can transmit chirps with either a horizontal or vertical polarization. In addition, some of these sensors can listen for either horizontal or vertical backscatter. This gives rise to 4 different types of returns: HH, HV, VV, and VH, with the first letter indicating the transmission method and the second the receive method. For example, VH is a vertically polarized transmit signal with horizontally polarized echoes recorded. For InSAR applications, processing is generally performed on the co-pol (VV or HH) data and not on the cross-pol (VH or HV) data. Also, each image used in an InSAR pair is required to be the same polarization - two HH images of the same area could form a valid pair, while a single HH with a single VV of the same area would not. Baselines \u00b6 Perpendicular Baseline \u00b6 The term baseline refers to the physical distance between the two vantage points from which images used as an InSAR pair are acquired. The baseline is decomposed into perpendicular (also called normal) and parallel components, as shown in Figure 2. To monitor surface deformation, the perpendicular baseline for the two acquisitions should be very small in order to maximize the coherence of the phase measurements. In order to determine topography, two slightly different vantage points are required. Sensitivity to topography depends on the perpendicular baseline, the sensor wavelength, the distance between the satellite and the ground, and the sensor look angle. Figure 2: Geometry of InSAR baselines. Two satellite passes image the same area on the ground from positions S 1 and S 2 , resulting in a baseline of B, which can be decomposed into perpendicular (B \u27c2 ) and parallel (B \u2225 ) components. Here Y is the direction of travel, referred to as the along-track or azimuth direction, and X is the direction perpendicular to motion, referred to as the cross-track or range direction. Credit: ASF Temporal Baseline \u00b6 In contrast to the (physical) baseline, the temporal baseline refers to the time separation between imaging passes. Along-track interferometry measures motion in the millisecond to second range. This technique can detect ocean currents and rapidly moving objects like boats. Differential interferometry is the standard method used to detect motion in the range of days to years. This is the type of interferometry that is performed by the Sentinel-1 HyP3 InSAR processing algorithm. Table 1 lists different temporal baselines, their common names, and what they can be used to measure. Duration Known as Measurement of ms to sec along-track ocean currents, moving object detection, MTI days differential glacier/ice fields/lava flows, surface water extent, hydrology days to years differential subsidence, seismic events, volcanic activity, crustal displacement Table 1: Temporal baselines and what they measure. Different geophysical phenomena can be detected based upon the temporal baseline. In general, the longer the temporal baseline, the smaller the motion that can be detected. Critical Baseline \u00b6 Large baselines are better than small for topographic mapping. However, as the baseline increases, coherence decreases. At some point, it is impossible to create an interferogram because of baseline decorrelation. The maximum viable baseline per platform, referred to as the critical baseline , is a function of the distance to the ground, the wavelength, and the viewing geometry of the platform. For Sentinel-1, this critical baseline is about 5 km. In practice, if the perpendicular baseline between images is more than 3/4 of the critical baseline, interferogram creation will be problematic due to the level of noise. For deformation mapping, it is best to minimize the perpendicular baseline whenever possible, but there may be tradeoffs in terms of finding suitable temporal baselines. In most cases, however, pairs selected for deformation mapping will have perpendicular baselines much smaller than the critical baseline. Ordering On Demand InSAR Products \u00b6 All of ASF's On Demand InSAR products are generated using ASF's HyP3 platform. Jobs can be submitted for processing using the Vertex data portal, the HyP3 Python SDK or the HyP3 API . Vertex \u00b6 InSAR pairs are selected in Vertex using either the Baseline Search or the SBAS Search interface. The Baseline tool is the best option for selecting specific InSAR pairs. Use the Geographic Search to find an image that covers your time and area of interest, select that item in the results, and click the Baseline button in the center panel. The Baseline tool then displays all of the scenes that could be used to generate an interferogram using the selected image. Scroll through the results to find pairs to add to the On Demand queue, or click on items displayed in the plot to highlight that particular image pair. The SBAS tool is designed for generating time series of InSAR pairs. As with the Baseline search, you can launch the SBAS search from the center panel of a Geographic Search result. It will display all of the valid InSAR pairs through time based on the acquisition location of the input scene. This functionality is designed for processing a series of interferograms to be used in SBAS (Small BAseline Subset) analysis. The results can be adjusted based on baseline criteria (both perpendicular and temporal), and restricted to specific periods of time. Once the list is refined, you have the option to add all of the InSAR pairs displayed in the results to the On Demand queue. HyP3 SDK and API \u00b6 The HyP3 SDK provides support for processing nearest-neighbor interferograms for a selected granule. Specifying nearest-neighbor processing will find the next appropriate scene back in time to use as the reference granule for generating an interferogram with the selected granule. You can specify up to 2 nearest neighbors, which will pair the scene closest in time and next-closest in time to the selected granule for generating InSAR products, as demonstrated in this sample HyP3 SDK Jupyter Notebook . You may still find the Geographic, Baseline and SBAS searches in Vertex useful for finding reference scenes or picking specific pairs to use when submitting InSAR jobs via the SDK or API . Considerations for Selecting an InSAR Pair \u00b6 When selecting an InSAR pair, observe the following required conditions: Images from an identical orbit direction (either ascending or descending) Images with identical incidence angles and beam mode Images with identical resolution and wavelength (usually from the same sensor) Images with the same viewing geometry (same path and frame) Images with identical polarizations (both HH or VV) In addition, the following suggestions may be helpful: Use images from similar seasons/growth/weather conditions For deformation mapping: limited spatial separation of acquisition locations (small physical baseline) For topographic mapping: limited time separation between images (small temporal baseline) To analyze deformation caused by a single discrete event, such as an earthquake, select images that bracket the event as closely in time as possible. Keeping the window narrowly focused on the time of the event will reduce the impacts of other processes that may mask the signal of the event of interest. Limitations \u00b6 Baseline Calculation \u00b6 The baseline is defined as the difference of the platform positions when a given area is imaged. HyP3 baselines are calculated using the best state vectors available. If precise orbits are not yet available for the input granules, restituted orbits will be used. The original predicted orbits are not used for InSAR processing in HyP3. If no restituted or precise state vectors are available, the process will not run. Coherence \u00b6 The phase measurements in the two images used in InSAR must be coherent in order to detect change. Random changes in phase from one acquisition to the next can mask actual surface deformation. Vegetation is a common driver of decorrelation, as changes can easily take place in the interval between two acquisitions due to growth, seasonal changes, or wind effects. It will be difficult to generate valid interferograms with C-band data in heavily vegetated regions due to lack of coherence even with fairly short time intervals. Consider seasonality when selecting image pairs. Decorrelation can be particularly high when comparing phase from different seasons. Changes in the condition of vegetation (especially deciduous canopies), snow, moisture, or freeze/thaw state can impact phase measurements. In cases where a temporal baseline is required that spans seasons, it may be better to use an annual interferogram if possible so that the images are more comparable in terms of seasonality. Error Sources \u00b6 On Demand InSAR products do not currently correct for some common sources of error in interferometry, such as atmospheric effects. Further processing or time series analysis can be performed by the user to identify or reduce the impact of some of these errors when using On Demand InSAR products for analysis. Atmospheric Delay \u00b6 While SAR signals can penetrate clouds, atmospheric conditions can delay the transmission of the signal. This results in phase differences that can look like surface deformation signals but are actually driven by differences in the atmospheric conditions between the pair of acquisitions used to generate the interferogram. In some cases, atmospheric errors can be corrected by using an atmospheric model to remove the impacts of the turbulent delay from the interferogram. Another approach is to use time series analysis to identify outliers. Always doubt your interferogram first! View the interferogram critically, and consider if fringe patterns could potentially be driven by atmospheric effects. In general, it is best to avoid drawing conclusions from the outcome of a single interferogram. Turbulent Delay \u00b6 These delays are generally caused by differences in water vapor distribution from one image to the next. They often manifest as wobbly or sausage-shaped fringes, and can potentially mask the signal of a small earthquake. Stratified Delay \u00b6 This type of delay is driven mostly by pressure and temperature differences or gradients through the atmospheric column, and often correlates with topography. This atmospheric signature can be confused with movement caused by volcanic activity. If there are multiple volcanoes in an image and they all exhibit similar patterns, it is likely being driven by this type of atmospheric delay. DEM Errors \u00b6 A DEM is used to remove topographic phase impacts, but if there are inaccuracies in the DEM, residual impacts of those errors can remain in the interferogram. Orbit Uncertainties \u00b6 This is generally not an issue for Sentinel-1 data, as the orbits are very precise and generally reliable. On Demand InSAR products are only processed once restituted or precise orbits are available. Orbit uncertainties are more problematic when working with datasets from older missions.","title":"Insar product guide template"},{"location":"guides/insar_product_guide_template/#introduction","text":"Interferometric Synthetic Aperture Radar (InSAR) processing uses two SAR images collected over the same area to determine geometric properties of the surface. Missions such as Sentinel-1 are designed for monitoring surface deformation using InSAR, which is optimal when acquisitions are made from a consistent location in space ( short perpendicular baseline ) over regular time intervals. The phase measurements of two SAR images acquired at different times from the same place in orbit are differenced to detect and quantify surface changes, such as deformation caused by earthquakes, volcanoes, or groundwater subsidence. InSAR can also be used to generate digital elevation models, but the optimal mission for DEM generation has the opposite characteristics of the Sentinel-1 mission. Topography is best mapped when the two acquisitions are obtained as close together as possible in time ( short temporal baseline ), but from different vantage points in space (larger perpendicular baseline than would be optimal for deformation mapping).","title":"Introduction"},{"location":"guides/insar_product_guide_template/#brief-overview-of-insar","text":"SAR is an active sensor that transmits pulses and listens for echoes. These echoes are recorded in phase and amplitude, with the phase being used to determine the distance from the sensor to the target and the amplitude yielding information about the roughness and dielectric constant of that target. Figure 1: Two passes of an imaging SAR taken at time T 0 and T 0 + \u2206t, will give two distances to the ground, R 1 and R 2 . A difference between R 1 and R 2 shows motion on the ground. In this case, a subsidence makes R 2 greater than R 1 . Credit: TRE ALTAMIRA InSAR exploits the phase difference between two SAR images to create an interferogram that shows where the phase and, therefore, the distance to the target has changed from one pass to the next, as illustrated in Figure 1. There are several factors that influence the interferogram, including earth curvature, topographic effects, atmospheric delays, surface motion, and noise. With proper processing, Sentinel-1 InSAR can be used to detect changes in the earth's surface down to the centimeter scale. Applications include volcanic deformation, subsidence, landslide detection, and earthquake assessment.","title":"Brief Overview of InSAR"},{"location":"guides/insar_product_guide_template/#wavelengths","text":"The SAR sensors on the Sentinel-1 satellites transmit C-band signals, with a wavelength of 5.6 cm. The signal wavelength impacts the penetration capability of the signal, so it is important to be aware of the sensor wavelength when working with SAR datasets. C-band SAR will penetrate more deeply into canopy or surfaces than an X-band signal, but not nearly as deep as an L-band SAR signal, which, with a wavelength on the order of 25 cm, is better able to penetrate canopy and return signals from the forest floor. Different wavelengths are also sensitive to different levels of deformation. To detect very small changes over relatively short periods of time, you may require a signal with a smaller wavelength (such as X-band). However, signals with shorter wavelengths are also more prone to decorrelation due to small changes in surface conditions such as vegetation growth. For slower processes that require a longer time interval to detect movement, longer wavelengths (such as L-band) may be necessary. C-band sits in the middle. It can detect fairly small changes over fairly short periods of time, but is not as sensitive to small changes as X-band or as able to monitor surface dynamics under canopy as L-band.","title":"Wavelengths"},{"location":"guides/insar_product_guide_template/#polarizations","text":"Polarization refers to the direction of travel of an electromagnetic wave. A horizontal wave is transmitted so that it oscillates in a plane parallel to the surface imaged, while a vertical wave oscillates in a plane perpendicular to the surface imaged. Most modern SAR systems can transmit chirps with either a horizontal or vertical polarization. In addition, some of these sensors can listen for either horizontal or vertical backscatter. This gives rise to 4 different types of returns: HH, HV, VV, and VH, with the first letter indicating the transmission method and the second the receive method. For example, VH is a vertically polarized transmit signal with horizontally polarized echoes recorded. For InSAR applications, processing is generally performed on the co-pol (VV or HH) data and not on the cross-pol (VH or HV) data. Also, each image used in an InSAR pair is required to be the same polarization - two HH images of the same area could form a valid pair, while a single HH with a single VV of the same area would not.","title":"Polarizations"},{"location":"guides/insar_product_guide_template/#baselines","text":"","title":"Baselines"},{"location":"guides/insar_product_guide_template/#perpendicular-baseline","text":"The term baseline refers to the physical distance between the two vantage points from which images used as an InSAR pair are acquired. The baseline is decomposed into perpendicular (also called normal) and parallel components, as shown in Figure 2. To monitor surface deformation, the perpendicular baseline for the two acquisitions should be very small in order to maximize the coherence of the phase measurements. In order to determine topography, two slightly different vantage points are required. Sensitivity to topography depends on the perpendicular baseline, the sensor wavelength, the distance between the satellite and the ground, and the sensor look angle. Figure 2: Geometry of InSAR baselines. Two satellite passes image the same area on the ground from positions S 1 and S 2 , resulting in a baseline of B, which can be decomposed into perpendicular (B \u27c2 ) and parallel (B \u2225 ) components. Here Y is the direction of travel, referred to as the along-track or azimuth direction, and X is the direction perpendicular to motion, referred to as the cross-track or range direction. Credit: ASF","title":"Perpendicular Baseline"},{"location":"guides/insar_product_guide_template/#temporal-baseline","text":"In contrast to the (physical) baseline, the temporal baseline refers to the time separation between imaging passes. Along-track interferometry measures motion in the millisecond to second range. This technique can detect ocean currents and rapidly moving objects like boats. Differential interferometry is the standard method used to detect motion in the range of days to years. This is the type of interferometry that is performed by the Sentinel-1 HyP3 InSAR processing algorithm. Table 1 lists different temporal baselines, their common names, and what they can be used to measure. Duration Known as Measurement of ms to sec along-track ocean currents, moving object detection, MTI days differential glacier/ice fields/lava flows, surface water extent, hydrology days to years differential subsidence, seismic events, volcanic activity, crustal displacement Table 1: Temporal baselines and what they measure. Different geophysical phenomena can be detected based upon the temporal baseline. In general, the longer the temporal baseline, the smaller the motion that can be detected.","title":"Temporal Baseline"},{"location":"guides/insar_product_guide_template/#critical-baseline","text":"Large baselines are better than small for topographic mapping. However, as the baseline increases, coherence decreases. At some point, it is impossible to create an interferogram because of baseline decorrelation. The maximum viable baseline per platform, referred to as the critical baseline , is a function of the distance to the ground, the wavelength, and the viewing geometry of the platform. For Sentinel-1, this critical baseline is about 5 km. In practice, if the perpendicular baseline between images is more than 3/4 of the critical baseline, interferogram creation will be problematic due to the level of noise. For deformation mapping, it is best to minimize the perpendicular baseline whenever possible, but there may be tradeoffs in terms of finding suitable temporal baselines. In most cases, however, pairs selected for deformation mapping will have perpendicular baselines much smaller than the critical baseline.","title":"Critical Baseline"},{"location":"guides/insar_product_guide_template/#ordering-on-demand-insar-products","text":"All of ASF's On Demand InSAR products are generated using ASF's HyP3 platform. Jobs can be submitted for processing using the Vertex data portal, the HyP3 Python SDK or the HyP3 API .","title":"Ordering On Demand InSAR Products"},{"location":"guides/insar_product_guide_template/#vertex","text":"InSAR pairs are selected in Vertex using either the Baseline Search or the SBAS Search interface. The Baseline tool is the best option for selecting specific InSAR pairs. Use the Geographic Search to find an image that covers your time and area of interest, select that item in the results, and click the Baseline button in the center panel. The Baseline tool then displays all of the scenes that could be used to generate an interferogram using the selected image. Scroll through the results to find pairs to add to the On Demand queue, or click on items displayed in the plot to highlight that particular image pair. The SBAS tool is designed for generating time series of InSAR pairs. As with the Baseline search, you can launch the SBAS search from the center panel of a Geographic Search result. It will display all of the valid InSAR pairs through time based on the acquisition location of the input scene. This functionality is designed for processing a series of interferograms to be used in SBAS (Small BAseline Subset) analysis. The results can be adjusted based on baseline criteria (both perpendicular and temporal), and restricted to specific periods of time. Once the list is refined, you have the option to add all of the InSAR pairs displayed in the results to the On Demand queue.","title":"Vertex"},{"location":"guides/insar_product_guide_template/#hyp3-sdk-and-api","text":"The HyP3 SDK provides support for processing nearest-neighbor interferograms for a selected granule. Specifying nearest-neighbor processing will find the next appropriate scene back in time to use as the reference granule for generating an interferogram with the selected granule. You can specify up to 2 nearest neighbors, which will pair the scene closest in time and next-closest in time to the selected granule for generating InSAR products, as demonstrated in this sample HyP3 SDK Jupyter Notebook . You may still find the Geographic, Baseline and SBAS searches in Vertex useful for finding reference scenes or picking specific pairs to use when submitting InSAR jobs via the SDK or API .","title":"HyP3 SDK and API"},{"location":"guides/insar_product_guide_template/#considerations-for-selecting-an-insar-pair","text":"When selecting an InSAR pair, observe the following required conditions: Images from an identical orbit direction (either ascending or descending) Images with identical incidence angles and beam mode Images with identical resolution and wavelength (usually from the same sensor) Images with the same viewing geometry (same path and frame) Images with identical polarizations (both HH or VV) In addition, the following suggestions may be helpful: Use images from similar seasons/growth/weather conditions For deformation mapping: limited spatial separation of acquisition locations (small physical baseline) For topographic mapping: limited time separation between images (small temporal baseline) To analyze deformation caused by a single discrete event, such as an earthquake, select images that bracket the event as closely in time as possible. Keeping the window narrowly focused on the time of the event will reduce the impacts of other processes that may mask the signal of the event of interest.","title":"Considerations for Selecting an InSAR Pair"},{"location":"guides/insar_product_guide_template/#limitations","text":"","title":"Limitations"},{"location":"guides/insar_product_guide_template/#baseline-calculation","text":"The baseline is defined as the difference of the platform positions when a given area is imaged. HyP3 baselines are calculated using the best state vectors available. If precise orbits are not yet available for the input granules, restituted orbits will be used. The original predicted orbits are not used for InSAR processing in HyP3. If no restituted or precise state vectors are available, the process will not run.","title":"Baseline Calculation"},{"location":"guides/insar_product_guide_template/#coherence","text":"The phase measurements in the two images used in InSAR must be coherent in order to detect change. Random changes in phase from one acquisition to the next can mask actual surface deformation. Vegetation is a common driver of decorrelation, as changes can easily take place in the interval between two acquisitions due to growth, seasonal changes, or wind effects. It will be difficult to generate valid interferograms with C-band data in heavily vegetated regions due to lack of coherence even with fairly short time intervals. Consider seasonality when selecting image pairs. Decorrelation can be particularly high when comparing phase from different seasons. Changes in the condition of vegetation (especially deciduous canopies), snow, moisture, or freeze/thaw state can impact phase measurements. In cases where a temporal baseline is required that spans seasons, it may be better to use an annual interferogram if possible so that the images are more comparable in terms of seasonality.","title":"Coherence"},{"location":"guides/insar_product_guide_template/#error-sources","text":"On Demand InSAR products do not currently correct for some common sources of error in interferometry, such as atmospheric effects. Further processing or time series analysis can be performed by the user to identify or reduce the impact of some of these errors when using On Demand InSAR products for analysis.","title":"Error Sources"},{"location":"guides/insar_product_guide_template/#atmospheric-delay","text":"While SAR signals can penetrate clouds, atmospheric conditions can delay the transmission of the signal. This results in phase differences that can look like surface deformation signals but are actually driven by differences in the atmospheric conditions between the pair of acquisitions used to generate the interferogram. In some cases, atmospheric errors can be corrected by using an atmospheric model to remove the impacts of the turbulent delay from the interferogram. Another approach is to use time series analysis to identify outliers. Always doubt your interferogram first! View the interferogram critically, and consider if fringe patterns could potentially be driven by atmospheric effects. In general, it is best to avoid drawing conclusions from the outcome of a single interferogram.","title":"Atmospheric Delay"},{"location":"guides/insar_product_guide_template/#turbulent-delay","text":"These delays are generally caused by differences in water vapor distribution from one image to the next. They often manifest as wobbly or sausage-shaped fringes, and can potentially mask the signal of a small earthquake.","title":"Turbulent Delay"},{"location":"guides/insar_product_guide_template/#stratified-delay","text":"This type of delay is driven mostly by pressure and temperature differences or gradients through the atmospheric column, and often correlates with topography. This atmospheric signature can be confused with movement caused by volcanic activity. If there are multiple volcanoes in an image and they all exhibit similar patterns, it is likely being driven by this type of atmospheric delay.","title":"Stratified Delay"},{"location":"guides/insar_product_guide_template/#dem-errors","text":"A DEM is used to remove topographic phase impacts, but if there are inaccuracies in the DEM, residual impacts of those errors can remain in the interferogram.","title":"DEM Errors"},{"location":"guides/insar_product_guide_template/#orbit-uncertainties","text":"This is generally not an issue for Sentinel-1 data, as the orbits are very precise and generally reliable. On Demand InSAR products are only processed once restituted or precise orbits are available. Orbit uncertainties are more problematic when working with datasets from older missions.","title":"Orbit Uncertainties"},{"location":"guides/introduction_to_sar/","text":"Introduction to SAR \u00b6 How SAR Operates \u00b6 SAR is an active sensor that transmits pulses and listens for echoes, called backscatter. The backscatter is recorded in both phase and amplitude. The phase is used to determine the distance from the sensor to a target, and amplitude indicates the amount of the sent signal that returns to the sensor. Amplitude measurements provide information about the roughness, geometry, wetness, and dielectric constant of that target, while phase measurements are used for SAR interferometry. Propagation of EM Waves \u00b6 At the most fundamental level, SAR transmits an encoded burst, called a chirp, of electromagnetic energy (Figure 1) and then listens for the return signal, called echoes. The wavelength of this chirp is in the centimeter range, with X-band (~3 cm), C-band (~6 cm), and L-band (~23 cm) all in common use. Figure 1: The spectrum of electromagnetic radiation. SAR is imaged using microwave wavelengths. The microwave range extends from about 1 mm to 1 m in wavelength, with most radar applications using bands within the 3 mm to 30 cm range. Polarizations \u00b6 Polarization refers to the direction of travel of an electromagnetic wave. A horizontal wave is transmitted so that it oscillates in a plane parallel to the surface imaged, while a vertical wave oscillates in a plane perpendicular to the surface imaged. There are four different polarization combinations commonly used by SAR sensors: VV, VH, HV and HH, as listed in Table 1. The first letter indicates the polarization used to transmit the signal, and the second letter indicates the polarization of the measured return, as illustrated in Figure 2. Table 1: SAR Polarizations Polarization Code Transmit Signal Polarization Return Signal Polarization VV Vertical Vertical VH Vertical Horizontal HV Horizontal Vertical HH Horizontal Horizontal Figure 2: SAR signals are transmitted and received either vertically (V) or horizontally (H). This gives the potential for four different polarization combinations (transmit listed first, receive second): VV, VH, HH, and HV. Credit: ASF Different SAR sensors have different polarization capabilities. Single-pol sensors send out a signal in one polarization and can only measure returns that are in that same polarization (VV or HH). Dual-pol sensors send out a signal in one polarization, but can measure returns that are in that same polarization (co-pol: VV or HH) as well as returns that are in the other polarization (cross-pol: VH or HV). Some SAR systems can transmit chirps with both a horizontal or vertical polarization and listen for both horizontal or vertical returns, giving full quad-pol capabilities (VV, VH, HV, HH). Polarimetry is an emerging field of SAR processing which is used in a number of applications such as measuring vegetation properties and changes of vegetation over time. Additional applications include oceanography, geology, and disaster response. Backscatter Contributors \u00b6 Many factors influence the backscatter received by the SAR sensor. The wavelength used by the SAR influences the signal's penetration, and, thus, what is being imaged. Surface roughness will modulate the backscatter returns from nothing up to a strong return, decreasing or increasing the brightness of the resulting pixel. Scattering mechanisms like volume scattering or double bounce can strongly influence the brightness of the SAR image as well, sometimes resulting in total saturation by the received signal. Wavelength \u00b6 The wavelength of the SAR system influences the amount of ground penetration that occurs. As shown in Figure 3, X-band has the least penetration, scattering from the top of the canopy in vegetated areas. All three bands will penetrate dry sand, with stronger returns from both C-band and L-band. L-band has the most penetration overall, with returns from the ground in vegetated areas, strong returns from substances under dry alluvium, and deep penetration of ice and snow. Figure 3: Effects of the SAR band on penetration of surfaces. The longer the wavelength, the deeper the penetration through most land types. Credit: The SAR Handbook Surface Roughness \u00b6 The strength of the return, or backscatter, is partially based upon relative roughness of the surface imaged. The smoother the surface, the more reflection away from the sensor, while rough surfaces give a much stronger return towards the imaging platform. As can be seen in Figure 4, if the height of the surface's roughness is less than 1/32 of the wavelength, mostly specular reflection occurs. If the height of the surface's roughness is greater than 1/2 the wavelength used, the echoes are scattered in all directions, giving a strong return back to the sensor. Figure 4: The amount of backscatter from a surface depends largely on the surface's roughness, with smooth surfaces getting the least returns and rough surfaces getting the strongest returns. Credit: The SAR Handbook Types of Scattering \u00b6 Figure 5: Scattering mechanisms. Rough surfaces give bright returns due to the wide scattering. Vegetated surfaces cause volumetric scattering, which gives a darker return to the imaging platform. Double bounce returns, found mostly in urban areas, give the brightest return, as the majority of the energy is re-directed back towards the sensor. Credit: The SAR Handbook The resolution of Sentinel-1 SAR images is roughly 10 m. This means that a square of 10 meters on the ground is represented by a single pixel in the SAR image. The relative roughness of this patch of ground compared to the wavelength used will affect the backscatter strength (see Figure 4). However, there are additional types of bounce mechanisms beyond specular and diffuse, as shown in Figure 5. In vegetation, volumetric scattering occurs when signals bounce around inside the vegetation imaged. The double bounce mechanism which occurs in urban areas and is exploited by corner reflectors, causes chirp to be reflected directly back to the sensor, causing a very strong backscatter. Double bounce returns are so strong in some places that they cause over saturation of the sensor, resulting in visible sidelobes. These sidelobes are evidenced by bright crosses surrounding the double bounce target. SAR Scale \u00b6 SAR backscatter are recorded in both return strength and phase. Each pixel in a single-look complex SAR image represents these values as an imaginary number (I,Q). To create the visible images we are used to looking at, the SAR image is detected . This process calculates the square root of the sum of the squares of the I and Q values found in an SLC image, creating a so-called intensity image. This image is real valued, and, when calibrated, gives the absolute backscatter of the surface imaged. Detected images can be stored using several different scales, including power, amplitude, and dB. Note the default scale of Sentinel-1 RTC products from HyP3 is power. However, in some cases, it may be desirable to convert the actual pixel values to a different scale. Two other scales commonly used for SAR data are amplitude and dB. Power Scale \u00b6 The values in this scale are generally very close to zero, so the dynamic range of the SAR image can be easily skewed by a few bright scatterers in the image. Power scale is appropriate for statistical analysis of the SAR dataset, but may not always be the best option for data visualization. When viewing a SAR image in power scale in a GIS environment, it may appear mostly or all black, and you may need to adjust the stretch to see features in the image. Often applying a stretch of 2 standard deviations, or setting the Min-Max stretch values to 0 and 0.3, will greatly improve the appearance of the image. You can adjust the stretch as desired to display your image to full advantage. Be aware that this does not change the actual pixel values. Amplitude Scale \u00b6 Amplitude scale is the square root of the power scale values. This brightens the darker pixels and darkens the brighter pixels, narrowing the dynamic range of the image. In many cases, amplitude scale presents a pleasing grayscale display of RTC images. Amplitude scale works well for calculating log difference ratios (see ASF Sentinel-1 RTC Product Guide ). dB Scale \u00b6 The dB scale is calculated by multiplying 10 times the Log10 of the power scale values. This scale brightens the pixels, allowing for better differentiation among very dark pixels. When identifying water on the landscape, this is often a good scale to use; the water pixels generally remain very dark, while the terrestrial pixels are even brighter (see Identifying Surface Water ). This scale is not always the best choice for general visualization of SAR products, as it can give a washed-out appearance, and because it is in a log scale, it is not appropriate for all types of statistical analyses. Geometric Distortions \u00b6 There are a number of distortions inherent to SAR data due to the side-looking nature of the sensor, and these impacts will be more prevalent in areas with rugged terrain. The process of radiometric terrain correction addresses the geometric distortions that lead to geolocation errors in terrain features, and also normalizes the backscatter values based on the actual area contributing returns. This process generates an image that aligns well with other geospatial data and is suitable for GIS applications or time-series analysis. The key distortions present in SAR images are foreshortening, layover and shadow (Figure 6). Figure 6: Distortions induced by side-looking SAR. Ground points a, b, c are \u2018seen\u2019 by radar as points a\u2019, b\u2019, c\u2019 in the slant range. Credit: Franz J. Meyer In the case of foreshortening , the backscatter from the front side of the mountain is compressed, with returns from a large area arriving back to the sensor at about the same time. This results in the front slope being displayed as a narrow, bright band. When layover occurs, returns from the front slope (and potentially even some of the area before the slope starts) are received at the same time as returns from the back slope. Thus, area in the front of the slope is projected onto the back side in the slant range image. In this case, the data from the front slope cannot be extracted from the returns. Another condition that results in missing data is radar shadow . In this case, the angle of the back slope is such that the sensor can not image it at all. These areas with steep back slopes offer no information to the SAR sensor. When RTC is performed, foreshortened areas are corrected based on the DEM. Areas impacted by layover or shadow, however, do not actually have data returns to correct. In this case, the pixels in the resulting RTC image will have a value of No Data. We do not interpolate missing data; users who would like to fill holes with estimated values will need to do so as appropriate for their particular application. Speckle \u00b6 In most cases, the patch of ground illuminated by the SAR transmitter will not be homogeneous. Instead it will be comprised of many different types of individual scatterers. The scatterers may interfere with each other either strengthening the return or weakening it. This creates a grainy (salt & pepper) appearance in SAR imagery. This a result of the nature of SAR and, thus, occurs in all SAR scenes. Speckle in SAR images can be mitigated by multi-looking, which, in effect, uses averaging to smooth out the image, resulting in a more homogeneous appearance at the expense of resolution.","title":"Introduction to SAR"},{"location":"guides/introduction_to_sar/#introduction-to-sar","text":"","title":"Introduction to SAR"},{"location":"guides/introduction_to_sar/#how-sar-operates","text":"SAR is an active sensor that transmits pulses and listens for echoes, called backscatter. The backscatter is recorded in both phase and amplitude. The phase is used to determine the distance from the sensor to a target, and amplitude indicates the amount of the sent signal that returns to the sensor. Amplitude measurements provide information about the roughness, geometry, wetness, and dielectric constant of that target, while phase measurements are used for SAR interferometry.","title":"How SAR Operates"},{"location":"guides/introduction_to_sar/#propagation-of-em-waves","text":"At the most fundamental level, SAR transmits an encoded burst, called a chirp, of electromagnetic energy (Figure 1) and then listens for the return signal, called echoes. The wavelength of this chirp is in the centimeter range, with X-band (~3 cm), C-band (~6 cm), and L-band (~23 cm) all in common use. Figure 1: The spectrum of electromagnetic radiation. SAR is imaged using microwave wavelengths. The microwave range extends from about 1 mm to 1 m in wavelength, with most radar applications using bands within the 3 mm to 30 cm range.","title":"Propagation of EM Waves"},{"location":"guides/introduction_to_sar/#polarizations","text":"Polarization refers to the direction of travel of an electromagnetic wave. A horizontal wave is transmitted so that it oscillates in a plane parallel to the surface imaged, while a vertical wave oscillates in a plane perpendicular to the surface imaged. There are four different polarization combinations commonly used by SAR sensors: VV, VH, HV and HH, as listed in Table 1. The first letter indicates the polarization used to transmit the signal, and the second letter indicates the polarization of the measured return, as illustrated in Figure 2. Table 1: SAR Polarizations Polarization Code Transmit Signal Polarization Return Signal Polarization VV Vertical Vertical VH Vertical Horizontal HV Horizontal Vertical HH Horizontal Horizontal Figure 2: SAR signals are transmitted and received either vertically (V) or horizontally (H). This gives the potential for four different polarization combinations (transmit listed first, receive second): VV, VH, HH, and HV. Credit: ASF Different SAR sensors have different polarization capabilities. Single-pol sensors send out a signal in one polarization and can only measure returns that are in that same polarization (VV or HH). Dual-pol sensors send out a signal in one polarization, but can measure returns that are in that same polarization (co-pol: VV or HH) as well as returns that are in the other polarization (cross-pol: VH or HV). Some SAR systems can transmit chirps with both a horizontal or vertical polarization and listen for both horizontal or vertical returns, giving full quad-pol capabilities (VV, VH, HV, HH). Polarimetry is an emerging field of SAR processing which is used in a number of applications such as measuring vegetation properties and changes of vegetation over time. Additional applications include oceanography, geology, and disaster response.","title":"Polarizations"},{"location":"guides/introduction_to_sar/#backscatter-contributors","text":"Many factors influence the backscatter received by the SAR sensor. The wavelength used by the SAR influences the signal's penetration, and, thus, what is being imaged. Surface roughness will modulate the backscatter returns from nothing up to a strong return, decreasing or increasing the brightness of the resulting pixel. Scattering mechanisms like volume scattering or double bounce can strongly influence the brightness of the SAR image as well, sometimes resulting in total saturation by the received signal.","title":"Backscatter Contributors"},{"location":"guides/introduction_to_sar/#wavelength","text":"The wavelength of the SAR system influences the amount of ground penetration that occurs. As shown in Figure 3, X-band has the least penetration, scattering from the top of the canopy in vegetated areas. All three bands will penetrate dry sand, with stronger returns from both C-band and L-band. L-band has the most penetration overall, with returns from the ground in vegetated areas, strong returns from substances under dry alluvium, and deep penetration of ice and snow. Figure 3: Effects of the SAR band on penetration of surfaces. The longer the wavelength, the deeper the penetration through most land types. Credit: The SAR Handbook","title":"Wavelength"},{"location":"guides/introduction_to_sar/#surface-roughness","text":"The strength of the return, or backscatter, is partially based upon relative roughness of the surface imaged. The smoother the surface, the more reflection away from the sensor, while rough surfaces give a much stronger return towards the imaging platform. As can be seen in Figure 4, if the height of the surface's roughness is less than 1/32 of the wavelength, mostly specular reflection occurs. If the height of the surface's roughness is greater than 1/2 the wavelength used, the echoes are scattered in all directions, giving a strong return back to the sensor. Figure 4: The amount of backscatter from a surface depends largely on the surface's roughness, with smooth surfaces getting the least returns and rough surfaces getting the strongest returns. Credit: The SAR Handbook","title":"Surface Roughness"},{"location":"guides/introduction_to_sar/#types-of-scattering","text":"Figure 5: Scattering mechanisms. Rough surfaces give bright returns due to the wide scattering. Vegetated surfaces cause volumetric scattering, which gives a darker return to the imaging platform. Double bounce returns, found mostly in urban areas, give the brightest return, as the majority of the energy is re-directed back towards the sensor. Credit: The SAR Handbook The resolution of Sentinel-1 SAR images is roughly 10 m. This means that a square of 10 meters on the ground is represented by a single pixel in the SAR image. The relative roughness of this patch of ground compared to the wavelength used will affect the backscatter strength (see Figure 4). However, there are additional types of bounce mechanisms beyond specular and diffuse, as shown in Figure 5. In vegetation, volumetric scattering occurs when signals bounce around inside the vegetation imaged. The double bounce mechanism which occurs in urban areas and is exploited by corner reflectors, causes chirp to be reflected directly back to the sensor, causing a very strong backscatter. Double bounce returns are so strong in some places that they cause over saturation of the sensor, resulting in visible sidelobes. These sidelobes are evidenced by bright crosses surrounding the double bounce target.","title":"Types of Scattering"},{"location":"guides/introduction_to_sar/#sar-scale","text":"SAR backscatter are recorded in both return strength and phase. Each pixel in a single-look complex SAR image represents these values as an imaginary number (I,Q). To create the visible images we are used to looking at, the SAR image is detected . This process calculates the square root of the sum of the squares of the I and Q values found in an SLC image, creating a so-called intensity image. This image is real valued, and, when calibrated, gives the absolute backscatter of the surface imaged. Detected images can be stored using several different scales, including power, amplitude, and dB. Note the default scale of Sentinel-1 RTC products from HyP3 is power. However, in some cases, it may be desirable to convert the actual pixel values to a different scale. Two other scales commonly used for SAR data are amplitude and dB.","title":"SAR Scale"},{"location":"guides/introduction_to_sar/#power-scale","text":"The values in this scale are generally very close to zero, so the dynamic range of the SAR image can be easily skewed by a few bright scatterers in the image. Power scale is appropriate for statistical analysis of the SAR dataset, but may not always be the best option for data visualization. When viewing a SAR image in power scale in a GIS environment, it may appear mostly or all black, and you may need to adjust the stretch to see features in the image. Often applying a stretch of 2 standard deviations, or setting the Min-Max stretch values to 0 and 0.3, will greatly improve the appearance of the image. You can adjust the stretch as desired to display your image to full advantage. Be aware that this does not change the actual pixel values.","title":"Power Scale"},{"location":"guides/introduction_to_sar/#amplitude-scale","text":"Amplitude scale is the square root of the power scale values. This brightens the darker pixels and darkens the brighter pixels, narrowing the dynamic range of the image. In many cases, amplitude scale presents a pleasing grayscale display of RTC images. Amplitude scale works well for calculating log difference ratios (see ASF Sentinel-1 RTC Product Guide ).","title":"Amplitude Scale"},{"location":"guides/introduction_to_sar/#db-scale","text":"The dB scale is calculated by multiplying 10 times the Log10 of the power scale values. This scale brightens the pixels, allowing for better differentiation among very dark pixels. When identifying water on the landscape, this is often a good scale to use; the water pixels generally remain very dark, while the terrestrial pixels are even brighter (see Identifying Surface Water ). This scale is not always the best choice for general visualization of SAR products, as it can give a washed-out appearance, and because it is in a log scale, it is not appropriate for all types of statistical analyses.","title":"dB Scale"},{"location":"guides/introduction_to_sar/#geometric-distortions","text":"There are a number of distortions inherent to SAR data due to the side-looking nature of the sensor, and these impacts will be more prevalent in areas with rugged terrain. The process of radiometric terrain correction addresses the geometric distortions that lead to geolocation errors in terrain features, and also normalizes the backscatter values based on the actual area contributing returns. This process generates an image that aligns well with other geospatial data and is suitable for GIS applications or time-series analysis. The key distortions present in SAR images are foreshortening, layover and shadow (Figure 6). Figure 6: Distortions induced by side-looking SAR. Ground points a, b, c are \u2018seen\u2019 by radar as points a\u2019, b\u2019, c\u2019 in the slant range. Credit: Franz J. Meyer In the case of foreshortening , the backscatter from the front side of the mountain is compressed, with returns from a large area arriving back to the sensor at about the same time. This results in the front slope being displayed as a narrow, bright band. When layover occurs, returns from the front slope (and potentially even some of the area before the slope starts) are received at the same time as returns from the back slope. Thus, area in the front of the slope is projected onto the back side in the slant range image. In this case, the data from the front slope cannot be extracted from the returns. Another condition that results in missing data is radar shadow . In this case, the angle of the back slope is such that the sensor can not image it at all. These areas with steep back slopes offer no information to the SAR sensor. When RTC is performed, foreshortened areas are corrected based on the DEM. Areas impacted by layover or shadow, however, do not actually have data returns to correct. In this case, the pixels in the resulting RTC image will have a value of No Data. We do not interpolate missing data; users who would like to fill holes with estimated values will need to do so as appropriate for their particular application.","title":"Geometric Distortions"},{"location":"guides/introduction_to_sar/#speckle","text":"In most cases, the patch of ground illuminated by the SAR transmitter will not be homogeneous. Instead it will be comprised of many different types of individual scatterers. The scatterers may interfere with each other either strengthening the return or weakening it. This creates a grainy (salt & pepper) appearance in SAR imagery. This a result of the nature of SAR and, thus, occurs in all SAR scenes. Speckle in SAR images can be mitigated by multi-looking, which, in effect, uses averaging to smooth out the image, resulting in a more homogeneous appearance at the expense of resolution.","title":"Speckle"},{"location":"guides/rtc_atbd/","text":"RTC Algorithm Theoretical Basis \u00b6","title":"Theoretical Basis"},{"location":"guides/rtc_atbd/#rtc-algorithm-theoretical-basis","text":"","title":"RTC Algorithm Theoretical Basis"},{"location":"guides/rtc_product_guide/","text":"Sentinel-1 RTC Product Guide \u00b6 This document is a guide for users of Radiometrically Terrain Corrected (RTC) Sentinel-1 products generated by the Alaska Satellite Facility (ASF). Users can request RTC products On Demand in ASF's Vertex data portal, or make use of our Python SDK or API . SAR datasets inherently contain geometric and radiometric distortions due to terrain being imaged by a side-looking instrument. Radiometric terrain correction corrects these distortions and creates analysis-ready data suitable for use in GIS applications or time-series analysis. RTC processing is a required first step for many amplitude-based SAR applications. ASF's Sentinel-1 On-Demand RTC products are generated using GAMMA Software . Products are distributed as GeoTIFFs (one for each available polarization) projected to the appropriate UTM Zone for the location of the scene. A Digital Elevation Model (DEM) is required for radiometric terrain correction. The GLO-30 Copernicus DEM is the default DEM used for processing RTC On Demand products. Refer to the Digital Elevation Model section for more information. Coverage gaps in Copernicus DEM GLO-30 filled using GLO-90 The Copernicus DEM GLO-30 dataset does not provide coverage over Armenia and Azerbaijan. In the past, we have not supported On Demand product generation over those areas using the Copernicus DEM option. We now use the Copernicus DEM GLO-90 to fill those gaps. Users should be aware that the GLO-90 dataset has a pixel spacing of 90 meters, which is not as detailed as the 30-m pixel spacing in the GLO-30 DEM. For a step-by-step tutorial on ordering On-Demand RTC Products using Vertex, visit our RTC On Demand! StoryMap , which also includes links to sample workflows using Sentinel-1 RTC products for GIS applications. New RTC Pixel Spacing Option Available On Demand Sentinel-1 RTC products can now be processed at 20-m pixel spacing . Refer to the Processing Options section for more information. Introduction \u00b6 Sentinel-1 Mission \u00b6 The Sentinel-1 mission collects C-band band SAR from a pair of polar-orbiting satellites launched by the European Space Agency (ESA) as part of the Copernicus program . The Sentinel-1A satellite was launched April 3, 2014, and the Sentinel-1B satellite was launched April 25, 2016. The Sentinel-1B satellite no longer acquires data as of December 23, 2021. The two Sentinel-1 satellites each have a 12-day repeat cycle, but their orbits are offset 180 degrees so that one or the other will pass over the same location on earth every 6 days. Most areas of the earth will still only have imagery collected every 12 days at best, but while both S1A and S1B were active, Europe and select areas of interest were imaged with a 6-day interval, as described in the mission observation scenario . Because this is a polar-orbiting satellite constellation, areas near the poles may have a number of overlapping paths, resulting in even more frequent acquisitions with similar footprints. The relatively short interval between acquisitions makes this SAR dataset a very useful tool for monitoring rapid or sudden landscape changes. In addition, SAR can image the earth's surface through cloud or smoke cover and does not require sunlight, so valid imagery can be collected on every pass. This is particularly useful for monitoring conditions during natural disasters such as hurricanes or wildfires, or in areas that are prone to frequent cloud cover. SAR Distortions \u00b6 There are a number of distortions inherent to SAR data due to the side-looking nature of the sensor, and these impacts will be more prevalent in areas with rugged terrain. The process of radiometric terrain correction addresses the geometric distortions that lead to geolocation errors in terrain features, and also normalizes the backscatter values based on the actual area contributing returns. This process generates an image that aligns well with other geospatial data and is suitable for GIS applications or time-series analysis. The key distortions present in SAR images are foreshortening, layover and shadow (Figure 1). Figure 1: Distortions induced by side-looking SAR. Ground points a, b, c are \u2018seen\u2019 by radar as points a\u2019, b\u2019, c\u2019 in the slant range. Credit: Franz J. Meyer In the case of foreshortening , the backscatter from the front side of the mountain is compressed, with returns from a large area arriving back to the sensor at about the same time. This results in the front slope being displayed as a narrow, bright band. When layover occurs, returns from the front slope (and potentially even some of the area before the slope starts) are received at the same time as returns from the back slope. Thus, area in the front of the slope is projected onto the back side in the slant range image. In this case, the data from the front slope cannot be extracted from the returns. Another condition that results in missing data is radar shadow . In this case, the angle of the back slope is such that the sensor can not image it at all. These areas with steep back slopes offer no information to the SAR sensor. When RTC is performed, foreshortened areas are corrected based on the DEM. Areas impacted by layover or shadow, however, do not actually have data returns to correct. In this case, the pixels in the resulting RTC image will have a value of No Data. We do not interpolate missing data; users who would like to fill holes with estimated values will need to do so as appropriate for their particular application. The RTC product package includes a Layover-Shadow mask (see Image Files section ) If you find that there are No Data pixels in your image, you can refer to that reference raster to see if the missing pixels are due to layover or shadow effects. Digital Elevation Models \u00b6 The quality of the terrain corrections are related to the quality of the digital elevation models (DEMs) used in the process of geometrically and radiometrically correcting the SAR imagery. We use DEMs that are publicly available and have wide-ranging coverage. In the past, ASF maintained a collection of DEMs that were pre-processed as appropriate for SAR workflows, and applied a preference hierarchy so that the best available DEM in any given area would be automatically selected for processing. With the public release of the GLO-30 Copernicus DEM , we have changed our default DEM strategy to leverage a cloud-hosted copy of the global Copernicus DEM. This is now the default DEM for processing RTC products, and the only option available for processing InSAR products . Users still have the option to use the legacy DEMs when processing RTC jobs On Demand in Vertex and when using the API or SDK , but we recommend using the Copernicus DEM whenever possible. Deprecation of Legacy DEMs for RTC Processing We are considering eliminating the option to use our legacy DEM dataset (NED/SRTM) as a HyP3 processing option for RTC. We would value your feedback as we decide if we will make this change. How would you be impacted if the NED/SRTM DEM option was no longer available? Would it affect your current workflows? Please send your feedback to uso@asf.alaska.edu . We use the 2022 Release of the Copernicus GLO-30 Public DEM , available on AWS . For more information, see the 'Releases' section of this article . Coverage gaps in Copernicus DEM GLO-30 filled using GLO-90 The Copernicus DEM GLO-30 dataset does not provide coverage over Armenia and Azerbaijan. In the past, we have not supported On Demand product generation over those areas using the Copernicus DEM option. We now use the Copernicus DEM GLO-90 to fill those gaps. Users should be aware that the GLO-90 dataset has a pixel spacing of 90 meters, which is not as detailed as the 30-m pixel spacing in the GLO-30 DEM. Table 1 summarizes ASF's DEM sources. Note that in each case, the DEM is resampled to RTC spacing and reprojected to a UTM Zone (WGS84), and a geoid correction is applied before being used for RTC processing. Resolution DEM Vertical Datum Area Posting Priority Medium GLO-30 EGM2008 Global 1 arc second Default High NED13 NAVD88 CONUS, Hawaii, parts of Alaska 1/3 arc seconds 1 Medium SRTMGL1 EGM96 60 N to 57 S latitude 1 arc second 2 Medium NED1 NAVD88 Canada 1 arc second 3 Low NED2 NAVD88 Parts of Alaska 2 arc seconds 4 Table 1: DEMs used for RTC processing. Note that the Copernicus 30 m DEM is the default, while the other four DEMs are only used if the legacy option is invoked. When ordering On-Demand RTC products, you can choose to include a copy of the DEM used for RTC processing in the RTC product package. This DEM copy is converted to 16-bit signed integer format, but is otherwise the same as the DEM used in the RTC process. Pixel values indicate the elevation in meters. Note that the elevation values will differ from the original source DEM in all cases, due to the geoid correction applied to prepare the DEM for use in RTC processing. Copernicus DEM \u00b6 The GLO-30 Copernicus DEM provides global coverage at 30-m pixel spacing (with the current exception of an area covering Armenia and Azerbaijan, see Figure 3). When an On Demand RTC job is requested, we download the required DEM tiles from the Copernicus Digital Elevation Model (DEM) GLO-30 Public dataset available in the Registry of Open Data on AWS , managed by Sinergise . We mosaic the tiles and reproject them to the appropriate UTM Zone for the location of the SAR granule to be processed, resampling them to match the pixel spacing and alignment of the RTC product. A geoid correction is applied before it is used for RTC processing. For the area that does not have coverage with the GLO-30 DEM, we use the Copernicus DEM GLO-90 dataset, which provides elevation data at 90-meter pixel spacing. Users ordering products over this area should be aware that a lower-resolution DEM is used for processing. Figure 2 shows the coverage of the Copernicus DEM GLO-30 Public dataset, and Figure 3 details the land area currently only covered by the GLO-90 DEM at 90-m pixel spacing. Figure 2: Copernicus DEM GLO-30 coverage map Figure 3: Detail of area currently not covered by Copernicus DEM GLO-30. On Demand jobs requested over this area will use the Copernicus DEM GLO-90. Legacy DEMs \u00b6 Deprecation of Legacy DEMs for RTC Processing We are considering eliminating the option to use our legacy DEM dataset (NED/SRTM) as a HyP3 processing option for RTC. We would value your feedback as we decide if we will make this change. How would you be impacted if the NED/SRTM DEM option was no longer available? Would it affect your current workflows? Please send your feedback to uso@asf.alaska.edu . The legacy DEMs were pre-processed by ASF to a consistent raster format (GeoTIFF) from the original source formats: height (*.hgt), ESRI ArcGrid (*.adf), etc. Many of the NASA-provided DEMs were provided as orthometric heights with EGM96 vertical datum. These were converted by ASF to ellipsoid heights using the ASF MapReady tool named geoid_adjust . The pixel reference varied from the center (pixel as point) to a corner (pixel as area). The GAMMA software used to generate the RTC products uses pixel as area and adjusts DEM coordinates as needed. These processed DEM collections are stored by ASF in AWS. When an RTC job is requested, the best-available DEM covering the SAR granule is selected, and the necessary tiles are reprojected to a mosaic in the UTM Zone appropriate for the granule location. If legacy DEM processing is selected, one of the following DEMs will be used: The National Elevation Dataset (NED) \u2153 arc second (about 10 m resolution) DEM covers the continental U.S. (CONUS), Hawaii, and parts of Alaska. Shuttle Radar Topography Mission (SRTM) GL1 data at 30 m resolution is used where NED 13 is not available. 1 arc second NED gives coverage of Canada at about 30 m resolution. 2 arc second NED (about 60 m) covers the remaining parts of Alaska above 60 degrees northern latitude. Since more than one DEM may be available in legacy processing, DEMs are selected in priority order as listed in Table 1. DEM coverage of at least 20% from a single DEM source is required for legacy processing to proceed. In no case will the DEM selected be from more than one source; only the single best source of terrain height values is used for a given scene. Figure 4 shows the coverage of the various legacy DEM sources. Figure 4: Coverage of the various legacy DEM sources used for terrain correction Pixel Spacing \u00b6 On Demand Sentinel-1 RTC now available at 10-m and 20-m pixel spacing There are now three pixel spacing options available for On Demand Sentinel-1 RTC products. Users can choose to output the RTC products at a pixel spacing of 30, 20, or 10 meters. RTC products can be output at 30-meter, 20-meter, or 10-meter pixel spacing. In most cases, the input SAR image has a resolution closer to the 10-m products, while the Copernicus DEM (used by default for RTC processing) has a pixel spacing of 30 m. The 10-m RTC product will be closer to the resolution of the source SAR granule, but the 30-m RTC product has a much smaller file size. Figure 5: Comparison of RTC products generated with different pixel spacing settings It is much faster to process, download and analyze 30-m RTC products than 10-m products, so it's a good idea to start with the coarser resolution option if possible. If the 30-m pixel spacing is not sufficient for your use case, try the 20-m RTC products. If even more detail is required, the 10-m products may be the best option. The 20-m product may be a good trade-off between resolution and file size. The amount of detail in the 20-m product is much closer to the 10-m product, but the file size is much closer to the 30-m product. Consider the file sizes for the RTC VV GeoTIFFs displayed in the comparison image: Pixel Spacing File Size 30 m 267 MB 20 m 600 MB 10 m 2350 MB DEM Resolution \u00b6 Keep in mind that the same DEM is used for processing the RTC products, regardless of the output pixel spacing. By default, the DEM is the Copernicus Global DEM, which has a pixel spacing of 30 meters. When processing 10-m RTC products, the source DEM is resampled to a pixel spacing of 10 meters. This resampled DEM can optionally be included in the product package, and the pixel spacing will align with the output RTC product. The same is true for the 20-m products; the DEM is resampled to a pixel spacing of 20 meters, and the resampled version is optionally included in the product package. The pixel spacing of the output DEM file does not indicate that the source DEM used for the 10-m or 20-m products is of higher resolution. Processing Options and Optional Files \u00b6 There are a number of options users can set when ordering RTC On Demand products. Some of these options set parameters used in the RTC processing workflow, others allow users to add additional files to the product package that are not included by default. Table 2 lists all of the options as displayed in the Vertex user interface and the HyP3 API, and the Processing Options and Optional Files sections provide more information about each option. Option Name in Vertex Option Name in HyP3 API/SDK Possible Values Default Description Radiometry radiometry (gamma0, sigma0) gamma0 Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) Scale scale (power, decibel, amplitude) power Scale of output backscatter values Pixel Spacing resolution (10.0, 20.0, 30.0) 30.0 Product pixel spacing in meters DEM Name dem_name (copernicus, legacy) copernicus Name of the DEM to use for processing: copernicus will use the Copernicus GLO-30 Public DEM, legacy will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets Apply DEM Matching dem_matching (true, false) false Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files Apply Speckle Filter speckle_filter (true, false) false Apply an Enhanced Lee speckle filter Include DEM include_dem (true, false) false Include a copy of the DEM used for RTC processing in the product package Include Incidence Angle Map include_inc_map (true, false) false Include the local incidence angle map in the product package Include Scattering Area Map include_scattering_area (true, false) false Include the scattering area map in the product package Include RGB Decomposition include_rgb (true, false) false Include a false-color RGB decomposition GeoTIFF in the product package Table 2: Processing Options Processing Options \u00b6 Radiometry \u00b6 The radiometry option allows users to set their preferred backscatter coefficient normalization to either gamma-nought (gamma0 or \u03b3 0 ) or sigma-nought (sigma0 or \u03c3 0 ) radiometry. As illustrated in Figure 6, the scattering coefficient gamma0 is normalized by the illuminated area projected into the look direction (A \u03b3 - the yellow area with the red outline in the diagram), and the sigma0 is normalized by the ground area (A \u03c3 - the grey area with the purple outline in the diagram). Figure 6: Normalization areas for SAR backscatter, from David Small, 2011, Flattening Gamma: Radiometric Terrain Correction for SAR Imagery, IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 49, NO. 8, AUGUST 2011 Although both sigma0 and gamma0 backscatter include the impact of local topography, the sensitivity of the impact is different. For applications where topographic impacts are an important consideration, gamma0 is generally the preferred choice. Scale \u00b6 The scale option allows users to choose the scale of the output backscatter images from the three commonly used scales for calibrated SAR values: power, amplitude, or decibel (dB). Refer to the SAR Scale section for more information. Pixel Spacing \u00b6 The resolution parameter sets the pixel spacing of the output images. Users have the option to set a pixel spacing of 30, 20, or 10 meters. The 30-m product has a much smaller file size, and is easier to work with for large areas of interest. It generally aligns with the native resolution of the DEM used for RTC processing. The 10-m product provides much more detail of surface features, and is closer to the native resolution of the source Sentinel-1 data. The file sizes are also much larger than those of the 30-m products. The 20-m product may be a good compromise between the native resolution of the source SAR imagery and the source DEM. The level of detail in the image is much closer to the 10-m product than the 30-m product, while the file size is much closer to the 30-m product than the 10-m product. Refer to the Pixel Spacing section for more information. Note that the source Sentinel-1 imagery and the source DEM used for RTC processing are the same regardless of the option selected for the output pixel spacing. DEM Name \u00b6 The dem_name parameter selects the DEM to use for RTC processing. By default, we use the Copernicus Global 30-m DEM , but allow users to select ASF's legacy DEMs (a combination of NED and SRTM) if desired. We recommend using the Copernicus DEM, which has more extensive and consistent coverage and more recent measurements. The main reason to select the legacy option is if a user already has a time series of products generated with the legacy DEM and wants to process new acquisitions using the same DEM. Refer to the Digital Elevation Models section for more information. DEM Matching \u00b6 The dem_matching option allows users to either try to coregister the SAR image to the DEM file, or simply use the Sentinel-1 orbit files for geocoding the RTC products. The process of terrain corrected geocoding includes 4 steps: Calculate the initial lookup table and simulated image with the image processing parameters and DEM. (Optional) Measure initial offset between simulated SAR image and actual SAR image. (Optional) Perform refinement of lookup table by offset measurement with respect to the simulated SAR image. Produce terrain geocoded SAR image and DEM in SAR range-Doppler coordinates (RDC). When DEM matching is applied, the optional steps 2 and 3 are performed. Using this option can improve the quality of the RTC calculations, as the features in the SAR image are matched to the features in the DEM, minimizing the offsets in geometry during the backscatter normalization calculations. Refer to the Terrain Correction section for more information. DEM Matching is not always beneficial, however. If the georeferencing of the DEM doesn't match the georeferencing of the Sentinel-1 imagery, DEM matching can result in variable offsets in the output images from one Sentinel-1 acquisition to the next, making it difficult to overlay images for time series analysis. Coregistration also works best when there are distinct topographic features that allow for reliable matching between the SAR image and the DEM. In areas that lack distinctive topographic features, there may also be substantial and inconsistent image offsets. The orbit files of the Sentinel-1 data are generally quite accurate, and not applying the DEM matching should output files with consistent geolocation. While it may not optimize the RTC calculations, it may be a better option for time series analysis, where having consistent alignment of images from one acquisition to the next is more important than optimizing the backscatter normalization. If you are interested in optimizing the RTC calculations, and are less concerned about consistent geolocation through time, the DEM Matching option is likely a good choice. In cases where consistency is more important than accuracy, consider not applying DEM Matching, or at least testing the outputs to make sure they are suitable for your application. Speckle Filter \u00b6 When the speckle_filter option is selected, an Enhanced Lee filter is applied during RTC processing to remove speckle while preserving edges of features. Speckle occurs due to interference among signal waves, as they interact with different scatterers on the surface of the earth and return to the sensor. It appears as granular noise in the image. Refer to the Speckle section of our Introduction to SAR document for more information. When applied, the filter is set to a dampening factor of 1, with a box size of 7x7 pixels. The number of looks depends on the multilooking treatment for the RTC processing, and is based on the pixel spacing and the input scene type. Refer to the readme file included with the RTC product to determine the number of looks used for the filter, which is the number of looks taken for RTC processing multiplied by 30. Applying a speckle filter can smooth the appearance of the image, but it comes at a cost to the resolution of the output RTC product. Keep in mind also that there are other speckle filters that may be better suited to a specific application. We do not currently offer any customization of the type of speckle filter used, or the parameters (window size, multilooking, dampening, etc.) used for the filter. You may also want to try applying other spatial speckle filters with custom settings, which can be accomplished programmatically or using GIS software. Some temporal analyses may also mitigate the impacts of speckle, such as calculating the median or mean pixel values of multiple images collected over a period of time. In both cases, it may be better not to apply a speckle filter during RTC processing. If you are unsure whether to apply this option, try generating some of your RTC products with and without the speckle filter applied, and check to see which product works best for your particular application. Optional Files \u00b6 In addition to the processing options, users can choose to add a number of ancillary files to the product package. These files are not included by default, as they increase the size of the product package and may not be of interest to all users. In Vertex, check the box in the \"Include\" section of the options to add these optional files to the product package. When using the HyP3 API or SDK, set the parameter to true. DEM \u00b6 Set the include_dem parameter to true to include a copy of the DEM file used for RTC processing. This DEM is not generated from the Sentinel-1 data, but is the reference DEM used for the RTC calculations. Pixel values indicate the elevation in meters. Refer to the Digital Elevation Models section for more information on the DEMs we use for RTC processing. This DEM file is intended as a quick reference to aid in interpretation of the RTC image, and should not be used as a stand-alone DEM product. The DEM used for RTC processing has a geoid correction applied before it is used for RTC, so elevation values in this file will differ from the source DEM. The DEM is resampled to match the pixel spacing of the output product, so the pixel spacing of this file is not a reflection of the resolution of the source DEM. Refer to the readme file included in the RTC product package for details on the pixel spacing of the included DEM file. Incidence Angle Map \u00b6 Set the include_inc_map parameter to true to include the local incidence angle map in the product package. The cell values in this raster indicate the angle between the incident radar beam and the direction perpendicular to the ground surface, expressed in radians. Scattering Area Map \u00b6 Set the include_scattering_area parameter to true to include the scattering area map in the product package. This map expresses the scattering area for each pixel in the RTC image in square meters. The values are calculated based on the effectively illuminated gamma-0 terrain surface using a digital elevation model, the local incidence angle map, and the layover-shadow map. This layer can be used to generate composites using the Local Resolution Weighting method, as described in the article Wide-Area Analysis-Ready Radar Backscatter Composites by David Small et al., 2022. RGB Decomposition \u00b6 Set the include_rgb parameter to true to include a full-resolution GeoTIFF of a false-color RGB Decomposition of the co- and cross-polarized RTC values. A low-resolution false-color browse image in PNG format is included in the product package by default, but selecting this option includes the RGB Decomposition image as a GeoTIFF with the same pixel spacing as the RTC images. This option is only available for dual-polarization products, as it uses both the co- and cross-polarized RTC values to determine the RGB values. A full description of the approach ASF uses for generating RGB Decomposition products is available here . In general, blue indicates areas with low backscatter in both co- and cross-polarizations (calm water, dry sand, frozen ground), green indicates high cross-pol values (vegetation or other volume scatterers), and red indicates areas with low cross-pol but relatively high co-pol values (urban areas or sparsely vegetated landscapes). Radiometric Terrain Correction Workflow \u00b6 Pre-processing \u00b6 The first step of pre-processing is the selection of the best DEM for the terrain correction. The DEM tiles are assembled to ensure sufficient coverage for the terrain correction of the Sentinel-1 granule. The application of the calibration parameters and multi-looking are the only pre-processing steps applied to the SAR image. Terrain Correction \u00b6 The terrain correction is performed in slant range geometry. A look-up table is created to map between DEM space and SAR space. The actual mapping of the initial image into projected space is only applied once to mitigate the propagation of any resampling errors. All intermediate steps only update the look-up table used for the mapping. By default, images are not coregistered to the DEM. While RTC results can be improved by matching imagery to a high-quality DEM, different acquisitions over the same area may not always be matched to the DEM in the same way, due in part to the presence of speckle. This can introduce spatial inconsistencies to the dataset, especially when viewing a time-series of RTC images. For consistency, we use the geolocation from the Sentinel-1 state vectors by default rather than matching the geolocation based on DEM features. When ordering products On Demand, the DEM Matching option is available for selection. When this option is applied, the first step is the co-registration of the SAR image with a simulated SAR image derived from the DEM. An initial offset is first attempted as a single match; if it fails, a larger number of image chips are used to determine an average offset in azimuth and range direction. This initial offset is then refined using strict matching criteria. Matching may fail for three different reasons: (1) no match can be found, (2) the magnitude of the residual offset errors is greater than 2 pixels, or (3) the maximum calculated offset is greater than 50 m. In any of these cases, the dead reckoning approach is taken when matching fails. This approach solely relies on the geolocations calculated from state vectors (the same approach used when DEM matching is not selected as an option) - no geolocation refinement is applied. Radiometric Correction \u00b6 During processing, a surface scattering area image for the scene is calculated and saved. This projected area image is used to create the RTC product - the SAR image is multiplied by the ratio of an ellipsoidal scattering image (used during calibration) and this scattering area image. Note that this image is always projected to gamma-nought (\u03b3 0 ). Geocoding \u00b6 In a final step, the RTC product is geocoded into map-projected space. Thus, radiometric terrain correction results in a geocoded radiometrically calibrated multi-looked image with gamma-nought (\u03b3 0 ) power scale values by default, though there are options to process to sigma-nought (\u03c3 0 ) radiometry and amplitude or decibel (dB) scale . Post-Processing \u00b6 After the terrain correction is completed, the RTC products are exported to GeoTIFF format. If the scene being processed is dual polarization, users have the option to add a full-resolution RGB Decomposition GeoTIFF to the RTC product package. Side products including the DEM , layover-shadow map (always included), scattering area map , and incidence angle map are converted into GeoTIFF format. In addition, a README text file, browse images, item-specific ArcGIS-compatible XML metadata files, a log file, and a shapefile indicating the data extent are generated for the product. Product Packaging \u00b6 Naming Convention \u00b6 The naming convention for the RTC products follows this pattern for its base names: S1x_yy_aaaaaaaaTbbbbbb_ppo_RTCzz_u_defklm_ssss Example: S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A Element Definition Example x Mission: A or B A yy Beam Mode IW aaaaaaaa Start Year-Month-Day 20180128 bbbbbb Start Hour-Minute-Second 161201 pp Polarization: Dual-pol (D) vs. Single-pol (S), Primary Polarization (H or V) DV o Orbit Type: Precise (P), Restituted (R), or Original Predicted (O) P zz Terrain Correction Pixel Spacing (m) 30 u Software Package Used: GAMMA (G) G d Gamma-0 (g) or Sigma-0 (s) Output g e Power (p), Decibel (d), or Amplitude (a) Output p f Unmasked (u) or Water Masked (w) u k Not Filtered (n) or Filtered (f) n l Entire Area (e) or Clipped Area (c) e m Dead Reckoning (d) or DEM Matching (m) d ssss Product ID FD6A Table 3: Naming convention for RTC products Image Files \u00b6 All files are stored in a folder named using the above convention, and the base name for each file matches the folder name. Multiple types of image files are present in this folder, and some of the files are optional. Users can choose to include the RGB Decomposition GeoTIFF, scattering area map, DEM, and incidence angle map rasters when ordering On-Demand RTC products. Extension Description Example _VV.tif, _VH.tif, _HH.tif, _HV.tif Terrain corrected product stored in separate files for each available polarization in GeoTIFF format S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_VV.tif .png Grayscale browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.png _rgb.png Color browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.png .kmz Zipped Google Earth image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.kmz _rgb.kmz Zipped Google Earth color image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.kmz _rgb.tif Color decomposition in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.tif _area.tif Scattering area map in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_area.tif _dem.tif DEM used for terrain correction in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_dem.tif _inc_map.tif Incidence angle file in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_inc_map.tif _ls_map.tif Layover/shadow mask in GeoTIFF format S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_ls_map.tif Table 4: Image files in product package The RTC products (one for each available polarization) are generated as 32-bit floating-point single-band GeoTIFF files, as are the incidence angle and scattering area maps. The RGB Decomposition is a 3-band unsigned 8-bit GeoTIFF file, the layover/shadow mask is a single-band unsigned 8-bit GeoTIFF, and the DEM is a 16-bit signed integer GeoTIFF. The browse images (both grayscale and color) are generated in PNG format, and are each 2048 pixels wide. Finally, KMZ files suitable for viewing in Google Earth are included. Note that colorized products (RGB Decomposition GeoTIFF or color browse PNG) can only be created for dual-polarization (SDV and SDH) granules, not for single-polarization (SSV or SSH). Metadata Files \u00b6 The product package also includes a number of metadata files. Extension Description Example .README.md.txt README file S1A _IW _20180128T161201 _DVP _RTC30 _G _gpuned _FD6A.README.md.txt .log Log file of the processing steps S1A _IW _20180128T161201 _DVP _RTC30 _G _gpuned _FD6A.log .tif.xml ArcGIS compliant XML metadata for GeoTIFF files S1A _IW _20180128T161201 _DVP _RTC30 _G _gpuned _FD6A _VV.tif.xml .png.xml ArcGIS compliant XML metadata for PNG files S1A _IW _20180128T161201 _DVP _RTC30 _G _gpuned _FD6A.png.xml .png.aux.xml Geolocation metadata for PNG browse images S1A _IW _20180128T161201 _DVP _RTC30 _G _gpuned _FD6A.png.aux.xml Table 5: Metadata files and their extensions README File \u00b6 The text file with extension .README.md.txt explains the files included in the folder, and is customized to reflect that particular product. Users unfamiliar with RTC products should start by reading this README file, which will give some background on each of the files included in the product folder. ArcGIS-Compatible XML Files \u00b6 There is an ArcGIS-compatible XML file for each raster in the product folder. When ArcGIS Desktop users view any of the rasters in ArcCatalog or the Catalog window in ArcMap, they can open the Item Description to view the contents of the associated XML file. ArcGIS Pro users can access the information from the Metadata tab. These files will not appear as separate items in ArcCatalog, though if you use Windows Explorer to look at the contents of the folder you will see them listed individually. Because each one is named identically to the product it describes (with the addition of the .xml extension), ArcGIS recognizes the appropriate file as the raster\u2019s associated metadata, and integrates the metadata accordingly. ArcGIS users should take care not to change these XML files outside of the ArcGIS environment; changing the filename or content directly may render the files unreadable by ArcGIS. Those not using ArcGIS will still find the contents of these XML files useful, but will have to contend with the XML tagging when viewing the files as text or in a browser. Auxiliary Geolocation Files \u00b6 Geolocation XML files (aux files) are included for each of the PNG browse images to allow for proper display in GIS platforms. Log File \u00b6 A log file detailing the processing parameters and outputs is also included for reference. Shapefile \u00b6 A shapefile indicating the extent of the RTC data coverage is included in the package. Extension Description Example _shape.dbf _shape.prj _shape.shp _shape.shx Shapefile (.shp) and supporting files S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_shape.shp Table 6: Shapefile files and their extensions SAR Scales \u00b6 On Demand Sentinel-1 RTC Products now available in dB scale Users can now choose to output Sentinel-1 RTC products in decibel (dB) scale. Previously, the only choices for output scale were power and amplitude. The default scale continues to be power. Power Scale \u00b6 Note that the default output of Sentinel-1 RTC products from HyP3 is in power scale. The values in this scale are generally very close to zero, so the dynamic range of the RTC image can be easily skewed by a few bright scatterers in the image. Power scale is appropriate for statistical analysis of the RTC dataset, but may not always be the best option for data visualization. When viewing an RTC image in power scale in a GIS environment, it may appear mostly or all black, and you may need to adjust the stretch to see features in the image. Often applying a stretch of 2 standard deviations, or setting the Min-Max stretch values to 0 and 0.3, will greatly improve the appearance of the image. You can adjust the stretch as desired to display your image to full advantage. Be aware that this does not change the actual pixel values. In some cases, it may be desirable to convert the actual pixel values to a different scale. Two other scales commonly used for SAR data are amplitude and decibel (dB). Amplitude Scale \u00b6 Values in the amplitude scale are the square root of the power scale values. This brightens the darker pixels (values <1) and darkens the brighter pixels (values >1), narrowing the dynamic range of the image. In many cases, amplitude scale presents a pleasing grayscale display of RTC images. Amplitude scale works well for calculating log difference ratios, as described in the Change Detection Using RTC Data use case example. Decibel (dB) Scale \u00b6 The decibel (dB) scale is calculated by multiplying 10 times the Log10 of the power scale values. This scale allows for better differentiation among very dark pixels. This is often a good scale to use for identifying water on the landscape; the water pixels generally remain very dark compared to the much brighter pixels of the surrounding landscape. Refer to the Identifying Surface Water use case example for more information. This scale is not always the best choice for general visualization of RTC products, as it can give a washed-out appearance to terrain features. In addition, because it is a logarithmic scale, dB pixel values are not appropriate for some types of statistical analyses. RTC Use Examples \u00b6 The RTC products are presented as Cloud-Optimized GeoTIFFs (COGs), a user-friendly format that is compatible with GIS software. The products include pre-generated overviews, so users will not need to generate pyramids to display the images efficiently in a GIS or web-mapping environment. The following sections present examples of how one might use RTC datasets to identify areas of change and integrate RTC datasets into other datasets for enhanced results. We also present a bibliography of some of the scientific literature making use of Sentinel-1 RTC datasets. Change Detection Using RTC Data \u00b6 There are a number of ways that SAR data sets can be used to identify areas of change. Here are two examples of what you can do in a GIS environment. Seasonal Change \u00b6 Stacking RTC images into a multiband image (Figure 7) allows the user to display different times of the year at the same time, using the color bands to highlight areas that differ in radar backscatter values from one month to the next. To generate this type of image, choose three images that capture different seasons or months of interest. These can either be individual RTC images from different times of the year, or rasters displaying the monthly median calculated from multiple RTC images collected in the same month. Combine the three images into a multiband raster and assign each to a different color band. The resulting RGB image highlights areas where there are distinctive differences among the three source image values. Figure 7: Monthly median VH gamma-0 power values for May, July and September, displayed as a multiband RGB (May, July, Sept) image. Contains modified Copernicus Sentinel data 2017, processed by ESA. Quantifying Change over Time \u00b6 A simple and informative approach to change detection is the calculation of the log difference between two RTC datasets from different dates. By calculating Log10(date2/date1) and applying a classified symbology, it is easy to identify areas where change occurred, as well as the direction of the change. Negative values indicate a decrease in radar backscatter over time, while positive values indicate an increase in backscatter. In the example below (Figure 8), RTC images from before and after heavy rains caused a dam breach. The area where the reservoir was located displays a significant increase in backscatter (symbolized in red). This positive change is driven by land that was once covered by standing water, which generally has very low backscatter, now being exposed saturated soil, which generally returns very high backscatter values. In surrounding areas, decreases in radar backscatter (symbolized by blue) are possibly the result of agricultural fields undergoing desiccation/hardening of the surface soil following the heavy rainfall and standing water. Areas with little change in backscatter are displayed in yellow. Figure 8: Log Difference Raster with Classified Symbology. Contains modified Copernicus Sentinel data 2020, processed by ESA. Identifying Surface Water \u00b6 Calm surface water has a very low radar cross section. Because freshwater has a high dielectric constant, most of the signal is reflected off the smooth surface of the water and away from the sensor, resulting in little to no backscatter. As such, surface water can often be delineated using a simple threshold value, where all pixels below the threshold are assumed to be water. It is often best to use datasets in dB scale for this process (refer to the dB Scale Section ). When using the threshold approach, surface water can be easily visualized by applying a classified symbology with two classes, using the threshold as the break point between the classes. There is no universal threshold value; it will need to be determined based on the surface water characteristics in the RTC image. When an RTC image contains significant surface water coverage, there is often a bimodal distribution of pixel values. The first peak in a histogram of the pixel values for the image can be expected to contain mostly water pixels, while the second peak contains all remaining pixels. A good first step in selecting a threshold value is to set the break point between classes at the lowest point between those two peaks, then adjust the value as needed to generate a good water mask for the image (Figure 9). Figure 9: Setting the break point to fall between the two peaks of the histogram Once you have determined the appropriate threshold (Figure 10), you can reclassify the RTC image to include only those pixels that fall below the threshold value, providing a water mask that can be used for analysis or to overlay with other imagery to show the water extent. Figure 10: Water Mask. Contains modified Copernicus Sentinel data 2020, processed by ESA. Combination of RTC Imagery with other Remote Sensing Data \u00b6 One of the main advantages of using RTC imagery is that it aligns geographically with other geospatial datasets. This makes it possible to combine SAR data with other remote sensing data, such as optical data. In the example below, the backscatter information of the Sentinel-1 SAR image (Figure 11) is used to enhance the spectral information of the optical Landsat 8 image (Figure 12) in the urban area of Pavia, Italy. Figure 11: Sentinel-1 RTC image. Figure 12: False color composite (bands 5, 4, 3) of a Landsat 8 image Figure 13 shows the image fusion result of an IHS transformation. In this transformation, the color channels red, green and blue (RGB) are first converted into a different color representation: intensity, hue and saturation (IHS). In the second step, the optical intensity is replaced by the SAR image values before IHS is transformed back to RGB. Figure 13: Image fusion result of SAR and optical imagery The color values for the two rivers in the SAR image are far more similar to each other than in the optical image. The vegetated areas (highlighted in red) show up more uniformly in the data fusion result than in the optical false color composite image. Image fusion uses the complementary nature of the different sources to generate an enhanced product. ArcGIS Toolbox \u00b6 ASF has developed a custom ArcGIS Toolbox for working with RTC datasets in either ArcGIS Desktop or ArcGIS Pro. It includes tools for converting between different SAR scales, calculating the log difference between two images, generating RGB Decomposition (false-color) products, and reclassifying a raster to generate a water mask. For more information and to download the toolbox, visit our website: https://asf.alaska.edu/how-to/data-tools/gis-tools/ . Application Examples in the Literature \u00b6 The following journal articles represent some of the work being done using Radiometric Terrain Corrected Sentinel-1 data sets. Crop Monitoring \u00b6 Clauss, K., Ottinger M. and Kuenzer, C. 2018. Mapping rice areas with Sentinel-1 time series and superpixel segmentation. International Journal of Remote Sensing , 39 (5):1399-1420. DOI: 10.1080/01431161.2017.1404162 Nguyen, D.B., Gruber A. and Wagner, W. 2016. Mapping rice extent and cropping scheme in the Mekong Delta using Sentinel-1A data. Remote Sensing Letters , 7 (12):1209-1218. DOI: 10.1080/2150704X.2016.1225172 Disaster Response \u00b6 Markert, K.N., Chishtie, F., Anderson, E.R., Saah, D., Griffin, R.E. 2018. On the merging of optical and SAR satellite imagery for surface water mapping applications. Results In Physics , 9 :275-277. DOI: 10.1016/j.rinp.2018.02.054 Twele, A., Cao, W., Plank, S. and Martinis, S. 2016. Sentinel-1-based flood mapping: a fully automated processing chain. International Journal of Remote Sensing , 37 (13):2990-3004. DOI: 10.1080/01431161.2016.1192304 Land Classification and Change Detection \u00b6 Muro, J., Canty, M., Conradsen, K., H\u00fcttich, C., Nielsen, A.A., Skriver, H., Remy, F., Strauch, A., Thonfeld, F. and Menz, G. 2016. Short-Term change detection in wetlands using Sentinel-1 time series. Remote Sensing , 8 (10):795. DOI: 10.3390/rs8100795 R\u00fcetschi, M., Schaepman, M.E., Small, D. 2018. Using Multitemporal Sentinel-1 C-band backscatter to monitor phenology and classify deciduous and coniferous forests in Northern Switzerland. Remote Sensing , 10 (1):55. DOI: 10.3390/rs10010055 Data Access \u00b6 To view or download Sentinel-1 RTC products, please see the links below: Vertex: https://search.asf.alaska.edu/ API: https://asf.alaska.edu/api/ For details on accessing data, including other SAR datasets, see ASF\u2019s Get Started guide: https://asf.alaska.edu/getstarted/ To access data recipes, which are step-by-step tutorials for processing and working with SAR data, see ASF\u2019s tutorials page: https://asf.alaska.edu/how-to/data-recipes/data-recipe-tutorials/","title":"Product Guide"},{"location":"guides/rtc_product_guide/#sentinel-1-rtc-product-guide","text":"This document is a guide for users of Radiometrically Terrain Corrected (RTC) Sentinel-1 products generated by the Alaska Satellite Facility (ASF). Users can request RTC products On Demand in ASF's Vertex data portal, or make use of our Python SDK or API . SAR datasets inherently contain geometric and radiometric distortions due to terrain being imaged by a side-looking instrument. Radiometric terrain correction corrects these distortions and creates analysis-ready data suitable for use in GIS applications or time-series analysis. RTC processing is a required first step for many amplitude-based SAR applications. ASF's Sentinel-1 On-Demand RTC products are generated using GAMMA Software . Products are distributed as GeoTIFFs (one for each available polarization) projected to the appropriate UTM Zone for the location of the scene. A Digital Elevation Model (DEM) is required for radiometric terrain correction. The GLO-30 Copernicus DEM is the default DEM used for processing RTC On Demand products. Refer to the Digital Elevation Model section for more information. Coverage gaps in Copernicus DEM GLO-30 filled using GLO-90 The Copernicus DEM GLO-30 dataset does not provide coverage over Armenia and Azerbaijan. In the past, we have not supported On Demand product generation over those areas using the Copernicus DEM option. We now use the Copernicus DEM GLO-90 to fill those gaps. Users should be aware that the GLO-90 dataset has a pixel spacing of 90 meters, which is not as detailed as the 30-m pixel spacing in the GLO-30 DEM. For a step-by-step tutorial on ordering On-Demand RTC Products using Vertex, visit our RTC On Demand! StoryMap , which also includes links to sample workflows using Sentinel-1 RTC products for GIS applications. New RTC Pixel Spacing Option Available On Demand Sentinel-1 RTC products can now be processed at 20-m pixel spacing . Refer to the Processing Options section for more information.","title":"Sentinel-1 RTC Product Guide"},{"location":"guides/rtc_product_guide/#introduction","text":"","title":"Introduction"},{"location":"guides/rtc_product_guide/#sentinel-1-mission","text":"The Sentinel-1 mission collects C-band band SAR from a pair of polar-orbiting satellites launched by the European Space Agency (ESA) as part of the Copernicus program . The Sentinel-1A satellite was launched April 3, 2014, and the Sentinel-1B satellite was launched April 25, 2016. The Sentinel-1B satellite no longer acquires data as of December 23, 2021. The two Sentinel-1 satellites each have a 12-day repeat cycle, but their orbits are offset 180 degrees so that one or the other will pass over the same location on earth every 6 days. Most areas of the earth will still only have imagery collected every 12 days at best, but while both S1A and S1B were active, Europe and select areas of interest were imaged with a 6-day interval, as described in the mission observation scenario . Because this is a polar-orbiting satellite constellation, areas near the poles may have a number of overlapping paths, resulting in even more frequent acquisitions with similar footprints. The relatively short interval between acquisitions makes this SAR dataset a very useful tool for monitoring rapid or sudden landscape changes. In addition, SAR can image the earth's surface through cloud or smoke cover and does not require sunlight, so valid imagery can be collected on every pass. This is particularly useful for monitoring conditions during natural disasters such as hurricanes or wildfires, or in areas that are prone to frequent cloud cover.","title":"Sentinel-1 Mission"},{"location":"guides/rtc_product_guide/#sar-distortions","text":"There are a number of distortions inherent to SAR data due to the side-looking nature of the sensor, and these impacts will be more prevalent in areas with rugged terrain. The process of radiometric terrain correction addresses the geometric distortions that lead to geolocation errors in terrain features, and also normalizes the backscatter values based on the actual area contributing returns. This process generates an image that aligns well with other geospatial data and is suitable for GIS applications or time-series analysis. The key distortions present in SAR images are foreshortening, layover and shadow (Figure 1). Figure 1: Distortions induced by side-looking SAR. Ground points a, b, c are \u2018seen\u2019 by radar as points a\u2019, b\u2019, c\u2019 in the slant range. Credit: Franz J. Meyer In the case of foreshortening , the backscatter from the front side of the mountain is compressed, with returns from a large area arriving back to the sensor at about the same time. This results in the front slope being displayed as a narrow, bright band. When layover occurs, returns from the front slope (and potentially even some of the area before the slope starts) are received at the same time as returns from the back slope. Thus, area in the front of the slope is projected onto the back side in the slant range image. In this case, the data from the front slope cannot be extracted from the returns. Another condition that results in missing data is radar shadow . In this case, the angle of the back slope is such that the sensor can not image it at all. These areas with steep back slopes offer no information to the SAR sensor. When RTC is performed, foreshortened areas are corrected based on the DEM. Areas impacted by layover or shadow, however, do not actually have data returns to correct. In this case, the pixels in the resulting RTC image will have a value of No Data. We do not interpolate missing data; users who would like to fill holes with estimated values will need to do so as appropriate for their particular application. The RTC product package includes a Layover-Shadow mask (see Image Files section ) If you find that there are No Data pixels in your image, you can refer to that reference raster to see if the missing pixels are due to layover or shadow effects.","title":"SAR Distortions"},{"location":"guides/rtc_product_guide/#digital-elevation-models","text":"The quality of the terrain corrections are related to the quality of the digital elevation models (DEMs) used in the process of geometrically and radiometrically correcting the SAR imagery. We use DEMs that are publicly available and have wide-ranging coverage. In the past, ASF maintained a collection of DEMs that were pre-processed as appropriate for SAR workflows, and applied a preference hierarchy so that the best available DEM in any given area would be automatically selected for processing. With the public release of the GLO-30 Copernicus DEM , we have changed our default DEM strategy to leverage a cloud-hosted copy of the global Copernicus DEM. This is now the default DEM for processing RTC products, and the only option available for processing InSAR products . Users still have the option to use the legacy DEMs when processing RTC jobs On Demand in Vertex and when using the API or SDK , but we recommend using the Copernicus DEM whenever possible. Deprecation of Legacy DEMs for RTC Processing We are considering eliminating the option to use our legacy DEM dataset (NED/SRTM) as a HyP3 processing option for RTC. We would value your feedback as we decide if we will make this change. How would you be impacted if the NED/SRTM DEM option was no longer available? Would it affect your current workflows? Please send your feedback to uso@asf.alaska.edu . We use the 2022 Release of the Copernicus GLO-30 Public DEM , available on AWS . For more information, see the 'Releases' section of this article . Coverage gaps in Copernicus DEM GLO-30 filled using GLO-90 The Copernicus DEM GLO-30 dataset does not provide coverage over Armenia and Azerbaijan. In the past, we have not supported On Demand product generation over those areas using the Copernicus DEM option. We now use the Copernicus DEM GLO-90 to fill those gaps. Users should be aware that the GLO-90 dataset has a pixel spacing of 90 meters, which is not as detailed as the 30-m pixel spacing in the GLO-30 DEM. Table 1 summarizes ASF's DEM sources. Note that in each case, the DEM is resampled to RTC spacing and reprojected to a UTM Zone (WGS84), and a geoid correction is applied before being used for RTC processing. Resolution DEM Vertical Datum Area Posting Priority Medium GLO-30 EGM2008 Global 1 arc second Default High NED13 NAVD88 CONUS, Hawaii, parts of Alaska 1/3 arc seconds 1 Medium SRTMGL1 EGM96 60 N to 57 S latitude 1 arc second 2 Medium NED1 NAVD88 Canada 1 arc second 3 Low NED2 NAVD88 Parts of Alaska 2 arc seconds 4 Table 1: DEMs used for RTC processing. Note that the Copernicus 30 m DEM is the default, while the other four DEMs are only used if the legacy option is invoked. When ordering On-Demand RTC products, you can choose to include a copy of the DEM used for RTC processing in the RTC product package. This DEM copy is converted to 16-bit signed integer format, but is otherwise the same as the DEM used in the RTC process. Pixel values indicate the elevation in meters. Note that the elevation values will differ from the original source DEM in all cases, due to the geoid correction applied to prepare the DEM for use in RTC processing.","title":"Digital Elevation Models"},{"location":"guides/rtc_product_guide/#copernicus-dem","text":"The GLO-30 Copernicus DEM provides global coverage at 30-m pixel spacing (with the current exception of an area covering Armenia and Azerbaijan, see Figure 3). When an On Demand RTC job is requested, we download the required DEM tiles from the Copernicus Digital Elevation Model (DEM) GLO-30 Public dataset available in the Registry of Open Data on AWS , managed by Sinergise . We mosaic the tiles and reproject them to the appropriate UTM Zone for the location of the SAR granule to be processed, resampling them to match the pixel spacing and alignment of the RTC product. A geoid correction is applied before it is used for RTC processing. For the area that does not have coverage with the GLO-30 DEM, we use the Copernicus DEM GLO-90 dataset, which provides elevation data at 90-meter pixel spacing. Users ordering products over this area should be aware that a lower-resolution DEM is used for processing. Figure 2 shows the coverage of the Copernicus DEM GLO-30 Public dataset, and Figure 3 details the land area currently only covered by the GLO-90 DEM at 90-m pixel spacing. Figure 2: Copernicus DEM GLO-30 coverage map Figure 3: Detail of area currently not covered by Copernicus DEM GLO-30. On Demand jobs requested over this area will use the Copernicus DEM GLO-90.","title":"Copernicus DEM"},{"location":"guides/rtc_product_guide/#legacy-dems","text":"Deprecation of Legacy DEMs for RTC Processing We are considering eliminating the option to use our legacy DEM dataset (NED/SRTM) as a HyP3 processing option for RTC. We would value your feedback as we decide if we will make this change. How would you be impacted if the NED/SRTM DEM option was no longer available? Would it affect your current workflows? Please send your feedback to uso@asf.alaska.edu . The legacy DEMs were pre-processed by ASF to a consistent raster format (GeoTIFF) from the original source formats: height (*.hgt), ESRI ArcGrid (*.adf), etc. Many of the NASA-provided DEMs were provided as orthometric heights with EGM96 vertical datum. These were converted by ASF to ellipsoid heights using the ASF MapReady tool named geoid_adjust . The pixel reference varied from the center (pixel as point) to a corner (pixel as area). The GAMMA software used to generate the RTC products uses pixel as area and adjusts DEM coordinates as needed. These processed DEM collections are stored by ASF in AWS. When an RTC job is requested, the best-available DEM covering the SAR granule is selected, and the necessary tiles are reprojected to a mosaic in the UTM Zone appropriate for the granule location. If legacy DEM processing is selected, one of the following DEMs will be used: The National Elevation Dataset (NED) \u2153 arc second (about 10 m resolution) DEM covers the continental U.S. (CONUS), Hawaii, and parts of Alaska. Shuttle Radar Topography Mission (SRTM) GL1 data at 30 m resolution is used where NED 13 is not available. 1 arc second NED gives coverage of Canada at about 30 m resolution. 2 arc second NED (about 60 m) covers the remaining parts of Alaska above 60 degrees northern latitude. Since more than one DEM may be available in legacy processing, DEMs are selected in priority order as listed in Table 1. DEM coverage of at least 20% from a single DEM source is required for legacy processing to proceed. In no case will the DEM selected be from more than one source; only the single best source of terrain height values is used for a given scene. Figure 4 shows the coverage of the various legacy DEM sources. Figure 4: Coverage of the various legacy DEM sources used for terrain correction","title":"Legacy DEMs"},{"location":"guides/rtc_product_guide/#pixel-spacing","text":"On Demand Sentinel-1 RTC now available at 10-m and 20-m pixel spacing There are now three pixel spacing options available for On Demand Sentinel-1 RTC products. Users can choose to output the RTC products at a pixel spacing of 30, 20, or 10 meters. RTC products can be output at 30-meter, 20-meter, or 10-meter pixel spacing. In most cases, the input SAR image has a resolution closer to the 10-m products, while the Copernicus DEM (used by default for RTC processing) has a pixel spacing of 30 m. The 10-m RTC product will be closer to the resolution of the source SAR granule, but the 30-m RTC product has a much smaller file size. Figure 5: Comparison of RTC products generated with different pixel spacing settings It is much faster to process, download and analyze 30-m RTC products than 10-m products, so it's a good idea to start with the coarser resolution option if possible. If the 30-m pixel spacing is not sufficient for your use case, try the 20-m RTC products. If even more detail is required, the 10-m products may be the best option. The 20-m product may be a good trade-off between resolution and file size. The amount of detail in the 20-m product is much closer to the 10-m product, but the file size is much closer to the 30-m product. Consider the file sizes for the RTC VV GeoTIFFs displayed in the comparison image: Pixel Spacing File Size 30 m 267 MB 20 m 600 MB 10 m 2350 MB","title":"Pixel Spacing"},{"location":"guides/rtc_product_guide/#dem-resolution","text":"Keep in mind that the same DEM is used for processing the RTC products, regardless of the output pixel spacing. By default, the DEM is the Copernicus Global DEM, which has a pixel spacing of 30 meters. When processing 10-m RTC products, the source DEM is resampled to a pixel spacing of 10 meters. This resampled DEM can optionally be included in the product package, and the pixel spacing will align with the output RTC product. The same is true for the 20-m products; the DEM is resampled to a pixel spacing of 20 meters, and the resampled version is optionally included in the product package. The pixel spacing of the output DEM file does not indicate that the source DEM used for the 10-m or 20-m products is of higher resolution.","title":"DEM Resolution"},{"location":"guides/rtc_product_guide/#processing-options-and-optional-files","text":"There are a number of options users can set when ordering RTC On Demand products. Some of these options set parameters used in the RTC processing workflow, others allow users to add additional files to the product package that are not included by default. Table 2 lists all of the options as displayed in the Vertex user interface and the HyP3 API, and the Processing Options and Optional Files sections provide more information about each option. Option Name in Vertex Option Name in HyP3 API/SDK Possible Values Default Description Radiometry radiometry (gamma0, sigma0) gamma0 Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) Scale scale (power, decibel, amplitude) power Scale of output backscatter values Pixel Spacing resolution (10.0, 20.0, 30.0) 30.0 Product pixel spacing in meters DEM Name dem_name (copernicus, legacy) copernicus Name of the DEM to use for processing: copernicus will use the Copernicus GLO-30 Public DEM, legacy will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets Apply DEM Matching dem_matching (true, false) false Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files Apply Speckle Filter speckle_filter (true, false) false Apply an Enhanced Lee speckle filter Include DEM include_dem (true, false) false Include a copy of the DEM used for RTC processing in the product package Include Incidence Angle Map include_inc_map (true, false) false Include the local incidence angle map in the product package Include Scattering Area Map include_scattering_area (true, false) false Include the scattering area map in the product package Include RGB Decomposition include_rgb (true, false) false Include a false-color RGB decomposition GeoTIFF in the product package Table 2: Processing Options","title":"Processing Options and Optional Files"},{"location":"guides/rtc_product_guide/#processing-options","text":"","title":"Processing Options"},{"location":"guides/rtc_product_guide/#radiometry","text":"The radiometry option allows users to set their preferred backscatter coefficient normalization to either gamma-nought (gamma0 or \u03b3 0 ) or sigma-nought (sigma0 or \u03c3 0 ) radiometry. As illustrated in Figure 6, the scattering coefficient gamma0 is normalized by the illuminated area projected into the look direction (A \u03b3 - the yellow area with the red outline in the diagram), and the sigma0 is normalized by the ground area (A \u03c3 - the grey area with the purple outline in the diagram). Figure 6: Normalization areas for SAR backscatter, from David Small, 2011, Flattening Gamma: Radiometric Terrain Correction for SAR Imagery, IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 49, NO. 8, AUGUST 2011 Although both sigma0 and gamma0 backscatter include the impact of local topography, the sensitivity of the impact is different. For applications where topographic impacts are an important consideration, gamma0 is generally the preferred choice.","title":"Radiometry"},{"location":"guides/rtc_product_guide/#scale","text":"The scale option allows users to choose the scale of the output backscatter images from the three commonly used scales for calibrated SAR values: power, amplitude, or decibel (dB). Refer to the SAR Scale section for more information.","title":"Scale"},{"location":"guides/rtc_product_guide/#pixel-spacing_1","text":"The resolution parameter sets the pixel spacing of the output images. Users have the option to set a pixel spacing of 30, 20, or 10 meters. The 30-m product has a much smaller file size, and is easier to work with for large areas of interest. It generally aligns with the native resolution of the DEM used for RTC processing. The 10-m product provides much more detail of surface features, and is closer to the native resolution of the source Sentinel-1 data. The file sizes are also much larger than those of the 30-m products. The 20-m product may be a good compromise between the native resolution of the source SAR imagery and the source DEM. The level of detail in the image is much closer to the 10-m product than the 30-m product, while the file size is much closer to the 30-m product than the 10-m product. Refer to the Pixel Spacing section for more information. Note that the source Sentinel-1 imagery and the source DEM used for RTC processing are the same regardless of the option selected for the output pixel spacing.","title":"Pixel Spacing"},{"location":"guides/rtc_product_guide/#dem-name","text":"The dem_name parameter selects the DEM to use for RTC processing. By default, we use the Copernicus Global 30-m DEM , but allow users to select ASF's legacy DEMs (a combination of NED and SRTM) if desired. We recommend using the Copernicus DEM, which has more extensive and consistent coverage and more recent measurements. The main reason to select the legacy option is if a user already has a time series of products generated with the legacy DEM and wants to process new acquisitions using the same DEM. Refer to the Digital Elevation Models section for more information.","title":"DEM Name"},{"location":"guides/rtc_product_guide/#dem-matching","text":"The dem_matching option allows users to either try to coregister the SAR image to the DEM file, or simply use the Sentinel-1 orbit files for geocoding the RTC products. The process of terrain corrected geocoding includes 4 steps: Calculate the initial lookup table and simulated image with the image processing parameters and DEM. (Optional) Measure initial offset between simulated SAR image and actual SAR image. (Optional) Perform refinement of lookup table by offset measurement with respect to the simulated SAR image. Produce terrain geocoded SAR image and DEM in SAR range-Doppler coordinates (RDC). When DEM matching is applied, the optional steps 2 and 3 are performed. Using this option can improve the quality of the RTC calculations, as the features in the SAR image are matched to the features in the DEM, minimizing the offsets in geometry during the backscatter normalization calculations. Refer to the Terrain Correction section for more information. DEM Matching is not always beneficial, however. If the georeferencing of the DEM doesn't match the georeferencing of the Sentinel-1 imagery, DEM matching can result in variable offsets in the output images from one Sentinel-1 acquisition to the next, making it difficult to overlay images for time series analysis. Coregistration also works best when there are distinct topographic features that allow for reliable matching between the SAR image and the DEM. In areas that lack distinctive topographic features, there may also be substantial and inconsistent image offsets. The orbit files of the Sentinel-1 data are generally quite accurate, and not applying the DEM matching should output files with consistent geolocation. While it may not optimize the RTC calculations, it may be a better option for time series analysis, where having consistent alignment of images from one acquisition to the next is more important than optimizing the backscatter normalization. If you are interested in optimizing the RTC calculations, and are less concerned about consistent geolocation through time, the DEM Matching option is likely a good choice. In cases where consistency is more important than accuracy, consider not applying DEM Matching, or at least testing the outputs to make sure they are suitable for your application.","title":"DEM Matching"},{"location":"guides/rtc_product_guide/#speckle-filter","text":"When the speckle_filter option is selected, an Enhanced Lee filter is applied during RTC processing to remove speckle while preserving edges of features. Speckle occurs due to interference among signal waves, as they interact with different scatterers on the surface of the earth and return to the sensor. It appears as granular noise in the image. Refer to the Speckle section of our Introduction to SAR document for more information. When applied, the filter is set to a dampening factor of 1, with a box size of 7x7 pixels. The number of looks depends on the multilooking treatment for the RTC processing, and is based on the pixel spacing and the input scene type. Refer to the readme file included with the RTC product to determine the number of looks used for the filter, which is the number of looks taken for RTC processing multiplied by 30. Applying a speckle filter can smooth the appearance of the image, but it comes at a cost to the resolution of the output RTC product. Keep in mind also that there are other speckle filters that may be better suited to a specific application. We do not currently offer any customization of the type of speckle filter used, or the parameters (window size, multilooking, dampening, etc.) used for the filter. You may also want to try applying other spatial speckle filters with custom settings, which can be accomplished programmatically or using GIS software. Some temporal analyses may also mitigate the impacts of speckle, such as calculating the median or mean pixel values of multiple images collected over a period of time. In both cases, it may be better not to apply a speckle filter during RTC processing. If you are unsure whether to apply this option, try generating some of your RTC products with and without the speckle filter applied, and check to see which product works best for your particular application.","title":"Speckle Filter"},{"location":"guides/rtc_product_guide/#optional-files","text":"In addition to the processing options, users can choose to add a number of ancillary files to the product package. These files are not included by default, as they increase the size of the product package and may not be of interest to all users. In Vertex, check the box in the \"Include\" section of the options to add these optional files to the product package. When using the HyP3 API or SDK, set the parameter to true.","title":"Optional Files"},{"location":"guides/rtc_product_guide/#dem","text":"Set the include_dem parameter to true to include a copy of the DEM file used for RTC processing. This DEM is not generated from the Sentinel-1 data, but is the reference DEM used for the RTC calculations. Pixel values indicate the elevation in meters. Refer to the Digital Elevation Models section for more information on the DEMs we use for RTC processing. This DEM file is intended as a quick reference to aid in interpretation of the RTC image, and should not be used as a stand-alone DEM product. The DEM used for RTC processing has a geoid correction applied before it is used for RTC, so elevation values in this file will differ from the source DEM. The DEM is resampled to match the pixel spacing of the output product, so the pixel spacing of this file is not a reflection of the resolution of the source DEM. Refer to the readme file included in the RTC product package for details on the pixel spacing of the included DEM file.","title":"DEM"},{"location":"guides/rtc_product_guide/#incidence-angle-map","text":"Set the include_inc_map parameter to true to include the local incidence angle map in the product package. The cell values in this raster indicate the angle between the incident radar beam and the direction perpendicular to the ground surface, expressed in radians.","title":"Incidence Angle Map"},{"location":"guides/rtc_product_guide/#scattering-area-map","text":"Set the include_scattering_area parameter to true to include the scattering area map in the product package. This map expresses the scattering area for each pixel in the RTC image in square meters. The values are calculated based on the effectively illuminated gamma-0 terrain surface using a digital elevation model, the local incidence angle map, and the layover-shadow map. This layer can be used to generate composites using the Local Resolution Weighting method, as described in the article Wide-Area Analysis-Ready Radar Backscatter Composites by David Small et al., 2022.","title":"Scattering Area Map"},{"location":"guides/rtc_product_guide/#rgb-decomposition","text":"Set the include_rgb parameter to true to include a full-resolution GeoTIFF of a false-color RGB Decomposition of the co- and cross-polarized RTC values. A low-resolution false-color browse image in PNG format is included in the product package by default, but selecting this option includes the RGB Decomposition image as a GeoTIFF with the same pixel spacing as the RTC images. This option is only available for dual-polarization products, as it uses both the co- and cross-polarized RTC values to determine the RGB values. A full description of the approach ASF uses for generating RGB Decomposition products is available here . In general, blue indicates areas with low backscatter in both co- and cross-polarizations (calm water, dry sand, frozen ground), green indicates high cross-pol values (vegetation or other volume scatterers), and red indicates areas with low cross-pol but relatively high co-pol values (urban areas or sparsely vegetated landscapes).","title":"RGB Decomposition"},{"location":"guides/rtc_product_guide/#radiometric-terrain-correction-workflow","text":"","title":"Radiometric Terrain Correction Workflow"},{"location":"guides/rtc_product_guide/#pre-processing","text":"The first step of pre-processing is the selection of the best DEM for the terrain correction. The DEM tiles are assembled to ensure sufficient coverage for the terrain correction of the Sentinel-1 granule. The application of the calibration parameters and multi-looking are the only pre-processing steps applied to the SAR image.","title":"Pre-processing"},{"location":"guides/rtc_product_guide/#terrain-correction","text":"The terrain correction is performed in slant range geometry. A look-up table is created to map between DEM space and SAR space. The actual mapping of the initial image into projected space is only applied once to mitigate the propagation of any resampling errors. All intermediate steps only update the look-up table used for the mapping. By default, images are not coregistered to the DEM. While RTC results can be improved by matching imagery to a high-quality DEM, different acquisitions over the same area may not always be matched to the DEM in the same way, due in part to the presence of speckle. This can introduce spatial inconsistencies to the dataset, especially when viewing a time-series of RTC images. For consistency, we use the geolocation from the Sentinel-1 state vectors by default rather than matching the geolocation based on DEM features. When ordering products On Demand, the DEM Matching option is available for selection. When this option is applied, the first step is the co-registration of the SAR image with a simulated SAR image derived from the DEM. An initial offset is first attempted as a single match; if it fails, a larger number of image chips are used to determine an average offset in azimuth and range direction. This initial offset is then refined using strict matching criteria. Matching may fail for three different reasons: (1) no match can be found, (2) the magnitude of the residual offset errors is greater than 2 pixels, or (3) the maximum calculated offset is greater than 50 m. In any of these cases, the dead reckoning approach is taken when matching fails. This approach solely relies on the geolocations calculated from state vectors (the same approach used when DEM matching is not selected as an option) - no geolocation refinement is applied.","title":"Terrain Correction"},{"location":"guides/rtc_product_guide/#radiometric-correction","text":"During processing, a surface scattering area image for the scene is calculated and saved. This projected area image is used to create the RTC product - the SAR image is multiplied by the ratio of an ellipsoidal scattering image (used during calibration) and this scattering area image. Note that this image is always projected to gamma-nought (\u03b3 0 ).","title":"Radiometric Correction"},{"location":"guides/rtc_product_guide/#geocoding","text":"In a final step, the RTC product is geocoded into map-projected space. Thus, radiometric terrain correction results in a geocoded radiometrically calibrated multi-looked image with gamma-nought (\u03b3 0 ) power scale values by default, though there are options to process to sigma-nought (\u03c3 0 ) radiometry and amplitude or decibel (dB) scale .","title":"Geocoding"},{"location":"guides/rtc_product_guide/#post-processing","text":"After the terrain correction is completed, the RTC products are exported to GeoTIFF format. If the scene being processed is dual polarization, users have the option to add a full-resolution RGB Decomposition GeoTIFF to the RTC product package. Side products including the DEM , layover-shadow map (always included), scattering area map , and incidence angle map are converted into GeoTIFF format. In addition, a README text file, browse images, item-specific ArcGIS-compatible XML metadata files, a log file, and a shapefile indicating the data extent are generated for the product.","title":"Post-Processing"},{"location":"guides/rtc_product_guide/#product-packaging","text":"","title":"Product Packaging"},{"location":"guides/rtc_product_guide/#naming-convention","text":"The naming convention for the RTC products follows this pattern for its base names: S1x_yy_aaaaaaaaTbbbbbb_ppo_RTCzz_u_defklm_ssss Example: S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A Element Definition Example x Mission: A or B A yy Beam Mode IW aaaaaaaa Start Year-Month-Day 20180128 bbbbbb Start Hour-Minute-Second 161201 pp Polarization: Dual-pol (D) vs. Single-pol (S), Primary Polarization (H or V) DV o Orbit Type: Precise (P), Restituted (R), or Original Predicted (O) P zz Terrain Correction Pixel Spacing (m) 30 u Software Package Used: GAMMA (G) G d Gamma-0 (g) or Sigma-0 (s) Output g e Power (p), Decibel (d), or Amplitude (a) Output p f Unmasked (u) or Water Masked (w) u k Not Filtered (n) or Filtered (f) n l Entire Area (e) or Clipped Area (c) e m Dead Reckoning (d) or DEM Matching (m) d ssss Product ID FD6A Table 3: Naming convention for RTC products","title":"Naming Convention"},{"location":"guides/rtc_product_guide/#image-files","text":"All files are stored in a folder named using the above convention, and the base name for each file matches the folder name. Multiple types of image files are present in this folder, and some of the files are optional. Users can choose to include the RGB Decomposition GeoTIFF, scattering area map, DEM, and incidence angle map rasters when ordering On-Demand RTC products. Extension Description Example _VV.tif, _VH.tif, _HH.tif, _HV.tif Terrain corrected product stored in separate files for each available polarization in GeoTIFF format S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_VV.tif .png Grayscale browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.png _rgb.png Color browse image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.png .kmz Zipped Google Earth image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A.kmz _rgb.kmz Zipped Google Earth color image S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.kmz _rgb.tif Color decomposition in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_rgb.tif _area.tif Scattering area map in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_area.tif _dem.tif DEM used for terrain correction in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_dem.tif _inc_map.tif Incidence angle file in GeoTIFF format (optional) S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_inc_map.tif _ls_map.tif Layover/shadow mask in GeoTIFF format S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_ls_map.tif Table 4: Image files in product package The RTC products (one for each available polarization) are generated as 32-bit floating-point single-band GeoTIFF files, as are the incidence angle and scattering area maps. The RGB Decomposition is a 3-band unsigned 8-bit GeoTIFF file, the layover/shadow mask is a single-band unsigned 8-bit GeoTIFF, and the DEM is a 16-bit signed integer GeoTIFF. The browse images (both grayscale and color) are generated in PNG format, and are each 2048 pixels wide. Finally, KMZ files suitable for viewing in Google Earth are included. Note that colorized products (RGB Decomposition GeoTIFF or color browse PNG) can only be created for dual-polarization (SDV and SDH) granules, not for single-polarization (SSV or SSH).","title":"Image Files"},{"location":"guides/rtc_product_guide/#metadata-files","text":"The product package also includes a number of metadata files. Extension Description Example .README.md.txt README file S1A _IW _20180128T161201 _DVP _RTC30 _G _gpuned _FD6A.README.md.txt .log Log file of the processing steps S1A _IW _20180128T161201 _DVP _RTC30 _G _gpuned _FD6A.log .tif.xml ArcGIS compliant XML metadata for GeoTIFF files S1A _IW _20180128T161201 _DVP _RTC30 _G _gpuned _FD6A _VV.tif.xml .png.xml ArcGIS compliant XML metadata for PNG files S1A _IW _20180128T161201 _DVP _RTC30 _G _gpuned _FD6A.png.xml .png.aux.xml Geolocation metadata for PNG browse images S1A _IW _20180128T161201 _DVP _RTC30 _G _gpuned _FD6A.png.aux.xml Table 5: Metadata files and their extensions","title":"Metadata Files"},{"location":"guides/rtc_product_guide/#readme-file","text":"The text file with extension .README.md.txt explains the files included in the folder, and is customized to reflect that particular product. Users unfamiliar with RTC products should start by reading this README file, which will give some background on each of the files included in the product folder.","title":"README File"},{"location":"guides/rtc_product_guide/#arcgis-compatible-xml-files","text":"There is an ArcGIS-compatible XML file for each raster in the product folder. When ArcGIS Desktop users view any of the rasters in ArcCatalog or the Catalog window in ArcMap, they can open the Item Description to view the contents of the associated XML file. ArcGIS Pro users can access the information from the Metadata tab. These files will not appear as separate items in ArcCatalog, though if you use Windows Explorer to look at the contents of the folder you will see them listed individually. Because each one is named identically to the product it describes (with the addition of the .xml extension), ArcGIS recognizes the appropriate file as the raster\u2019s associated metadata, and integrates the metadata accordingly. ArcGIS users should take care not to change these XML files outside of the ArcGIS environment; changing the filename or content directly may render the files unreadable by ArcGIS. Those not using ArcGIS will still find the contents of these XML files useful, but will have to contend with the XML tagging when viewing the files as text or in a browser.","title":"ArcGIS-Compatible XML Files"},{"location":"guides/rtc_product_guide/#auxiliary-geolocation-files","text":"Geolocation XML files (aux files) are included for each of the PNG browse images to allow for proper display in GIS platforms.","title":"Auxiliary Geolocation Files"},{"location":"guides/rtc_product_guide/#log-file","text":"A log file detailing the processing parameters and outputs is also included for reference.","title":"Log File"},{"location":"guides/rtc_product_guide/#shapefile","text":"A shapefile indicating the extent of the RTC data coverage is included in the package. Extension Description Example _shape.dbf _shape.prj _shape.shp _shape.shx Shapefile (.shp) and supporting files S1A_IW_20180128T161201_DVP_RTC30_G_gpuned_FD6A_shape.shp Table 6: Shapefile files and their extensions","title":"Shapefile"},{"location":"guides/rtc_product_guide/#sar-scales","text":"On Demand Sentinel-1 RTC Products now available in dB scale Users can now choose to output Sentinel-1 RTC products in decibel (dB) scale. Previously, the only choices for output scale were power and amplitude. The default scale continues to be power.","title":"SAR Scales"},{"location":"guides/rtc_product_guide/#power-scale","text":"Note that the default output of Sentinel-1 RTC products from HyP3 is in power scale. The values in this scale are generally very close to zero, so the dynamic range of the RTC image can be easily skewed by a few bright scatterers in the image. Power scale is appropriate for statistical analysis of the RTC dataset, but may not always be the best option for data visualization. When viewing an RTC image in power scale in a GIS environment, it may appear mostly or all black, and you may need to adjust the stretch to see features in the image. Often applying a stretch of 2 standard deviations, or setting the Min-Max stretch values to 0 and 0.3, will greatly improve the appearance of the image. You can adjust the stretch as desired to display your image to full advantage. Be aware that this does not change the actual pixel values. In some cases, it may be desirable to convert the actual pixel values to a different scale. Two other scales commonly used for SAR data are amplitude and decibel (dB).","title":"Power Scale"},{"location":"guides/rtc_product_guide/#amplitude-scale","text":"Values in the amplitude scale are the square root of the power scale values. This brightens the darker pixels (values <1) and darkens the brighter pixels (values >1), narrowing the dynamic range of the image. In many cases, amplitude scale presents a pleasing grayscale display of RTC images. Amplitude scale works well for calculating log difference ratios, as described in the Change Detection Using RTC Data use case example.","title":"Amplitude Scale"},{"location":"guides/rtc_product_guide/#decibel-db-scale","text":"The decibel (dB) scale is calculated by multiplying 10 times the Log10 of the power scale values. This scale allows for better differentiation among very dark pixels. This is often a good scale to use for identifying water on the landscape; the water pixels generally remain very dark compared to the much brighter pixels of the surrounding landscape. Refer to the Identifying Surface Water use case example for more information. This scale is not always the best choice for general visualization of RTC products, as it can give a washed-out appearance to terrain features. In addition, because it is a logarithmic scale, dB pixel values are not appropriate for some types of statistical analyses.","title":"Decibel (dB) Scale"},{"location":"guides/rtc_product_guide/#rtc-use-examples","text":"The RTC products are presented as Cloud-Optimized GeoTIFFs (COGs), a user-friendly format that is compatible with GIS software. The products include pre-generated overviews, so users will not need to generate pyramids to display the images efficiently in a GIS or web-mapping environment. The following sections present examples of how one might use RTC datasets to identify areas of change and integrate RTC datasets into other datasets for enhanced results. We also present a bibliography of some of the scientific literature making use of Sentinel-1 RTC datasets.","title":"RTC Use Examples"},{"location":"guides/rtc_product_guide/#change-detection-using-rtc-data","text":"There are a number of ways that SAR data sets can be used to identify areas of change. Here are two examples of what you can do in a GIS environment.","title":"Change Detection Using RTC Data"},{"location":"guides/rtc_product_guide/#seasonal-change","text":"Stacking RTC images into a multiband image (Figure 7) allows the user to display different times of the year at the same time, using the color bands to highlight areas that differ in radar backscatter values from one month to the next. To generate this type of image, choose three images that capture different seasons or months of interest. These can either be individual RTC images from different times of the year, or rasters displaying the monthly median calculated from multiple RTC images collected in the same month. Combine the three images into a multiband raster and assign each to a different color band. The resulting RGB image highlights areas where there are distinctive differences among the three source image values. Figure 7: Monthly median VH gamma-0 power values for May, July and September, displayed as a multiband RGB (May, July, Sept) image. Contains modified Copernicus Sentinel data 2017, processed by ESA.","title":"Seasonal Change"},{"location":"guides/rtc_product_guide/#quantifying-change-over-time","text":"A simple and informative approach to change detection is the calculation of the log difference between two RTC datasets from different dates. By calculating Log10(date2/date1) and applying a classified symbology, it is easy to identify areas where change occurred, as well as the direction of the change. Negative values indicate a decrease in radar backscatter over time, while positive values indicate an increase in backscatter. In the example below (Figure 8), RTC images from before and after heavy rains caused a dam breach. The area where the reservoir was located displays a significant increase in backscatter (symbolized in red). This positive change is driven by land that was once covered by standing water, which generally has very low backscatter, now being exposed saturated soil, which generally returns very high backscatter values. In surrounding areas, decreases in radar backscatter (symbolized by blue) are possibly the result of agricultural fields undergoing desiccation/hardening of the surface soil following the heavy rainfall and standing water. Areas with little change in backscatter are displayed in yellow. Figure 8: Log Difference Raster with Classified Symbology. Contains modified Copernicus Sentinel data 2020, processed by ESA.","title":"Quantifying Change over Time"},{"location":"guides/rtc_product_guide/#identifying-surface-water","text":"Calm surface water has a very low radar cross section. Because freshwater has a high dielectric constant, most of the signal is reflected off the smooth surface of the water and away from the sensor, resulting in little to no backscatter. As such, surface water can often be delineated using a simple threshold value, where all pixels below the threshold are assumed to be water. It is often best to use datasets in dB scale for this process (refer to the dB Scale Section ). When using the threshold approach, surface water can be easily visualized by applying a classified symbology with two classes, using the threshold as the break point between the classes. There is no universal threshold value; it will need to be determined based on the surface water characteristics in the RTC image. When an RTC image contains significant surface water coverage, there is often a bimodal distribution of pixel values. The first peak in a histogram of the pixel values for the image can be expected to contain mostly water pixels, while the second peak contains all remaining pixels. A good first step in selecting a threshold value is to set the break point between classes at the lowest point between those two peaks, then adjust the value as needed to generate a good water mask for the image (Figure 9). Figure 9: Setting the break point to fall between the two peaks of the histogram Once you have determined the appropriate threshold (Figure 10), you can reclassify the RTC image to include only those pixels that fall below the threshold value, providing a water mask that can be used for analysis or to overlay with other imagery to show the water extent. Figure 10: Water Mask. Contains modified Copernicus Sentinel data 2020, processed by ESA.","title":"Identifying Surface Water"},{"location":"guides/rtc_product_guide/#combination-of-rtc-imagery-with-other-remote-sensing-data","text":"One of the main advantages of using RTC imagery is that it aligns geographically with other geospatial datasets. This makes it possible to combine SAR data with other remote sensing data, such as optical data. In the example below, the backscatter information of the Sentinel-1 SAR image (Figure 11) is used to enhance the spectral information of the optical Landsat 8 image (Figure 12) in the urban area of Pavia, Italy. Figure 11: Sentinel-1 RTC image. Figure 12: False color composite (bands 5, 4, 3) of a Landsat 8 image Figure 13 shows the image fusion result of an IHS transformation. In this transformation, the color channels red, green and blue (RGB) are first converted into a different color representation: intensity, hue and saturation (IHS). In the second step, the optical intensity is replaced by the SAR image values before IHS is transformed back to RGB. Figure 13: Image fusion result of SAR and optical imagery The color values for the two rivers in the SAR image are far more similar to each other than in the optical image. The vegetated areas (highlighted in red) show up more uniformly in the data fusion result than in the optical false color composite image. Image fusion uses the complementary nature of the different sources to generate an enhanced product.","title":"Combination of RTC Imagery with other Remote Sensing Data"},{"location":"guides/rtc_product_guide/#arcgis-toolbox","text":"ASF has developed a custom ArcGIS Toolbox for working with RTC datasets in either ArcGIS Desktop or ArcGIS Pro. It includes tools for converting between different SAR scales, calculating the log difference between two images, generating RGB Decomposition (false-color) products, and reclassifying a raster to generate a water mask. For more information and to download the toolbox, visit our website: https://asf.alaska.edu/how-to/data-tools/gis-tools/ .","title":"ArcGIS Toolbox"},{"location":"guides/rtc_product_guide/#application-examples-in-the-literature","text":"The following journal articles represent some of the work being done using Radiometric Terrain Corrected Sentinel-1 data sets.","title":"Application Examples in the Literature"},{"location":"guides/rtc_product_guide/#crop-monitoring","text":"Clauss, K., Ottinger M. and Kuenzer, C. 2018. Mapping rice areas with Sentinel-1 time series and superpixel segmentation. International Journal of Remote Sensing , 39 (5):1399-1420. DOI: 10.1080/01431161.2017.1404162 Nguyen, D.B., Gruber A. and Wagner, W. 2016. Mapping rice extent and cropping scheme in the Mekong Delta using Sentinel-1A data. Remote Sensing Letters , 7 (12):1209-1218. DOI: 10.1080/2150704X.2016.1225172","title":"Crop Monitoring"},{"location":"guides/rtc_product_guide/#disaster-response","text":"Markert, K.N., Chishtie, F., Anderson, E.R., Saah, D., Griffin, R.E. 2018. On the merging of optical and SAR satellite imagery for surface water mapping applications. Results In Physics , 9 :275-277. DOI: 10.1016/j.rinp.2018.02.054 Twele, A., Cao, W., Plank, S. and Martinis, S. 2016. Sentinel-1-based flood mapping: a fully automated processing chain. International Journal of Remote Sensing , 37 (13):2990-3004. DOI: 10.1080/01431161.2016.1192304","title":"Disaster Response"},{"location":"guides/rtc_product_guide/#land-classification-and-change-detection","text":"Muro, J., Canty, M., Conradsen, K., H\u00fcttich, C., Nielsen, A.A., Skriver, H., Remy, F., Strauch, A., Thonfeld, F. and Menz, G. 2016. Short-Term change detection in wetlands using Sentinel-1 time series. Remote Sensing , 8 (10):795. DOI: 10.3390/rs8100795 R\u00fcetschi, M., Schaepman, M.E., Small, D. 2018. Using Multitemporal Sentinel-1 C-band backscatter to monitor phenology and classify deciduous and coniferous forests in Northern Switzerland. Remote Sensing , 10 (1):55. DOI: 10.3390/rs10010055","title":"Land Classification and Change Detection"},{"location":"guides/rtc_product_guide/#data-access","text":"To view or download Sentinel-1 RTC products, please see the links below: Vertex: https://search.asf.alaska.edu/ API: https://asf.alaska.edu/api/ For details on accessing data, including other SAR datasets, see ASF\u2019s Get Started guide: https://asf.alaska.edu/getstarted/ To access data recipes, which are step-by-step tutorials for processing and working with SAR data, see ASF\u2019s tutorials page: https://asf.alaska.edu/how-to/data-recipes/data-recipe-tutorials/","title":"Data Access"},{"location":"tools/arcgis_toolbox/","text":"ArcGIS Toolbox \u00b6 The ASF_Tools ArcGIS Python Toolbox can be used with either ArcGIS Desktop or ArcGIS Pro, and contains tools that perform geoprocessing tasks useful for working with Synthetic Aperture Radar (SAR) data. The tools were designed to be used with Sentinel-1 Radiometric Terrain Corrected (RTC) SAR datasets , such as those available on-demand using ASF's Data Search - Vertex portal, but several of the tools have the potential to be used with a variety of rasters, including non-SAR datasets. The Toolbox is distributed as a zipped archive including the .pyt Toolbox script and associated .xml files. There is an XML file for the toolbox itself and one for each of the tools it contains. These XML files contain the metadata displayed in the item descriptions and tool help windows in ArcGIS, and must be kept in the same directory as the Python Toolbox (.pyt) file, or the information they contain will no longer be accessible. Toolbox Contents \u00b6 Unzip Files Tool \u00b6 This tool assists in file management when downloading .zip files from ASF. It could be used to extract to a specified location any zip files with an additional internal directory containing the individual files. The tool deletes the original zip files once they are extracted, and is especially helpful when dealing with file paths that are so long that they are beyond the maximum allowed in default Windows unzip utilities. Scale Conversion Tool \u00b6 This tool converts pixel values in calibrated SAR datasets (such as RTC rasters) from power or amplitude scale into power, amplitude or dB scale. This is an application specific to SAR data values/scales. Reclassify RTC Tool \u00b6 This tool generates a raster that includes only those pixels below a user-defined threshold value, and is designed for isolating water pixels. While intended for RTC files in dB scale, this tool could be used for any application where the user is interested in generating a spatial mask for values below a given threshold in a single-band raster. Log Difference Tool \u00b6 This tool compares two rasters by calculating the log difference on a pixel-by-pixel basis to identify areas where backscatter values have changed over time. While intended for RTC files in amplitude scale, this tool could be used to compare the pixel values of any two single-band rasters, as long as there are no negative values (NoData values will be returned for pixels with a negative number in either of the datasets). RGB Decomposition Tool \u00b6 This tool generates an RGB image using the co- and cross-polarized datasets from an RTC product. Input datasets can be in either amplitude or power scale, and the primary polarization can be either vertical (VV/VH) or horizontal (HH/HV). Additional documentation is available regarding the calculations used and the interpretation of these false-color images. Prerequisites \u00b6 Users must have either ArcGIS Desktop (ArcMap) or ArcGIS Pro installed and licensed on their computer. The Toolbox has been tested with Desktop versions 10.6.1 and 10.7.1 and Pro versions 2.4.2, 2.5.x and 2.6.1, but it may work with earlier versions as well. Note that several of the tools require the Spatial Analyst extension. Users who do not have licensing for this extension in ArcGIS will not be able to use many of the included tools. To install the Toolbox \u00b6 Download the zip file and extract the contents to any directory accessible by the computer running ArcGIS. Ensure that the Spatial Analyst extension is licensed and enabled. ArcGIS Desktop (ArcMap) \u00b6 Click on the Customize menu in ArcMap and select Extensions\u2026 Check the box next to Spatial Analyst and click the Close button at the bottom of the Extensions window. If you are unable to check this box, you do not have access to the Spatial Analyst extension and will not be able to make use of tools requiring this extension. ArcGIS Pro \u00b6 Click on the Project tab and select the Licensing tab. In the list of Esri Extensions, scroll down to verify that the Spatial Analyst is licensed and enabled. If it is not, an organization administrator will need to enable the extension in your user account. If your organization does not have a license available for you to use, you will not be able to make use of tools requiring this extension. Using the Toolbox \u00b6 In the ArcMap Catalog window or the ArcGIS Pro Catalog pane/view, navigate to the directory containing the toolbox (create a new folder connection if necessary). - To open the Catalog window in ArcMap, click on the Windows menu and select Catalog. - To open the Catalog pane or view in ArcGIS Pro, click the View tab and click on either the Catalog Pane or Catalog View button. Note that if you explore the extracted contents of the zip file outside of the ArcGIS environment, the directory will contain one .pyt file and a number of .xml files. In the ArcGIS Catalog window/pane/view, only the Toolbox is displayed, and when it is expanded, all of the Tools contained in the Toolbox script are displayed. The XML files are automatically referenced when ArcGIS requires the information they contain, and do not appear as additional files in the ArcGIS Catalog environment. The XML files must remain in the same directory as the .pyt file, and their filenames should not be changed. Double-click the ASF_Tools.pyt file to display the Tools (Scripts) included in the toolbox. Double-click on a Tool (displayed with a Script icon) to launch the dialog box or geoprocessing pane, as you would for any other ArcGIS Tool/Script. Enter the parameters as prompted and click the OK button to execute the tool. Note that output products are not automatically added to a project by default. You must navigate to them in the Catalog window/pane/view (or using the Add Data dialog) and add them to your project if desired. Tool Help \u00b6 The XML files included in the zip file are accessed when a user views the metadata for the toolbox, individual tools, or even different fields within the tool dialog. Accessing Help from within the Tool Dialog Box \u00b6 ArcGIS Desktop \u00b6 Click on the Show Help button at the bottom of the tool window to open the help panel. This panel will display information about the tool in general if no field is activated. If the user clicks on any of the parameter fields, information specific to that parameter will be displayed. Click on the Tool Help button at the bottom of the Help pane to open another window that displays most of the information that would be displayed in the tool\u2019s Item Description. ArcGIS Pro \u00b6 When you hover over any of the parameter fields in the tool dialog, a blue i appears. Hover over or click the blue i icon to view helpful tips specific to that parameter. Hover over the blue question mark at the top of the geoprocessing pane to display information about the tool. Click on it to open the full tool description in a browser window. Accessing Help from the Catalog Interface \u00b6 ArcGIS Desktop \u00b6 ArcCatalog displays the information contained in the xml metadata files in the Description tab for the toolbox and each tool. In the ArcMap Catalog window, the Item Description for the toolbox or any of its constituent tools displays the xml content. - Right-click the toolbox or tool in the Catalog window and select Item Description to view the information. ArcGIS Pro \u00b6 The xml metadata is displayed in the Metadata tab in the Catalog view. - Right-click a tool in the Catalog pane and select View Metadata to open the Metadata tab for the item in the Catalog view. OR - Open the Catalog View directly to navigate to the tool and select the Metadata tab.","title":"ArcGIS Toolbox"},{"location":"tools/arcgis_toolbox/#arcgis-toolbox","text":"The ASF_Tools ArcGIS Python Toolbox can be used with either ArcGIS Desktop or ArcGIS Pro, and contains tools that perform geoprocessing tasks useful for working with Synthetic Aperture Radar (SAR) data. The tools were designed to be used with Sentinel-1 Radiometric Terrain Corrected (RTC) SAR datasets , such as those available on-demand using ASF's Data Search - Vertex portal, but several of the tools have the potential to be used with a variety of rasters, including non-SAR datasets. The Toolbox is distributed as a zipped archive including the .pyt Toolbox script and associated .xml files. There is an XML file for the toolbox itself and one for each of the tools it contains. These XML files contain the metadata displayed in the item descriptions and tool help windows in ArcGIS, and must be kept in the same directory as the Python Toolbox (.pyt) file, or the information they contain will no longer be accessible.","title":"ArcGIS Toolbox"},{"location":"tools/arcgis_toolbox/#toolbox-contents","text":"","title":"Toolbox Contents"},{"location":"tools/arcgis_toolbox/#unzip-files-tool","text":"This tool assists in file management when downloading .zip files from ASF. It could be used to extract to a specified location any zip files with an additional internal directory containing the individual files. The tool deletes the original zip files once they are extracted, and is especially helpful when dealing with file paths that are so long that they are beyond the maximum allowed in default Windows unzip utilities.","title":"Unzip Files Tool"},{"location":"tools/arcgis_toolbox/#scale-conversion-tool","text":"This tool converts pixel values in calibrated SAR datasets (such as RTC rasters) from power or amplitude scale into power, amplitude or dB scale. This is an application specific to SAR data values/scales.","title":"Scale Conversion Tool"},{"location":"tools/arcgis_toolbox/#reclassify-rtc-tool","text":"This tool generates a raster that includes only those pixels below a user-defined threshold value, and is designed for isolating water pixels. While intended for RTC files in dB scale, this tool could be used for any application where the user is interested in generating a spatial mask for values below a given threshold in a single-band raster.","title":"Reclassify RTC Tool"},{"location":"tools/arcgis_toolbox/#log-difference-tool","text":"This tool compares two rasters by calculating the log difference on a pixel-by-pixel basis to identify areas where backscatter values have changed over time. While intended for RTC files in amplitude scale, this tool could be used to compare the pixel values of any two single-band rasters, as long as there are no negative values (NoData values will be returned for pixels with a negative number in either of the datasets).","title":"Log Difference Tool"},{"location":"tools/arcgis_toolbox/#rgb-decomposition-tool","text":"This tool generates an RGB image using the co- and cross-polarized datasets from an RTC product. Input datasets can be in either amplitude or power scale, and the primary polarization can be either vertical (VV/VH) or horizontal (HH/HV). Additional documentation is available regarding the calculations used and the interpretation of these false-color images.","title":"RGB Decomposition Tool"},{"location":"tools/arcgis_toolbox/#prerequisites","text":"Users must have either ArcGIS Desktop (ArcMap) or ArcGIS Pro installed and licensed on their computer. The Toolbox has been tested with Desktop versions 10.6.1 and 10.7.1 and Pro versions 2.4.2, 2.5.x and 2.6.1, but it may work with earlier versions as well. Note that several of the tools require the Spatial Analyst extension. Users who do not have licensing for this extension in ArcGIS will not be able to use many of the included tools.","title":"Prerequisites"},{"location":"tools/arcgis_toolbox/#to-install-the-toolbox","text":"Download the zip file and extract the contents to any directory accessible by the computer running ArcGIS. Ensure that the Spatial Analyst extension is licensed and enabled.","title":"To install the Toolbox"},{"location":"tools/arcgis_toolbox/#using-the-toolbox","text":"In the ArcMap Catalog window or the ArcGIS Pro Catalog pane/view, navigate to the directory containing the toolbox (create a new folder connection if necessary). - To open the Catalog window in ArcMap, click on the Windows menu and select Catalog. - To open the Catalog pane or view in ArcGIS Pro, click the View tab and click on either the Catalog Pane or Catalog View button. Note that if you explore the extracted contents of the zip file outside of the ArcGIS environment, the directory will contain one .pyt file and a number of .xml files. In the ArcGIS Catalog window/pane/view, only the Toolbox is displayed, and when it is expanded, all of the Tools contained in the Toolbox script are displayed. The XML files are automatically referenced when ArcGIS requires the information they contain, and do not appear as additional files in the ArcGIS Catalog environment. The XML files must remain in the same directory as the .pyt file, and their filenames should not be changed. Double-click the ASF_Tools.pyt file to display the Tools (Scripts) included in the toolbox. Double-click on a Tool (displayed with a Script icon) to launch the dialog box or geoprocessing pane, as you would for any other ArcGIS Tool/Script. Enter the parameters as prompted and click the OK button to execute the tool. Note that output products are not automatically added to a project by default. You must navigate to them in the Catalog window/pane/view (or using the Add Data dialog) and add them to your project if desired.","title":"Using the Toolbox"},{"location":"tools/arcgis_toolbox/#tool-help","text":"The XML files included in the zip file are accessed when a user views the metadata for the toolbox, individual tools, or even different fields within the tool dialog.","title":"Tool Help"},{"location":"tools/arcgis_toolbox/#accessing-help-from-within-the-tool-dialog-box","text":"","title":"Accessing Help from within the Tool Dialog Box"},{"location":"tools/arcgis_toolbox/#accessing-help-from-the-catalog-interface","text":"","title":"Accessing Help from the Catalog Interface"},{"location":"tools/asf_tools/","text":"ASF Tools for Python \u00b6 asf_tools is a Python package for working with Synthetic Aperture Radar (SAR) data. It was designed for working with datasets generated by HyP3 , but several of the tools have the potential to be used with a variety of rasters, including non-SAR datasets. Install \u00b6 In order to easily manage dependencies, we recommend using dedicated project environments via Anaconda/Miniconda . It is also possible to use Python virtual environments , but installation of non-python dependencies (e.g., gdal ) can be challenging. asf_tools can be installed into a conda environment with: conda install -c conda-forge asf_tools or into a virtual environment with: python -m pip install asf_tools Running as a Docker container \u00b6 We also publish a Docker image for asf_tools , with all the dependencies pre-installed, to the GitHub Container Registry: https://github.com/ASFHyP3/asf-tools/pkgs/container/asf-tools . You can pull an image with the latest released version of asf_tools with the command: docker pull ghcr.io/asfhyp3/asf-tools:latest Or, the development version with: docker pull ghcr.io/asfhyp3/asf-tools:test And then run the container with: docker run --rm -it ghcr.io/asfhyp3/asf-tools:latest which will drop you into a bash shell inside the container with an active asf-tools conda environment. To move data between your local (host) machine and the container, you can mount a volume with: docker run --rm -it -v /path/to/data:/home/conda/data ghcr.io/asfhyp3/asf-tools:latest Quick Usage \u00b6 Local Resolution Weighted Composite \u00b6 The make_composite tool allows you to create a local-resolution-weighted composite from a set of Sentinel-1 RTC products ( D. Small, 2012 ). It is intended to be used with RTC products generated by ASF HyP3 . You will need to request RTC products using the Include Scattering Area option, then download and unzip them into an empty directory. To generate a composite of the co-polarization images, navigate to the directory containing the unzipped RTC products and run: make_composite VV-composite */*VV.tif To generate a composite of the cross-polarization images, navigate to the directory containing the unzipped RTC products and run: make_composite VH-composite */*VH.tif Usage Tip \u00b6 Because the imagery has been radiometrically terrain corrected (RTC), geometric and radiometric distortions have been removed from the files to be composited. One the strong points of LRW composites is that you combine both ascending and descending datatakes into a single product. In this manner no layover or shadow masks are required - what is shadowed on an ascending pass is visible in a descending pass and vice-versa. Thus, not only is it possible to combine ascending and descending, but it is highly encouraged. Using many datatakes from both the ascending and descending satellite passes will make the best composites possible. About Local Resolution Weighting (LRW) \u00b6 In an LRW composite, each satellite pass contributes to creating the output pixels. The amount of this contribution is scaled by the inverse of the scattering area used during terrain correction (thus the need for requesting the area map option of HyP3 RTC). The inverse of the surface scattering area, also referred to as local resolution, is multiplied by each pixel's backscatter value. The results of all of the images covering any single pixel are then summed. This total is then divided by the sum of the weights used to get the output average backscatter. Water extent mapping \u00b6 The water_map tool allows you to create a surface water extent map from a Sentinel-1 dual-pol (VV+VH) RTC product. It is intended to be used with RTC products generated by ASF HyP3 . Additionally, a HAND (height above nearest drainage) GeoTIFF that is pixel aligned to the RTC images is required, and preferably derived from the same DEM used to correct the RTC images -- the quality of the HAND used is directly tied to the quality of the output water extent map. To make a water extent map, run: water_map [OUT_RASTER] [VV_RASTER] [VH_RASTER] [HAND_RASTER] For more information and to see the options available, see: water_map --help For details on the algorithm see the asf_tools.water_map.make_water_map docstring. Flood depth mapping \u00b6 Warning: The flood depth tool is still under active development and the products created using this tool are likely to change in the future. The flood_map tool allows you to create an estimated flood depth map from the surface water extent map created by the water_map tool. Additionally, a HAND (height above nearest drainage) GeoTIFF that is pixel aligned to the surface water extent map is required. An ideal candidate is the HAND image created by the water_map tool. To make a flood depth map, run: flood_map [OUT_RASTER] [SURFACE_WATER_MAP] [HAND_RASTER] For more information and to see the options available, see: flood_map --help For details on the algorithm see the asf_tools.flood_map.make_flood_map docstring.","title":"ASF Tools for Python"},{"location":"tools/asf_tools/#asf-tools-for-python","text":"asf_tools is a Python package for working with Synthetic Aperture Radar (SAR) data. It was designed for working with datasets generated by HyP3 , but several of the tools have the potential to be used with a variety of rasters, including non-SAR datasets.","title":"ASF Tools for Python"},{"location":"tools/asf_tools/#install","text":"In order to easily manage dependencies, we recommend using dedicated project environments via Anaconda/Miniconda . It is also possible to use Python virtual environments , but installation of non-python dependencies (e.g., gdal ) can be challenging. asf_tools can be installed into a conda environment with: conda install -c conda-forge asf_tools or into a virtual environment with: python -m pip install asf_tools","title":"Install"},{"location":"tools/asf_tools/#running-as-a-docker-container","text":"We also publish a Docker image for asf_tools , with all the dependencies pre-installed, to the GitHub Container Registry: https://github.com/ASFHyP3/asf-tools/pkgs/container/asf-tools . You can pull an image with the latest released version of asf_tools with the command: docker pull ghcr.io/asfhyp3/asf-tools:latest Or, the development version with: docker pull ghcr.io/asfhyp3/asf-tools:test And then run the container with: docker run --rm -it ghcr.io/asfhyp3/asf-tools:latest which will drop you into a bash shell inside the container with an active asf-tools conda environment. To move data between your local (host) machine and the container, you can mount a volume with: docker run --rm -it -v /path/to/data:/home/conda/data ghcr.io/asfhyp3/asf-tools:latest","title":"Running as a Docker container"},{"location":"tools/asf_tools/#quick-usage","text":"","title":"Quick Usage"},{"location":"tools/asf_tools/#local-resolution-weighted-composite","text":"The make_composite tool allows you to create a local-resolution-weighted composite from a set of Sentinel-1 RTC products ( D. Small, 2012 ). It is intended to be used with RTC products generated by ASF HyP3 . You will need to request RTC products using the Include Scattering Area option, then download and unzip them into an empty directory. To generate a composite of the co-polarization images, navigate to the directory containing the unzipped RTC products and run: make_composite VV-composite */*VV.tif To generate a composite of the cross-polarization images, navigate to the directory containing the unzipped RTC products and run: make_composite VH-composite */*VH.tif","title":"Local Resolution Weighted Composite"},{"location":"tools/asf_tools/#usage-tip","text":"Because the imagery has been radiometrically terrain corrected (RTC), geometric and radiometric distortions have been removed from the files to be composited. One the strong points of LRW composites is that you combine both ascending and descending datatakes into a single product. In this manner no layover or shadow masks are required - what is shadowed on an ascending pass is visible in a descending pass and vice-versa. Thus, not only is it possible to combine ascending and descending, but it is highly encouraged. Using many datatakes from both the ascending and descending satellite passes will make the best composites possible.","title":"Usage Tip"},{"location":"tools/asf_tools/#about-local-resolution-weighting-lrw","text":"In an LRW composite, each satellite pass contributes to creating the output pixels. The amount of this contribution is scaled by the inverse of the scattering area used during terrain correction (thus the need for requesting the area map option of HyP3 RTC). The inverse of the surface scattering area, also referred to as local resolution, is multiplied by each pixel's backscatter value. The results of all of the images covering any single pixel are then summed. This total is then divided by the sum of the weights used to get the output average backscatter.","title":"About Local Resolution Weighting (LRW)"},{"location":"tools/asf_tools/#water-extent-mapping","text":"The water_map tool allows you to create a surface water extent map from a Sentinel-1 dual-pol (VV+VH) RTC product. It is intended to be used with RTC products generated by ASF HyP3 . Additionally, a HAND (height above nearest drainage) GeoTIFF that is pixel aligned to the RTC images is required, and preferably derived from the same DEM used to correct the RTC images -- the quality of the HAND used is directly tied to the quality of the output water extent map. To make a water extent map, run: water_map [OUT_RASTER] [VV_RASTER] [VH_RASTER] [HAND_RASTER] For more information and to see the options available, see: water_map --help For details on the algorithm see the asf_tools.water_map.make_water_map docstring.","title":"Water extent mapping"},{"location":"tools/asf_tools/#flood-depth-mapping","text":"Warning: The flood depth tool is still under active development and the products created using this tool are likely to change in the future. The flood_map tool allows you to create an estimated flood depth map from the surface water extent map created by the water_map tool. Additionally, a HAND (height above nearest drainage) GeoTIFF that is pixel aligned to the surface water extent map is required. An ideal candidate is the HAND image created by the water_map tool. To make a flood depth map, run: flood_map [OUT_RASTER] [SURFACE_WATER_MAP] [HAND_RASTER] For more information and to see the options available, see: flood_map --help For details on the algorithm see the asf_tools.flood_map.make_flood_map docstring.","title":"Flood depth mapping"},{"location":"tools/asf_tools_api/","text":"asf_tools v0.5.2 API Reference \u00b6 Tools developed by ASF for working with SAR data composite \u00b6 Create a local-resolution-weighted composite from Sentinel-1 RTC products. Create a local-resolution-weighted composite from a set of Sentinel-1 RTC products (D. Small, 2012). The local resolution, defined as the inverse of the local contributing (scattering) area, is used to weight each RTC products' contributions to the composite image on a pixel-by-pixel basis. The composite image is created as a Cloud Optimized GeoTIFF (COG). Additionally, a COG specifying the number of rasters contributing to each composite pixel is created. References David Small, 2012: https://doi.org/10.1109/IGARSS.2012.6350465 epsg_to_wkt ( epsg_code ) \u00b6 Get the WKT representation of a projection from its EPSG code Parameters: Name Type Description Default epsg_code int The integer EPSG code required Returns: Name Type Description wkt str The WKT representation of the projection Source code in asf_tools/composite.py 44 45 46 47 48 49 50 51 52 53 54 55 def epsg_to_wkt ( epsg_code : int ) -> str : \"\"\"Get the WKT representation of a projection from its EPSG code Args: epsg_code: The integer EPSG code Returns: wkt: The WKT representation of the projection \"\"\" srs = osr . SpatialReference () srs . ImportFromEPSG ( epsg_code ) return srs . ExportToWkt () get_area_raster ( raster ) \u00b6 Determine the path of the area raster for a given backscatter raster based on naming conventions for HyP3 RTC products Parameters: Name Type Description Default raster str path of the backscatter raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_VV.tif required Returns: Name Type Description area_raster str path of the area raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_area.tif Source code in asf_tools/composite.py 86 87 88 89 90 91 92 93 94 95 96 def get_area_raster ( raster : str ) -> str : \"\"\"Determine the path of the area raster for a given backscatter raster based on naming conventions for HyP3 RTC products Args: raster: path of the backscatter raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_VV.tif Returns: area_raster: path of the area raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_area.tif \"\"\" return '_' . join ( raster . split ( '_' )[: - 1 ] + [ 'area.tif' ]) get_epsg_code ( info ) \u00b6 Get the EPSG code from a GDAL Info dictionary Parameters: Name Type Description Default info dict The dictionary returned by a gdal.Info call required Returns: Name Type Description epsg_code int The integer EPSG code Source code in asf_tools/composite.py 30 31 32 33 34 35 36 37 38 39 40 41 def get_epsg_code ( info : dict ) -> int : \"\"\"Get the EPSG code from a GDAL Info dictionary Args: info: The dictionary returned by a gdal.Info call Returns: epsg_code: The integer EPSG code \"\"\" proj = osr . SpatialReference ( info [ 'coordinateSystem' ][ 'wkt' ]) epsg_code = int ( proj . GetAttrValue ( 'AUTHORITY' , 1 )) return epsg_code get_full_extent ( raster_info ) \u00b6 Determine the corner coordinates and geotransform for the full extent of a set of rasters Parameters: Name Type Description Default raster_info dict A dictionary of gdal.Info results for the set of rasters required Returns: Name Type Description upper_left The upper left corner of the extent as a tuple upper_right The lower right corner of the extent as a tuple geotransform The geotransform of the extent as a list Source code in asf_tools/composite.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def get_full_extent ( raster_info : dict ): \"\"\"Determine the corner coordinates and geotransform for the full extent of a set of rasters Args: raster_info: A dictionary of gdal.Info results for the set of rasters Returns: upper_left: The upper left corner of the extent as a tuple upper_right: The lower right corner of the extent as a tuple geotransform: The geotransform of the extent as a list \"\"\" upper_left_corners = [ info [ 'cornerCoordinates' ][ 'upperLeft' ] for info in raster_info . values ()] lower_right_corners = [ info [ 'cornerCoordinates' ][ 'lowerRight' ] for info in raster_info . values ()] ulx = min ([ ul [ 0 ] for ul in upper_left_corners ]) uly = max ([ ul [ 1 ] for ul in upper_left_corners ]) lrx = max ([ lr [ 0 ] for lr in lower_right_corners ]) lry = min ([ lr [ 1 ] for lr in lower_right_corners ]) log . debug ( f 'Full extent raster upper left: ( { ulx , uly } ); lower right: ( { lrx , lry } )' ) trans = [] for info in raster_info . values (): # Only need info from any one raster trans = info [ 'geoTransform' ] break trans [ 0 ] = ulx trans [ 3 ] = uly return ( ulx , uly ), ( lrx , lry ), trans get_target_epsg_code ( codes ) \u00b6 Determine the target UTM EPSG projection for the output composite Parameters: Name Type Description Default codes List [ int ] List of UTM EPSG codes required Returns: Name Type Description target int UTM EPSG code Source code in asf_tools/composite.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def get_target_epsg_code ( codes : List [ int ]) -> int : \"\"\"Determine the target UTM EPSG projection for the output composite Args: codes: List of UTM EPSG codes Returns: target: UTM EPSG code \"\"\" # use median east/west UTM zone of all files, regardless of hemisphere # UTM EPSG codes for each hemisphere will look like: # North: 326XX # South: 327XX valid_codes = list ( range ( 32601 , 32661 )) + list ( range ( 32701 , 32761 )) if bad_codes := set ( codes ) - set ( valid_codes ): raise ValueError ( f 'Non UTM EPSG code encountered: { bad_codes } ' ) hemispheres = [ c // 100 * 100 for c in codes ] # if even modes, choose lowest (North) target_hemisphere = min ( multimode ( hemispheres )) zones = sorted ([ c % 100 for c in codes ]) # if even length, choose fist of median two target_zone = zones [( len ( zones ) - 1 ) // 2 ] return target_hemisphere + target_zone make_composite ( out_name , rasters , resolution = None ) \u00b6 Creates a local-resolution-weighted composite from Sentinel-1 RTC products Parameters: Name Type Description Default out_name str The base name of the output GeoTIFFs required rasters List [ str ] A list of file paths of the images to composite required resolution float The pixel size for the output GeoTIFFs None Returns: Name Type Description out_raster Path to the created composite backscatter GeoTIFF out_counts_raster Path to the created GeoTIFF with counts of scenes contributing to each pixel Source code in asf_tools/composite.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 def make_composite ( out_name : str , rasters : List [ str ], resolution : float = None ): \"\"\"Creates a local-resolution-weighted composite from Sentinel-1 RTC products Args: out_name: The base name of the output GeoTIFFs rasters: A list of file paths of the images to composite resolution: The pixel size for the output GeoTIFFs Returns: out_raster: Path to the created composite backscatter GeoTIFF out_counts_raster: Path to the created GeoTIFF with counts of scenes contributing to each pixel \"\"\" if not rasters : raise ValueError ( 'Must specify at least one raster to composite' ) raster_info = {} for raster in rasters : raster_info [ raster ] = gdal . Info ( raster , format = 'json' ) # make sure gdal can read the area raster gdal . Info ( get_area_raster ( raster )) target_epsg_code = get_target_epsg_code ([ get_epsg_code ( info ) for info in raster_info . values ()]) log . debug ( f 'Composite projection is EPSG: { target_epsg_code } ' ) if resolution is None : resolution = max ([ info [ 'geoTransform' ][ 1 ] for info in raster_info . values ()]) log . debug ( f 'Composite resolution is { resolution } meters' ) # resample rasters to maximum resolution & common UTM zone with TemporaryDirectory ( prefix = 'reprojected_' ) as temp_dir : raster_info = reproject_to_target ( raster_info , target_epsg_code = target_epsg_code , target_resolution = resolution , directory = temp_dir ) # Get extent of union of all images full_ul , full_lr , full_trans = get_full_extent ( raster_info ) nx = int ( abs ( full_ul [ 0 ] - full_lr [ 0 ]) // resolution ) ny = int ( abs ( full_ul [ 1 ] - full_lr [ 1 ]) // resolution ) outputs = np . zeros (( ny , nx )) weights = np . zeros ( outputs . shape ) counts = np . zeros ( outputs . shape , dtype = np . int8 ) for raster , info in raster_info . items (): log . info ( f 'Processing raster { raster } ' ) log . debug ( f \"Raster upper left: { info [ 'cornerCoordinates' ][ 'upperLeft' ] } ; \" f \"lower right: { info [ 'cornerCoordinates' ][ 'lowerRight' ] } \" ) values = read_as_array ( raster ) area_raster = get_area_raster ( raster ) areas = read_as_array ( area_raster ) ulx , uly = info [ 'cornerCoordinates' ][ 'upperLeft' ] y_index_start = int (( full_ul [ 1 ] - uly ) // resolution ) y_index_end = y_index_start + values . shape [ 0 ] x_index_start = int (( ulx - full_ul [ 0 ]) // resolution ) x_index_end = x_index_start + values . shape [ 1 ] log . debug ( f 'Placing values in output grid at { y_index_start } : { y_index_end } and { x_index_start } : { x_index_end } ' ) mask = values == 0 raster_weights = 1.0 / areas raster_weights [ mask ] = 0 outputs [ y_index_start : y_index_end , x_index_start : x_index_end ] += values * raster_weights weights [ y_index_start : y_index_end , x_index_start : x_index_end ] += raster_weights counts [ y_index_start : y_index_end , x_index_start : x_index_end ] += ~ mask del values , areas , mask , raster_weights # Divide by the total weight applied outputs /= weights del weights out_raster = write_cog ( f ' { out_name } .tif' , outputs , full_trans , target_epsg_code , nodata_value = 0 ) del outputs out_counts_raster = write_cog ( f ' { out_name } _counts.tif' , counts , full_trans , target_epsg_code , dtype = gdal . GDT_Int16 ) del counts return out_raster , out_counts_raster read_as_array ( raster , band = 1 ) \u00b6 Reads data from a raster image into memory Parameters: Name Type Description Default raster str The file path to a raster image required band int The raster band to read 1 Returns: Name Type Description data array The raster pixel data as a numpy array Source code in asf_tools/composite.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def read_as_array ( raster : str , band : int = 1 ) -> np . array : \"\"\"Reads data from a raster image into memory Args: raster: The file path to a raster image band: The raster band to read Returns: data: The raster pixel data as a numpy array \"\"\" log . debug ( f 'Reading raster values from { raster } ' ) ds = gdal . Open ( raster ) data = ds . GetRasterBand ( band ) . ReadAsArray () del ds # How to close w/ gdal return data reproject_to_target ( raster_info , target_epsg_code , target_resolution , directory ) \u00b6 Reprojects a set of raster images to a common projection and resolution Parameters: Name Type Description Default raster_info dict A dictionary of gdal.Info results for the set of rasters required target_epsg_code int The integer EPSG code for the target projection required target_resolution float The target resolution required directory str The directory in which to create the reprojected files required Returns: Name Type Description target_raster_info dict An updated dictionary of gdal.Info results for the reprojected files Source code in asf_tools/composite.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 def reproject_to_target ( raster_info : dict , target_epsg_code : int , target_resolution : float , directory : str ) -> dict : \"\"\"Reprojects a set of raster images to a common projection and resolution Args: raster_info: A dictionary of gdal.Info results for the set of rasters target_epsg_code: The integer EPSG code for the target projection target_resolution: The target resolution directory: The directory in which to create the reprojected files Returns: target_raster_info: An updated dictionary of gdal.Info results for the reprojected files \"\"\" target_raster_info = {} for raster , info in raster_info . items (): epsg_code = get_epsg_code ( info ) resolution = info [ 'geoTransform' ][ 1 ] if epsg_code != target_epsg_code or resolution != target_resolution : log . info ( f 'Reprojecting { raster } ' ) reprojected_raster = os . path . join ( directory , os . path . basename ( raster )) gdal . Warp ( reprojected_raster , raster , dstSRS = f 'EPSG: { target_epsg_code } ' , xRes = target_resolution , yRes = target_resolution , targetAlignedPixels = True ) area_raster = get_area_raster ( raster ) log . info ( f 'Reprojecting { area_raster } ' ) reprojected_area_raster = os . path . join ( directory , os . path . basename ( area_raster )) gdal . Warp ( reprojected_area_raster , area_raster , dstSRS = f 'EPSG: { target_epsg_code } ' , xRes = target_resolution , yRes = target_resolution , targetAlignedPixels = True ) target_raster_info [ reprojected_raster ] = gdal . Info ( reprojected_raster , format = 'json' ) else : log . info ( f 'No need to reproject { raster } ' ) target_raster_info [ raster ] = info return target_raster_info write_cog ( file_name , data , transform , epsg_code , dtype = gdal . GDT_Float32 , nodata_value = None ) \u00b6 Creates a Cloud Optimized GeoTIFF Parameters: Name Type Description Default file_name Union [ str , Path ] The output file name required data ndarray The raster data required transform List [ float ] The geotransform for the output GeoTIFF required epsg_code int The integer EPSG code for the output GeoTIFF projection required dtype The pixel data type for the output GeoTIFF GDT_Float32 nodata_value The NODATA value for the output Geotiff None Returns: Name Type Description file_name The output file name Source code in asf_tools/composite.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 def write_cog ( file_name : Union [ str , Path ], data : np . ndarray , transform : List [ float ], epsg_code : int , dtype = gdal . GDT_Float32 , nodata_value = None ): \"\"\"Creates a Cloud Optimized GeoTIFF Args: file_name: The output file name data: The raster data transform: The geotransform for the output GeoTIFF epsg_code: The integer EPSG code for the output GeoTIFF projection dtype: The pixel data type for the output GeoTIFF nodata_value: The NODATA value for the output Geotiff Returns: file_name: The output file name \"\"\" log . info ( f 'Creating { file_name } ' ) with NamedTemporaryFile () as temp_file : driver = gdal . GetDriverByName ( 'GTiff' ) temp_geotiff = driver . Create ( temp_file . name , data . shape [ 1 ], data . shape [ 0 ], 1 , dtype ) temp_geotiff . GetRasterBand ( 1 ) . WriteArray ( data ) if nodata_value is not None : temp_geotiff . GetRasterBand ( 1 ) . SetNoDataValue ( nodata_value ) temp_geotiff . SetGeoTransform ( transform ) temp_geotiff . SetProjection ( epsg_to_wkt ( epsg_code )) driver = gdal . GetDriverByName ( 'COG' ) options = [ 'COMPRESS=LZW' , 'OVERVIEW_RESAMPLING=AVERAGE' , 'NUM_THREADS=ALL_CPUS' , 'BIGTIFF=YES' ] driver . CreateCopy ( str ( file_name ), temp_geotiff , options = options ) del temp_geotiff # How to close w/ gdal return file_name dem \u00b6 Prepare a Copernicus GLO-30 DEM virtual raster (VRT) covering a given geometry prepare_dem_vrt ( vrt , geometry ) \u00b6 Create a DEM mosaic VRT covering a given geometry The DEM mosaic is assembled from the Copernicus GLO-30 DEM tiles that intersect the geometry. Note: asf_tools does not currently support geometries that cross the antimeridian. Parameters: Name Type Description Default vrt Union [ str , Path ] Path for the output VRT file required geometry Union [ Geometry , BaseGeometry ] Geometry in EPSG:4326 (lon/lat) projection for which to prepare a DEM mosaic required Source code in asf_tools/dem.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def prepare_dem_vrt ( vrt : Union [ str , Path ], geometry : Union [ ogr . Geometry , BaseGeometry ]): \"\"\"Create a DEM mosaic VRT covering a given geometry The DEM mosaic is assembled from the Copernicus GLO-30 DEM tiles that intersect the geometry. Note: `asf_tools` does not currently support geometries that cross the antimeridian. Args: vrt: Path for the output VRT file geometry: Geometry in EPSG:4326 (lon/lat) projection for which to prepare a DEM mosaic \"\"\" with GDALConfigManager ( GDAL_DISABLE_READDIR_ON_OPEN = 'EMPTY_DIR' ): if isinstance ( geometry , BaseGeometry ): geometry = ogr . CreateGeometryFromWkb ( geometry . wkb ) min_lon , max_lon , _ , _ = geometry . GetEnvelope () if min_lon < - 160. and max_lon > 160. : raise ValueError ( f 'asf_tools does not currently support geometries that cross the antimeridian: { geometry } ' ) tile_features = vector . get_features ( DEM_GEOJSON ) if not vector . get_property_values_for_intersecting_features ( geometry , tile_features ): raise ValueError ( f 'Copernicus GLO-30 DEM does not intersect this geometry: { geometry } ' ) dem_file_paths = vector . intersecting_feature_properties ( geometry , tile_features , 'file_path' ) gdal . BuildVRT ( str ( vrt ), dem_file_paths ) flood_map \u00b6 Generate flood depth map from surface water extent map. Create a flood depth map from a surface water extent map and a HAND image. The HAND image must be pixel-aligned (same extent and size) to the water extent map, and the surface water extent map should be a byte GeoTIFF indicating water (true), not water (false). Flood depth maps are estimated using either a numerical, normalized median absolute deviation, logarithmic or iterative approach. logstat ( data , func = np . nanstd ) \u00b6 Calculate a function in logarithmic scale and return in linear scale. INF values inside the data array are set to nan. Parameters: Name Type Description Default data ndarray array of data required func Callable statistical function to calculate in logarithmic scale nanstd Returns: statistic: statistic of data in linear scale Source code in asf_tools/flood_map.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def logstat ( data : np . ndarray , func : Callable = np . nanstd ) -> Union [ np . ndarray , float ]: \"\"\" Calculate a function in logarithmic scale and return in linear scale. INF values inside the data array are set to nan. Args: data: array of data func: statistical function to calculate in logarithmic scale Returns: statistic: statistic of data in linear scale \"\"\" ld = np . log ( data ) ld [ np . isinf ( ld )] = np . nan st = func ( ld ) return np . exp ( st ) make_flood_map ( out_raster , vv_raster , water_raster , hand_raster , estimator = 'iterative' , water_level_sigma = 3.0 , known_water_threshold = 30.0 , iterative_bounds = ( 0 , 15 )) \u00b6 Create a flood depth map from a surface water extent map. WARNING: This functionality is still under active development and the products created using this function are likely to change in the future. Create a flood depth map from a single surface water extent map and a HAND image. The HAND image must be pixel-aligned to the surface water extent map. The surface water extent map should be a byte GeoTIFF indicating water (true) and not water (false) Known perennial Global Surface-water data are produced under the Copernicus Programme (Pekel et al., 2016), and are included with surface-water detection maps when generating the flood depth product. Flood depth maps are estimated using one of the approaches: Iterative: (Default) Basin hopping optimization method matches flooded areas to flood depth estimates given by the HAND layer. This is the most accurate method but also the most time-intensive. Normalized Median Absolute Deviation (nmad): Uses a median operator to estimate the variation to increase robustness in the presence of outliers. Logstat: Calculates the mean and standard deviation of HAND heights in the logarithmic domain to improve robustness for very non-Gaussian data distributions. Numpy: Calculates statistics on a linear scale. Least robust to outliers and non-Gaussian distributions. Parameters: Name Type Description Default out_raster Union [ str , Path ] Flood depth GeoTIFF to create required vv_raster Union [ str , Path ] Sentinel-1 RTC GeoTIFF, in power scale, with VV polarization required water_raster Union [ str , Path ] Surface water extent GeoTIFF required hand_raster Union [ str , Path ] Height Above Nearest Drainage (HAND) GeoTIFF aligned to the surface water extent raster required estimator str Estimation approach for determining flood depth 'iterative' water_level_sigma float Max water height used in logstat, nmad, and numpy estimations 3.0 known_water_threshold float Threshold for extracting the known water area in percent 30.0 iterative_bounds Tuple [ int , int ] Bounds on basin-hopping algorithm used in iterative estimation (0, 15) References Jean-Francios Pekel, Andrew Cottam, Noel Gorelik, Alan S. Belward. 2016. https://doi:10.1038/nature20584 Source code in asf_tools/flood_map.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 def make_flood_map ( out_raster : Union [ str , Path ], vv_raster : Union [ str , Path ], water_raster : Union [ str , Path ], hand_raster : Union [ str , Path ], estimator : str = 'iterative' , water_level_sigma : float = 3. , known_water_threshold : float = 30. , iterative_bounds : Tuple [ int , int ] = ( 0 , 15 )): \"\"\"Create a flood depth map from a surface water extent map. WARNING: This functionality is still under active development and the products created using this function are likely to change in the future. Create a flood depth map from a single surface water extent map and a HAND image. The HAND image must be pixel-aligned to the surface water extent map. The surface water extent map should be a byte GeoTIFF indicating water (true) and not water (false) Known perennial Global Surface-water data are produced under the Copernicus Programme (Pekel et al., 2016), and are included with surface-water detection maps when generating the flood depth product. Flood depth maps are estimated using one of the approaches: *Iterative: (Default) Basin hopping optimization method matches flooded areas to flood depth estimates given by the HAND layer. This is the most accurate method but also the most time-intensive. *Normalized Median Absolute Deviation (nmad): Uses a median operator to estimate the variation to increase robustness in the presence of outliers. *Logstat: Calculates the mean and standard deviation of HAND heights in the logarithmic domain to improve robustness for very non-Gaussian data distributions. *Numpy: Calculates statistics on a linear scale. Least robust to outliers and non-Gaussian distributions. Args: out_raster: Flood depth GeoTIFF to create vv_raster: Sentinel-1 RTC GeoTIFF, in power scale, with VV polarization water_raster: Surface water extent GeoTIFF hand_raster: Height Above Nearest Drainage (HAND) GeoTIFF aligned to the surface water extent raster estimator: Estimation approach for determining flood depth water_level_sigma: Max water height used in logstat, nmad, and numpy estimations known_water_threshold: Threshold for extracting the known water area in percent iterative_bounds: Bounds on basin-hopping algorithm used in iterative estimation References: Jean-Francios Pekel, Andrew Cottam, Noel Gorelik, Alan S. Belward. 2016. <https://doi:10.1038/nature20584> \"\"\" info = gdal . Info ( str ( water_raster ), format = 'json' ) epsg = get_epsg_code ( info ) geotransform = info [ 'geoTransform' ] hand_array = gdal . Open ( str ( hand_raster ), gdal . GA_ReadOnly ) . ReadAsArray () log . info ( 'Fetching perennial flood data.' ) known_water_mask = get_waterbody ( info , threshold = known_water_threshold ) write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { estimator } _PW.tif' ), known_water_mask , transform = geotransform , epsg_code = epsg , dtype = gdal . GDT_Byte , nodata_value = False ) water_map = gdal . Open ( str ( water_raster )) . ReadAsArray () flood_mask = np . logical_or ( water_map , known_water_mask ) del water_map vv_array = read_as_masked_array ( vv_raster ) flood_mask [ vv_array . mask ] = False padding_mask = vv_array . mask del vv_array labeled_flood_mask , num_labels = ndimage . label ( flood_mask ) object_slices = ndimage . find_objects ( labeled_flood_mask ) log . info ( f 'Detected { num_labels } water bodies...' ) flood_depth = np . zeros ( flood_mask . shape ) for ll in tqdm ( range ( 1 , num_labels )): # Skip first, largest label. slices = object_slices [ ll - 1 ] min0 , max0 = slices [ 0 ] . start , slices [ 0 ] . stop min1 , max1 = slices [ 1 ] . start , slices [ 1 ] . stop flood_window = labeled_flood_mask [ min0 : max0 , min1 : max1 ] hand_window = hand_array [ min0 : max0 , min1 : max1 ] water_height = estimate_flood_depth ( ll , hand_window , flood_window , estimator = estimator , water_level_sigma = water_level_sigma , iterative_bounds = iterative_bounds ) flood_depth_window = flood_depth [ min0 : max0 , min1 : max1 ] flood_depth_window [ flood_window == ll ] = water_height - hand_window [ flood_window == ll ] flood_depth [ flood_depth < 0 ] = 0 nodata = - 1 flood_depth [ padding_mask ] = nodata floodmask_nodata = np . iinfo ( np . uint8 ) . max flood_mask_byte = flood_mask . astype ( np . uint8 ) flood_mask_byte [ padding_mask ] = floodmask_nodata write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { estimator } _WaterDepth.tif' ), flood_depth , transform = geotransform , epsg_code = epsg , dtype = gdal . GDT_Float64 , nodata_value = nodata ) write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { estimator } _FloodMask.tif' ), flood_mask_byte , transform = geotransform , epsg_code = epsg , dtype = gdal . GDT_Byte , nodata_value = floodmask_nodata ) flood_mask [ known_water_mask ] = False flood_depth [ np . logical_not ( flood_mask )] = 0 flood_depth [ padding_mask ] = nodata write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { estimator } _FloodDepth.tif' ), flood_depth , transform = geotransform , epsg_code = epsg , dtype = gdal . GDT_Float64 , nodata_value = nodata ) hand \u00b6 calculate_hand_for_basins ( out_raster , geometries , dem_file , acc_thresh = 100 ) \u00b6 Calculate the Height Above Nearest Drainage (HAND) for watershed boundaries (hydrobasins). For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Parameters: Name Type Description Default out_raster Union [ str , Path ] HAND GeoTIFF to create required geometries GeometryCollection watershed boundary (hydrobasin) polygons to calculate HAND over required dem_file Union [ str , Path ] DEM raster covering (containing) geometries required acc_thresh Optional [ int ] Accumulation threshold for determining the drainage mask. If None , the mean accumulation value is used 100 Source code in 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def calculate_hand_for_basins ( out_raster : Union [ str , Path ], geometries : GeometryCollection , dem_file : Union [ str , Path ], acc_thresh : Optional [ int ] = 100 ): \"\"\"Calculate the Height Above Nearest Drainage (HAND) for watershed boundaries (hydrobasins). For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Args: out_raster: HAND GeoTIFF to create geometries: watershed boundary (hydrobasin) polygons to calculate HAND over dem_file: DEM raster covering (containing) `geometries` acc_thresh: Accumulation threshold for determining the drainage mask. If `None`, the mean accumulation value is used \"\"\" with rasterio . open ( dem_file ) as src : basin_mask , basin_affine_tf , basin_window = rasterio . mask . raster_geometry_mask ( src , geometries . geoms , all_touched = True , crop = True , pad = True , pad_width = 1 ) basin_array = src . read ( 1 , window = basin_window ) hand = calculate_hand ( basin_array , basin_affine_tf , src . crs , basin_mask , acc_thresh = acc_thresh ) write_cog ( out_raster , hand , transform = basin_affine_tf . to_gdal (), epsg_code = src . crs . to_epsg (), nodata_value = np . nan , ) make_copernicus_hand ( out_raster , vector_file , acc_thresh = 100 ) \u00b6 Copernicus GLO-30 Height Above Nearest Drainage (HAND) Make a Height Above Nearest Drainage (HAND) GeoTIFF from the Copernicus GLO-30 DEM covering the watershed boundaries (hydrobasins) defined in a vector file. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Parameters: Name Type Description Default out_raster Union [ str , Path ] HAND GeoTIFF to create required vector_file Union [ str , Path ] Vector file of watershed boundary (hydrobasin) polygons to calculate HAND over required acc_thresh Optional [ int ] Accumulation threshold for determining the drainage mask. If None , the mean accumulation value is used 100 Source code in 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def make_copernicus_hand ( out_raster : Union [ str , Path ], vector_file : Union [ str , Path ], acc_thresh : Optional [ int ] = 100 ): \"\"\"Copernicus GLO-30 Height Above Nearest Drainage (HAND) Make a Height Above Nearest Drainage (HAND) GeoTIFF from the Copernicus GLO-30 DEM covering the watershed boundaries (hydrobasins) defined in a vector file. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Args: out_raster: HAND GeoTIFF to create vector_file: Vector file of watershed boundary (hydrobasin) polygons to calculate HAND over acc_thresh: Accumulation threshold for determining the drainage mask. If `None`, the mean accumulation value is used \"\"\" with fiona . open ( vector_file ) as vds : geometries = GeometryCollection ([ shape ( feature [ 'geometry' ]) for feature in vds ]) with NamedTemporaryFile ( suffix = '.vrt' , delete = False ) as dem_vrt : prepare_dem_vrt ( dem_vrt . name , geometries ) calculate_hand_for_basins ( out_raster , geometries , dem_vrt . name , acc_thresh = acc_thresh ) prepare_hand_vrt ( vrt , geometry ) \u00b6 Prepare a HAND mosaic VRT covering a given geometry Prepare a Height Above Nearest Drainage (HAND) virtual raster (VRT) covering a given geometry. The Height Above Nearest Drainage (HAND) mosaic is assembled from the HAND tiles that intersect the geometry, using a HAND derived from the Copernicus GLO-30 DEM. Note: asf_tools does not currently support geometries that cross the antimeridian. Parameters: Name Type Description Default vrt Union [ str , Path ] Path for the output VRT file required geometry Union [ Geometry , BaseGeometry ] Geometry in EPSG:4326 (lon/lat) projection for which to prepare a HAND mosaic required Source code in 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def prepare_hand_vrt ( vrt : Union [ str , Path ], geometry : Union [ ogr . Geometry , BaseGeometry ]): \"\"\"Prepare a HAND mosaic VRT covering a given geometry Prepare a Height Above Nearest Drainage (HAND) virtual raster (VRT) covering a given geometry. The Height Above Nearest Drainage (HAND) mosaic is assembled from the HAND tiles that intersect the geometry, using a HAND derived from the Copernicus GLO-30 DEM. Note: `asf_tools` does not currently support geometries that cross the antimeridian. Args: vrt: Path for the output VRT file geometry: Geometry in EPSG:4326 (lon/lat) projection for which to prepare a HAND mosaic \"\"\" with GDALConfigManager ( GDAL_DISABLE_READDIR_ON_OPEN = 'EMPTY_DIR' ): if isinstance ( geometry , BaseGeometry ): geometry = ogr . CreateGeometryFromWkb ( geometry . wkb ) min_lon , max_lon , _ , _ = geometry . GetEnvelope () if min_lon < - 160. and max_lon > 160. : raise ValueError ( f 'asf_tools does not currently support geometries that cross the antimeridian: { geometry } ' ) tile_features = vector . get_features ( HAND_GEOJSON ) if not vector . get_property_values_for_intersecting_features ( geometry , tile_features ): raise ValueError ( f 'Copernicus GLO-30 HAND does not intersect this geometry: { geometry } ' ) hand_file_paths = vector . intersecting_feature_properties ( geometry , tile_features , 'file_path' ) gdal . BuildVRT ( str ( vrt ), hand_file_paths ) calculate \u00b6 Calculate Height Above Nearest Drainage (HAND) from the Copernicus GLO-30 DEM calculate_hand ( dem_array , dem_affine , dem_crs , basin_mask , acc_thresh = 100 ) \u00b6 Calculate the Height Above Nearest Drainage (HAND) Calculate the Height Above Nearest Drainage (HAND) using pySHEDS library. Because HAND is tied to watershed boundaries (hydrobasins), clipped/cut basins will produce weird edge effects, and incomplete basins should be masked out. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins This involves: * Filling pits (single-cells lower than their surrounding neighbors) in the Digital Elevation Model (DEM) * Filling depressions (regions of cells lower than their surrounding neighbors) in the Digital Elevation Model (DEM) * Resolving un-drainable flats * Determining the flow direction using the ESRI D8 routing scheme * Determining flow accumulation (number of upstream cells) * Creating a drainage mask using the accumulation threshold acc_thresh * Calculating HAND In the HAND calculation, NaNs inside the basin filled using fill_hand Parameters: Name Type Description Default dem_array DEM to calculate HAND for required dem_crs CRS DEM Coordinate Reference System (CRS) required dem_affine Affine DEM Affine geotransform required basin_mask Array of booleans indicating wither an element should be masked out (\u00e0 la Numpy Masked Arrays: https://numpy.org/doc/stable/reference/maskedarray.generic.html#what-is-a-masked-array) required acc_thresh Optional [ int ] Accumulation threshold for determining the drainage mask. If None , the mean accumulation value is used 100 Source code in asf_tools/hand/calculate.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def calculate_hand ( dem_array , dem_affine : rasterio . Affine , dem_crs : rasterio . crs . CRS , basin_mask , acc_thresh : Optional [ int ] = 100 ): \"\"\"Calculate the Height Above Nearest Drainage (HAND) Calculate the Height Above Nearest Drainage (HAND) using pySHEDS library. Because HAND is tied to watershed boundaries (hydrobasins), clipped/cut basins will produce weird edge effects, and incomplete basins should be masked out. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins This involves: * Filling pits (single-cells lower than their surrounding neighbors) in the Digital Elevation Model (DEM) * Filling depressions (regions of cells lower than their surrounding neighbors) in the Digital Elevation Model (DEM) * Resolving un-drainable flats * Determining the flow direction using the ESRI D8 routing scheme * Determining flow accumulation (number of upstream cells) * Creating a drainage mask using the accumulation threshold `acc_thresh` * Calculating HAND In the HAND calculation, NaNs inside the basin filled using `fill_hand` Args: dem_array: DEM to calculate HAND for dem_crs: DEM Coordinate Reference System (CRS) dem_affine: DEM Affine geotransform basin_mask: Array of booleans indicating wither an element should be masked out (\u00e0 la Numpy Masked Arrays: https://numpy.org/doc/stable/reference/maskedarray.generic.html#what-is-a-masked-array) acc_thresh: Accumulation threshold for determining the drainage mask. If `None`, the mean accumulation value is used \"\"\" nodata_fill_value = np . finfo ( float ) . eps with NamedTemporaryFile () as temp_file : write_cog ( temp_file . name , dem_array , transform = dem_affine . to_gdal (), epsg_code = dem_crs . to_epsg (), # Prevents PySheds from assuming using zero as the nodata value nodata_value = nodata_fill_value ) # From PySheds; see example usage: http://mattbartos.com/pysheds/ grid = sGrid . from_raster ( str ( temp_file . name )) dem = grid . read_raster ( str ( temp_file . name )) log . info ( 'Fill pits in DEM' ) pit_filled_dem = grid . fill_pits ( dem ) log . info ( 'Filling depressions' ) flooded_dem = grid . fill_depressions ( pit_filled_dem ) del pit_filled_dem log . info ( 'Resolving flats' ) inflated_dem = grid . resolve_flats ( flooded_dem ) del flooded_dem log . info ( 'Obtaining flow direction' ) flow_dir = grid . flowdir ( inflated_dem , apply_mask = True ) log . info ( 'Calculating flow accumulation' ) acc = grid . accumulation ( flow_dir ) if acc_thresh is None : acc_thresh = acc . mean () log . info ( f 'Calculating HAND using accumulation threshold of { acc_thresh } ' ) hand = grid . compute_hand ( flow_dir , inflated_dem , acc > acc_thresh , inplace = False ) if np . isnan ( hand ) . any (): log . info ( 'Filling NaNs in the HAND' ) # mask outside of basin with a not-NaN value to prevent NaN-filling outside of basin (optimization) hand [ basin_mask ] = nodata_fill_value hand = fill_hand ( hand , dem_array ) # set pixels outside of basin to nodata hand [ basin_mask ] = np . nan # TODO: also mask ocean pixels here? return hand calculate_hand_for_basins ( out_raster , geometries , dem_file , acc_thresh = 100 ) \u00b6 Calculate the Height Above Nearest Drainage (HAND) for watershed boundaries (hydrobasins). For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Parameters: Name Type Description Default out_raster Union [ str , Path ] HAND GeoTIFF to create required geometries GeometryCollection watershed boundary (hydrobasin) polygons to calculate HAND over required dem_file Union [ str , Path ] DEM raster covering (containing) geometries required acc_thresh Optional [ int ] Accumulation threshold for determining the drainage mask. If None , the mean accumulation value is used 100 Source code in asf_tools/hand/calculate.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def calculate_hand_for_basins ( out_raster : Union [ str , Path ], geometries : GeometryCollection , dem_file : Union [ str , Path ], acc_thresh : Optional [ int ] = 100 ): \"\"\"Calculate the Height Above Nearest Drainage (HAND) for watershed boundaries (hydrobasins). For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Args: out_raster: HAND GeoTIFF to create geometries: watershed boundary (hydrobasin) polygons to calculate HAND over dem_file: DEM raster covering (containing) `geometries` acc_thresh: Accumulation threshold for determining the drainage mask. If `None`, the mean accumulation value is used \"\"\" with rasterio . open ( dem_file ) as src : basin_mask , basin_affine_tf , basin_window = rasterio . mask . raster_geometry_mask ( src , geometries . geoms , all_touched = True , crop = True , pad = True , pad_width = 1 ) basin_array = src . read ( 1 , window = basin_window ) hand = calculate_hand ( basin_array , basin_affine_tf , src . crs , basin_mask , acc_thresh = acc_thresh ) write_cog ( out_raster , hand , transform = basin_affine_tf . to_gdal (), epsg_code = src . crs . to_epsg (), nodata_value = np . nan , ) fill_hand ( hand , dem ) \u00b6 Replace NaNs in a HAND array with values interpolated from their neighbor's HOND Replace NaNs in a HAND array with values interpolated from their neighbor's HOND (height of nearest drainage) using a 2D Gaussian kernel. Here, HOND is defined as the DEM value less the HAND value. For the kernel, see: https://docs.astropy.org/en/stable/convolution/#using-astropy-s-convolution-to-replace-bad-data Source code in asf_tools/hand/calculate.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def fill_hand ( hand : np . ndarray , dem : np . ndarray ): \"\"\"Replace NaNs in a HAND array with values interpolated from their neighbor's HOND Replace NaNs in a HAND array with values interpolated from their neighbor's HOND (height of nearest drainage) using a 2D Gaussian kernel. Here, HOND is defined as the DEM value less the HAND value. For the kernel, see: https://docs.astropy.org/en/stable/convolution/#using-astropy-s-convolution-to-replace-bad-data \"\"\" hond = dem - hand hond = fill_nan ( hond ) hand_mask = np . isnan ( hand ) hand [ hand_mask ] = dem [ hand_mask ] - hond [ hand_mask ] hand [ hand < 0 ] = 0 return hand fill_nan ( array ) \u00b6 Replace NaNs with values interpolated from their neighbors Replace NaNs with values interpolated from their neighbors using a 2D Gaussian kernel, see: https://docs.astropy.org/en/stable/convolution/#using-astropy-s-convolution-to-replace-bad-data Source code in asf_tools/hand/calculate.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def fill_nan ( array : np . ndarray ) -> np . ndarray : \"\"\"Replace NaNs with values interpolated from their neighbors Replace NaNs with values interpolated from their neighbors using a 2D Gaussian kernel, see: https://docs.astropy.org/en/stable/convolution/#using-astropy-s-convolution-to-replace-bad-data \"\"\" kernel = astropy . convolution . Gaussian2DKernel ( x_stddev = 3 ) # kernel x_size=8*stddev with warnings . catch_warnings (): warnings . simplefilter ( \"ignore\" ) while np . any ( np . isnan ( array )): array = astropy . convolution . interpolate_replace_nans ( array , kernel , convolve = astropy . convolution . convolve ) return array make_copernicus_hand ( out_raster , vector_file , acc_thresh = 100 ) \u00b6 Copernicus GLO-30 Height Above Nearest Drainage (HAND) Make a Height Above Nearest Drainage (HAND) GeoTIFF from the Copernicus GLO-30 DEM covering the watershed boundaries (hydrobasins) defined in a vector file. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Parameters: Name Type Description Default out_raster Union [ str , Path ] HAND GeoTIFF to create required vector_file Union [ str , Path ] Vector file of watershed boundary (hydrobasin) polygons to calculate HAND over required acc_thresh Optional [ int ] Accumulation threshold for determining the drainage mask. If None , the mean accumulation value is used 100 Source code in asf_tools/hand/calculate.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def make_copernicus_hand ( out_raster : Union [ str , Path ], vector_file : Union [ str , Path ], acc_thresh : Optional [ int ] = 100 ): \"\"\"Copernicus GLO-30 Height Above Nearest Drainage (HAND) Make a Height Above Nearest Drainage (HAND) GeoTIFF from the Copernicus GLO-30 DEM covering the watershed boundaries (hydrobasins) defined in a vector file. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Args: out_raster: HAND GeoTIFF to create vector_file: Vector file of watershed boundary (hydrobasin) polygons to calculate HAND over acc_thresh: Accumulation threshold for determining the drainage mask. If `None`, the mean accumulation value is used \"\"\" with fiona . open ( vector_file ) as vds : geometries = GeometryCollection ([ shape ( feature [ 'geometry' ]) for feature in vds ]) with NamedTemporaryFile ( suffix = '.vrt' , delete = False ) as dem_vrt : prepare_dem_vrt ( dem_vrt . name , geometries ) calculate_hand_for_basins ( out_raster , geometries , dem_vrt . name , acc_thresh = acc_thresh ) prepare \u00b6 Prepare a Height Above Nearest Drainage (HAND) virtual raster (VRT) covering a given geometry prepare_hand_for_raster ( hand_raster , source_raster , resampling_method = 'lanczos' ) \u00b6 Create a HAND raster pixel-aligned to a source raster Parameters: Name Type Description Default hand_raster Union [ str , Path ] Path for the output HAND raster required source_raster Union [ str , Path ] Path for the source raster required resampling_method str Name of the resampling method to use. For available methods, see: https://gdal.org/programs/gdalwarp.html#cmdoption-gdalwarp-r 'lanczos' Source code in asf_tools/hand/prepare.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def prepare_hand_for_raster ( hand_raster : Union [ str , Path ], source_raster : Union [ str , Path ], resampling_method : str = 'lanczos' ): \"\"\"Create a HAND raster pixel-aligned to a source raster Args: hand_raster: Path for the output HAND raster source_raster: Path for the source raster resampling_method: Name of the resampling method to use. For available methods, see: https://gdal.org/programs/gdalwarp.html#cmdoption-gdalwarp-r \"\"\" info = gdal . Info ( str ( source_raster ), format = 'json' ) hand_geometry = shape ( info [ 'wgs84Extent' ]) hand_bounds = [ info [ 'cornerCoordinates' ][ 'upperLeft' ][ 0 ], info [ 'cornerCoordinates' ][ 'lowerRight' ][ 1 ], info [ 'cornerCoordinates' ][ 'lowerRight' ][ 0 ], info [ 'cornerCoordinates' ][ 'upperLeft' ][ 1 ]] with NamedTemporaryFile ( suffix = '.vrt' , delete = False ) as hand_vrt : prepare_hand_vrt ( hand_vrt . name , hand_geometry ) gdal . Warp ( str ( hand_raster ), hand_vrt . name , dstSRS = f 'EPSG: { get_epsg_code ( info ) } ' , outputBounds = hand_bounds , width = info [ 'size' ][ 0 ], height = info [ 'size' ][ 1 ], resampleAlg = Resampling [ resampling_method ] . value ) prepare_hand_vrt ( vrt , geometry ) \u00b6 Prepare a HAND mosaic VRT covering a given geometry Prepare a Height Above Nearest Drainage (HAND) virtual raster (VRT) covering a given geometry. The Height Above Nearest Drainage (HAND) mosaic is assembled from the HAND tiles that intersect the geometry, using a HAND derived from the Copernicus GLO-30 DEM. Note: asf_tools does not currently support geometries that cross the antimeridian. Parameters: Name Type Description Default vrt Union [ str , Path ] Path for the output VRT file required geometry Union [ Geometry , BaseGeometry ] Geometry in EPSG:4326 (lon/lat) projection for which to prepare a HAND mosaic required Source code in asf_tools/hand/prepare.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def prepare_hand_vrt ( vrt : Union [ str , Path ], geometry : Union [ ogr . Geometry , BaseGeometry ]): \"\"\"Prepare a HAND mosaic VRT covering a given geometry Prepare a Height Above Nearest Drainage (HAND) virtual raster (VRT) covering a given geometry. The Height Above Nearest Drainage (HAND) mosaic is assembled from the HAND tiles that intersect the geometry, using a HAND derived from the Copernicus GLO-30 DEM. Note: `asf_tools` does not currently support geometries that cross the antimeridian. Args: vrt: Path for the output VRT file geometry: Geometry in EPSG:4326 (lon/lat) projection for which to prepare a HAND mosaic \"\"\" with GDALConfigManager ( GDAL_DISABLE_READDIR_ON_OPEN = 'EMPTY_DIR' ): if isinstance ( geometry , BaseGeometry ): geometry = ogr . CreateGeometryFromWkb ( geometry . wkb ) min_lon , max_lon , _ , _ = geometry . GetEnvelope () if min_lon < - 160. and max_lon > 160. : raise ValueError ( f 'asf_tools does not currently support geometries that cross the antimeridian: { geometry } ' ) tile_features = vector . get_features ( HAND_GEOJSON ) if not vector . get_property_values_for_intersecting_features ( geometry , tile_features ): raise ValueError ( f 'Copernicus GLO-30 HAND does not intersect this geometry: { geometry } ' ) hand_file_paths = vector . intersecting_feature_properties ( geometry , tile_features , 'file_path' ) gdal . BuildVRT ( str ( vrt ), hand_file_paths ) raster \u00b6 convert_scale ( array , in_scale , out_scale ) \u00b6 Convert calibrated raster scale between db, amplitude and power Source code in asf_tools/raster.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def convert_scale ( array : Union [ np . ndarray , np . ma . MaskedArray ], in_scale : Literal [ 'db' , 'amplitude' , 'power' ], out_scale : Literal [ 'db' , 'amplitude' , 'power' ]) -> Union [ np . ndarray , np . ma . MaskedArray ]: \"\"\"Convert calibrated raster scale between db, amplitude and power\"\"\" if in_scale == out_scale : warnings . warn ( f 'Nothing to do! { in_scale } is same as { out_scale } .' ) return array log10 = np . ma . log10 if isinstance ( array , np . ma . MaskedArray ) else np . log10 if in_scale == 'db' : if out_scale == 'power' : return 10 ** ( array / 10 ) if out_scale == 'amplitude' : return 10 ** ( array / 20 ) if in_scale == 'amplitude' : if out_scale == 'power' : return array ** 2 if out_scale == 'db' : return 10 * log10 ( array ** 2 ) if in_scale == 'power' : if out_scale == 'amplitude' : return np . sqrt ( array ) if out_scale == 'db' : return 10 * log10 ( array ) raise ValueError ( f 'Cannot convert raster of scale { in_scale } to { out_scale } ' ) read_as_masked_array ( raster , band = 1 ) \u00b6 Reads data from a raster image into memory, masking invalid and NoData values Parameters: Name Type Description Default raster Union [ str , Path ] The file path to a raster image required band int The raster band to read 1 Returns: Name Type Description data MaskedArray The raster pixel data as a numpy MaskedArray Source code in asf_tools/raster.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def read_as_masked_array ( raster : Union [ str , Path ], band : int = 1 ) -> np . ma . MaskedArray : \"\"\"Reads data from a raster image into memory, masking invalid and NoData values Args: raster: The file path to a raster image band: The raster band to read Returns: data: The raster pixel data as a numpy MaskedArray \"\"\" log . debug ( f 'Reading raster values from { raster } ' ) ds = gdal . Open ( str ( raster )) band = ds . GetRasterBand ( band ) data = np . ma . masked_invalid ( band . ReadAsArray ()) nodata = band . GetNoDataValue () if nodata is not None : return np . ma . masked_values ( data , nodata ) return data threshold \u00b6 expectation_maximization_threshold ( tile , number_of_classes = 3 ) \u00b6 Water threshold Calculation using a multi-mode Expectation Maximization Approach Thresholding works best when backscatter tiles are provided on a decibel scale to get Gaussian distribution that is scaled to a range of 0-255, and performed on a small tile that is likely to have a transition between water and not water. Parameters: Name Type Description Default tile ndarray array of backscatter values for a tile from an RTC raster required number_of_classes int classify the tile into this many classes. Typically, three classes capture: (1) urban and bright slopes, (2) average brightness farmland, and (3) water, as is often seen in the US Midwest. 3 Returns: Name Type Description threshold float threshold value that can be used to create a water extent map Source code in asf_tools/threshold.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def expectation_maximization_threshold ( tile : np . ndarray , number_of_classes : int = 3 ) -> float : \"\"\"Water threshold Calculation using a multi-mode Expectation Maximization Approach Thresholding works best when backscatter tiles are provided on a decibel scale to get Gaussian distribution that is scaled to a range of 0-255, and performed on a small tile that is likely to have a transition between water and not water. Args: tile: array of backscatter values for a tile from an RTC raster number_of_classes: classify the tile into this many classes. Typically, three classes capture: (1) urban and bright slopes, (2) average brightness farmland, and (3) water, as is often seen in the US Midwest. Returns: threshold: threshold value that can be used to create a water extent map \"\"\" image_copy = tile . copy () image_copy2 = np . ma . filled ( tile . astype ( float ), np . nan ) # needed for valid posterior_lookup keys image = tile . flatten () minimum = np . amin ( image ) image = image - minimum + 1 maximum = np . amax ( image ) histogram = _make_histogram ( image ) nonzero_indices = np . nonzero ( histogram )[ 0 ] histogram = histogram [ nonzero_indices ] histogram = histogram . flatten () class_means = ( ( np . arange ( number_of_classes ) + 1 ) * maximum / ( number_of_classes + 1 ) ) class_variances = np . ones ( number_of_classes ) * maximum class_proportions = np . ones ( number_of_classes ) * 1 / number_of_classes sml = np . mean ( np . diff ( nonzero_indices )) / 1000 iteration = 0 while True : class_likelihood = _make_distribution ( class_means , class_variances , class_proportions , nonzero_indices ) sum_likelihood = np . sum ( class_likelihood , 1 ) + np . finfo ( class_likelihood [ 0 ][ 0 ]) . eps log_likelihood = np . sum ( histogram * np . log ( sum_likelihood )) for j in range ( 0 , number_of_classes ): class_posterior_probability = ( histogram * class_likelihood [:, j ] / sum_likelihood ) class_proportions [ j ] = np . sum ( class_posterior_probability ) class_means [ j ] = ( np . sum ( nonzero_indices * class_posterior_probability ) / class_proportions [ j ] ) vr = ( nonzero_indices - class_means [ j ]) class_variances [ j ] = ( np . sum ( vr * vr * class_posterior_probability ) / class_proportions [ j ] + sml ) del class_posterior_probability , vr class_proportions += 1e-3 class_proportions /= np . sum ( class_proportions ) class_likelihood = _make_distribution ( class_means , class_variances , class_proportions , nonzero_indices ) sum_likelihood = np . sum ( class_likelihood , 1 ) + np . finfo ( class_likelihood [ 0 , 0 ]) . eps del class_likelihood new_log_likelihood = np . sum ( histogram * np . log ( sum_likelihood )) del sum_likelihood if ( new_log_likelihood - log_likelihood ) < 0.000001 : break iteration += 1 del log_likelihood , new_log_likelihood class_means = class_means + minimum - 1 s = image_copy . shape posterior = np . zeros (( s [ 0 ], s [ 1 ], number_of_classes )) posterior_lookup = dict () for i in range ( 0 , s [ 0 ]): for j in range ( 0 , s [ 1 ]): pixel_val = image_copy2 [ i , j ] if pixel_val in posterior_lookup : for n in range ( 0 , number_of_classes ): posterior [ i , j , n ] = posterior_lookup [ pixel_val ][ n ] else : posterior_lookup . update ({ pixel_val : [ 0 ] * number_of_classes }) for n in range ( 0 , number_of_classes ): x = _make_distribution ( class_means [ n ], class_variances [ n ], class_proportions [ n ], image_copy [ i , j ] ) posterior [ i , j , n ] = x * class_proportions [ n ] posterior_lookup [ pixel_val ][ n ] = posterior [ i , j , n ] sorti = np . argsort ( class_means ) xvec = np . arange ( class_means [ sorti [ 0 ]], class_means [ sorti [ 1 ]], step = .05 ) x1 = _make_distribution ( class_means [ sorti [ 0 ]], class_variances [ sorti [ 0 ]], class_proportions [ sorti [ 0 ]], xvec ) x2 = _make_distribution ( class_means [ sorti [ 1 ]], class_variances [ sorti [ 1 ]], class_proportions [ sorti [ 1 ]], xvec ) dx = np . abs ( x1 - x2 ) return xvec [ np . argmin ( dx )] tile \u00b6 tile_array ( array , tile_shape = ( 200 , 200 ), pad_value = None ) \u00b6 Tile a 2D numpy array Turn a 2D numpy array like array = [[0, 0, 1, 1], ... [0, 0, 1, 1], ... [2, 2, 3, 3], ... [2, 2, 3, 3]] array.shape (4, 4) into a tiled array like tiles = tiled_array(array, 2, 2) print(tiles) [[[0, 0], [0, 0]], [[1, 1], [1, 1]], [[2, 2], [2, 2]], [[3, 3], [3, 3]]] tiles.shape (4, 2, 2) Parameters: Name Type Description Default array Union [ ndarray , MaskedArray ] 2D array to tile required tile_shape Tuple [ int , int ] the shape of each tile (200, 200) pad_value float right-bottom pad a with pad as needed so a is evenly divisible into tiles None Returns: Type Description Union [ ndarray , MaskedArray ] the tiled array Source code in asf_tools/tile.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def tile_array ( array : Union [ np . ndarray , np . ma . MaskedArray ], tile_shape : Tuple [ int , int ] = ( 200 , 200 ), pad_value : float = None ) -> Union [ np . ndarray , np . ma . MaskedArray ]: \"\"\"Tile a 2D numpy array Turn a 2D numpy array like: >>> array = [[0, 0, 1, 1], ... [0, 0, 1, 1], ... [2, 2, 3, 3], ... [2, 2, 3, 3]] >>> array.shape (4, 4) into a tiled array like: >>> tiles = tiled_array(array, 2, 2) >>> print(tiles) [[[0, 0], [0, 0]], [[1, 1], [1, 1]], [[2, 2], [2, 2]], [[3, 3], [3, 3]]] >>> tiles.shape (4, 2, 2) Args: array: 2D array to tile tile_shape: the shape of each tile pad_value: right-bottom pad `a` with `pad` as needed so `a` is evenly divisible into tiles Returns: the tiled array \"\"\" array_rows , array_columns = array . shape tile_rows , tile_columns = tile_shape # CREDIT: https://twitter.com/LizzUltee/status/1379508448262512641 rpad = - array_rows % tile_rows cpad = - array_columns % tile_columns if ( rpad or cpad ) and pad_value is None : raise ValueError ( f 'Cannot evenly tile a { array . shape } array into ( { tile_rows } , { tile_columns } ) tiles' ) if rpad or cpad : padded_array = np . pad ( array , (( 0 , rpad ), ( 0 , cpad )), constant_values = pad_value ) if isinstance ( array , np . ma . MaskedArray ): mask = np . pad ( array . mask , (( 0 , rpad ), ( 0 , cpad )), constant_values = True ) padded_array = np . ma . MaskedArray ( padded_array , mask = mask ) else : padded_array = array tile_list = [] for rows in np . vsplit ( padded_array , range ( tile_rows , array_rows , tile_rows )): tile_list . extend ( np . hsplit ( rows , range ( tile_columns , array_columns , tile_columns ))) dstack = np . ma . dstack if isinstance ( array , np . ma . MaskedArray ) else np . dstack tiled = np . moveaxis ( dstack ( tile_list ), - 1 , 0 ) return tiled untile_array ( tiled_array , array_shape ) \u00b6 Untile a tiled array into a 2D numpy array This is the reverse of tile_array and will turn a tiled array like: >>> tiled_array = [[[0,0], ... [0,0]], ... [[1,1], ... [1,1]], ... [[2,2], ... [2,2]], ... [[3,3], ... [3,3]]] >>> tiled_array.shape (4, 2, 2) into a 2D array like array = untile_array(tiled_array) print(array) [[0, 0, 1, 1], [0, 0, 1, 1], [2, 2, 3, 3], [2, 2, 3, 3]] array.shape (4, 4) Parameters: Name Type Description Default tiled_array Union [ ndarray , MaskedArray ] a tiled array required array_shape Tuple [ int , int ] shape to untile the array to. If array_shape's size is smaller than the tiled array, untile_array will subset the tiled array assuming bottom right padding was added when tiling. required Returns: Type Description Union [ ndarray , MaskedArray ] the untiled array Source code in asf_tools/tile.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def untile_array ( tiled_array : Union [ np . ndarray , np . ma . MaskedArray ], array_shape : Tuple [ int , int ]) \\ -> Union [ np . ndarray , np . ma . MaskedArray ]: \"\"\"Untile a tiled array into a 2D numpy array This is the reverse of `tile_array` and will turn a tiled array like: >>> tiled_array = [[[0,0], ... [0,0]], ... [[1,1], ... [1,1]], ... [[2,2], ... [2,2]], ... [[3,3], ... [3,3]]] >>> tiled_array.shape (4, 2, 2) into a 2D array like: >>> array = untile_array(tiled_array) >>> print(array) [[0, 0, 1, 1], [0, 0, 1, 1], [2, 2, 3, 3], [2, 2, 3, 3]] >>> array.shape (4, 4) Args: tiled_array: a tiled array array_shape: shape to untile the array to. If array_shape's size is smaller than the tiled array, `untile_array` will subset the tiled array assuming bottom right padding was added when tiling. Returns: the untiled array \"\"\" _ , tile_rows , tile_columns = tiled_array . shape array_rows , array_columns = array_shape untiled_rows = int ( np . ceil ( array_rows / tile_rows )) untiled_columns = int ( np . ceil ( array_columns / tile_columns )) untiled = np . zeros (( untiled_rows * tile_rows , untiled_columns * tile_columns ), dtype = tiled_array . dtype ) if ( array_size := array_rows * array_columns ) > tiled_array . size : raise ValueError ( f 'array_shape { array_shape } will result in an array bigger than the tiled array:' f ' { array_size } > { tiled_array . size } ' ) for ii in range ( untiled_rows ): for jj in range ( untiled_columns ): untiled [ ii * tile_rows :( ii + 1 ) * tile_rows , jj * tile_columns :( jj + 1 ) * tile_columns ] = \\ tiled_array [ ii * untiled_columns + jj , :, :] if isinstance ( tiled_array , np . ma . MaskedArray ): untiled_mask = untile_array ( tiled_array . mask , untiled . shape ) untiled = np . ma . MaskedArray ( untiled , mask = untiled_mask ) return untiled [: array_rows , : array_columns ] util \u00b6 GDALConfigManager \u00b6 Context manager for setting GDAL config options temporarily Source code in asf_tools/util.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class GDALConfigManager : \"\"\"Context manager for setting GDAL config options temporarily\"\"\" def __init__ ( self , ** options ): \"\"\" Args: **options: GDAL Config `option=value` keyword arguments. \"\"\" self . options = options . copy () self . _previous_options = {} def __enter__ ( self ): for key in self . options : self . _previous_options [ key ] = gdal . GetConfigOption ( key ) for key , value in self . options . items (): gdal . SetConfigOption ( key , value ) def __exit__ ( self , exc_type , exc_val , exc_tb ): for key , value in self . _previous_options . items (): gdal . SetConfigOption ( key , value ) __init__ ( ** options ) \u00b6 Parameters: Name Type Description Default **options GDAL Config option=value keyword arguments. {} Source code in asf_tools/util.py 8 9 10 11 12 13 14 def __init__ ( self , ** options ): \"\"\" Args: **options: GDAL Config `option=value` keyword arguments. \"\"\" self . options = options . copy () self . _previous_options = {} water_map \u00b6 Generate surface water maps from Sentinel-1 RTC products Create a surface water extent map from a dual-pol Sentinel-1 RTC product and a HAND image. The HAND image must be pixel-aligned (same extent and size) to the RTC images. The water extent maps are created using an adaptive Expectation Maximization thresholding approach and refined using Fuzzy Logic. format_raster_data ( raster , padding_mask = None , nodata = np . iinfo ( np . uint8 ) . max ) \u00b6 Ensure raster data is uint8 and set the area outside the valid data to nodata Source code in asf_tools/water_map.py 136 137 138 139 140 141 142 143 144 145 146 def format_raster_data ( raster , padding_mask = None , nodata = np . iinfo ( np . uint8 ) . max ): \"\"\" Ensure raster data is uint8 and set the area outside the valid data to nodata \"\"\" if padding_mask is None : array = read_as_masked_array ( raster ) padding_mask = array . mask raster = raster . astype ( np . uint8 ) raster [ padding_mask ] = nodata return raster make_water_map ( out_raster , vv_raster , vh_raster , hand_raster = None , tile_shape = ( 100 , 100 ), max_vv_threshold =- 15.5 , max_vh_threshold =- 23.0 , hand_threshold = 15.0 , hand_fraction = 0.8 , membership_threshold = 0.45 ) \u00b6 Creates a surface water extent map from a Sentinel-1 RTC product Create a surface water extent map from a dual-pol Sentinel-1 RTC product and a HAND image. The HAND image must be pixel-aligned (same extent and size) to the RTC images. The water extent maps are created using an adaptive Expectation Maximization thresholding approach and refined with Fuzzy Logic. The input images are broken into a set of corresponding tiles with a shape of tile_shape , and a set of tiles are selected from the VH RTC image that contain water boundaries to determine an appropriate water threshold. Candidate tiles must meet these criteria: * hand_fraction of pixels within a tile must have HAND pixel values lower than hand_threshold * The median backscatter value for the tile must be lower than an average tiles' backscatter values * The tile must have a high variance -- high variance is considered initially to be a variance in the 95th percentile of the tile variances, but progressively relaxed to the 5th percentile if there not at least 5 candidate tiles. The 5 VH tiles with the highest variance are selected for thresholding and a water threshold value is determined using an Expectation Maximization approach. If there were not enough candidate tiles or the threshold is too high, max_vh_threshold and/or max_vv_threshold will be used instead. From the initial threshold-based water extent maps, Fuzzy Logic is used to remove spurious false detections and improve the water extent map quality. The fuzzy logic uses these indicators for the presence of water: * radar cross section in a pixel relative to the determined detection threshold * the height above nearest drainage (HAND) * the surface slope, which is derived from the HAND data * the size of the detected water feature For each indicator, a Z-shaped activation function is used to determine pixel membership. The membership maps are combined to form the final water extent map. Pixels classified as water pixels will: * have non-zero membership in all of the indicators, and * have an average membership above the membership_threshold value. Finally, the VV and VH water masks will be combined to include all water pixels from both masks, and the combined water map will be written to out_raster . Parameters: Name Type Description Default out_raster Union [ str , Path ] Water map GeoTIFF to create required vv_raster Union [ str , Path ] Sentinel-1 RTC GeoTIFF, in power scale, with VV polarization required vh_raster Union [ str , Path ] Sentinel-1 RTC GeoTIFF, in power scale, with VH polarization required hand_raster Optional [ Union [ str , Path ]] Height Above Nearest Drainage (HAND) GeoTIFF aligned to the RTC rasters None tile_shape Tuple [ int , int ] shape (height, width) in pixels to tile the image to (100, 100) max_vv_threshold float Maximum threshold value to use for vv_raster in decibels (db) -15.5 max_vh_threshold float Maximum threshold value to use for vh_raster in decibels (db) -23.0 hand_threshold float The maximum height above nearest drainage in meters to consider a pixel valid 15.0 hand_fraction float The minimum fraction of valid HAND pixels required in a tile for thresholding 0.8 membership_threshold float The average membership to the fuzzy indicators required for a water pixel 0.45 Source code in asf_tools/water_map.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 def make_water_map ( out_raster : Union [ str , Path ], vv_raster : Union [ str , Path ], vh_raster : Union [ str , Path ], hand_raster : Optional [ Union [ str , Path ]] = None , tile_shape : Tuple [ int , int ] = ( 100 , 100 ), max_vv_threshold : float = - 15.5 , max_vh_threshold : float = - 23.0 , hand_threshold : float = 15. , hand_fraction : float = 0.8 , membership_threshold : float = 0.45 ): \"\"\"Creates a surface water extent map from a Sentinel-1 RTC product Create a surface water extent map from a dual-pol Sentinel-1 RTC product and a HAND image. The HAND image must be pixel-aligned (same extent and size) to the RTC images. The water extent maps are created using an adaptive Expectation Maximization thresholding approach and refined with Fuzzy Logic. The input images are broken into a set of corresponding tiles with a shape of `tile_shape`, and a set of tiles are selected from the VH RTC image that contain water boundaries to determine an appropriate water threshold. Candidate tiles must meet these criteria: * `hand_fraction` of pixels within a tile must have HAND pixel values lower than `hand_threshold` * The median backscatter value for the tile must be lower than an average tiles' backscatter values * The tile must have a high variance -- high variance is considered initially to be a variance in the 95th percentile of the tile variances, but progressively relaxed to the 5th percentile if there not at least 5 candidate tiles. The 5 VH tiles with the highest variance are selected for thresholding and a water threshold value is determined using an Expectation Maximization approach. If there were not enough candidate tiles or the threshold is too high, `max_vh_threshold` and/or `max_vv_threshold` will be used instead. From the initial threshold-based water extent maps, Fuzzy Logic is used to remove spurious false detections and improve the water extent map quality. The fuzzy logic uses these indicators for the presence of water: * radar cross section in a pixel relative to the determined detection threshold * the height above nearest drainage (HAND) * the surface slope, which is derived from the HAND data * the size of the detected water feature For each indicator, a Z-shaped activation function is used to determine pixel membership. The membership maps are combined to form the final water extent map. Pixels classified as water pixels will: * have non-zero membership in all of the indicators, and * have an average membership above the `membership_threshold` value. Finally, the VV and VH water masks will be combined to include all water pixels from both masks, and the combined water map will be written to `out_raster`. Args: out_raster: Water map GeoTIFF to create vv_raster: Sentinel-1 RTC GeoTIFF, in power scale, with VV polarization vh_raster: Sentinel-1 RTC GeoTIFF, in power scale, with VH polarization hand_raster: Height Above Nearest Drainage (HAND) GeoTIFF aligned to the RTC rasters tile_shape: shape (height, width) in pixels to tile the image to max_vv_threshold: Maximum threshold value to use for `vv_raster` in decibels (db) max_vh_threshold: Maximum threshold value to use for `vh_raster` in decibels (db) hand_threshold: The maximum height above nearest drainage in meters to consider a pixel valid hand_fraction: The minimum fraction of valid HAND pixels required in a tile for thresholding membership_threshold: The average membership to the fuzzy indicators required for a water pixel \"\"\" if tile_shape [ 0 ] % 2 or tile_shape [ 1 ] % 2 : raise ValueError ( f 'tile_shape { tile_shape } requires even values.' ) info = gdal . Info ( str ( vh_raster ), format = 'json' ) out_transform = info [ 'geoTransform' ] out_epsg = get_epsg_code ( info ) if hand_raster is None : hand_raster = str ( out_raster ) . replace ( '.tif' , '_HAND.tif' ) log . info ( f 'Extracting HAND data to: { hand_raster } ' ) prepare_hand_for_raster ( hand_raster , vh_raster ) log . info ( f 'Determining HAND memberships from { hand_raster } ' ) hand_array = read_as_masked_array ( hand_raster ) hand_tiles = tile_array ( hand_array , tile_shape = tile_shape , pad_value = np . nan ) hand_candidates = select_hand_tiles ( hand_tiles , hand_threshold , hand_fraction ) log . debug ( f 'Selected HAND tile candidates { hand_candidates } ' ) selected_tiles = None nodata = np . iinfo ( np . uint8 ) . max water_extent_maps = [] for max_db_threshold , raster , pol in (( max_vh_threshold , vh_raster , 'VH' ), ( max_vv_threshold , vv_raster , 'VV' )): log . info ( f 'Creating initial { pol } water extent map from { raster } ' ) array = read_as_masked_array ( raster ) padding_mask = array . mask tiles = tile_array ( array , tile_shape = tile_shape , pad_value = 0. ) # Masking less than zero only necessary for old HyP3/GAMMA products which sometimes returned negative powers tiles = np . ma . masked_less_equal ( tiles , 0. ) if selected_tiles is None : selected_tiles = select_backscatter_tiles ( tiles , hand_candidates ) log . info ( f 'Selected tiles { selected_tiles } from { raster } ' ) with np . testing . suppress_warnings () as sup : sup . filter ( RuntimeWarning ) # invalid value and divide by zero encountered in log10 tiles = np . log10 ( tiles ) + 30. # linear power scale -> Gaussian scale optimized for thresholding max_gaussian_threshold = max_db_threshold / 10. + 30. # db -> Gaussian scale optimized for thresholding if selected_tiles . size : scaling = 256 / ( np . mean ( tiles ) + 3 * np . std ( tiles )) gaussian_threshold = determine_em_threshold ( tiles [ selected_tiles , :, :], scaling ) threshold_db = 10. * ( gaussian_threshold - 30. ) log . info ( f 'Threshold determined to be { threshold_db } db' ) if gaussian_threshold > max_gaussian_threshold : log . warning ( f 'Threshold too high! Using maximum threshold { max_db_threshold } db' ) gaussian_threshold = max_gaussian_threshold else : log . warning ( f 'Tile selection did not converge! using default threshold { max_db_threshold } db' ) gaussian_threshold = max_gaussian_threshold gaussian_array = untile_array ( tiles , array . shape ) water_map = np . ma . masked_less_equal ( gaussian_array , gaussian_threshold ) . mask water_map &= ~ array . mask write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { pol } _initial.tif' ), format_raster_data ( water_map , padding_mask , nodata ), transform = out_transform , epsg_code = out_epsg , dtype = gdal . GDT_Byte , nodata_value = nodata ) log . info ( f 'Refining initial { pol } water extent map using Fuzzy Logic' ) array = np . ma . masked_where ( ~ water_map , array ) gaussian_lower_limit = np . log10 ( np . ma . median ( array )) + 30. water_map = fuzzy_refinement ( water_map , gaussian_array , hand_array , pixel_size = out_transform [ 1 ], gaussian_thresholds = ( gaussian_lower_limit , gaussian_threshold ), membership_threshold = membership_threshold ) water_map &= ~ array . mask write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { pol } _fuzzy.tif' ), format_raster_data ( water_map , padding_mask , nodata ), transform = out_transform , epsg_code = out_epsg , dtype = gdal . GDT_Byte , nodata_value = nodata ) water_extent_maps . append ( water_map ) log . info ( 'Combining Fuzzy VH and VV extent map' ) combined_water_map = np . logical_or ( * water_extent_maps ) combined_segments = measure . label ( combined_water_map , connectivity = 2 ) combined_water_map = remove_small_segments ( combined_segments ) write_cog ( out_raster , format_raster_data ( combined_water_map , padding_mask , nodata ), transform = out_transform , epsg_code = out_epsg , dtype = gdal . GDT_Byte , nodata_value = nodata )","title":"API Reference"},{"location":"tools/asf_tools_api/#asf_tools-v052-api-reference","text":"Tools developed by ASF for working with SAR data","title":"asf_tools v0.5.2 API Reference"},{"location":"tools/asf_tools_api/#asf_tools.composite","text":"Create a local-resolution-weighted composite from Sentinel-1 RTC products. Create a local-resolution-weighted composite from a set of Sentinel-1 RTC products (D. Small, 2012). The local resolution, defined as the inverse of the local contributing (scattering) area, is used to weight each RTC products' contributions to the composite image on a pixel-by-pixel basis. The composite image is created as a Cloud Optimized GeoTIFF (COG). Additionally, a COG specifying the number of rasters contributing to each composite pixel is created. References David Small, 2012: https://doi.org/10.1109/IGARSS.2012.6350465","title":"composite"},{"location":"tools/asf_tools_api/#asf_tools.composite.epsg_to_wkt","text":"Get the WKT representation of a projection from its EPSG code Parameters: Name Type Description Default epsg_code int The integer EPSG code required Returns: Name Type Description wkt str The WKT representation of the projection Source code in asf_tools/composite.py 44 45 46 47 48 49 50 51 52 53 54 55 def epsg_to_wkt ( epsg_code : int ) -> str : \"\"\"Get the WKT representation of a projection from its EPSG code Args: epsg_code: The integer EPSG code Returns: wkt: The WKT representation of the projection \"\"\" srs = osr . SpatialReference () srs . ImportFromEPSG ( epsg_code ) return srs . ExportToWkt ()","title":"epsg_to_wkt()"},{"location":"tools/asf_tools_api/#asf_tools.composite.get_area_raster","text":"Determine the path of the area raster for a given backscatter raster based on naming conventions for HyP3 RTC products Parameters: Name Type Description Default raster str path of the backscatter raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_VV.tif required Returns: Name Type Description area_raster str path of the area raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_area.tif Source code in asf_tools/composite.py 86 87 88 89 90 91 92 93 94 95 96 def get_area_raster ( raster : str ) -> str : \"\"\"Determine the path of the area raster for a given backscatter raster based on naming conventions for HyP3 RTC products Args: raster: path of the backscatter raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_VV.tif Returns: area_raster: path of the area raster, e.g. S1A_IW_20181102T155531_DVP_RTC30_G_gpuned_5685_area.tif \"\"\" return '_' . join ( raster . split ( '_' )[: - 1 ] + [ 'area.tif' ])","title":"get_area_raster()"},{"location":"tools/asf_tools_api/#asf_tools.composite.get_epsg_code","text":"Get the EPSG code from a GDAL Info dictionary Parameters: Name Type Description Default info dict The dictionary returned by a gdal.Info call required Returns: Name Type Description epsg_code int The integer EPSG code Source code in asf_tools/composite.py 30 31 32 33 34 35 36 37 38 39 40 41 def get_epsg_code ( info : dict ) -> int : \"\"\"Get the EPSG code from a GDAL Info dictionary Args: info: The dictionary returned by a gdal.Info call Returns: epsg_code: The integer EPSG code \"\"\" proj = osr . SpatialReference ( info [ 'coordinateSystem' ][ 'wkt' ]) epsg_code = int ( proj . GetAttrValue ( 'AUTHORITY' , 1 )) return epsg_code","title":"get_epsg_code()"},{"location":"tools/asf_tools_api/#asf_tools.composite.get_full_extent","text":"Determine the corner coordinates and geotransform for the full extent of a set of rasters Parameters: Name Type Description Default raster_info dict A dictionary of gdal.Info results for the set of rasters required Returns: Name Type Description upper_left The upper left corner of the extent as a tuple upper_right The lower right corner of the extent as a tuple geotransform The geotransform of the extent as a list Source code in asf_tools/composite.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def get_full_extent ( raster_info : dict ): \"\"\"Determine the corner coordinates and geotransform for the full extent of a set of rasters Args: raster_info: A dictionary of gdal.Info results for the set of rasters Returns: upper_left: The upper left corner of the extent as a tuple upper_right: The lower right corner of the extent as a tuple geotransform: The geotransform of the extent as a list \"\"\" upper_left_corners = [ info [ 'cornerCoordinates' ][ 'upperLeft' ] for info in raster_info . values ()] lower_right_corners = [ info [ 'cornerCoordinates' ][ 'lowerRight' ] for info in raster_info . values ()] ulx = min ([ ul [ 0 ] for ul in upper_left_corners ]) uly = max ([ ul [ 1 ] for ul in upper_left_corners ]) lrx = max ([ lr [ 0 ] for lr in lower_right_corners ]) lry = min ([ lr [ 1 ] for lr in lower_right_corners ]) log . debug ( f 'Full extent raster upper left: ( { ulx , uly } ); lower right: ( { lrx , lry } )' ) trans = [] for info in raster_info . values (): # Only need info from any one raster trans = info [ 'geoTransform' ] break trans [ 0 ] = ulx trans [ 3 ] = uly return ( ulx , uly ), ( lrx , lry ), trans","title":"get_full_extent()"},{"location":"tools/asf_tools_api/#asf_tools.composite.get_target_epsg_code","text":"Determine the target UTM EPSG projection for the output composite Parameters: Name Type Description Default codes List [ int ] List of UTM EPSG codes required Returns: Name Type Description target int UTM EPSG code Source code in asf_tools/composite.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def get_target_epsg_code ( codes : List [ int ]) -> int : \"\"\"Determine the target UTM EPSG projection for the output composite Args: codes: List of UTM EPSG codes Returns: target: UTM EPSG code \"\"\" # use median east/west UTM zone of all files, regardless of hemisphere # UTM EPSG codes for each hemisphere will look like: # North: 326XX # South: 327XX valid_codes = list ( range ( 32601 , 32661 )) + list ( range ( 32701 , 32761 )) if bad_codes := set ( codes ) - set ( valid_codes ): raise ValueError ( f 'Non UTM EPSG code encountered: { bad_codes } ' ) hemispheres = [ c // 100 * 100 for c in codes ] # if even modes, choose lowest (North) target_hemisphere = min ( multimode ( hemispheres )) zones = sorted ([ c % 100 for c in codes ]) # if even length, choose fist of median two target_zone = zones [( len ( zones ) - 1 ) // 2 ] return target_hemisphere + target_zone","title":"get_target_epsg_code()"},{"location":"tools/asf_tools_api/#asf_tools.composite.make_composite","text":"Creates a local-resolution-weighted composite from Sentinel-1 RTC products Parameters: Name Type Description Default out_name str The base name of the output GeoTIFFs required rasters List [ str ] A list of file paths of the images to composite required resolution float The pixel size for the output GeoTIFFs None Returns: Name Type Description out_raster Path to the created composite backscatter GeoTIFF out_counts_raster Path to the created GeoTIFF with counts of scenes contributing to each pixel Source code in asf_tools/composite.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 def make_composite ( out_name : str , rasters : List [ str ], resolution : float = None ): \"\"\"Creates a local-resolution-weighted composite from Sentinel-1 RTC products Args: out_name: The base name of the output GeoTIFFs rasters: A list of file paths of the images to composite resolution: The pixel size for the output GeoTIFFs Returns: out_raster: Path to the created composite backscatter GeoTIFF out_counts_raster: Path to the created GeoTIFF with counts of scenes contributing to each pixel \"\"\" if not rasters : raise ValueError ( 'Must specify at least one raster to composite' ) raster_info = {} for raster in rasters : raster_info [ raster ] = gdal . Info ( raster , format = 'json' ) # make sure gdal can read the area raster gdal . Info ( get_area_raster ( raster )) target_epsg_code = get_target_epsg_code ([ get_epsg_code ( info ) for info in raster_info . values ()]) log . debug ( f 'Composite projection is EPSG: { target_epsg_code } ' ) if resolution is None : resolution = max ([ info [ 'geoTransform' ][ 1 ] for info in raster_info . values ()]) log . debug ( f 'Composite resolution is { resolution } meters' ) # resample rasters to maximum resolution & common UTM zone with TemporaryDirectory ( prefix = 'reprojected_' ) as temp_dir : raster_info = reproject_to_target ( raster_info , target_epsg_code = target_epsg_code , target_resolution = resolution , directory = temp_dir ) # Get extent of union of all images full_ul , full_lr , full_trans = get_full_extent ( raster_info ) nx = int ( abs ( full_ul [ 0 ] - full_lr [ 0 ]) // resolution ) ny = int ( abs ( full_ul [ 1 ] - full_lr [ 1 ]) // resolution ) outputs = np . zeros (( ny , nx )) weights = np . zeros ( outputs . shape ) counts = np . zeros ( outputs . shape , dtype = np . int8 ) for raster , info in raster_info . items (): log . info ( f 'Processing raster { raster } ' ) log . debug ( f \"Raster upper left: { info [ 'cornerCoordinates' ][ 'upperLeft' ] } ; \" f \"lower right: { info [ 'cornerCoordinates' ][ 'lowerRight' ] } \" ) values = read_as_array ( raster ) area_raster = get_area_raster ( raster ) areas = read_as_array ( area_raster ) ulx , uly = info [ 'cornerCoordinates' ][ 'upperLeft' ] y_index_start = int (( full_ul [ 1 ] - uly ) // resolution ) y_index_end = y_index_start + values . shape [ 0 ] x_index_start = int (( ulx - full_ul [ 0 ]) // resolution ) x_index_end = x_index_start + values . shape [ 1 ] log . debug ( f 'Placing values in output grid at { y_index_start } : { y_index_end } and { x_index_start } : { x_index_end } ' ) mask = values == 0 raster_weights = 1.0 / areas raster_weights [ mask ] = 0 outputs [ y_index_start : y_index_end , x_index_start : x_index_end ] += values * raster_weights weights [ y_index_start : y_index_end , x_index_start : x_index_end ] += raster_weights counts [ y_index_start : y_index_end , x_index_start : x_index_end ] += ~ mask del values , areas , mask , raster_weights # Divide by the total weight applied outputs /= weights del weights out_raster = write_cog ( f ' { out_name } .tif' , outputs , full_trans , target_epsg_code , nodata_value = 0 ) del outputs out_counts_raster = write_cog ( f ' { out_name } _counts.tif' , counts , full_trans , target_epsg_code , dtype = gdal . GDT_Int16 ) del counts return out_raster , out_counts_raster","title":"make_composite()"},{"location":"tools/asf_tools_api/#asf_tools.composite.read_as_array","text":"Reads data from a raster image into memory Parameters: Name Type Description Default raster str The file path to a raster image required band int The raster band to read 1 Returns: Name Type Description data array The raster pixel data as a numpy array Source code in asf_tools/composite.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def read_as_array ( raster : str , band : int = 1 ) -> np . array : \"\"\"Reads data from a raster image into memory Args: raster: The file path to a raster image band: The raster band to read Returns: data: The raster pixel data as a numpy array \"\"\" log . debug ( f 'Reading raster values from { raster } ' ) ds = gdal . Open ( raster ) data = ds . GetRasterBand ( band ) . ReadAsArray () del ds # How to close w/ gdal return data","title":"read_as_array()"},{"location":"tools/asf_tools_api/#asf_tools.composite.reproject_to_target","text":"Reprojects a set of raster images to a common projection and resolution Parameters: Name Type Description Default raster_info dict A dictionary of gdal.Info results for the set of rasters required target_epsg_code int The integer EPSG code for the target projection required target_resolution float The target resolution required directory str The directory in which to create the reprojected files required Returns: Name Type Description target_raster_info dict An updated dictionary of gdal.Info results for the reprojected files Source code in asf_tools/composite.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 def reproject_to_target ( raster_info : dict , target_epsg_code : int , target_resolution : float , directory : str ) -> dict : \"\"\"Reprojects a set of raster images to a common projection and resolution Args: raster_info: A dictionary of gdal.Info results for the set of rasters target_epsg_code: The integer EPSG code for the target projection target_resolution: The target resolution directory: The directory in which to create the reprojected files Returns: target_raster_info: An updated dictionary of gdal.Info results for the reprojected files \"\"\" target_raster_info = {} for raster , info in raster_info . items (): epsg_code = get_epsg_code ( info ) resolution = info [ 'geoTransform' ][ 1 ] if epsg_code != target_epsg_code or resolution != target_resolution : log . info ( f 'Reprojecting { raster } ' ) reprojected_raster = os . path . join ( directory , os . path . basename ( raster )) gdal . Warp ( reprojected_raster , raster , dstSRS = f 'EPSG: { target_epsg_code } ' , xRes = target_resolution , yRes = target_resolution , targetAlignedPixels = True ) area_raster = get_area_raster ( raster ) log . info ( f 'Reprojecting { area_raster } ' ) reprojected_area_raster = os . path . join ( directory , os . path . basename ( area_raster )) gdal . Warp ( reprojected_area_raster , area_raster , dstSRS = f 'EPSG: { target_epsg_code } ' , xRes = target_resolution , yRes = target_resolution , targetAlignedPixels = True ) target_raster_info [ reprojected_raster ] = gdal . Info ( reprojected_raster , format = 'json' ) else : log . info ( f 'No need to reproject { raster } ' ) target_raster_info [ raster ] = info return target_raster_info","title":"reproject_to_target()"},{"location":"tools/asf_tools_api/#asf_tools.composite.write_cog","text":"Creates a Cloud Optimized GeoTIFF Parameters: Name Type Description Default file_name Union [ str , Path ] The output file name required data ndarray The raster data required transform List [ float ] The geotransform for the output GeoTIFF required epsg_code int The integer EPSG code for the output GeoTIFF projection required dtype The pixel data type for the output GeoTIFF GDT_Float32 nodata_value The NODATA value for the output Geotiff None Returns: Name Type Description file_name The output file name Source code in asf_tools/composite.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 def write_cog ( file_name : Union [ str , Path ], data : np . ndarray , transform : List [ float ], epsg_code : int , dtype = gdal . GDT_Float32 , nodata_value = None ): \"\"\"Creates a Cloud Optimized GeoTIFF Args: file_name: The output file name data: The raster data transform: The geotransform for the output GeoTIFF epsg_code: The integer EPSG code for the output GeoTIFF projection dtype: The pixel data type for the output GeoTIFF nodata_value: The NODATA value for the output Geotiff Returns: file_name: The output file name \"\"\" log . info ( f 'Creating { file_name } ' ) with NamedTemporaryFile () as temp_file : driver = gdal . GetDriverByName ( 'GTiff' ) temp_geotiff = driver . Create ( temp_file . name , data . shape [ 1 ], data . shape [ 0 ], 1 , dtype ) temp_geotiff . GetRasterBand ( 1 ) . WriteArray ( data ) if nodata_value is not None : temp_geotiff . GetRasterBand ( 1 ) . SetNoDataValue ( nodata_value ) temp_geotiff . SetGeoTransform ( transform ) temp_geotiff . SetProjection ( epsg_to_wkt ( epsg_code )) driver = gdal . GetDriverByName ( 'COG' ) options = [ 'COMPRESS=LZW' , 'OVERVIEW_RESAMPLING=AVERAGE' , 'NUM_THREADS=ALL_CPUS' , 'BIGTIFF=YES' ] driver . CreateCopy ( str ( file_name ), temp_geotiff , options = options ) del temp_geotiff # How to close w/ gdal return file_name","title":"write_cog()"},{"location":"tools/asf_tools_api/#asf_tools.dem","text":"Prepare a Copernicus GLO-30 DEM virtual raster (VRT) covering a given geometry","title":"dem"},{"location":"tools/asf_tools_api/#asf_tools.dem.prepare_dem_vrt","text":"Create a DEM mosaic VRT covering a given geometry The DEM mosaic is assembled from the Copernicus GLO-30 DEM tiles that intersect the geometry. Note: asf_tools does not currently support geometries that cross the antimeridian. Parameters: Name Type Description Default vrt Union [ str , Path ] Path for the output VRT file required geometry Union [ Geometry , BaseGeometry ] Geometry in EPSG:4326 (lon/lat) projection for which to prepare a DEM mosaic required Source code in asf_tools/dem.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def prepare_dem_vrt ( vrt : Union [ str , Path ], geometry : Union [ ogr . Geometry , BaseGeometry ]): \"\"\"Create a DEM mosaic VRT covering a given geometry The DEM mosaic is assembled from the Copernicus GLO-30 DEM tiles that intersect the geometry. Note: `asf_tools` does not currently support geometries that cross the antimeridian. Args: vrt: Path for the output VRT file geometry: Geometry in EPSG:4326 (lon/lat) projection for which to prepare a DEM mosaic \"\"\" with GDALConfigManager ( GDAL_DISABLE_READDIR_ON_OPEN = 'EMPTY_DIR' ): if isinstance ( geometry , BaseGeometry ): geometry = ogr . CreateGeometryFromWkb ( geometry . wkb ) min_lon , max_lon , _ , _ = geometry . GetEnvelope () if min_lon < - 160. and max_lon > 160. : raise ValueError ( f 'asf_tools does not currently support geometries that cross the antimeridian: { geometry } ' ) tile_features = vector . get_features ( DEM_GEOJSON ) if not vector . get_property_values_for_intersecting_features ( geometry , tile_features ): raise ValueError ( f 'Copernicus GLO-30 DEM does not intersect this geometry: { geometry } ' ) dem_file_paths = vector . intersecting_feature_properties ( geometry , tile_features , 'file_path' ) gdal . BuildVRT ( str ( vrt ), dem_file_paths )","title":"prepare_dem_vrt()"},{"location":"tools/asf_tools_api/#asf_tools.flood_map","text":"Generate flood depth map from surface water extent map. Create a flood depth map from a surface water extent map and a HAND image. The HAND image must be pixel-aligned (same extent and size) to the water extent map, and the surface water extent map should be a byte GeoTIFF indicating water (true), not water (false). Flood depth maps are estimated using either a numerical, normalized median absolute deviation, logarithmic or iterative approach.","title":"flood_map"},{"location":"tools/asf_tools_api/#asf_tools.flood_map.logstat","text":"Calculate a function in logarithmic scale and return in linear scale. INF values inside the data array are set to nan. Parameters: Name Type Description Default data ndarray array of data required func Callable statistical function to calculate in logarithmic scale nanstd Returns: statistic: statistic of data in linear scale Source code in asf_tools/flood_map.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def logstat ( data : np . ndarray , func : Callable = np . nanstd ) -> Union [ np . ndarray , float ]: \"\"\" Calculate a function in logarithmic scale and return in linear scale. INF values inside the data array are set to nan. Args: data: array of data func: statistical function to calculate in logarithmic scale Returns: statistic: statistic of data in linear scale \"\"\" ld = np . log ( data ) ld [ np . isinf ( ld )] = np . nan st = func ( ld ) return np . exp ( st )","title":"logstat()"},{"location":"tools/asf_tools_api/#asf_tools.flood_map.make_flood_map","text":"Create a flood depth map from a surface water extent map. WARNING: This functionality is still under active development and the products created using this function are likely to change in the future. Create a flood depth map from a single surface water extent map and a HAND image. The HAND image must be pixel-aligned to the surface water extent map. The surface water extent map should be a byte GeoTIFF indicating water (true) and not water (false) Known perennial Global Surface-water data are produced under the Copernicus Programme (Pekel et al., 2016), and are included with surface-water detection maps when generating the flood depth product. Flood depth maps are estimated using one of the approaches: Iterative: (Default) Basin hopping optimization method matches flooded areas to flood depth estimates given by the HAND layer. This is the most accurate method but also the most time-intensive. Normalized Median Absolute Deviation (nmad): Uses a median operator to estimate the variation to increase robustness in the presence of outliers. Logstat: Calculates the mean and standard deviation of HAND heights in the logarithmic domain to improve robustness for very non-Gaussian data distributions. Numpy: Calculates statistics on a linear scale. Least robust to outliers and non-Gaussian distributions. Parameters: Name Type Description Default out_raster Union [ str , Path ] Flood depth GeoTIFF to create required vv_raster Union [ str , Path ] Sentinel-1 RTC GeoTIFF, in power scale, with VV polarization required water_raster Union [ str , Path ] Surface water extent GeoTIFF required hand_raster Union [ str , Path ] Height Above Nearest Drainage (HAND) GeoTIFF aligned to the surface water extent raster required estimator str Estimation approach for determining flood depth 'iterative' water_level_sigma float Max water height used in logstat, nmad, and numpy estimations 3.0 known_water_threshold float Threshold for extracting the known water area in percent 30.0 iterative_bounds Tuple [ int , int ] Bounds on basin-hopping algorithm used in iterative estimation (0, 15) References Jean-Francios Pekel, Andrew Cottam, Noel Gorelik, Alan S. Belward. 2016. https://doi:10.1038/nature20584 Source code in asf_tools/flood_map.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 def make_flood_map ( out_raster : Union [ str , Path ], vv_raster : Union [ str , Path ], water_raster : Union [ str , Path ], hand_raster : Union [ str , Path ], estimator : str = 'iterative' , water_level_sigma : float = 3. , known_water_threshold : float = 30. , iterative_bounds : Tuple [ int , int ] = ( 0 , 15 )): \"\"\"Create a flood depth map from a surface water extent map. WARNING: This functionality is still under active development and the products created using this function are likely to change in the future. Create a flood depth map from a single surface water extent map and a HAND image. The HAND image must be pixel-aligned to the surface water extent map. The surface water extent map should be a byte GeoTIFF indicating water (true) and not water (false) Known perennial Global Surface-water data are produced under the Copernicus Programme (Pekel et al., 2016), and are included with surface-water detection maps when generating the flood depth product. Flood depth maps are estimated using one of the approaches: *Iterative: (Default) Basin hopping optimization method matches flooded areas to flood depth estimates given by the HAND layer. This is the most accurate method but also the most time-intensive. *Normalized Median Absolute Deviation (nmad): Uses a median operator to estimate the variation to increase robustness in the presence of outliers. *Logstat: Calculates the mean and standard deviation of HAND heights in the logarithmic domain to improve robustness for very non-Gaussian data distributions. *Numpy: Calculates statistics on a linear scale. Least robust to outliers and non-Gaussian distributions. Args: out_raster: Flood depth GeoTIFF to create vv_raster: Sentinel-1 RTC GeoTIFF, in power scale, with VV polarization water_raster: Surface water extent GeoTIFF hand_raster: Height Above Nearest Drainage (HAND) GeoTIFF aligned to the surface water extent raster estimator: Estimation approach for determining flood depth water_level_sigma: Max water height used in logstat, nmad, and numpy estimations known_water_threshold: Threshold for extracting the known water area in percent iterative_bounds: Bounds on basin-hopping algorithm used in iterative estimation References: Jean-Francios Pekel, Andrew Cottam, Noel Gorelik, Alan S. Belward. 2016. <https://doi:10.1038/nature20584> \"\"\" info = gdal . Info ( str ( water_raster ), format = 'json' ) epsg = get_epsg_code ( info ) geotransform = info [ 'geoTransform' ] hand_array = gdal . Open ( str ( hand_raster ), gdal . GA_ReadOnly ) . ReadAsArray () log . info ( 'Fetching perennial flood data.' ) known_water_mask = get_waterbody ( info , threshold = known_water_threshold ) write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { estimator } _PW.tif' ), known_water_mask , transform = geotransform , epsg_code = epsg , dtype = gdal . GDT_Byte , nodata_value = False ) water_map = gdal . Open ( str ( water_raster )) . ReadAsArray () flood_mask = np . logical_or ( water_map , known_water_mask ) del water_map vv_array = read_as_masked_array ( vv_raster ) flood_mask [ vv_array . mask ] = False padding_mask = vv_array . mask del vv_array labeled_flood_mask , num_labels = ndimage . label ( flood_mask ) object_slices = ndimage . find_objects ( labeled_flood_mask ) log . info ( f 'Detected { num_labels } water bodies...' ) flood_depth = np . zeros ( flood_mask . shape ) for ll in tqdm ( range ( 1 , num_labels )): # Skip first, largest label. slices = object_slices [ ll - 1 ] min0 , max0 = slices [ 0 ] . start , slices [ 0 ] . stop min1 , max1 = slices [ 1 ] . start , slices [ 1 ] . stop flood_window = labeled_flood_mask [ min0 : max0 , min1 : max1 ] hand_window = hand_array [ min0 : max0 , min1 : max1 ] water_height = estimate_flood_depth ( ll , hand_window , flood_window , estimator = estimator , water_level_sigma = water_level_sigma , iterative_bounds = iterative_bounds ) flood_depth_window = flood_depth [ min0 : max0 , min1 : max1 ] flood_depth_window [ flood_window == ll ] = water_height - hand_window [ flood_window == ll ] flood_depth [ flood_depth < 0 ] = 0 nodata = - 1 flood_depth [ padding_mask ] = nodata floodmask_nodata = np . iinfo ( np . uint8 ) . max flood_mask_byte = flood_mask . astype ( np . uint8 ) flood_mask_byte [ padding_mask ] = floodmask_nodata write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { estimator } _WaterDepth.tif' ), flood_depth , transform = geotransform , epsg_code = epsg , dtype = gdal . GDT_Float64 , nodata_value = nodata ) write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { estimator } _FloodMask.tif' ), flood_mask_byte , transform = geotransform , epsg_code = epsg , dtype = gdal . GDT_Byte , nodata_value = floodmask_nodata ) flood_mask [ known_water_mask ] = False flood_depth [ np . logical_not ( flood_mask )] = 0 flood_depth [ padding_mask ] = nodata write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { estimator } _FloodDepth.tif' ), flood_depth , transform = geotransform , epsg_code = epsg , dtype = gdal . GDT_Float64 , nodata_value = nodata )","title":"make_flood_map()"},{"location":"tools/asf_tools_api/#asf_tools.hand","text":"","title":"hand"},{"location":"tools/asf_tools_api/#asf_tools.hand.calculate_hand_for_basins","text":"Calculate the Height Above Nearest Drainage (HAND) for watershed boundaries (hydrobasins). For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Parameters: Name Type Description Default out_raster Union [ str , Path ] HAND GeoTIFF to create required geometries GeometryCollection watershed boundary (hydrobasin) polygons to calculate HAND over required dem_file Union [ str , Path ] DEM raster covering (containing) geometries required acc_thresh Optional [ int ] Accumulation threshold for determining the drainage mask. If None , the mean accumulation value is used 100 Source code in 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def calculate_hand_for_basins ( out_raster : Union [ str , Path ], geometries : GeometryCollection , dem_file : Union [ str , Path ], acc_thresh : Optional [ int ] = 100 ): \"\"\"Calculate the Height Above Nearest Drainage (HAND) for watershed boundaries (hydrobasins). For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Args: out_raster: HAND GeoTIFF to create geometries: watershed boundary (hydrobasin) polygons to calculate HAND over dem_file: DEM raster covering (containing) `geometries` acc_thresh: Accumulation threshold for determining the drainage mask. If `None`, the mean accumulation value is used \"\"\" with rasterio . open ( dem_file ) as src : basin_mask , basin_affine_tf , basin_window = rasterio . mask . raster_geometry_mask ( src , geometries . geoms , all_touched = True , crop = True , pad = True , pad_width = 1 ) basin_array = src . read ( 1 , window = basin_window ) hand = calculate_hand ( basin_array , basin_affine_tf , src . crs , basin_mask , acc_thresh = acc_thresh ) write_cog ( out_raster , hand , transform = basin_affine_tf . to_gdal (), epsg_code = src . crs . to_epsg (), nodata_value = np . nan , )","title":"calculate_hand_for_basins()"},{"location":"tools/asf_tools_api/#asf_tools.hand.make_copernicus_hand","text":"Copernicus GLO-30 Height Above Nearest Drainage (HAND) Make a Height Above Nearest Drainage (HAND) GeoTIFF from the Copernicus GLO-30 DEM covering the watershed boundaries (hydrobasins) defined in a vector file. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Parameters: Name Type Description Default out_raster Union [ str , Path ] HAND GeoTIFF to create required vector_file Union [ str , Path ] Vector file of watershed boundary (hydrobasin) polygons to calculate HAND over required acc_thresh Optional [ int ] Accumulation threshold for determining the drainage mask. If None , the mean accumulation value is used 100 Source code in 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def make_copernicus_hand ( out_raster : Union [ str , Path ], vector_file : Union [ str , Path ], acc_thresh : Optional [ int ] = 100 ): \"\"\"Copernicus GLO-30 Height Above Nearest Drainage (HAND) Make a Height Above Nearest Drainage (HAND) GeoTIFF from the Copernicus GLO-30 DEM covering the watershed boundaries (hydrobasins) defined in a vector file. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Args: out_raster: HAND GeoTIFF to create vector_file: Vector file of watershed boundary (hydrobasin) polygons to calculate HAND over acc_thresh: Accumulation threshold for determining the drainage mask. If `None`, the mean accumulation value is used \"\"\" with fiona . open ( vector_file ) as vds : geometries = GeometryCollection ([ shape ( feature [ 'geometry' ]) for feature in vds ]) with NamedTemporaryFile ( suffix = '.vrt' , delete = False ) as dem_vrt : prepare_dem_vrt ( dem_vrt . name , geometries ) calculate_hand_for_basins ( out_raster , geometries , dem_vrt . name , acc_thresh = acc_thresh )","title":"make_copernicus_hand()"},{"location":"tools/asf_tools_api/#asf_tools.hand.prepare_hand_vrt","text":"Prepare a HAND mosaic VRT covering a given geometry Prepare a Height Above Nearest Drainage (HAND) virtual raster (VRT) covering a given geometry. The Height Above Nearest Drainage (HAND) mosaic is assembled from the HAND tiles that intersect the geometry, using a HAND derived from the Copernicus GLO-30 DEM. Note: asf_tools does not currently support geometries that cross the antimeridian. Parameters: Name Type Description Default vrt Union [ str , Path ] Path for the output VRT file required geometry Union [ Geometry , BaseGeometry ] Geometry in EPSG:4326 (lon/lat) projection for which to prepare a HAND mosaic required Source code in 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def prepare_hand_vrt ( vrt : Union [ str , Path ], geometry : Union [ ogr . Geometry , BaseGeometry ]): \"\"\"Prepare a HAND mosaic VRT covering a given geometry Prepare a Height Above Nearest Drainage (HAND) virtual raster (VRT) covering a given geometry. The Height Above Nearest Drainage (HAND) mosaic is assembled from the HAND tiles that intersect the geometry, using a HAND derived from the Copernicus GLO-30 DEM. Note: `asf_tools` does not currently support geometries that cross the antimeridian. Args: vrt: Path for the output VRT file geometry: Geometry in EPSG:4326 (lon/lat) projection for which to prepare a HAND mosaic \"\"\" with GDALConfigManager ( GDAL_DISABLE_READDIR_ON_OPEN = 'EMPTY_DIR' ): if isinstance ( geometry , BaseGeometry ): geometry = ogr . CreateGeometryFromWkb ( geometry . wkb ) min_lon , max_lon , _ , _ = geometry . GetEnvelope () if min_lon < - 160. and max_lon > 160. : raise ValueError ( f 'asf_tools does not currently support geometries that cross the antimeridian: { geometry } ' ) tile_features = vector . get_features ( HAND_GEOJSON ) if not vector . get_property_values_for_intersecting_features ( geometry , tile_features ): raise ValueError ( f 'Copernicus GLO-30 HAND does not intersect this geometry: { geometry } ' ) hand_file_paths = vector . intersecting_feature_properties ( geometry , tile_features , 'file_path' ) gdal . BuildVRT ( str ( vrt ), hand_file_paths )","title":"prepare_hand_vrt()"},{"location":"tools/asf_tools_api/#asf_tools.hand.calculate","text":"Calculate Height Above Nearest Drainage (HAND) from the Copernicus GLO-30 DEM","title":"calculate"},{"location":"tools/asf_tools_api/#asf_tools.hand.calculate.calculate_hand","text":"Calculate the Height Above Nearest Drainage (HAND) Calculate the Height Above Nearest Drainage (HAND) using pySHEDS library. Because HAND is tied to watershed boundaries (hydrobasins), clipped/cut basins will produce weird edge effects, and incomplete basins should be masked out. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins This involves: * Filling pits (single-cells lower than their surrounding neighbors) in the Digital Elevation Model (DEM) * Filling depressions (regions of cells lower than their surrounding neighbors) in the Digital Elevation Model (DEM) * Resolving un-drainable flats * Determining the flow direction using the ESRI D8 routing scheme * Determining flow accumulation (number of upstream cells) * Creating a drainage mask using the accumulation threshold acc_thresh * Calculating HAND In the HAND calculation, NaNs inside the basin filled using fill_hand Parameters: Name Type Description Default dem_array DEM to calculate HAND for required dem_crs CRS DEM Coordinate Reference System (CRS) required dem_affine Affine DEM Affine geotransform required basin_mask Array of booleans indicating wither an element should be masked out (\u00e0 la Numpy Masked Arrays: https://numpy.org/doc/stable/reference/maskedarray.generic.html#what-is-a-masked-array) required acc_thresh Optional [ int ] Accumulation threshold for determining the drainage mask. If None , the mean accumulation value is used 100 Source code in asf_tools/hand/calculate.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def calculate_hand ( dem_array , dem_affine : rasterio . Affine , dem_crs : rasterio . crs . CRS , basin_mask , acc_thresh : Optional [ int ] = 100 ): \"\"\"Calculate the Height Above Nearest Drainage (HAND) Calculate the Height Above Nearest Drainage (HAND) using pySHEDS library. Because HAND is tied to watershed boundaries (hydrobasins), clipped/cut basins will produce weird edge effects, and incomplete basins should be masked out. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins This involves: * Filling pits (single-cells lower than their surrounding neighbors) in the Digital Elevation Model (DEM) * Filling depressions (regions of cells lower than their surrounding neighbors) in the Digital Elevation Model (DEM) * Resolving un-drainable flats * Determining the flow direction using the ESRI D8 routing scheme * Determining flow accumulation (number of upstream cells) * Creating a drainage mask using the accumulation threshold `acc_thresh` * Calculating HAND In the HAND calculation, NaNs inside the basin filled using `fill_hand` Args: dem_array: DEM to calculate HAND for dem_crs: DEM Coordinate Reference System (CRS) dem_affine: DEM Affine geotransform basin_mask: Array of booleans indicating wither an element should be masked out (\u00e0 la Numpy Masked Arrays: https://numpy.org/doc/stable/reference/maskedarray.generic.html#what-is-a-masked-array) acc_thresh: Accumulation threshold for determining the drainage mask. If `None`, the mean accumulation value is used \"\"\" nodata_fill_value = np . finfo ( float ) . eps with NamedTemporaryFile () as temp_file : write_cog ( temp_file . name , dem_array , transform = dem_affine . to_gdal (), epsg_code = dem_crs . to_epsg (), # Prevents PySheds from assuming using zero as the nodata value nodata_value = nodata_fill_value ) # From PySheds; see example usage: http://mattbartos.com/pysheds/ grid = sGrid . from_raster ( str ( temp_file . name )) dem = grid . read_raster ( str ( temp_file . name )) log . info ( 'Fill pits in DEM' ) pit_filled_dem = grid . fill_pits ( dem ) log . info ( 'Filling depressions' ) flooded_dem = grid . fill_depressions ( pit_filled_dem ) del pit_filled_dem log . info ( 'Resolving flats' ) inflated_dem = grid . resolve_flats ( flooded_dem ) del flooded_dem log . info ( 'Obtaining flow direction' ) flow_dir = grid . flowdir ( inflated_dem , apply_mask = True ) log . info ( 'Calculating flow accumulation' ) acc = grid . accumulation ( flow_dir ) if acc_thresh is None : acc_thresh = acc . mean () log . info ( f 'Calculating HAND using accumulation threshold of { acc_thresh } ' ) hand = grid . compute_hand ( flow_dir , inflated_dem , acc > acc_thresh , inplace = False ) if np . isnan ( hand ) . any (): log . info ( 'Filling NaNs in the HAND' ) # mask outside of basin with a not-NaN value to prevent NaN-filling outside of basin (optimization) hand [ basin_mask ] = nodata_fill_value hand = fill_hand ( hand , dem_array ) # set pixels outside of basin to nodata hand [ basin_mask ] = np . nan # TODO: also mask ocean pixels here? return hand","title":"calculate_hand()"},{"location":"tools/asf_tools_api/#asf_tools.hand.calculate.calculate_hand_for_basins","text":"Calculate the Height Above Nearest Drainage (HAND) for watershed boundaries (hydrobasins). For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Parameters: Name Type Description Default out_raster Union [ str , Path ] HAND GeoTIFF to create required geometries GeometryCollection watershed boundary (hydrobasin) polygons to calculate HAND over required dem_file Union [ str , Path ] DEM raster covering (containing) geometries required acc_thresh Optional [ int ] Accumulation threshold for determining the drainage mask. If None , the mean accumulation value is used 100 Source code in asf_tools/hand/calculate.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def calculate_hand_for_basins ( out_raster : Union [ str , Path ], geometries : GeometryCollection , dem_file : Union [ str , Path ], acc_thresh : Optional [ int ] = 100 ): \"\"\"Calculate the Height Above Nearest Drainage (HAND) for watershed boundaries (hydrobasins). For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Args: out_raster: HAND GeoTIFF to create geometries: watershed boundary (hydrobasin) polygons to calculate HAND over dem_file: DEM raster covering (containing) `geometries` acc_thresh: Accumulation threshold for determining the drainage mask. If `None`, the mean accumulation value is used \"\"\" with rasterio . open ( dem_file ) as src : basin_mask , basin_affine_tf , basin_window = rasterio . mask . raster_geometry_mask ( src , geometries . geoms , all_touched = True , crop = True , pad = True , pad_width = 1 ) basin_array = src . read ( 1 , window = basin_window ) hand = calculate_hand ( basin_array , basin_affine_tf , src . crs , basin_mask , acc_thresh = acc_thresh ) write_cog ( out_raster , hand , transform = basin_affine_tf . to_gdal (), epsg_code = src . crs . to_epsg (), nodata_value = np . nan , )","title":"calculate_hand_for_basins()"},{"location":"tools/asf_tools_api/#asf_tools.hand.calculate.fill_hand","text":"Replace NaNs in a HAND array with values interpolated from their neighbor's HOND Replace NaNs in a HAND array with values interpolated from their neighbor's HOND (height of nearest drainage) using a 2D Gaussian kernel. Here, HOND is defined as the DEM value less the HAND value. For the kernel, see: https://docs.astropy.org/en/stable/convolution/#using-astropy-s-convolution-to-replace-bad-data Source code in asf_tools/hand/calculate.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def fill_hand ( hand : np . ndarray , dem : np . ndarray ): \"\"\"Replace NaNs in a HAND array with values interpolated from their neighbor's HOND Replace NaNs in a HAND array with values interpolated from their neighbor's HOND (height of nearest drainage) using a 2D Gaussian kernel. Here, HOND is defined as the DEM value less the HAND value. For the kernel, see: https://docs.astropy.org/en/stable/convolution/#using-astropy-s-convolution-to-replace-bad-data \"\"\" hond = dem - hand hond = fill_nan ( hond ) hand_mask = np . isnan ( hand ) hand [ hand_mask ] = dem [ hand_mask ] - hond [ hand_mask ] hand [ hand < 0 ] = 0 return hand","title":"fill_hand()"},{"location":"tools/asf_tools_api/#asf_tools.hand.calculate.fill_nan","text":"Replace NaNs with values interpolated from their neighbors Replace NaNs with values interpolated from their neighbors using a 2D Gaussian kernel, see: https://docs.astropy.org/en/stable/convolution/#using-astropy-s-convolution-to-replace-bad-data Source code in asf_tools/hand/calculate.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def fill_nan ( array : np . ndarray ) -> np . ndarray : \"\"\"Replace NaNs with values interpolated from their neighbors Replace NaNs with values interpolated from their neighbors using a 2D Gaussian kernel, see: https://docs.astropy.org/en/stable/convolution/#using-astropy-s-convolution-to-replace-bad-data \"\"\" kernel = astropy . convolution . Gaussian2DKernel ( x_stddev = 3 ) # kernel x_size=8*stddev with warnings . catch_warnings (): warnings . simplefilter ( \"ignore\" ) while np . any ( np . isnan ( array )): array = astropy . convolution . interpolate_replace_nans ( array , kernel , convolve = astropy . convolution . convolve ) return array","title":"fill_nan()"},{"location":"tools/asf_tools_api/#asf_tools.hand.calculate.make_copernicus_hand","text":"Copernicus GLO-30 Height Above Nearest Drainage (HAND) Make a Height Above Nearest Drainage (HAND) GeoTIFF from the Copernicus GLO-30 DEM covering the watershed boundaries (hydrobasins) defined in a vector file. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Parameters: Name Type Description Default out_raster Union [ str , Path ] HAND GeoTIFF to create required vector_file Union [ str , Path ] Vector file of watershed boundary (hydrobasin) polygons to calculate HAND over required acc_thresh Optional [ int ] Accumulation threshold for determining the drainage mask. If None , the mean accumulation value is used 100 Source code in asf_tools/hand/calculate.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def make_copernicus_hand ( out_raster : Union [ str , Path ], vector_file : Union [ str , Path ], acc_thresh : Optional [ int ] = 100 ): \"\"\"Copernicus GLO-30 Height Above Nearest Drainage (HAND) Make a Height Above Nearest Drainage (HAND) GeoTIFF from the Copernicus GLO-30 DEM covering the watershed boundaries (hydrobasins) defined in a vector file. For watershed boundaries, see: https://www.hydrosheds.org/page/hydrobasins Args: out_raster: HAND GeoTIFF to create vector_file: Vector file of watershed boundary (hydrobasin) polygons to calculate HAND over acc_thresh: Accumulation threshold for determining the drainage mask. If `None`, the mean accumulation value is used \"\"\" with fiona . open ( vector_file ) as vds : geometries = GeometryCollection ([ shape ( feature [ 'geometry' ]) for feature in vds ]) with NamedTemporaryFile ( suffix = '.vrt' , delete = False ) as dem_vrt : prepare_dem_vrt ( dem_vrt . name , geometries ) calculate_hand_for_basins ( out_raster , geometries , dem_vrt . name , acc_thresh = acc_thresh )","title":"make_copernicus_hand()"},{"location":"tools/asf_tools_api/#asf_tools.hand.prepare","text":"Prepare a Height Above Nearest Drainage (HAND) virtual raster (VRT) covering a given geometry","title":"prepare"},{"location":"tools/asf_tools_api/#asf_tools.hand.prepare.prepare_hand_for_raster","text":"Create a HAND raster pixel-aligned to a source raster Parameters: Name Type Description Default hand_raster Union [ str , Path ] Path for the output HAND raster required source_raster Union [ str , Path ] Path for the source raster required resampling_method str Name of the resampling method to use. For available methods, see: https://gdal.org/programs/gdalwarp.html#cmdoption-gdalwarp-r 'lanczos' Source code in asf_tools/hand/prepare.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def prepare_hand_for_raster ( hand_raster : Union [ str , Path ], source_raster : Union [ str , Path ], resampling_method : str = 'lanczos' ): \"\"\"Create a HAND raster pixel-aligned to a source raster Args: hand_raster: Path for the output HAND raster source_raster: Path for the source raster resampling_method: Name of the resampling method to use. For available methods, see: https://gdal.org/programs/gdalwarp.html#cmdoption-gdalwarp-r \"\"\" info = gdal . Info ( str ( source_raster ), format = 'json' ) hand_geometry = shape ( info [ 'wgs84Extent' ]) hand_bounds = [ info [ 'cornerCoordinates' ][ 'upperLeft' ][ 0 ], info [ 'cornerCoordinates' ][ 'lowerRight' ][ 1 ], info [ 'cornerCoordinates' ][ 'lowerRight' ][ 0 ], info [ 'cornerCoordinates' ][ 'upperLeft' ][ 1 ]] with NamedTemporaryFile ( suffix = '.vrt' , delete = False ) as hand_vrt : prepare_hand_vrt ( hand_vrt . name , hand_geometry ) gdal . Warp ( str ( hand_raster ), hand_vrt . name , dstSRS = f 'EPSG: { get_epsg_code ( info ) } ' , outputBounds = hand_bounds , width = info [ 'size' ][ 0 ], height = info [ 'size' ][ 1 ], resampleAlg = Resampling [ resampling_method ] . value )","title":"prepare_hand_for_raster()"},{"location":"tools/asf_tools_api/#asf_tools.hand.prepare.prepare_hand_vrt","text":"Prepare a HAND mosaic VRT covering a given geometry Prepare a Height Above Nearest Drainage (HAND) virtual raster (VRT) covering a given geometry. The Height Above Nearest Drainage (HAND) mosaic is assembled from the HAND tiles that intersect the geometry, using a HAND derived from the Copernicus GLO-30 DEM. Note: asf_tools does not currently support geometries that cross the antimeridian. Parameters: Name Type Description Default vrt Union [ str , Path ] Path for the output VRT file required geometry Union [ Geometry , BaseGeometry ] Geometry in EPSG:4326 (lon/lat) projection for which to prepare a HAND mosaic required Source code in asf_tools/hand/prepare.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def prepare_hand_vrt ( vrt : Union [ str , Path ], geometry : Union [ ogr . Geometry , BaseGeometry ]): \"\"\"Prepare a HAND mosaic VRT covering a given geometry Prepare a Height Above Nearest Drainage (HAND) virtual raster (VRT) covering a given geometry. The Height Above Nearest Drainage (HAND) mosaic is assembled from the HAND tiles that intersect the geometry, using a HAND derived from the Copernicus GLO-30 DEM. Note: `asf_tools` does not currently support geometries that cross the antimeridian. Args: vrt: Path for the output VRT file geometry: Geometry in EPSG:4326 (lon/lat) projection for which to prepare a HAND mosaic \"\"\" with GDALConfigManager ( GDAL_DISABLE_READDIR_ON_OPEN = 'EMPTY_DIR' ): if isinstance ( geometry , BaseGeometry ): geometry = ogr . CreateGeometryFromWkb ( geometry . wkb ) min_lon , max_lon , _ , _ = geometry . GetEnvelope () if min_lon < - 160. and max_lon > 160. : raise ValueError ( f 'asf_tools does not currently support geometries that cross the antimeridian: { geometry } ' ) tile_features = vector . get_features ( HAND_GEOJSON ) if not vector . get_property_values_for_intersecting_features ( geometry , tile_features ): raise ValueError ( f 'Copernicus GLO-30 HAND does not intersect this geometry: { geometry } ' ) hand_file_paths = vector . intersecting_feature_properties ( geometry , tile_features , 'file_path' ) gdal . BuildVRT ( str ( vrt ), hand_file_paths )","title":"prepare_hand_vrt()"},{"location":"tools/asf_tools_api/#asf_tools.raster","text":"","title":"raster"},{"location":"tools/asf_tools_api/#asf_tools.raster.convert_scale","text":"Convert calibrated raster scale between db, amplitude and power Source code in asf_tools/raster.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def convert_scale ( array : Union [ np . ndarray , np . ma . MaskedArray ], in_scale : Literal [ 'db' , 'amplitude' , 'power' ], out_scale : Literal [ 'db' , 'amplitude' , 'power' ]) -> Union [ np . ndarray , np . ma . MaskedArray ]: \"\"\"Convert calibrated raster scale between db, amplitude and power\"\"\" if in_scale == out_scale : warnings . warn ( f 'Nothing to do! { in_scale } is same as { out_scale } .' ) return array log10 = np . ma . log10 if isinstance ( array , np . ma . MaskedArray ) else np . log10 if in_scale == 'db' : if out_scale == 'power' : return 10 ** ( array / 10 ) if out_scale == 'amplitude' : return 10 ** ( array / 20 ) if in_scale == 'amplitude' : if out_scale == 'power' : return array ** 2 if out_scale == 'db' : return 10 * log10 ( array ** 2 ) if in_scale == 'power' : if out_scale == 'amplitude' : return np . sqrt ( array ) if out_scale == 'db' : return 10 * log10 ( array ) raise ValueError ( f 'Cannot convert raster of scale { in_scale } to { out_scale } ' )","title":"convert_scale()"},{"location":"tools/asf_tools_api/#asf_tools.raster.read_as_masked_array","text":"Reads data from a raster image into memory, masking invalid and NoData values Parameters: Name Type Description Default raster Union [ str , Path ] The file path to a raster image required band int The raster band to read 1 Returns: Name Type Description data MaskedArray The raster pixel data as a numpy MaskedArray Source code in asf_tools/raster.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def read_as_masked_array ( raster : Union [ str , Path ], band : int = 1 ) -> np . ma . MaskedArray : \"\"\"Reads data from a raster image into memory, masking invalid and NoData values Args: raster: The file path to a raster image band: The raster band to read Returns: data: The raster pixel data as a numpy MaskedArray \"\"\" log . debug ( f 'Reading raster values from { raster } ' ) ds = gdal . Open ( str ( raster )) band = ds . GetRasterBand ( band ) data = np . ma . masked_invalid ( band . ReadAsArray ()) nodata = band . GetNoDataValue () if nodata is not None : return np . ma . masked_values ( data , nodata ) return data","title":"read_as_masked_array()"},{"location":"tools/asf_tools_api/#asf_tools.threshold","text":"","title":"threshold"},{"location":"tools/asf_tools_api/#asf_tools.threshold.expectation_maximization_threshold","text":"Water threshold Calculation using a multi-mode Expectation Maximization Approach Thresholding works best when backscatter tiles are provided on a decibel scale to get Gaussian distribution that is scaled to a range of 0-255, and performed on a small tile that is likely to have a transition between water and not water. Parameters: Name Type Description Default tile ndarray array of backscatter values for a tile from an RTC raster required number_of_classes int classify the tile into this many classes. Typically, three classes capture: (1) urban and bright slopes, (2) average brightness farmland, and (3) water, as is often seen in the US Midwest. 3 Returns: Name Type Description threshold float threshold value that can be used to create a water extent map Source code in asf_tools/threshold.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def expectation_maximization_threshold ( tile : np . ndarray , number_of_classes : int = 3 ) -> float : \"\"\"Water threshold Calculation using a multi-mode Expectation Maximization Approach Thresholding works best when backscatter tiles are provided on a decibel scale to get Gaussian distribution that is scaled to a range of 0-255, and performed on a small tile that is likely to have a transition between water and not water. Args: tile: array of backscatter values for a tile from an RTC raster number_of_classes: classify the tile into this many classes. Typically, three classes capture: (1) urban and bright slopes, (2) average brightness farmland, and (3) water, as is often seen in the US Midwest. Returns: threshold: threshold value that can be used to create a water extent map \"\"\" image_copy = tile . copy () image_copy2 = np . ma . filled ( tile . astype ( float ), np . nan ) # needed for valid posterior_lookup keys image = tile . flatten () minimum = np . amin ( image ) image = image - minimum + 1 maximum = np . amax ( image ) histogram = _make_histogram ( image ) nonzero_indices = np . nonzero ( histogram )[ 0 ] histogram = histogram [ nonzero_indices ] histogram = histogram . flatten () class_means = ( ( np . arange ( number_of_classes ) + 1 ) * maximum / ( number_of_classes + 1 ) ) class_variances = np . ones ( number_of_classes ) * maximum class_proportions = np . ones ( number_of_classes ) * 1 / number_of_classes sml = np . mean ( np . diff ( nonzero_indices )) / 1000 iteration = 0 while True : class_likelihood = _make_distribution ( class_means , class_variances , class_proportions , nonzero_indices ) sum_likelihood = np . sum ( class_likelihood , 1 ) + np . finfo ( class_likelihood [ 0 ][ 0 ]) . eps log_likelihood = np . sum ( histogram * np . log ( sum_likelihood )) for j in range ( 0 , number_of_classes ): class_posterior_probability = ( histogram * class_likelihood [:, j ] / sum_likelihood ) class_proportions [ j ] = np . sum ( class_posterior_probability ) class_means [ j ] = ( np . sum ( nonzero_indices * class_posterior_probability ) / class_proportions [ j ] ) vr = ( nonzero_indices - class_means [ j ]) class_variances [ j ] = ( np . sum ( vr * vr * class_posterior_probability ) / class_proportions [ j ] + sml ) del class_posterior_probability , vr class_proportions += 1e-3 class_proportions /= np . sum ( class_proportions ) class_likelihood = _make_distribution ( class_means , class_variances , class_proportions , nonzero_indices ) sum_likelihood = np . sum ( class_likelihood , 1 ) + np . finfo ( class_likelihood [ 0 , 0 ]) . eps del class_likelihood new_log_likelihood = np . sum ( histogram * np . log ( sum_likelihood )) del sum_likelihood if ( new_log_likelihood - log_likelihood ) < 0.000001 : break iteration += 1 del log_likelihood , new_log_likelihood class_means = class_means + minimum - 1 s = image_copy . shape posterior = np . zeros (( s [ 0 ], s [ 1 ], number_of_classes )) posterior_lookup = dict () for i in range ( 0 , s [ 0 ]): for j in range ( 0 , s [ 1 ]): pixel_val = image_copy2 [ i , j ] if pixel_val in posterior_lookup : for n in range ( 0 , number_of_classes ): posterior [ i , j , n ] = posterior_lookup [ pixel_val ][ n ] else : posterior_lookup . update ({ pixel_val : [ 0 ] * number_of_classes }) for n in range ( 0 , number_of_classes ): x = _make_distribution ( class_means [ n ], class_variances [ n ], class_proportions [ n ], image_copy [ i , j ] ) posterior [ i , j , n ] = x * class_proportions [ n ] posterior_lookup [ pixel_val ][ n ] = posterior [ i , j , n ] sorti = np . argsort ( class_means ) xvec = np . arange ( class_means [ sorti [ 0 ]], class_means [ sorti [ 1 ]], step = .05 ) x1 = _make_distribution ( class_means [ sorti [ 0 ]], class_variances [ sorti [ 0 ]], class_proportions [ sorti [ 0 ]], xvec ) x2 = _make_distribution ( class_means [ sorti [ 1 ]], class_variances [ sorti [ 1 ]], class_proportions [ sorti [ 1 ]], xvec ) dx = np . abs ( x1 - x2 ) return xvec [ np . argmin ( dx )]","title":"expectation_maximization_threshold()"},{"location":"tools/asf_tools_api/#asf_tools.tile","text":"","title":"tile"},{"location":"tools/asf_tools_api/#asf_tools.tile.tile_array","text":"Tile a 2D numpy array Turn a 2D numpy array like array = [[0, 0, 1, 1], ... [0, 0, 1, 1], ... [2, 2, 3, 3], ... [2, 2, 3, 3]] array.shape (4, 4) into a tiled array like tiles = tiled_array(array, 2, 2) print(tiles) [[[0, 0], [0, 0]], [[1, 1], [1, 1]], [[2, 2], [2, 2]], [[3, 3], [3, 3]]] tiles.shape (4, 2, 2) Parameters: Name Type Description Default array Union [ ndarray , MaskedArray ] 2D array to tile required tile_shape Tuple [ int , int ] the shape of each tile (200, 200) pad_value float right-bottom pad a with pad as needed so a is evenly divisible into tiles None Returns: Type Description Union [ ndarray , MaskedArray ] the tiled array Source code in asf_tools/tile.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def tile_array ( array : Union [ np . ndarray , np . ma . MaskedArray ], tile_shape : Tuple [ int , int ] = ( 200 , 200 ), pad_value : float = None ) -> Union [ np . ndarray , np . ma . MaskedArray ]: \"\"\"Tile a 2D numpy array Turn a 2D numpy array like: >>> array = [[0, 0, 1, 1], ... [0, 0, 1, 1], ... [2, 2, 3, 3], ... [2, 2, 3, 3]] >>> array.shape (4, 4) into a tiled array like: >>> tiles = tiled_array(array, 2, 2) >>> print(tiles) [[[0, 0], [0, 0]], [[1, 1], [1, 1]], [[2, 2], [2, 2]], [[3, 3], [3, 3]]] >>> tiles.shape (4, 2, 2) Args: array: 2D array to tile tile_shape: the shape of each tile pad_value: right-bottom pad `a` with `pad` as needed so `a` is evenly divisible into tiles Returns: the tiled array \"\"\" array_rows , array_columns = array . shape tile_rows , tile_columns = tile_shape # CREDIT: https://twitter.com/LizzUltee/status/1379508448262512641 rpad = - array_rows % tile_rows cpad = - array_columns % tile_columns if ( rpad or cpad ) and pad_value is None : raise ValueError ( f 'Cannot evenly tile a { array . shape } array into ( { tile_rows } , { tile_columns } ) tiles' ) if rpad or cpad : padded_array = np . pad ( array , (( 0 , rpad ), ( 0 , cpad )), constant_values = pad_value ) if isinstance ( array , np . ma . MaskedArray ): mask = np . pad ( array . mask , (( 0 , rpad ), ( 0 , cpad )), constant_values = True ) padded_array = np . ma . MaskedArray ( padded_array , mask = mask ) else : padded_array = array tile_list = [] for rows in np . vsplit ( padded_array , range ( tile_rows , array_rows , tile_rows )): tile_list . extend ( np . hsplit ( rows , range ( tile_columns , array_columns , tile_columns ))) dstack = np . ma . dstack if isinstance ( array , np . ma . MaskedArray ) else np . dstack tiled = np . moveaxis ( dstack ( tile_list ), - 1 , 0 ) return tiled","title":"tile_array()"},{"location":"tools/asf_tools_api/#asf_tools.tile.untile_array","text":"Untile a tiled array into a 2D numpy array This is the reverse of tile_array and will turn a tiled array like: >>> tiled_array = [[[0,0], ... [0,0]], ... [[1,1], ... [1,1]], ... [[2,2], ... [2,2]], ... [[3,3], ... [3,3]]] >>> tiled_array.shape (4, 2, 2) into a 2D array like array = untile_array(tiled_array) print(array) [[0, 0, 1, 1], [0, 0, 1, 1], [2, 2, 3, 3], [2, 2, 3, 3]] array.shape (4, 4) Parameters: Name Type Description Default tiled_array Union [ ndarray , MaskedArray ] a tiled array required array_shape Tuple [ int , int ] shape to untile the array to. If array_shape's size is smaller than the tiled array, untile_array will subset the tiled array assuming bottom right padding was added when tiling. required Returns: Type Description Union [ ndarray , MaskedArray ] the untiled array Source code in asf_tools/tile.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def untile_array ( tiled_array : Union [ np . ndarray , np . ma . MaskedArray ], array_shape : Tuple [ int , int ]) \\ -> Union [ np . ndarray , np . ma . MaskedArray ]: \"\"\"Untile a tiled array into a 2D numpy array This is the reverse of `tile_array` and will turn a tiled array like: >>> tiled_array = [[[0,0], ... [0,0]], ... [[1,1], ... [1,1]], ... [[2,2], ... [2,2]], ... [[3,3], ... [3,3]]] >>> tiled_array.shape (4, 2, 2) into a 2D array like: >>> array = untile_array(tiled_array) >>> print(array) [[0, 0, 1, 1], [0, 0, 1, 1], [2, 2, 3, 3], [2, 2, 3, 3]] >>> array.shape (4, 4) Args: tiled_array: a tiled array array_shape: shape to untile the array to. If array_shape's size is smaller than the tiled array, `untile_array` will subset the tiled array assuming bottom right padding was added when tiling. Returns: the untiled array \"\"\" _ , tile_rows , tile_columns = tiled_array . shape array_rows , array_columns = array_shape untiled_rows = int ( np . ceil ( array_rows / tile_rows )) untiled_columns = int ( np . ceil ( array_columns / tile_columns )) untiled = np . zeros (( untiled_rows * tile_rows , untiled_columns * tile_columns ), dtype = tiled_array . dtype ) if ( array_size := array_rows * array_columns ) > tiled_array . size : raise ValueError ( f 'array_shape { array_shape } will result in an array bigger than the tiled array:' f ' { array_size } > { tiled_array . size } ' ) for ii in range ( untiled_rows ): for jj in range ( untiled_columns ): untiled [ ii * tile_rows :( ii + 1 ) * tile_rows , jj * tile_columns :( jj + 1 ) * tile_columns ] = \\ tiled_array [ ii * untiled_columns + jj , :, :] if isinstance ( tiled_array , np . ma . MaskedArray ): untiled_mask = untile_array ( tiled_array . mask , untiled . shape ) untiled = np . ma . MaskedArray ( untiled , mask = untiled_mask ) return untiled [: array_rows , : array_columns ]","title":"untile_array()"},{"location":"tools/asf_tools_api/#asf_tools.util","text":"","title":"util"},{"location":"tools/asf_tools_api/#asf_tools.util.GDALConfigManager","text":"Context manager for setting GDAL config options temporarily Source code in asf_tools/util.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class GDALConfigManager : \"\"\"Context manager for setting GDAL config options temporarily\"\"\" def __init__ ( self , ** options ): \"\"\" Args: **options: GDAL Config `option=value` keyword arguments. \"\"\" self . options = options . copy () self . _previous_options = {} def __enter__ ( self ): for key in self . options : self . _previous_options [ key ] = gdal . GetConfigOption ( key ) for key , value in self . options . items (): gdal . SetConfigOption ( key , value ) def __exit__ ( self , exc_type , exc_val , exc_tb ): for key , value in self . _previous_options . items (): gdal . SetConfigOption ( key , value )","title":"GDALConfigManager"},{"location":"tools/asf_tools_api/#asf_tools.util.GDALConfigManager.__init__","text":"Parameters: Name Type Description Default **options GDAL Config option=value keyword arguments. {} Source code in asf_tools/util.py 8 9 10 11 12 13 14 def __init__ ( self , ** options ): \"\"\" Args: **options: GDAL Config `option=value` keyword arguments. \"\"\" self . options = options . copy () self . _previous_options = {}","title":"__init__()"},{"location":"tools/asf_tools_api/#asf_tools.water_map","text":"Generate surface water maps from Sentinel-1 RTC products Create a surface water extent map from a dual-pol Sentinel-1 RTC product and a HAND image. The HAND image must be pixel-aligned (same extent and size) to the RTC images. The water extent maps are created using an adaptive Expectation Maximization thresholding approach and refined using Fuzzy Logic.","title":"water_map"},{"location":"tools/asf_tools_api/#asf_tools.water_map.format_raster_data","text":"Ensure raster data is uint8 and set the area outside the valid data to nodata Source code in asf_tools/water_map.py 136 137 138 139 140 141 142 143 144 145 146 def format_raster_data ( raster , padding_mask = None , nodata = np . iinfo ( np . uint8 ) . max ): \"\"\" Ensure raster data is uint8 and set the area outside the valid data to nodata \"\"\" if padding_mask is None : array = read_as_masked_array ( raster ) padding_mask = array . mask raster = raster . astype ( np . uint8 ) raster [ padding_mask ] = nodata return raster","title":"format_raster_data()"},{"location":"tools/asf_tools_api/#asf_tools.water_map.make_water_map","text":"Creates a surface water extent map from a Sentinel-1 RTC product Create a surface water extent map from a dual-pol Sentinel-1 RTC product and a HAND image. The HAND image must be pixel-aligned (same extent and size) to the RTC images. The water extent maps are created using an adaptive Expectation Maximization thresholding approach and refined with Fuzzy Logic. The input images are broken into a set of corresponding tiles with a shape of tile_shape , and a set of tiles are selected from the VH RTC image that contain water boundaries to determine an appropriate water threshold. Candidate tiles must meet these criteria: * hand_fraction of pixels within a tile must have HAND pixel values lower than hand_threshold * The median backscatter value for the tile must be lower than an average tiles' backscatter values * The tile must have a high variance -- high variance is considered initially to be a variance in the 95th percentile of the tile variances, but progressively relaxed to the 5th percentile if there not at least 5 candidate tiles. The 5 VH tiles with the highest variance are selected for thresholding and a water threshold value is determined using an Expectation Maximization approach. If there were not enough candidate tiles or the threshold is too high, max_vh_threshold and/or max_vv_threshold will be used instead. From the initial threshold-based water extent maps, Fuzzy Logic is used to remove spurious false detections and improve the water extent map quality. The fuzzy logic uses these indicators for the presence of water: * radar cross section in a pixel relative to the determined detection threshold * the height above nearest drainage (HAND) * the surface slope, which is derived from the HAND data * the size of the detected water feature For each indicator, a Z-shaped activation function is used to determine pixel membership. The membership maps are combined to form the final water extent map. Pixels classified as water pixels will: * have non-zero membership in all of the indicators, and * have an average membership above the membership_threshold value. Finally, the VV and VH water masks will be combined to include all water pixels from both masks, and the combined water map will be written to out_raster . Parameters: Name Type Description Default out_raster Union [ str , Path ] Water map GeoTIFF to create required vv_raster Union [ str , Path ] Sentinel-1 RTC GeoTIFF, in power scale, with VV polarization required vh_raster Union [ str , Path ] Sentinel-1 RTC GeoTIFF, in power scale, with VH polarization required hand_raster Optional [ Union [ str , Path ]] Height Above Nearest Drainage (HAND) GeoTIFF aligned to the RTC rasters None tile_shape Tuple [ int , int ] shape (height, width) in pixels to tile the image to (100, 100) max_vv_threshold float Maximum threshold value to use for vv_raster in decibels (db) -15.5 max_vh_threshold float Maximum threshold value to use for vh_raster in decibels (db) -23.0 hand_threshold float The maximum height above nearest drainage in meters to consider a pixel valid 15.0 hand_fraction float The minimum fraction of valid HAND pixels required in a tile for thresholding 0.8 membership_threshold float The average membership to the fuzzy indicators required for a water pixel 0.45 Source code in asf_tools/water_map.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 def make_water_map ( out_raster : Union [ str , Path ], vv_raster : Union [ str , Path ], vh_raster : Union [ str , Path ], hand_raster : Optional [ Union [ str , Path ]] = None , tile_shape : Tuple [ int , int ] = ( 100 , 100 ), max_vv_threshold : float = - 15.5 , max_vh_threshold : float = - 23.0 , hand_threshold : float = 15. , hand_fraction : float = 0.8 , membership_threshold : float = 0.45 ): \"\"\"Creates a surface water extent map from a Sentinel-1 RTC product Create a surface water extent map from a dual-pol Sentinel-1 RTC product and a HAND image. The HAND image must be pixel-aligned (same extent and size) to the RTC images. The water extent maps are created using an adaptive Expectation Maximization thresholding approach and refined with Fuzzy Logic. The input images are broken into a set of corresponding tiles with a shape of `tile_shape`, and a set of tiles are selected from the VH RTC image that contain water boundaries to determine an appropriate water threshold. Candidate tiles must meet these criteria: * `hand_fraction` of pixels within a tile must have HAND pixel values lower than `hand_threshold` * The median backscatter value for the tile must be lower than an average tiles' backscatter values * The tile must have a high variance -- high variance is considered initially to be a variance in the 95th percentile of the tile variances, but progressively relaxed to the 5th percentile if there not at least 5 candidate tiles. The 5 VH tiles with the highest variance are selected for thresholding and a water threshold value is determined using an Expectation Maximization approach. If there were not enough candidate tiles or the threshold is too high, `max_vh_threshold` and/or `max_vv_threshold` will be used instead. From the initial threshold-based water extent maps, Fuzzy Logic is used to remove spurious false detections and improve the water extent map quality. The fuzzy logic uses these indicators for the presence of water: * radar cross section in a pixel relative to the determined detection threshold * the height above nearest drainage (HAND) * the surface slope, which is derived from the HAND data * the size of the detected water feature For each indicator, a Z-shaped activation function is used to determine pixel membership. The membership maps are combined to form the final water extent map. Pixels classified as water pixels will: * have non-zero membership in all of the indicators, and * have an average membership above the `membership_threshold` value. Finally, the VV and VH water masks will be combined to include all water pixels from both masks, and the combined water map will be written to `out_raster`. Args: out_raster: Water map GeoTIFF to create vv_raster: Sentinel-1 RTC GeoTIFF, in power scale, with VV polarization vh_raster: Sentinel-1 RTC GeoTIFF, in power scale, with VH polarization hand_raster: Height Above Nearest Drainage (HAND) GeoTIFF aligned to the RTC rasters tile_shape: shape (height, width) in pixels to tile the image to max_vv_threshold: Maximum threshold value to use for `vv_raster` in decibels (db) max_vh_threshold: Maximum threshold value to use for `vh_raster` in decibels (db) hand_threshold: The maximum height above nearest drainage in meters to consider a pixel valid hand_fraction: The minimum fraction of valid HAND pixels required in a tile for thresholding membership_threshold: The average membership to the fuzzy indicators required for a water pixel \"\"\" if tile_shape [ 0 ] % 2 or tile_shape [ 1 ] % 2 : raise ValueError ( f 'tile_shape { tile_shape } requires even values.' ) info = gdal . Info ( str ( vh_raster ), format = 'json' ) out_transform = info [ 'geoTransform' ] out_epsg = get_epsg_code ( info ) if hand_raster is None : hand_raster = str ( out_raster ) . replace ( '.tif' , '_HAND.tif' ) log . info ( f 'Extracting HAND data to: { hand_raster } ' ) prepare_hand_for_raster ( hand_raster , vh_raster ) log . info ( f 'Determining HAND memberships from { hand_raster } ' ) hand_array = read_as_masked_array ( hand_raster ) hand_tiles = tile_array ( hand_array , tile_shape = tile_shape , pad_value = np . nan ) hand_candidates = select_hand_tiles ( hand_tiles , hand_threshold , hand_fraction ) log . debug ( f 'Selected HAND tile candidates { hand_candidates } ' ) selected_tiles = None nodata = np . iinfo ( np . uint8 ) . max water_extent_maps = [] for max_db_threshold , raster , pol in (( max_vh_threshold , vh_raster , 'VH' ), ( max_vv_threshold , vv_raster , 'VV' )): log . info ( f 'Creating initial { pol } water extent map from { raster } ' ) array = read_as_masked_array ( raster ) padding_mask = array . mask tiles = tile_array ( array , tile_shape = tile_shape , pad_value = 0. ) # Masking less than zero only necessary for old HyP3/GAMMA products which sometimes returned negative powers tiles = np . ma . masked_less_equal ( tiles , 0. ) if selected_tiles is None : selected_tiles = select_backscatter_tiles ( tiles , hand_candidates ) log . info ( f 'Selected tiles { selected_tiles } from { raster } ' ) with np . testing . suppress_warnings () as sup : sup . filter ( RuntimeWarning ) # invalid value and divide by zero encountered in log10 tiles = np . log10 ( tiles ) + 30. # linear power scale -> Gaussian scale optimized for thresholding max_gaussian_threshold = max_db_threshold / 10. + 30. # db -> Gaussian scale optimized for thresholding if selected_tiles . size : scaling = 256 / ( np . mean ( tiles ) + 3 * np . std ( tiles )) gaussian_threshold = determine_em_threshold ( tiles [ selected_tiles , :, :], scaling ) threshold_db = 10. * ( gaussian_threshold - 30. ) log . info ( f 'Threshold determined to be { threshold_db } db' ) if gaussian_threshold > max_gaussian_threshold : log . warning ( f 'Threshold too high! Using maximum threshold { max_db_threshold } db' ) gaussian_threshold = max_gaussian_threshold else : log . warning ( f 'Tile selection did not converge! using default threshold { max_db_threshold } db' ) gaussian_threshold = max_gaussian_threshold gaussian_array = untile_array ( tiles , array . shape ) water_map = np . ma . masked_less_equal ( gaussian_array , gaussian_threshold ) . mask water_map &= ~ array . mask write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { pol } _initial.tif' ), format_raster_data ( water_map , padding_mask , nodata ), transform = out_transform , epsg_code = out_epsg , dtype = gdal . GDT_Byte , nodata_value = nodata ) log . info ( f 'Refining initial { pol } water extent map using Fuzzy Logic' ) array = np . ma . masked_where ( ~ water_map , array ) gaussian_lower_limit = np . log10 ( np . ma . median ( array )) + 30. water_map = fuzzy_refinement ( water_map , gaussian_array , hand_array , pixel_size = out_transform [ 1 ], gaussian_thresholds = ( gaussian_lower_limit , gaussian_threshold ), membership_threshold = membership_threshold ) water_map &= ~ array . mask write_cog ( str ( out_raster ) . replace ( '.tif' , f '_ { pol } _fuzzy.tif' ), format_raster_data ( water_map , padding_mask , nodata ), transform = out_transform , epsg_code = out_epsg , dtype = gdal . GDT_Byte , nodata_value = nodata ) water_extent_maps . append ( water_map ) log . info ( 'Combining Fuzzy VH and VV extent map' ) combined_water_map = np . logical_or ( * water_extent_maps ) combined_segments = measure . label ( combined_water_map , connectivity = 2 ) combined_water_map = remove_small_segments ( combined_segments ) write_cog ( out_raster , format_raster_data ( combined_water_map , padding_mask , nodata ), transform = out_transform , epsg_code = out_epsg , dtype = gdal . GDT_Byte , nodata_value = nodata )","title":"make_water_map()"},{"location":"tutorials/process-new-granules-for-search-parameters/","text":"Using the HyP3 SDK to process new granules for given search parameters \u00b6 In the past, ASF offered subscription functionality for HyP3 products. A user could create a subscription with a particular set of search parameters (date range, area of interest, etc.), and new Sentinel-1 acquisitions that met these criteria would be automatically submitted for processing. However, this feature was only accessed by a very small minority of HyP3 users, and most users did not regularly check their subscriptions and download the generated products before they expired. As such, we have removed this feature in favor of a more flexible approach. The following Jupyter notebooks demonstrate how to achieve subscription-like functionality. They can be run as needed so that you do not have to worry about your products expiring before you are ready to download them. This workflow is particularly useful for ongoing monitoring of a geographic area of interest. The first notebook demonstrates how to submit RTC jobs using this method, while the second notebook demonstrates how to submit InSAR jobs. These tutorials can easily be adapted to support other job types. Please contact us if you need help adapting these tutorials for your particular use case. Using the HyP3 SDK to generate RTC products for given search parameters Using the HyP3 SDK to generate InSAR products for given search parameters","title":"Process new granules for search parameters"},{"location":"tutorials/process-new-granules-for-search-parameters/#using-the-hyp3-sdk-to-process-new-granules-for-given-search-parameters","text":"In the past, ASF offered subscription functionality for HyP3 products. A user could create a subscription with a particular set of search parameters (date range, area of interest, etc.), and new Sentinel-1 acquisitions that met these criteria would be automatically submitted for processing. However, this feature was only accessed by a very small minority of HyP3 users, and most users did not regularly check their subscriptions and download the generated products before they expired. As such, we have removed this feature in favor of a more flexible approach. The following Jupyter notebooks demonstrate how to achieve subscription-like functionality. They can be run as needed so that you do not have to worry about your products expiring before you are ready to download them. This workflow is particularly useful for ongoing monitoring of a geographic area of interest. The first notebook demonstrates how to submit RTC jobs using this method, while the second notebook demonstrates how to submit InSAR jobs. These tutorials can easily be adapted to support other job types. Please contact us if you need help adapting these tutorials for your particular use case. Using the HyP3 SDK to generate RTC products for given search parameters Using the HyP3 SDK to generate InSAR products for given search parameters","title":"Using the HyP3 SDK to process new granules for given search parameters"},{"location":"using/api/","text":"Using the HyP3 API \u00b6 The HyP3 API is built on OpenAPI and Swagger . A friendly interface for exploring the API is available at: https://hyp3-api.asf.alaska.edu/ui/ \u00b6 In order to use the API, you'll need a asf-urs session cookie, which you can get by signing in to Vertex Confirm you are authenticated \u00b6 To confirm you are authenticated, you can run a GET request to our /user endpoint. Select the blue GET button next to /user and click the Try it out button Then, execute the request and look at the response If you get a Code 200 you should see a JSON dictionary of your user information. Authentication Required If you get a 401 response back you need to sign in to Vertex to get the asf-urs session cookie. { \"detail\" : \"No authorization token provided\" , \"status\" : 401 , \"title\" : \"Unauthorized\" , \"type\" : \"about:blank\" } Submitting Sentinel-1 RTC jobs \u00b6 Jobs are submitted through the API by providing a JSON payload with a list of job definitions. Sentinel-1 jobs are submitted using ESA granule IDs . A minimal job list for a single Sentinel-1 RTC job would look like: { \"jobs\" : [ { \"name\" : \"minimal-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_GRDH_1SDV_20210214T154837_20210214T154901_036588_044C54_032E\" ] } } ] } The job list may contain up to 200 job definitions. You can also provide custom RTC options: { \"jobs\" : [ { \"name\" : \"custom-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1B_IW_GRDH_1SDV_20210210T153157_20210210T153222_025546_030B48_2901\" ], \"radiometry\" : \"gamma0\" , \"scale\" : \"power\" , \"dem_matching\" : false , \"include_dem\" : true , \"include_inc_map\" : true , \"include_scattering_area\" : false , \"speckle_filter\" : false } }, { \"name\" : \"custom-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1B_IW_GRDH_1SDV_20210210T153132_20210210T153157_025546_030B48_4E31\" ], \"radiometry\" : \"sigma0\" , \"scale\" : \"amplitude\" , \"dem_matching\" : false , \"include_dem\" : false , \"include_inc_map\" : false , \"include_scattering_area\" : true , \"speckle_filter\" : true } } ] } Submitting Sentinel-1 InSAR jobs \u00b6 You can also submit InSAR jobs for scene pairs using ESA granule IDs . { \"jobs\" : [ { \"name\" : \"minimal-insar-example\" , \"job_type\" : \"INSAR_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SDV_20200203T172103_20200203T172122_031091_03929B_3048\" , \"S1A_IW_SLC__1SDV_20200110T172104_20200110T172123_030741_03864E_A996\" ] } }, { \"name\" : \"custom-insar-example\" , \"job_type\" : \"INSAR_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SDV_20200527T195012_20200527T195028_032755_03CB56_3D96\" , \"S1A_IW_SLC__1SDV_20200515T195012_20200515T195027_032580_03C609_4EBA\" ], \"looks\" : \"10x2\" , \"include_look_vectors\" : true , \"include_los_displacement\" : true } } ] } Submitting autoRIFT jobs \u00b6 AutoRIFT supports processing Sentinel-1, Sentinel-2, or Landsat-8 Collection 2 pairs. Sentinel-1 jobs are submitted using ESA granule IDs Sentinel-2 jobs are submitted using ESA granule IDs Landsat-8 Collection 2 jobs are submitted using USGS scene IDs To submit an example set of jobs including all supported missions, you could write a job list like: { \"jobs\" : [ { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SSH_20170221T204710_20170221T204737_015387_0193F6_AB07\" , \"S1B_IW_SLC__1SSH_20170227T204628_20170227T204655_004491_007D11_6654\" ] } }, { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"S2B_MSIL1C_20200612T150759_N0209_R025_T22WEB_20200612T184700\" , \"S2A_MSIL1C_20200627T150921_N0209_R025_T22WEB_20200627T170912\" ] } }, { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"LC08_L1TP_009011_20200703_20200913_02_T1\" , \"LC08_L1TP_009011_20200820_20200905_02_T1\" ] } } ] } With your JSON jobs definition, you can POST to the /jobs endpoint to submit the jobs. click the green POST button next to /jobs click Try it out on the right paste your jobs definition into the Request body click execute If your jobs were submitted successfully you should see a Code 200 and a JSON response of your job list, with some additional job attributes filled in. Querying jobs \u00b6 You can GET job information from the /jobs endpoint. You may provide query parameters to filter which jobs are returned: For our above examples, you can get the RTC job that was submitted with the default options by searching for name=minimal-rtc-example . If you provide no query parameters, you'll get a JSON response with a jobs list for every job you've submitted. Within the jobs list, a complete job dictionary will look like: { \"jobs\" : [ { \"name\" : \"minimal-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8\" ] }, \"job_id\" : \"20c377be-2511-46a8-b908-e015abd3c24e\" , \"user_id\" : \"MY_EDL_USERNAME\" , \"status_code\" : \"SUCCEEDED\" , \"request_time\" : \"2021-02-24T21:30:45+00:00\" , \"expiration_time\" : \"2021-03-11T00:00:00+00:00\" , \"files\" : [ { \"filename\" : \"S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" , \"s3\" : { \"bucket\" : \"hyp3-contentbucket-fo259f6r6dn6\" , \"key\" : \"20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" }, \"size\" : 28676279 , \"url\" : \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" } ], \"browse_images\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.png\" ], \"thumbnail_images\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA_thumb.png\" ], \"logs\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/20c377be-2511-46a8-b908-e015abd3c24e.log\" ] } ] } Importantly, the files block provides download links for the product files. For large queries results may be truncated. In this case there will be a next key in the response that will contain a URL to continue the query (this response may be similarly truncated and include a next key). { \"jobs\" : [ ... ], \"next\" : \"https://hyp3-api.asf.alaska.edu/jobs?start_token=eyJqb2JfaWQiOiAiYzk1MDUzY2ItYWQzNy00ZGFhLTgxZDItYzA0YmQ4NWZiNDhiIiwgInVzZXJfaWQiOiAiamxyaW5lMiIsICJyZXF1ZXN0X3RpbWUiOiAiMjAyMC0xMC0yOVQxOTo0Mzo0NCswMDowMCJ9\" }","title":"API"},{"location":"using/api/#using-the-hyp3-api","text":"The HyP3 API is built on OpenAPI and Swagger . A friendly interface for exploring the API is available at:","title":"Using the HyP3 API"},{"location":"using/api/#httpshyp3-apiasfalaskaeduui","text":"In order to use the API, you'll need a asf-urs session cookie, which you can get by signing in to Vertex","title":"https://hyp3-api.asf.alaska.edu/ui/"},{"location":"using/api/#confirm-you-are-authenticated","text":"To confirm you are authenticated, you can run a GET request to our /user endpoint. Select the blue GET button next to /user and click the Try it out button Then, execute the request and look at the response If you get a Code 200 you should see a JSON dictionary of your user information. Authentication Required If you get a 401 response back you need to sign in to Vertex to get the asf-urs session cookie. { \"detail\" : \"No authorization token provided\" , \"status\" : 401 , \"title\" : \"Unauthorized\" , \"type\" : \"about:blank\" }","title":"Confirm you are authenticated"},{"location":"using/api/#submitting-sentinel-1-rtc-jobs","text":"Jobs are submitted through the API by providing a JSON payload with a list of job definitions. Sentinel-1 jobs are submitted using ESA granule IDs . A minimal job list for a single Sentinel-1 RTC job would look like: { \"jobs\" : [ { \"name\" : \"minimal-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_GRDH_1SDV_20210214T154837_20210214T154901_036588_044C54_032E\" ] } } ] } The job list may contain up to 200 job definitions. You can also provide custom RTC options: { \"jobs\" : [ { \"name\" : \"custom-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1B_IW_GRDH_1SDV_20210210T153157_20210210T153222_025546_030B48_2901\" ], \"radiometry\" : \"gamma0\" , \"scale\" : \"power\" , \"dem_matching\" : false , \"include_dem\" : true , \"include_inc_map\" : true , \"include_scattering_area\" : false , \"speckle_filter\" : false } }, { \"name\" : \"custom-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1B_IW_GRDH_1SDV_20210210T153132_20210210T153157_025546_030B48_4E31\" ], \"radiometry\" : \"sigma0\" , \"scale\" : \"amplitude\" , \"dem_matching\" : false , \"include_dem\" : false , \"include_inc_map\" : false , \"include_scattering_area\" : true , \"speckle_filter\" : true } } ] }","title":"Submitting Sentinel-1 RTC jobs"},{"location":"using/api/#submitting-sentinel-1-insar-jobs","text":"You can also submit InSAR jobs for scene pairs using ESA granule IDs . { \"jobs\" : [ { \"name\" : \"minimal-insar-example\" , \"job_type\" : \"INSAR_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SDV_20200203T172103_20200203T172122_031091_03929B_3048\" , \"S1A_IW_SLC__1SDV_20200110T172104_20200110T172123_030741_03864E_A996\" ] } }, { \"name\" : \"custom-insar-example\" , \"job_type\" : \"INSAR_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SDV_20200527T195012_20200527T195028_032755_03CB56_3D96\" , \"S1A_IW_SLC__1SDV_20200515T195012_20200515T195027_032580_03C609_4EBA\" ], \"looks\" : \"10x2\" , \"include_look_vectors\" : true , \"include_los_displacement\" : true } } ] }","title":"Submitting Sentinel-1 InSAR jobs"},{"location":"using/api/#submitting-autorift-jobs","text":"AutoRIFT supports processing Sentinel-1, Sentinel-2, or Landsat-8 Collection 2 pairs. Sentinel-1 jobs are submitted using ESA granule IDs Sentinel-2 jobs are submitted using ESA granule IDs Landsat-8 Collection 2 jobs are submitted using USGS scene IDs To submit an example set of jobs including all supported missions, you could write a job list like: { \"jobs\" : [ { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SSH_20170221T204710_20170221T204737_015387_0193F6_AB07\" , \"S1B_IW_SLC__1SSH_20170227T204628_20170227T204655_004491_007D11_6654\" ] } }, { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"S2B_MSIL1C_20200612T150759_N0209_R025_T22WEB_20200612T184700\" , \"S2A_MSIL1C_20200627T150921_N0209_R025_T22WEB_20200627T170912\" ] } }, { \"name\" : \"autorift-example\" , \"job_type\" : \"AUTORIFT\" , \"job_parameters\" : { \"granules\" : [ \"LC08_L1TP_009011_20200703_20200913_02_T1\" , \"LC08_L1TP_009011_20200820_20200905_02_T1\" ] } } ] } With your JSON jobs definition, you can POST to the /jobs endpoint to submit the jobs. click the green POST button next to /jobs click Try it out on the right paste your jobs definition into the Request body click execute If your jobs were submitted successfully you should see a Code 200 and a JSON response of your job list, with some additional job attributes filled in.","title":"Submitting autoRIFT jobs"},{"location":"using/api/#querying-jobs","text":"You can GET job information from the /jobs endpoint. You may provide query parameters to filter which jobs are returned: For our above examples, you can get the RTC job that was submitted with the default options by searching for name=minimal-rtc-example . If you provide no query parameters, you'll get a JSON response with a jobs list for every job you've submitted. Within the jobs list, a complete job dictionary will look like: { \"jobs\" : [ { \"name\" : \"minimal-rtc-example\" , \"job_type\" : \"RTC_GAMMA\" , \"job_parameters\" : { \"granules\" : [ \"S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8\" ] }, \"job_id\" : \"20c377be-2511-46a8-b908-e015abd3c24e\" , \"user_id\" : \"MY_EDL_USERNAME\" , \"status_code\" : \"SUCCEEDED\" , \"request_time\" : \"2021-02-24T21:30:45+00:00\" , \"expiration_time\" : \"2021-03-11T00:00:00+00:00\" , \"files\" : [ { \"filename\" : \"S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" , \"s3\" : { \"bucket\" : \"hyp3-contentbucket-fo259f6r6dn6\" , \"key\" : \"20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" }, \"size\" : 28676279 , \"url\" : \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.zip\" } ], \"browse_images\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA.png\" ], \"thumbnail_images\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/S1A_IW_20150621T120220_SVP_RTC30_G_gpuned_0AEA_thumb.png\" ], \"logs\" : [ \"https://hyp3-contentbucket-fo259f6r6dn6.s3.us-west-2.amazonaws.com/20c377be-2511-46a8-b908-e015abd3c24e/20c377be-2511-46a8-b908-e015abd3c24e.log\" ] } ] } Importantly, the files block provides download links for the product files. For large queries results may be truncated. In this case there will be a next key in the response that will contain a URL to continue the query (this response may be similarly truncated and include a next key). { \"jobs\" : [ ... ], \"next\" : \"https://hyp3-api.asf.alaska.edu/jobs?start_token=eyJqb2JfaWQiOiAiYzk1MDUzY2ItYWQzNy00ZGFhLTgxZDItYzA0YmQ4NWZiNDhiIiwgInVzZXJfaWQiOiAiamxyaW5lMiIsICJyZXF1ZXN0X3RpbWUiOiAiMjAyMC0xMC0yOVQxOTo0Mzo0NCswMDowMCJ9\" }","title":"Querying jobs"},{"location":"using/quota/","text":"Monthly Processing Quota \u00b6 Attention Due to the increasing popularity of On Demand processing, and in order to continue providing this service at no cost to users, beginning February 2022, processing quotas will be set to 1000 jobs per user per month. If this change impacts your current workflows, or doesn't meet your needs, please let us know! In order to provide On Demand products across the community, and to support our mission of making remote-sensing data accessible , we've implemented a monthly processing quota. Anyone with an Earthdata Login can freely request 1000 jobs each calendar month. We may periodically adjust this quota based on usage, with the goal of providing valuable products to the widest breadth of users possible. If the quota doesn't meet your needs, please contact us and let us know how you would like to use the service. We have several options available for increased processing via HyP3. All requests will be balanced against our mission -- to make remote-sensing data accessible to the community. Contact Us \u00b6 Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? Open an issue General questions? Suggestions? Or just want to talk to the team? Chat with us on Gitter You can also reach us by email through ASF User Services: Email ASF User Services","title":"Processing Quota"},{"location":"using/quota/#monthly-processing-quota","text":"Attention Due to the increasing popularity of On Demand processing, and in order to continue providing this service at no cost to users, beginning February 2022, processing quotas will be set to 1000 jobs per user per month. If this change impacts your current workflows, or doesn't meet your needs, please let us know! In order to provide On Demand products across the community, and to support our mission of making remote-sensing data accessible , we've implemented a monthly processing quota. Anyone with an Earthdata Login can freely request 1000 jobs each calendar month. We may periodically adjust this quota based on usage, with the goal of providing valuable products to the widest breadth of users possible. If the quota doesn't meet your needs, please contact us and let us know how you would like to use the service. We have several options available for increased processing via HyP3. All requests will be balanced against our mission -- to make remote-sensing data accessible to the community.","title":"Monthly Processing Quota"},{"location":"using/quota/#contact-us","text":"Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? Open an issue General questions? Suggestions? Or just want to talk to the team? Chat with us on Gitter You can also reach us by email through ASF User Services: Email ASF User Services","title":"Contact Us"},{"location":"using/sdk/","text":"HyP3 SDK \u00b6 A python wrapper around the HyP3 API >>> from hyp3_sdk import HyP3 >>> hyp3 = HyP3 ( username = 'MyUsername' , password = 'MyPassword' ) >>> granule = 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' >>> job = hyp3 . submit_rtc_job ( granule = granule , name = 'MyNewJob' ) >>> job = hyp3 . watch ( job ) >>> job . download_files () Install \u00b6 In order to easily manage dependencies, we recommend using dedicated project environments via Anaconda/Miniconda or Python virtual environments . The HyP3 SDK can be installed into a conda environment with conda install -c conda-forge hyp3_sdk or into a virtual environment with python -m pip install hyp3_sdk Quick Usage \u00b6 There are 3 main classes that the SDK exposes: HyP3 to perform HyP3 operations (find jobs, refresh job information, submitting new jobs) Job to perform operations on single jobs (downloading products, check status) Batch to perform operations on multiple jobs at once (downloading products, check status) An instance of the HyP3 class will be needed to interact with the external HyP3 API. >>> from hyp3_sdk import HyP3 >>> hyp3 = HyP3 ( username = 'MyUsername' , password = 'MyPassword' ) >>> granule = 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' >>> job = hyp3 . submit_rtc_job ( granule = granule , name = 'MyNewJob' ) >>> job = hyp3 . watch ( job ) >>> job . download_files () Submitting Jobs \u00b6 hyp3 has member functions for submitting new jobs: rtc_job = hyp3 . submit_rtc_job ( 'granule_id' , 'job_name' ) insar_job = hyp3 . submit_insar_job ( 'reference_granule_id' , 'secondary_granule_id' , 'job_name' ) autorift_job = hyp3 . submit_autorift_job ( 'reference_granule_id' , 'secondary_granule_id' , 'job_name' ) Each of these functions will return an instance of the Job class that represents a new HyP3 job request. Finding Existing Jobs \u00b6 To find HyP3 jobs that were run previously, you can use the hyp3.find_jobs() batch = hyp3 . find_jobs () This will return a Batch instance representing all jobs owned by you. You can also pass parameters to query to a specific set of jobs Operations on Job and Batch \u00b6 If your jobs are not complete you can use the HyP3 instance to update them, and wait from completion batch = hyp3 . find_jobs () if not batch . complete (): # to get updated information batch = hyp3 . refresh ( batch ) # or to wait until completion and get updated information (which will take a fair bit) batch = hyp3 . watch ( batch ) Once you have complete jobs you can download the products to your machine batch . download_files () These operations also work on Job objects job = hyp3 . submit_rtc_job ( 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' , 'MyJobName' ) job = hyp3 . watch ( job ) job . download_files () Documentation \u00b6 For the full SDK API Reference, see the HyP3 documentation Contact Us \u00b6 Want to talk about the HyP3 SDK? We would love to hear from you! Found a bug? Want to request a feature? Open an issue General questions? Suggestions? Or just want to talk to the team? Chat with us on Gitter","title":"SDK"},{"location":"using/sdk/#hyp3-sdk","text":"A python wrapper around the HyP3 API >>> from hyp3_sdk import HyP3 >>> hyp3 = HyP3 ( username = 'MyUsername' , password = 'MyPassword' ) >>> granule = 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' >>> job = hyp3 . submit_rtc_job ( granule = granule , name = 'MyNewJob' ) >>> job = hyp3 . watch ( job ) >>> job . download_files ()","title":"HyP3 SDK"},{"location":"using/sdk/#install","text":"In order to easily manage dependencies, we recommend using dedicated project environments via Anaconda/Miniconda or Python virtual environments . The HyP3 SDK can be installed into a conda environment with conda install -c conda-forge hyp3_sdk or into a virtual environment with python -m pip install hyp3_sdk","title":"Install"},{"location":"using/sdk/#quick-usage","text":"There are 3 main classes that the SDK exposes: HyP3 to perform HyP3 operations (find jobs, refresh job information, submitting new jobs) Job to perform operations on single jobs (downloading products, check status) Batch to perform operations on multiple jobs at once (downloading products, check status) An instance of the HyP3 class will be needed to interact with the external HyP3 API. >>> from hyp3_sdk import HyP3 >>> hyp3 = HyP3 ( username = 'MyUsername' , password = 'MyPassword' ) >>> granule = 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' >>> job = hyp3 . submit_rtc_job ( granule = granule , name = 'MyNewJob' ) >>> job = hyp3 . watch ( job ) >>> job . download_files ()","title":"Quick Usage"},{"location":"using/sdk/#submitting-jobs","text":"hyp3 has member functions for submitting new jobs: rtc_job = hyp3 . submit_rtc_job ( 'granule_id' , 'job_name' ) insar_job = hyp3 . submit_insar_job ( 'reference_granule_id' , 'secondary_granule_id' , 'job_name' ) autorift_job = hyp3 . submit_autorift_job ( 'reference_granule_id' , 'secondary_granule_id' , 'job_name' ) Each of these functions will return an instance of the Job class that represents a new HyP3 job request.","title":"Submitting Jobs"},{"location":"using/sdk/#finding-existing-jobs","text":"To find HyP3 jobs that were run previously, you can use the hyp3.find_jobs() batch = hyp3 . find_jobs () This will return a Batch instance representing all jobs owned by you. You can also pass parameters to query to a specific set of jobs","title":"Finding Existing Jobs"},{"location":"using/sdk/#operations-on-job-and-batch","text":"If your jobs are not complete you can use the HyP3 instance to update them, and wait from completion batch = hyp3 . find_jobs () if not batch . complete (): # to get updated information batch = hyp3 . refresh ( batch ) # or to wait until completion and get updated information (which will take a fair bit) batch = hyp3 . watch ( batch ) Once you have complete jobs you can download the products to your machine batch . download_files () These operations also work on Job objects job = hyp3 . submit_rtc_job ( 'S1A_IW_SLC__1SSV_20150621T120220_20150621T120232_006471_008934_72D8' , 'MyJobName' ) job = hyp3 . watch ( job ) job . download_files ()","title":"Operations on Job and Batch"},{"location":"using/sdk/#documentation","text":"For the full SDK API Reference, see the HyP3 documentation","title":"Documentation"},{"location":"using/sdk/#contact-us","text":"Want to talk about the HyP3 SDK? We would love to hear from you! Found a bug? Want to request a feature? Open an issue General questions? Suggestions? Or just want to talk to the team? Chat with us on Gitter","title":"Contact Us"},{"location":"using/sdk_api/","text":"hyp3_sdk v3.0.0 API Reference \u00b6 hyp3_sdk \u00b6 A python wrapper around the HyP3 API Batch \u00b6 Source code in 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 class Batch : def __init__ ( self , jobs : Optional [ List [ Job ]] = None ): if jobs is None : jobs = [] self . jobs = jobs def __add__ ( self , other : Union [ Job , 'Batch' ]): if isinstance ( other , Batch ): return Batch ( self . jobs + other . jobs ) elif isinstance ( other , Job ): return Batch ( self . jobs + [ other ]) else : raise TypeError ( f \"unsupported operand type(s) for +: ' { type ( self ) } ' and ' { type ( other ) } '\" ) def __iadd__ ( self , other : Union [ Job , 'Batch' ]): if isinstance ( other , Batch ): self . jobs += other . jobs elif isinstance ( other , Job ): self . jobs += [ other ] else : raise TypeError ( f \"unsupported operand type(s) for +=: ' { type ( self ) } ' and ' { type ( other ) } '\" ) return self def __iter__ ( self ): return iter ( self . jobs ) def __len__ ( self ): return len ( self . jobs ) def __contains__ ( self , job : Job ): return job in self . jobs def __eq__ ( self , other : 'Batch' ): return self . jobs == other . jobs def __delitem__ ( self , job : int ): self . jobs . pop ( job ) return self def __getitem__ ( self , index : int ): if isinstance ( index , slice ): return Batch ( self . jobs [ index ]) return self . jobs [ index ] def __setitem__ ( self , index : int , job : Job ): self . jobs [ index ] = job return self def __repr__ ( self ): reprs = \", \" . join ([ job . __repr__ () for job in self . jobs ]) return f 'Batch([ { reprs } ])' def __str__ ( self ): count = self . _count_statuses () return f ' { len ( self ) } HyP3 Jobs: ' \\ f ' { count [ \"SUCCEEDED\" ] } succeeded, ' \\ f ' { count [ \"FAILED\" ] } failed, ' \\ f ' { count [ \"RUNNING\" ] } running, ' \\ f ' { count [ \"PENDING\" ] } pending.' def _count_statuses ( self ): return Counter ([ job . status_code for job in self . jobs ]) def complete ( self ) -> bool : \"\"\" Returns: True if all jobs are complete, otherwise returns False \"\"\" for job in self . jobs : if not job . complete (): return False return True def succeeded ( self ) -> bool : \"\"\" Returns: True if all jobs have succeeded, otherwise returns False \"\"\" for job in self . jobs : if not job . succeeded (): return False return True def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" downloaded_files = [] tqdm = get_tqdm_progress_bar () for job in tqdm ( self . jobs ): try : downloaded_files . extend ( job . download_files ( location , create )) except HyP3SDKError as e : print ( f 'Warning: { e } Skipping download for { job } .' ) return downloaded_files def any_expired ( self ) -> bool : \"\"\"Check succeeded jobs for expiration\"\"\" for job in self . jobs : try : if job . expired (): return True except HyP3SDKError : continue return False def filter_jobs ( self , succeeded : bool = True , running : bool = True , failed : bool = False , include_expired : bool = True , ) -> 'Batch' : \"\"\"Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Args: succeeded: Include all succeeded jobs running: Include all running jobs failed: Include all failed jobs include_expired: Include expired jobs in the result Returns: batch: A batch object containing jobs matching all the selected statuses \"\"\" filtered_jobs = [] for job in self . jobs : if job . succeeded () and succeeded : if include_expired or not job . expired (): filtered_jobs . append ( job ) elif job . running () and running : filtered_jobs . append ( job ) elif job . failed () and failed : filtered_jobs . append ( job ) return Batch ( filtered_jobs ) any_expired () \u00b6 Check succeeded jobs for expiration Source code in 241 242 243 244 245 246 247 248 249 def any_expired ( self ) -> bool : \"\"\"Check succeeded jobs for expiration\"\"\" for job in self . jobs : try : if job . expired (): return True except HyP3SDKError : continue return False complete () \u00b6 Returns: True if all jobs are complete, otherwise returns False Source code in 206 207 208 209 210 211 212 213 def complete ( self ) -> bool : \"\"\" Returns: True if all jobs are complete, otherwise returns False \"\"\" for job in self . jobs : if not job . complete (): return False return True download_files ( location = '.' , create = True ) \u00b6 Parameters: Name Type Description Default location Union [ Path , str ] Directory location to put files into '.' create bool Create location if it does not point to an existing directory True Returns: list of Path objects to downloaded files Source code in 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" downloaded_files = [] tqdm = get_tqdm_progress_bar () for job in tqdm ( self . jobs ): try : downloaded_files . extend ( job . download_files ( location , create )) except HyP3SDKError as e : print ( f 'Warning: { e } Skipping download for { job } .' ) return downloaded_files filter_jobs ( succeeded = True , running = True , failed = False , include_expired = True ) \u00b6 Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Parameters: Name Type Description Default succeeded bool Include all succeeded jobs True running bool Include all running jobs True failed bool Include all failed jobs False include_expired bool Include expired jobs in the result True Returns: Name Type Description batch Batch A batch object containing jobs matching all the selected statuses Source code in 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 def filter_jobs ( self , succeeded : bool = True , running : bool = True , failed : bool = False , include_expired : bool = True , ) -> 'Batch' : \"\"\"Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Args: succeeded: Include all succeeded jobs running: Include all running jobs failed: Include all failed jobs include_expired: Include expired jobs in the result Returns: batch: A batch object containing jobs matching all the selected statuses \"\"\" filtered_jobs = [] for job in self . jobs : if job . succeeded () and succeeded : if include_expired or not job . expired (): filtered_jobs . append ( job ) elif job . running () and running : filtered_jobs . append ( job ) elif job . failed () and failed : filtered_jobs . append ( job ) return Batch ( filtered_jobs ) succeeded () \u00b6 Returns: True if all jobs have succeeded, otherwise returns False Source code in 215 216 217 218 219 220 221 222 def succeeded ( self ) -> bool : \"\"\" Returns: True if all jobs have succeeded, otherwise returns False \"\"\" for job in self . jobs : if not job . succeeded (): return False return True HyP3 \u00b6 A python wrapper around the HyP3 API. Warning: All jobs submitted to HyP3 are publicly visible. For more information, see https://hyp3-docs.asf.alaska.edu/#public-visibility-of-jobs Source code in 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 class HyP3 : \"\"\"A python wrapper around the HyP3 API. Warning: All jobs submitted to HyP3 are publicly visible. For more information, see https://hyp3-docs.asf.alaska.edu/#public-visibility-of-jobs \"\"\" def __init__ ( self , api_url : str = PROD_API , username : Optional [ str ] = None , password : Optional [ str ] = None , prompt : bool = False ): \"\"\"If username and password are not provided, attempts to use credentials from a `.netrc` file. Args: api_url: Address of the HyP3 API username: Username for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. password: Password for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. prompt: Prompt for username and/or password interactively when they are not provided as keyword parameters \"\"\" self . url = api_url if username is None and prompt : username = input ( 'NASA Earthdata Login username: ' ) if password is None and prompt : password = getpass ( 'NASA Earthdata Login password: ' ) self . session = hyp3_sdk . util . get_authenticated_session ( username , password ) self . session . headers . update ({ 'User-Agent' : f ' { hyp3_sdk . __name__ } / { hyp3_sdk . __version__ } ' }) def find_jobs ( self , start : Optional [ datetime ] = None , end : Optional [ datetime ] = None , status_code : Optional [ str ] = None , name : Optional [ str ] = None , job_type : Optional [ str ] = None , user_id : Optional [ str ] = None ) -> Batch : \"\"\"Gets a Batch of jobs from HyP3 matching the provided search criteria Args: start: only jobs submitted after given time end: only jobs submitted before given time status_code: only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) name: only jobs with this name job_type: only jobs with this job_type user_id: only jobs submitted by this user (defaults to the current user) Returns: A Batch object containing the found jobs \"\"\" params = {} for param_name in ( 'start' , 'end' , 'status_code' , 'name' , 'job_type' , 'user_id' ): param_value = locals () . get ( param_name ) if param_value is not None : if isinstance ( param_value , datetime ): if param_value . tzinfo is None : param_value = param_value . replace ( tzinfo = timezone . utc ) param_value = param_value . isoformat ( timespec = 'seconds' ) params [ param_name ] = param_value response = self . session . get ( urljoin ( self . url , '/jobs' ), params = params ) _raise_for_hyp3_status ( response ) jobs = [ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]] while 'next' in response . json (): next_url = response . json ()[ 'next' ] response = self . session . get ( next_url ) _raise_for_hyp3_status ( response ) jobs . extend ([ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]]) return Batch ( jobs ) def get_job_by_id ( self , job_id : str ) -> Job : \"\"\"Get job by job ID Args: job_id: A job ID Returns: A Job object \"\"\" response = self . session . get ( urljoin ( self . url , f '/jobs/ { job_id } ' )) _raise_for_hyp3_status ( response ) return Job . from_dict ( response . json ()) @singledispatchmethod def watch ( self , job_or_batch : Union [ Batch , Job ], timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Union [ Batch , Job ]: \"\"\"Watch jobs until they complete Args: job_or_batch: A Batch or Job object of jobs to watch timeout: How long to wait until exiting in seconds interval: How often to check for updates in seconds Returns: A Batch or Job object with refreshed watched jobs \"\"\" raise NotImplementedError ( f 'Cannot watch { type ( job_or_batch ) } type object' ) @watch . register def _watch_batch ( self , batch : Batch , timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Batch : tqdm = hyp3_sdk . util . get_tqdm_progress_bar () iterations_until_timeout = math . ceil ( timeout / interval ) bar_format = ' {l_bar}{bar} | {n_fmt} / {total_fmt} [ {postfix[0]} ]' with tqdm ( total = len ( batch ), bar_format = bar_format , postfix = [ f 'timeout in { timeout } s' ]) as progress_bar : for ii in range ( iterations_until_timeout ): batch = self . refresh ( batch ) counts = batch . _count_statuses () complete = counts [ 'SUCCEEDED' ] + counts [ 'FAILED' ] progress_bar . postfix = [ f 'timeout in { timeout - ii * interval } s' ] # to control n/total manually; update is n += value progress_bar . n = complete progress_bar . update ( 0 ) if batch . complete (): return batch time . sleep ( interval ) raise HyP3Error ( f 'Timeout occurred while waiting for { batch } ' ) @watch . register def _watch_job ( self , job : Job , timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Job : tqdm = hyp3_sdk . util . get_tqdm_progress_bar () iterations_until_timeout = math . ceil ( timeout / interval ) bar_format = ' {n_fmt} / {total_fmt} [ {postfix[0]} ]' with tqdm ( total = 1 , bar_format = bar_format , postfix = [ f 'timeout in { timeout } s' ]) as progress_bar : for ii in range ( iterations_until_timeout ): job = self . refresh ( job ) progress_bar . postfix = [ f 'timeout in { timeout - ii * interval } s' ] progress_bar . update ( int ( job . complete ())) if job . complete (): return job time . sleep ( interval ) raise HyP3Error ( f 'Timeout occurred while waiting for { job } ' ) @singledispatchmethod def refresh ( self , job_or_batch : Union [ Batch , Job ]) -> Union [ Batch , Job ]: \"\"\"Refresh each jobs' information Args: job_or_batch: A Batch of Job object to refresh Returns: A Batch or Job object with refreshed information \"\"\" raise NotImplementedError ( f 'Cannot refresh { type ( job_or_batch ) } type object' ) @refresh . register def _refresh_batch ( self , batch : Batch ): jobs = [] for job in batch . jobs : jobs . append ( self . refresh ( job )) return Batch ( jobs ) @refresh . register def _refresh_job ( self , job : Job ): return self . get_job_by_id ( job . job_id ) def submit_prepared_jobs ( self , prepared_jobs : Union [ dict , List [ dict ]]) -> Batch : \"\"\"Submit a prepared job dictionary, or list of prepared job dictionaries Args: prepared_jobs: A prepared job dictionary, or list of prepared job dictionaries Returns: A Batch object containing the submitted job(s) \"\"\" if isinstance ( prepared_jobs , dict ): payload = { 'jobs' : [ prepared_jobs ]} else : payload = { 'jobs' : prepared_jobs } response = self . session . post ( urljoin ( self . url , '/jobs' ), json = payload ) _raise_for_hyp3_status ( response ) batch = Batch () for job in response . json ()[ 'jobs' ]: batch += Job . from_dict ( job ) return batch def submit_autorift_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> Batch : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A Batch object containing the autoRIFT job \"\"\" job_dict = self . prepare_autorift_job ( granule1 , granule2 , name = name ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_autorift_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> dict : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A dictionary containing the prepared autoRIFT job \"\"\" job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ]}, 'job_type' : 'AUTORIFT' , } if name is not None : job_dict [ 'name' ] = name return job_dict def submit_rtc_job ( self , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> Batch : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A Batch object containing the RTC job \"\"\" arguments = locals () arguments . pop ( 'self' ) job_dict = self . prepare_rtc_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_rtc_job ( cls , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> dict : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A dictionary containing the prepared RTC job \"\"\" job_parameters = locals () . copy () for key in [ 'granule' , 'name' , 'cls' ]: job_parameters . pop ( key , None ) job_dict = { 'job_parameters' : { 'granules' : [ granule ], ** job_parameters }, 'job_type' : 'RTC_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict def submit_insar_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> Batch : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A Batch object containing the InSAR job \"\"\" arguments = locals () . copy () arguments . pop ( 'self' ) job_dict = self . prepare_insar_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_insar_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> dict : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A dictionary containing the prepared InSAR job \"\"\" if include_los_displacement : warnings . warn ( 'The include_los_displacement parameter has been deprecated in favor of ' 'include_displacement_maps, and will be removed in a future release.' , FutureWarning ) job_parameters = locals () . copy () for key in [ 'cls' , 'granule1' , 'granule2' , 'name' ]: job_parameters . pop ( key ) job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ], ** job_parameters }, 'job_type' : 'INSAR_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict def my_info ( self ) -> dict : \"\"\" Returns: Your user information \"\"\" response = self . session . get ( urljoin ( self . url , '/user' )) _raise_for_hyp3_status ( response ) return response . json () def check_quota ( self ) -> Optional [ int ]: \"\"\" Returns: The number of jobs left in your quota, or None if you have no quota \"\"\" info = self . my_info () return info [ 'quota' ][ 'remaining' ] __init__ ( api_url = PROD_API , username = None , password = None , prompt = False ) \u00b6 If username and password are not provided, attempts to use credentials from a .netrc file. Parameters: Name Type Description Default api_url str Address of the HyP3 API PROD_API username Optional [ str ] Username for authenticating to urs.earthdata.nasa.gov . Both username and password must be provided if either is provided. None password Optional [ str ] Password for authenticating to urs.earthdata.nasa.gov . Both username and password must be provided if either is provided. None prompt bool Prompt for username and/or password interactively when they are not provided as keyword parameters False Source code in 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def __init__ ( self , api_url : str = PROD_API , username : Optional [ str ] = None , password : Optional [ str ] = None , prompt : bool = False ): \"\"\"If username and password are not provided, attempts to use credentials from a `.netrc` file. Args: api_url: Address of the HyP3 API username: Username for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. password: Password for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. prompt: Prompt for username and/or password interactively when they are not provided as keyword parameters \"\"\" self . url = api_url if username is None and prompt : username = input ( 'NASA Earthdata Login username: ' ) if password is None and prompt : password = getpass ( 'NASA Earthdata Login password: ' ) self . session = hyp3_sdk . util . get_authenticated_session ( username , password ) self . session . headers . update ({ 'User-Agent' : f ' { hyp3_sdk . __name__ } / { hyp3_sdk . __version__ } ' }) check_quota () \u00b6 Returns: Type Description Optional [ int ] The number of jobs left in your quota, or None if you have no quota Source code in 423 424 425 426 427 428 429 def check_quota ( self ) -> Optional [ int ]: \"\"\" Returns: The number of jobs left in your quota, or None if you have no quota \"\"\" info = self . my_info () return info [ 'quota' ][ 'remaining' ] find_jobs ( start = None , end = None , status_code = None , name = None , job_type = None , user_id = None ) \u00b6 Gets a Batch of jobs from HyP3 matching the provided search criteria Parameters: Name Type Description Default start Optional [ datetime ] only jobs submitted after given time None end Optional [ datetime ] only jobs submitted before given time None status_code Optional [ str ] only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) None name Optional [ str ] only jobs with this name None job_type Optional [ str ] only jobs with this job_type None user_id Optional [ str ] only jobs submitted by this user (defaults to the current user) None Returns: Type Description Batch A Batch object containing the found jobs Source code in 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def find_jobs ( self , start : Optional [ datetime ] = None , end : Optional [ datetime ] = None , status_code : Optional [ str ] = None , name : Optional [ str ] = None , job_type : Optional [ str ] = None , user_id : Optional [ str ] = None ) -> Batch : \"\"\"Gets a Batch of jobs from HyP3 matching the provided search criteria Args: start: only jobs submitted after given time end: only jobs submitted before given time status_code: only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) name: only jobs with this name job_type: only jobs with this job_type user_id: only jobs submitted by this user (defaults to the current user) Returns: A Batch object containing the found jobs \"\"\" params = {} for param_name in ( 'start' , 'end' , 'status_code' , 'name' , 'job_type' , 'user_id' ): param_value = locals () . get ( param_name ) if param_value is not None : if isinstance ( param_value , datetime ): if param_value . tzinfo is None : param_value = param_value . replace ( tzinfo = timezone . utc ) param_value = param_value . isoformat ( timespec = 'seconds' ) params [ param_name ] = param_value response = self . session . get ( urljoin ( self . url , '/jobs' ), params = params ) _raise_for_hyp3_status ( response ) jobs = [ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]] while 'next' in response . json (): next_url = response . json ()[ 'next' ] response = self . session . get ( next_url ) _raise_for_hyp3_status ( response ) jobs . extend ([ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]]) return Batch ( jobs ) get_job_by_id ( job_id ) \u00b6 Get job by job ID Parameters: Name Type Description Default job_id str A job ID required Returns: Type Description Job A Job object Source code in 92 93 94 95 96 97 98 99 100 101 102 103 104 def get_job_by_id ( self , job_id : str ) -> Job : \"\"\"Get job by job ID Args: job_id: A job ID Returns: A Job object \"\"\" response = self . session . get ( urljoin ( self . url , f '/jobs/ { job_id } ' )) _raise_for_hyp3_status ( response ) return Job . from_dict ( response . json ()) my_info () \u00b6 Returns: Type Description dict Your user information Source code in 414 415 416 417 418 419 420 421 def my_info ( self ) -> dict : \"\"\" Returns: Your user information \"\"\" response = self . session . get ( urljoin ( self . url , '/user' )) _raise_for_hyp3_status ( response ) return response . json () prepare_autorift_job ( granule1 , granule2 , name = None ) classmethod \u00b6 Submit an autoRIFT job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None Returns: Type Description dict A dictionary containing the prepared autoRIFT job Source code in 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 @classmethod def prepare_autorift_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> dict : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A dictionary containing the prepared autoRIFT job \"\"\" job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ]}, 'job_type' : 'AUTORIFT' , } if name is not None : job_dict [ 'name' ] = name return job_dict prepare_insar_job ( granule1 , granule2 , name = None , include_look_vectors = False , include_los_displacement = False , include_inc_map = False , looks = '20x4' , include_dem = False , include_wrapped_phase = False , apply_water_mask = False , include_displacement_maps = False ) classmethod \u00b6 Submit an InSAR job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None include_look_vectors bool Include the look vector theta and phi files in the product package False include_los_displacement bool Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of include_displacement_maps , and will be removed in a future release. False include_inc_map bool Include the local and ellipsoidal incidence angle maps in the product package False looks Literal ['20x4', '10x2'] Number of looks to take in range and azimuth '20x4' include_dem bool Include the digital elevation model GeoTIFF in the product package False include_wrapped_phase bool Include the wrapped phase GeoTIFF in the product package False apply_water_mask bool Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping False include_displacement_maps bool Include displacement maps (line-of-sight and vertical) in the product package False Returns: A dictionary containing the prepared InSAR job Source code in 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 @classmethod def prepare_insar_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> dict : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A dictionary containing the prepared InSAR job \"\"\" if include_los_displacement : warnings . warn ( 'The include_los_displacement parameter has been deprecated in favor of ' 'include_displacement_maps, and will be removed in a future release.' , FutureWarning ) job_parameters = locals () . copy () for key in [ 'cls' , 'granule1' , 'granule2' , 'name' ]: job_parameters . pop ( key ) job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ], ** job_parameters }, 'job_type' : 'INSAR_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict prepare_rtc_job ( granule , name = None , dem_matching = False , include_dem = False , include_inc_map = False , include_rgb = False , include_scattering_area = False , radiometry = 'gamma0' , resolution = 30 , scale = 'power' , speckle_filter = False , dem_name = 'copernicus' ) classmethod \u00b6 Submit an RTC job Parameters: Name Type Description Default granule str The granule (scene) to use required name Optional [ str ] A name for the job None dem_matching bool Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files False include_dem bool Include the DEM file in the product package False include_inc_map bool Include the local incidence angle map in the product package False include_rgb bool Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) False include_scattering_area bool Include the scattering area in the product package False radiometry Literal ['sigma0', 'gamma0'] Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) 'gamma0' resolution Literal [10, 20, 30] Desired output pixel spacing in meters 30 scale Literal ['amplitude', 'decibel', 'power'] Scale of output image; power, decibel or amplitude 'power' speckle_filter bool Apply an Enhanced Lee speckle filter False dem_name Literal ['copernicus', 'legacy'] Name of the DEM to use for processing. copernicus will use the Copernicus GLO-30 Public DEM, while legacy will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. 'copernicus' Returns: Type Description dict A dictionary containing the prepared RTC job Source code in 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 @classmethod def prepare_rtc_job ( cls , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> dict : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A dictionary containing the prepared RTC job \"\"\" job_parameters = locals () . copy () for key in [ 'granule' , 'name' , 'cls' ]: job_parameters . pop ( key , None ) job_dict = { 'job_parameters' : { 'granules' : [ granule ], ** job_parameters }, 'job_type' : 'RTC_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict refresh ( job_or_batch ) \u00b6 Refresh each jobs' information Parameters: Name Type Description Default job_or_batch Union [ Batch , Job ] A Batch of Job object to refresh required Returns: Type Description Union [ Batch , Job ] A Batch or Job object with refreshed information Source code in 159 160 161 162 163 164 165 166 167 168 169 @singledispatchmethod def refresh ( self , job_or_batch : Union [ Batch , Job ]) -> Union [ Batch , Job ]: \"\"\"Refresh each jobs' information Args: job_or_batch: A Batch of Job object to refresh Returns: A Batch or Job object with refreshed information \"\"\" raise NotImplementedError ( f 'Cannot refresh { type ( job_or_batch ) } type object' ) submit_autorift_job ( granule1 , granule2 , name = None ) \u00b6 Submit an autoRIFT job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None Returns: Type Description Batch A Batch object containing the autoRIFT job Source code in 204 205 206 207 208 209 210 211 212 213 214 215 216 def submit_autorift_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> Batch : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A Batch object containing the autoRIFT job \"\"\" job_dict = self . prepare_autorift_job ( granule1 , granule2 , name = name ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) submit_insar_job ( granule1 , granule2 , name = None , include_look_vectors = False , include_los_displacement = False , include_inc_map = False , looks = '20x4' , include_dem = False , include_wrapped_phase = False , apply_water_mask = False , include_displacement_maps = False ) \u00b6 Submit an InSAR job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None include_look_vectors bool Include the look vector theta and phi files in the product package False include_los_displacement bool Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of include_displacement_maps , and will be removed in a future release. False include_inc_map bool Include the local and ellipsoidal incidence angle maps in the product package False looks Literal ['20x4', '10x2'] Number of looks to take in range and azimuth '20x4' include_dem bool Include the digital elevation model GeoTIFF in the product package False include_wrapped_phase bool Include the wrapped phase GeoTIFF in the product package False apply_water_mask bool Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping False include_displacement_maps bool Include displacement maps (line-of-sight and vertical) in the product package False Returns: Type Description Batch A Batch object containing the InSAR job Source code in 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 def submit_insar_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> Batch : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A Batch object containing the InSAR job \"\"\" arguments = locals () . copy () arguments . pop ( 'self' ) job_dict = self . prepare_insar_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) submit_prepared_jobs ( prepared_jobs ) \u00b6 Submit a prepared job dictionary, or list of prepared job dictionaries Parameters: Name Type Description Default prepared_jobs Union [ dict , List [ dict ]] A prepared job dictionary, or list of prepared job dictionaries required Returns: Type Description Batch A Batch object containing the submitted job(s) Source code in 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 def submit_prepared_jobs ( self , prepared_jobs : Union [ dict , List [ dict ]]) -> Batch : \"\"\"Submit a prepared job dictionary, or list of prepared job dictionaries Args: prepared_jobs: A prepared job dictionary, or list of prepared job dictionaries Returns: A Batch object containing the submitted job(s) \"\"\" if isinstance ( prepared_jobs , dict ): payload = { 'jobs' : [ prepared_jobs ]} else : payload = { 'jobs' : prepared_jobs } response = self . session . post ( urljoin ( self . url , '/jobs' ), json = payload ) _raise_for_hyp3_status ( response ) batch = Batch () for job in response . json ()[ 'jobs' ]: batch += Job . from_dict ( job ) return batch submit_rtc_job ( granule , name = None , dem_matching = False , include_dem = False , include_inc_map = False , include_rgb = False , include_scattering_area = False , radiometry = 'gamma0' , resolution = 30 , scale = 'power' , speckle_filter = False , dem_name = 'copernicus' ) \u00b6 Submit an RTC job Parameters: Name Type Description Default granule str The granule (scene) to use required name Optional [ str ] A name for the job None dem_matching bool Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files False include_dem bool Include the DEM file in the product package False include_inc_map bool Include the local incidence angle map in the product package False include_rgb bool Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) False include_scattering_area bool Include the scattering area in the product package False radiometry Literal ['sigma0', 'gamma0'] Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) 'gamma0' resolution Literal [10, 20, 30] Desired output pixel spacing in meters 30 scale Literal ['amplitude', 'decibel', 'power'] Scale of output image; power, decibel or amplitude 'power' speckle_filter bool Apply an Enhanced Lee speckle filter False dem_name Literal ['copernicus', 'legacy'] Name of the DEM to use for processing. copernicus will use the Copernicus GLO-30 Public DEM, while legacy will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. 'copernicus' Returns: Type Description Batch A Batch object containing the RTC job Source code in 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 def submit_rtc_job ( self , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> Batch : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A Batch object containing the RTC job \"\"\" arguments = locals () arguments . pop ( 'self' ) job_dict = self . prepare_rtc_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) watch ( job_or_batch , timeout = 10800 , interval = 60 ) \u00b6 Watch jobs until they complete Parameters: Name Type Description Default job_or_batch Union [ Batch , Job ] A Batch or Job object of jobs to watch required timeout int How long to wait until exiting in seconds 10800 interval Union [ int , float ] How often to check for updates in seconds 60 Returns: Type Description Union [ Batch , Job ] A Batch or Job object with refreshed watched jobs Source code in 106 107 108 109 110 111 112 113 114 115 116 117 118 119 @singledispatchmethod def watch ( self , job_or_batch : Union [ Batch , Job ], timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Union [ Batch , Job ]: \"\"\"Watch jobs until they complete Args: job_or_batch: A Batch or Job object of jobs to watch timeout: How long to wait until exiting in seconds interval: How often to check for updates in seconds Returns: A Batch or Job object with refreshed watched jobs \"\"\" raise NotImplementedError ( f 'Cannot watch { type ( job_or_batch ) } type object' ) Job \u00b6 Source code in 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 class Job : _attributes_for_resubmit = { 'name' , 'job_parameters' , 'job_type' } def __init__ ( self , job_type : str , job_id : str , request_time : datetime , status_code : str , user_id : str , name : Optional [ str ] = None , job_parameters : Optional [ dict ] = None , files : Optional [ List ] = None , logs : Optional [ List ] = None , browse_images : Optional [ List ] = None , thumbnail_images : Optional [ List ] = None , expiration_time : Optional [ datetime ] = None , processing_times : Optional [ List [ float ]] = None , ): self . job_id = job_id self . job_type = job_type self . request_time = request_time self . status_code = status_code self . user_id = user_id self . name = name self . job_parameters = job_parameters self . files = files self . logs = logs self . browse_images = browse_images self . thumbnail_images = thumbnail_images self . expiration_time = expiration_time self . processing_times = processing_times def __repr__ ( self ): return f 'Job.from_dict( { self . to_dict () } )' def __str__ ( self ): return f 'HyP3 { self . job_type } job { self . job_id } ' def __eq__ ( self , other ): return self . __dict__ == other . __dict__ @staticmethod def from_dict ( input_dict : dict ): expiration_time = parse_date ( input_dict [ 'expiration_time' ]) if input_dict . get ( 'expiration_time' ) else None return Job ( job_type = input_dict [ 'job_type' ], job_id = input_dict [ 'job_id' ], request_time = parse_date ( input_dict [ 'request_time' ]), status_code = input_dict [ 'status_code' ], user_id = input_dict [ 'user_id' ], name = input_dict . get ( 'name' ), job_parameters = input_dict . get ( 'job_parameters' ), files = input_dict . get ( 'files' ), logs = input_dict . get ( 'logs' ), browse_images = input_dict . get ( 'browse_images' ), thumbnail_images = input_dict . get ( 'thumbnail_images' ), expiration_time = expiration_time , processing_times = input_dict . get ( 'processing_times' ), ) def to_dict ( self , for_resubmit : bool = False ): job_dict = {} if for_resubmit : keys_to_process = Job . _attributes_for_resubmit else : keys_to_process = vars ( self ) . keys () for key in keys_to_process : value = self . __getattribute__ ( key ) if value is not None : if isinstance ( value , datetime ): job_dict [ key ] = value . isoformat ( timespec = 'seconds' ) else : job_dict [ key ] = value return job_dict def succeeded ( self ) -> bool : return self . status_code == 'SUCCEEDED' def failed ( self ) -> bool : return self . status_code == 'FAILED' def complete ( self ) -> bool : return self . succeeded () or self . failed () # TODO may want to update this to check if status code is actually RUNNING, because currently this also returns # true if status is PENDING def running ( self ) -> bool : return not self . complete () def expired ( self ) -> bool : return self . expiration_time is not None and datetime . now ( tz . UTC ) >= self . expiration_time def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" location = Path ( location ) if not self . succeeded (): raise HyP3SDKError ( f 'Only succeeded jobs can be downloaded; job is { self . status_code } .' ) if self . expired (): raise HyP3SDKError ( f 'Expired jobs cannot be downloaded; ' f 'job expired { self . expiration_time . isoformat ( timespec = \"seconds\" ) } .' ) if create : location . mkdir ( parents = True , exist_ok = True ) elif not location . is_dir (): raise NotADirectoryError ( str ( location )) downloaded_files = [] for file in self . files : download_url = file [ 'url' ] filename = location / file [ 'filename' ] try : downloaded_files . append ( download_file ( download_url , filename , chunk_size = 10485760 )) except HTTPError : raise HyP3SDKError ( f 'Unable to download file: { download_url } ' ) return downloaded_files download_files ( location = '.' , create = True ) \u00b6 Parameters: Name Type Description Default location Union [ Path , str ] Directory location to put files into '.' create bool Create location if it does not point to an existing directory True Returns: list of Path objects to downloaded files Source code in 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" location = Path ( location ) if not self . succeeded (): raise HyP3SDKError ( f 'Only succeeded jobs can be downloaded; job is { self . status_code } .' ) if self . expired (): raise HyP3SDKError ( f 'Expired jobs cannot be downloaded; ' f 'job expired { self . expiration_time . isoformat ( timespec = \"seconds\" ) } .' ) if create : location . mkdir ( parents = True , exist_ok = True ) elif not location . is_dir (): raise NotADirectoryError ( str ( location )) downloaded_files = [] for file in self . files : download_url = file [ 'url' ] filename = location / file [ 'filename' ] try : downloaded_files . append ( download_file ( download_url , filename , chunk_size = 10485760 )) except HTTPError : raise HyP3SDKError ( f 'Unable to download file: { download_url } ' ) return downloaded_files exceptions \u00b6 Errors and exceptions to raise when the SDK runs into problems ASFSearchError \u00b6 Bases: HyP3SDKError Raise for errors when using the ASF Search module Source code in hyp3_sdk/exceptions.py 15 16 class ASFSearchError ( HyP3SDKError ): \"\"\"Raise for errors when using the ASF Search module\"\"\" AuthenticationError \u00b6 Bases: HyP3SDKError Raise when authentication does not succeed Source code in hyp3_sdk/exceptions.py 23 24 class AuthenticationError ( HyP3SDKError ): \"\"\"Raise when authentication does not succeed\"\"\" HyP3Error \u00b6 Bases: HyP3SDKError Raise for errors when using the HyP3 module Source code in hyp3_sdk/exceptions.py 11 12 class HyP3Error ( HyP3SDKError ): \"\"\"Raise for errors when using the HyP3 module\"\"\" HyP3SDKError \u00b6 Bases: Exception Base Exception for the HyP3 SDK Source code in hyp3_sdk/exceptions.py 7 8 class HyP3SDKError ( Exception ): \"\"\"Base Exception for the HyP3 SDK\"\"\" ServerError \u00b6 Bases: HyP3SDKError Raise when the HyP3 SDK encounters a server error Source code in hyp3_sdk/exceptions.py 19 20 class ServerError ( HyP3SDKError ): \"\"\"Raise when the HyP3 SDK encounters a server error\"\"\" hyp3 \u00b6 HyP3 \u00b6 A python wrapper around the HyP3 API. Warning: All jobs submitted to HyP3 are publicly visible. For more information, see https://hyp3-docs.asf.alaska.edu/#public-visibility-of-jobs Source code in hyp3_sdk/hyp3.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 class HyP3 : \"\"\"A python wrapper around the HyP3 API. Warning: All jobs submitted to HyP3 are publicly visible. For more information, see https://hyp3-docs.asf.alaska.edu/#public-visibility-of-jobs \"\"\" def __init__ ( self , api_url : str = PROD_API , username : Optional [ str ] = None , password : Optional [ str ] = None , prompt : bool = False ): \"\"\"If username and password are not provided, attempts to use credentials from a `.netrc` file. Args: api_url: Address of the HyP3 API username: Username for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. password: Password for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. prompt: Prompt for username and/or password interactively when they are not provided as keyword parameters \"\"\" self . url = api_url if username is None and prompt : username = input ( 'NASA Earthdata Login username: ' ) if password is None and prompt : password = getpass ( 'NASA Earthdata Login password: ' ) self . session = hyp3_sdk . util . get_authenticated_session ( username , password ) self . session . headers . update ({ 'User-Agent' : f ' { hyp3_sdk . __name__ } / { hyp3_sdk . __version__ } ' }) def find_jobs ( self , start : Optional [ datetime ] = None , end : Optional [ datetime ] = None , status_code : Optional [ str ] = None , name : Optional [ str ] = None , job_type : Optional [ str ] = None , user_id : Optional [ str ] = None ) -> Batch : \"\"\"Gets a Batch of jobs from HyP3 matching the provided search criteria Args: start: only jobs submitted after given time end: only jobs submitted before given time status_code: only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) name: only jobs with this name job_type: only jobs with this job_type user_id: only jobs submitted by this user (defaults to the current user) Returns: A Batch object containing the found jobs \"\"\" params = {} for param_name in ( 'start' , 'end' , 'status_code' , 'name' , 'job_type' , 'user_id' ): param_value = locals () . get ( param_name ) if param_value is not None : if isinstance ( param_value , datetime ): if param_value . tzinfo is None : param_value = param_value . replace ( tzinfo = timezone . utc ) param_value = param_value . isoformat ( timespec = 'seconds' ) params [ param_name ] = param_value response = self . session . get ( urljoin ( self . url , '/jobs' ), params = params ) _raise_for_hyp3_status ( response ) jobs = [ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]] while 'next' in response . json (): next_url = response . json ()[ 'next' ] response = self . session . get ( next_url ) _raise_for_hyp3_status ( response ) jobs . extend ([ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]]) return Batch ( jobs ) def get_job_by_id ( self , job_id : str ) -> Job : \"\"\"Get job by job ID Args: job_id: A job ID Returns: A Job object \"\"\" response = self . session . get ( urljoin ( self . url , f '/jobs/ { job_id } ' )) _raise_for_hyp3_status ( response ) return Job . from_dict ( response . json ()) @singledispatchmethod def watch ( self , job_or_batch : Union [ Batch , Job ], timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Union [ Batch , Job ]: \"\"\"Watch jobs until they complete Args: job_or_batch: A Batch or Job object of jobs to watch timeout: How long to wait until exiting in seconds interval: How often to check for updates in seconds Returns: A Batch or Job object with refreshed watched jobs \"\"\" raise NotImplementedError ( f 'Cannot watch { type ( job_or_batch ) } type object' ) @watch . register def _watch_batch ( self , batch : Batch , timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Batch : tqdm = hyp3_sdk . util . get_tqdm_progress_bar () iterations_until_timeout = math . ceil ( timeout / interval ) bar_format = ' {l_bar}{bar} | {n_fmt} / {total_fmt} [ {postfix[0]} ]' with tqdm ( total = len ( batch ), bar_format = bar_format , postfix = [ f 'timeout in { timeout } s' ]) as progress_bar : for ii in range ( iterations_until_timeout ): batch = self . refresh ( batch ) counts = batch . _count_statuses () complete = counts [ 'SUCCEEDED' ] + counts [ 'FAILED' ] progress_bar . postfix = [ f 'timeout in { timeout - ii * interval } s' ] # to control n/total manually; update is n += value progress_bar . n = complete progress_bar . update ( 0 ) if batch . complete (): return batch time . sleep ( interval ) raise HyP3Error ( f 'Timeout occurred while waiting for { batch } ' ) @watch . register def _watch_job ( self , job : Job , timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Job : tqdm = hyp3_sdk . util . get_tqdm_progress_bar () iterations_until_timeout = math . ceil ( timeout / interval ) bar_format = ' {n_fmt} / {total_fmt} [ {postfix[0]} ]' with tqdm ( total = 1 , bar_format = bar_format , postfix = [ f 'timeout in { timeout } s' ]) as progress_bar : for ii in range ( iterations_until_timeout ): job = self . refresh ( job ) progress_bar . postfix = [ f 'timeout in { timeout - ii * interval } s' ] progress_bar . update ( int ( job . complete ())) if job . complete (): return job time . sleep ( interval ) raise HyP3Error ( f 'Timeout occurred while waiting for { job } ' ) @singledispatchmethod def refresh ( self , job_or_batch : Union [ Batch , Job ]) -> Union [ Batch , Job ]: \"\"\"Refresh each jobs' information Args: job_or_batch: A Batch of Job object to refresh Returns: A Batch or Job object with refreshed information \"\"\" raise NotImplementedError ( f 'Cannot refresh { type ( job_or_batch ) } type object' ) @refresh . register def _refresh_batch ( self , batch : Batch ): jobs = [] for job in batch . jobs : jobs . append ( self . refresh ( job )) return Batch ( jobs ) @refresh . register def _refresh_job ( self , job : Job ): return self . get_job_by_id ( job . job_id ) def submit_prepared_jobs ( self , prepared_jobs : Union [ dict , List [ dict ]]) -> Batch : \"\"\"Submit a prepared job dictionary, or list of prepared job dictionaries Args: prepared_jobs: A prepared job dictionary, or list of prepared job dictionaries Returns: A Batch object containing the submitted job(s) \"\"\" if isinstance ( prepared_jobs , dict ): payload = { 'jobs' : [ prepared_jobs ]} else : payload = { 'jobs' : prepared_jobs } response = self . session . post ( urljoin ( self . url , '/jobs' ), json = payload ) _raise_for_hyp3_status ( response ) batch = Batch () for job in response . json ()[ 'jobs' ]: batch += Job . from_dict ( job ) return batch def submit_autorift_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> Batch : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A Batch object containing the autoRIFT job \"\"\" job_dict = self . prepare_autorift_job ( granule1 , granule2 , name = name ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_autorift_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> dict : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A dictionary containing the prepared autoRIFT job \"\"\" job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ]}, 'job_type' : 'AUTORIFT' , } if name is not None : job_dict [ 'name' ] = name return job_dict def submit_rtc_job ( self , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> Batch : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A Batch object containing the RTC job \"\"\" arguments = locals () arguments . pop ( 'self' ) job_dict = self . prepare_rtc_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_rtc_job ( cls , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> dict : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A dictionary containing the prepared RTC job \"\"\" job_parameters = locals () . copy () for key in [ 'granule' , 'name' , 'cls' ]: job_parameters . pop ( key , None ) job_dict = { 'job_parameters' : { 'granules' : [ granule ], ** job_parameters }, 'job_type' : 'RTC_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict def submit_insar_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> Batch : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A Batch object containing the InSAR job \"\"\" arguments = locals () . copy () arguments . pop ( 'self' ) job_dict = self . prepare_insar_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_insar_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> dict : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A dictionary containing the prepared InSAR job \"\"\" if include_los_displacement : warnings . warn ( 'The include_los_displacement parameter has been deprecated in favor of ' 'include_displacement_maps, and will be removed in a future release.' , FutureWarning ) job_parameters = locals () . copy () for key in [ 'cls' , 'granule1' , 'granule2' , 'name' ]: job_parameters . pop ( key ) job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ], ** job_parameters }, 'job_type' : 'INSAR_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict def my_info ( self ) -> dict : \"\"\" Returns: Your user information \"\"\" response = self . session . get ( urljoin ( self . url , '/user' )) _raise_for_hyp3_status ( response ) return response . json () def check_quota ( self ) -> Optional [ int ]: \"\"\" Returns: The number of jobs left in your quota, or None if you have no quota \"\"\" info = self . my_info () return info [ 'quota' ][ 'remaining' ] __init__ ( api_url = PROD_API , username = None , password = None , prompt = False ) \u00b6 If username and password are not provided, attempts to use credentials from a .netrc file. Parameters: Name Type Description Default api_url str Address of the HyP3 API PROD_API username Optional [ str ] Username for authenticating to urs.earthdata.nasa.gov . Both username and password must be provided if either is provided. None password Optional [ str ] Password for authenticating to urs.earthdata.nasa.gov . Both username and password must be provided if either is provided. None prompt bool Prompt for username and/or password interactively when they are not provided as keyword parameters False Source code in hyp3_sdk/hyp3.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def __init__ ( self , api_url : str = PROD_API , username : Optional [ str ] = None , password : Optional [ str ] = None , prompt : bool = False ): \"\"\"If username and password are not provided, attempts to use credentials from a `.netrc` file. Args: api_url: Address of the HyP3 API username: Username for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. password: Password for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. prompt: Prompt for username and/or password interactively when they are not provided as keyword parameters \"\"\" self . url = api_url if username is None and prompt : username = input ( 'NASA Earthdata Login username: ' ) if password is None and prompt : password = getpass ( 'NASA Earthdata Login password: ' ) self . session = hyp3_sdk . util . get_authenticated_session ( username , password ) self . session . headers . update ({ 'User-Agent' : f ' { hyp3_sdk . __name__ } / { hyp3_sdk . __version__ } ' }) check_quota () \u00b6 Returns: Type Description Optional [ int ] The number of jobs left in your quota, or None if you have no quota Source code in hyp3_sdk/hyp3.py 423 424 425 426 427 428 429 def check_quota ( self ) -> Optional [ int ]: \"\"\" Returns: The number of jobs left in your quota, or None if you have no quota \"\"\" info = self . my_info () return info [ 'quota' ][ 'remaining' ] find_jobs ( start = None , end = None , status_code = None , name = None , job_type = None , user_id = None ) \u00b6 Gets a Batch of jobs from HyP3 matching the provided search criteria Parameters: Name Type Description Default start Optional [ datetime ] only jobs submitted after given time None end Optional [ datetime ] only jobs submitted before given time None status_code Optional [ str ] only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) None name Optional [ str ] only jobs with this name None job_type Optional [ str ] only jobs with this job_type None user_id Optional [ str ] only jobs submitted by this user (defaults to the current user) None Returns: Type Description Batch A Batch object containing the found jobs Source code in hyp3_sdk/hyp3.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def find_jobs ( self , start : Optional [ datetime ] = None , end : Optional [ datetime ] = None , status_code : Optional [ str ] = None , name : Optional [ str ] = None , job_type : Optional [ str ] = None , user_id : Optional [ str ] = None ) -> Batch : \"\"\"Gets a Batch of jobs from HyP3 matching the provided search criteria Args: start: only jobs submitted after given time end: only jobs submitted before given time status_code: only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) name: only jobs with this name job_type: only jobs with this job_type user_id: only jobs submitted by this user (defaults to the current user) Returns: A Batch object containing the found jobs \"\"\" params = {} for param_name in ( 'start' , 'end' , 'status_code' , 'name' , 'job_type' , 'user_id' ): param_value = locals () . get ( param_name ) if param_value is not None : if isinstance ( param_value , datetime ): if param_value . tzinfo is None : param_value = param_value . replace ( tzinfo = timezone . utc ) param_value = param_value . isoformat ( timespec = 'seconds' ) params [ param_name ] = param_value response = self . session . get ( urljoin ( self . url , '/jobs' ), params = params ) _raise_for_hyp3_status ( response ) jobs = [ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]] while 'next' in response . json (): next_url = response . json ()[ 'next' ] response = self . session . get ( next_url ) _raise_for_hyp3_status ( response ) jobs . extend ([ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]]) return Batch ( jobs ) get_job_by_id ( job_id ) \u00b6 Get job by job ID Parameters: Name Type Description Default job_id str A job ID required Returns: Type Description Job A Job object Source code in hyp3_sdk/hyp3.py 92 93 94 95 96 97 98 99 100 101 102 103 104 def get_job_by_id ( self , job_id : str ) -> Job : \"\"\"Get job by job ID Args: job_id: A job ID Returns: A Job object \"\"\" response = self . session . get ( urljoin ( self . url , f '/jobs/ { job_id } ' )) _raise_for_hyp3_status ( response ) return Job . from_dict ( response . json ()) my_info () \u00b6 Returns: Type Description dict Your user information Source code in hyp3_sdk/hyp3.py 414 415 416 417 418 419 420 421 def my_info ( self ) -> dict : \"\"\" Returns: Your user information \"\"\" response = self . session . get ( urljoin ( self . url , '/user' )) _raise_for_hyp3_status ( response ) return response . json () prepare_autorift_job ( granule1 , granule2 , name = None ) classmethod \u00b6 Submit an autoRIFT job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None Returns: Type Description dict A dictionary containing the prepared autoRIFT job Source code in hyp3_sdk/hyp3.py 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 @classmethod def prepare_autorift_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> dict : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A dictionary containing the prepared autoRIFT job \"\"\" job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ]}, 'job_type' : 'AUTORIFT' , } if name is not None : job_dict [ 'name' ] = name return job_dict prepare_insar_job ( granule1 , granule2 , name = None , include_look_vectors = False , include_los_displacement = False , include_inc_map = False , looks = '20x4' , include_dem = False , include_wrapped_phase = False , apply_water_mask = False , include_displacement_maps = False ) classmethod \u00b6 Submit an InSAR job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None include_look_vectors bool Include the look vector theta and phi files in the product package False include_los_displacement bool Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of include_displacement_maps , and will be removed in a future release. False include_inc_map bool Include the local and ellipsoidal incidence angle maps in the product package False looks Literal ['20x4', '10x2'] Number of looks to take in range and azimuth '20x4' include_dem bool Include the digital elevation model GeoTIFF in the product package False include_wrapped_phase bool Include the wrapped phase GeoTIFF in the product package False apply_water_mask bool Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping False include_displacement_maps bool Include displacement maps (line-of-sight and vertical) in the product package False Returns: A dictionary containing the prepared InSAR job Source code in hyp3_sdk/hyp3.py 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 @classmethod def prepare_insar_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> dict : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A dictionary containing the prepared InSAR job \"\"\" if include_los_displacement : warnings . warn ( 'The include_los_displacement parameter has been deprecated in favor of ' 'include_displacement_maps, and will be removed in a future release.' , FutureWarning ) job_parameters = locals () . copy () for key in [ 'cls' , 'granule1' , 'granule2' , 'name' ]: job_parameters . pop ( key ) job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ], ** job_parameters }, 'job_type' : 'INSAR_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict prepare_rtc_job ( granule , name = None , dem_matching = False , include_dem = False , include_inc_map = False , include_rgb = False , include_scattering_area = False , radiometry = 'gamma0' , resolution = 30 , scale = 'power' , speckle_filter = False , dem_name = 'copernicus' ) classmethod \u00b6 Submit an RTC job Parameters: Name Type Description Default granule str The granule (scene) to use required name Optional [ str ] A name for the job None dem_matching bool Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files False include_dem bool Include the DEM file in the product package False include_inc_map bool Include the local incidence angle map in the product package False include_rgb bool Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) False include_scattering_area bool Include the scattering area in the product package False radiometry Literal ['sigma0', 'gamma0'] Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) 'gamma0' resolution Literal [10, 20, 30] Desired output pixel spacing in meters 30 scale Literal ['amplitude', 'decibel', 'power'] Scale of output image; power, decibel or amplitude 'power' speckle_filter bool Apply an Enhanced Lee speckle filter False dem_name Literal ['copernicus', 'legacy'] Name of the DEM to use for processing. copernicus will use the Copernicus GLO-30 Public DEM, while legacy will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. 'copernicus' Returns: Type Description dict A dictionary containing the prepared RTC job Source code in hyp3_sdk/hyp3.py 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 @classmethod def prepare_rtc_job ( cls , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> dict : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A dictionary containing the prepared RTC job \"\"\" job_parameters = locals () . copy () for key in [ 'granule' , 'name' , 'cls' ]: job_parameters . pop ( key , None ) job_dict = { 'job_parameters' : { 'granules' : [ granule ], ** job_parameters }, 'job_type' : 'RTC_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict refresh ( job_or_batch ) \u00b6 Refresh each jobs' information Parameters: Name Type Description Default job_or_batch Union [ Batch , Job ] A Batch of Job object to refresh required Returns: Type Description Union [ Batch , Job ] A Batch or Job object with refreshed information Source code in hyp3_sdk/hyp3.py 159 160 161 162 163 164 165 166 167 168 169 @singledispatchmethod def refresh ( self , job_or_batch : Union [ Batch , Job ]) -> Union [ Batch , Job ]: \"\"\"Refresh each jobs' information Args: job_or_batch: A Batch of Job object to refresh Returns: A Batch or Job object with refreshed information \"\"\" raise NotImplementedError ( f 'Cannot refresh { type ( job_or_batch ) } type object' ) submit_autorift_job ( granule1 , granule2 , name = None ) \u00b6 Submit an autoRIFT job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None Returns: Type Description Batch A Batch object containing the autoRIFT job Source code in hyp3_sdk/hyp3.py 204 205 206 207 208 209 210 211 212 213 214 215 216 def submit_autorift_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> Batch : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A Batch object containing the autoRIFT job \"\"\" job_dict = self . prepare_autorift_job ( granule1 , granule2 , name = name ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) submit_insar_job ( granule1 , granule2 , name = None , include_look_vectors = False , include_los_displacement = False , include_inc_map = False , looks = '20x4' , include_dem = False , include_wrapped_phase = False , apply_water_mask = False , include_displacement_maps = False ) \u00b6 Submit an InSAR job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None include_look_vectors bool Include the look vector theta and phi files in the product package False include_los_displacement bool Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of include_displacement_maps , and will be removed in a future release. False include_inc_map bool Include the local and ellipsoidal incidence angle maps in the product package False looks Literal ['20x4', '10x2'] Number of looks to take in range and azimuth '20x4' include_dem bool Include the digital elevation model GeoTIFF in the product package False include_wrapped_phase bool Include the wrapped phase GeoTIFF in the product package False apply_water_mask bool Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping False include_displacement_maps bool Include displacement maps (line-of-sight and vertical) in the product package False Returns: Type Description Batch A Batch object containing the InSAR job Source code in hyp3_sdk/hyp3.py 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 def submit_insar_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> Batch : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A Batch object containing the InSAR job \"\"\" arguments = locals () . copy () arguments . pop ( 'self' ) job_dict = self . prepare_insar_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) submit_prepared_jobs ( prepared_jobs ) \u00b6 Submit a prepared job dictionary, or list of prepared job dictionaries Parameters: Name Type Description Default prepared_jobs Union [ dict , List [ dict ]] A prepared job dictionary, or list of prepared job dictionaries required Returns: Type Description Batch A Batch object containing the submitted job(s) Source code in hyp3_sdk/hyp3.py 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 def submit_prepared_jobs ( self , prepared_jobs : Union [ dict , List [ dict ]]) -> Batch : \"\"\"Submit a prepared job dictionary, or list of prepared job dictionaries Args: prepared_jobs: A prepared job dictionary, or list of prepared job dictionaries Returns: A Batch object containing the submitted job(s) \"\"\" if isinstance ( prepared_jobs , dict ): payload = { 'jobs' : [ prepared_jobs ]} else : payload = { 'jobs' : prepared_jobs } response = self . session . post ( urljoin ( self . url , '/jobs' ), json = payload ) _raise_for_hyp3_status ( response ) batch = Batch () for job in response . json ()[ 'jobs' ]: batch += Job . from_dict ( job ) return batch submit_rtc_job ( granule , name = None , dem_matching = False , include_dem = False , include_inc_map = False , include_rgb = False , include_scattering_area = False , radiometry = 'gamma0' , resolution = 30 , scale = 'power' , speckle_filter = False , dem_name = 'copernicus' ) \u00b6 Submit an RTC job Parameters: Name Type Description Default granule str The granule (scene) to use required name Optional [ str ] A name for the job None dem_matching bool Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files False include_dem bool Include the DEM file in the product package False include_inc_map bool Include the local incidence angle map in the product package False include_rgb bool Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) False include_scattering_area bool Include the scattering area in the product package False radiometry Literal ['sigma0', 'gamma0'] Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) 'gamma0' resolution Literal [10, 20, 30] Desired output pixel spacing in meters 30 scale Literal ['amplitude', 'decibel', 'power'] Scale of output image; power, decibel or amplitude 'power' speckle_filter bool Apply an Enhanced Lee speckle filter False dem_name Literal ['copernicus', 'legacy'] Name of the DEM to use for processing. copernicus will use the Copernicus GLO-30 Public DEM, while legacy will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. 'copernicus' Returns: Type Description Batch A Batch object containing the RTC job Source code in hyp3_sdk/hyp3.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 def submit_rtc_job ( self , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> Batch : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A Batch object containing the RTC job \"\"\" arguments = locals () arguments . pop ( 'self' ) job_dict = self . prepare_rtc_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) watch ( job_or_batch , timeout = 10800 , interval = 60 ) \u00b6 Watch jobs until they complete Parameters: Name Type Description Default job_or_batch Union [ Batch , Job ] A Batch or Job object of jobs to watch required timeout int How long to wait until exiting in seconds 10800 interval Union [ int , float ] How often to check for updates in seconds 60 Returns: Type Description Union [ Batch , Job ] A Batch or Job object with refreshed watched jobs Source code in hyp3_sdk/hyp3.py 106 107 108 109 110 111 112 113 114 115 116 117 118 119 @singledispatchmethod def watch ( self , job_or_batch : Union [ Batch , Job ], timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Union [ Batch , Job ]: \"\"\"Watch jobs until they complete Args: job_or_batch: A Batch or Job object of jobs to watch timeout: How long to wait until exiting in seconds interval: How often to check for updates in seconds Returns: A Batch or Job object with refreshed watched jobs \"\"\" raise NotImplementedError ( f 'Cannot watch { type ( job_or_batch ) } type object' ) jobs \u00b6 Batch \u00b6 Source code in hyp3_sdk/jobs.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 class Batch : def __init__ ( self , jobs : Optional [ List [ Job ]] = None ): if jobs is None : jobs = [] self . jobs = jobs def __add__ ( self , other : Union [ Job , 'Batch' ]): if isinstance ( other , Batch ): return Batch ( self . jobs + other . jobs ) elif isinstance ( other , Job ): return Batch ( self . jobs + [ other ]) else : raise TypeError ( f \"unsupported operand type(s) for +: ' { type ( self ) } ' and ' { type ( other ) } '\" ) def __iadd__ ( self , other : Union [ Job , 'Batch' ]): if isinstance ( other , Batch ): self . jobs += other . jobs elif isinstance ( other , Job ): self . jobs += [ other ] else : raise TypeError ( f \"unsupported operand type(s) for +=: ' { type ( self ) } ' and ' { type ( other ) } '\" ) return self def __iter__ ( self ): return iter ( self . jobs ) def __len__ ( self ): return len ( self . jobs ) def __contains__ ( self , job : Job ): return job in self . jobs def __eq__ ( self , other : 'Batch' ): return self . jobs == other . jobs def __delitem__ ( self , job : int ): self . jobs . pop ( job ) return self def __getitem__ ( self , index : int ): if isinstance ( index , slice ): return Batch ( self . jobs [ index ]) return self . jobs [ index ] def __setitem__ ( self , index : int , job : Job ): self . jobs [ index ] = job return self def __repr__ ( self ): reprs = \", \" . join ([ job . __repr__ () for job in self . jobs ]) return f 'Batch([ { reprs } ])' def __str__ ( self ): count = self . _count_statuses () return f ' { len ( self ) } HyP3 Jobs: ' \\ f ' { count [ \"SUCCEEDED\" ] } succeeded, ' \\ f ' { count [ \"FAILED\" ] } failed, ' \\ f ' { count [ \"RUNNING\" ] } running, ' \\ f ' { count [ \"PENDING\" ] } pending.' def _count_statuses ( self ): return Counter ([ job . status_code for job in self . jobs ]) def complete ( self ) -> bool : \"\"\" Returns: True if all jobs are complete, otherwise returns False \"\"\" for job in self . jobs : if not job . complete (): return False return True def succeeded ( self ) -> bool : \"\"\" Returns: True if all jobs have succeeded, otherwise returns False \"\"\" for job in self . jobs : if not job . succeeded (): return False return True def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" downloaded_files = [] tqdm = get_tqdm_progress_bar () for job in tqdm ( self . jobs ): try : downloaded_files . extend ( job . download_files ( location , create )) except HyP3SDKError as e : print ( f 'Warning: { e } Skipping download for { job } .' ) return downloaded_files def any_expired ( self ) -> bool : \"\"\"Check succeeded jobs for expiration\"\"\" for job in self . jobs : try : if job . expired (): return True except HyP3SDKError : continue return False def filter_jobs ( self , succeeded : bool = True , running : bool = True , failed : bool = False , include_expired : bool = True , ) -> 'Batch' : \"\"\"Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Args: succeeded: Include all succeeded jobs running: Include all running jobs failed: Include all failed jobs include_expired: Include expired jobs in the result Returns: batch: A batch object containing jobs matching all the selected statuses \"\"\" filtered_jobs = [] for job in self . jobs : if job . succeeded () and succeeded : if include_expired or not job . expired (): filtered_jobs . append ( job ) elif job . running () and running : filtered_jobs . append ( job ) elif job . failed () and failed : filtered_jobs . append ( job ) return Batch ( filtered_jobs ) any_expired () \u00b6 Check succeeded jobs for expiration Source code in hyp3_sdk/jobs.py 241 242 243 244 245 246 247 248 249 def any_expired ( self ) -> bool : \"\"\"Check succeeded jobs for expiration\"\"\" for job in self . jobs : try : if job . expired (): return True except HyP3SDKError : continue return False complete () \u00b6 Returns: True if all jobs are complete, otherwise returns False Source code in hyp3_sdk/jobs.py 206 207 208 209 210 211 212 213 def complete ( self ) -> bool : \"\"\" Returns: True if all jobs are complete, otherwise returns False \"\"\" for job in self . jobs : if not job . complete (): return False return True download_files ( location = '.' , create = True ) \u00b6 Parameters: Name Type Description Default location Union [ Path , str ] Directory location to put files into '.' create bool Create location if it does not point to an existing directory True Returns: list of Path objects to downloaded files Source code in hyp3_sdk/jobs.py 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" downloaded_files = [] tqdm = get_tqdm_progress_bar () for job in tqdm ( self . jobs ): try : downloaded_files . extend ( job . download_files ( location , create )) except HyP3SDKError as e : print ( f 'Warning: { e } Skipping download for { job } .' ) return downloaded_files filter_jobs ( succeeded = True , running = True , failed = False , include_expired = True ) \u00b6 Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Parameters: Name Type Description Default succeeded bool Include all succeeded jobs True running bool Include all running jobs True failed bool Include all failed jobs False include_expired bool Include expired jobs in the result True Returns: Name Type Description batch Batch A batch object containing jobs matching all the selected statuses Source code in hyp3_sdk/jobs.py 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 def filter_jobs ( self , succeeded : bool = True , running : bool = True , failed : bool = False , include_expired : bool = True , ) -> 'Batch' : \"\"\"Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Args: succeeded: Include all succeeded jobs running: Include all running jobs failed: Include all failed jobs include_expired: Include expired jobs in the result Returns: batch: A batch object containing jobs matching all the selected statuses \"\"\" filtered_jobs = [] for job in self . jobs : if job . succeeded () and succeeded : if include_expired or not job . expired (): filtered_jobs . append ( job ) elif job . running () and running : filtered_jobs . append ( job ) elif job . failed () and failed : filtered_jobs . append ( job ) return Batch ( filtered_jobs ) succeeded () \u00b6 Returns: True if all jobs have succeeded, otherwise returns False Source code in hyp3_sdk/jobs.py 215 216 217 218 219 220 221 222 def succeeded ( self ) -> bool : \"\"\" Returns: True if all jobs have succeeded, otherwise returns False \"\"\" for job in self . jobs : if not job . succeeded (): return False return True Job \u00b6 Source code in hyp3_sdk/jobs.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 class Job : _attributes_for_resubmit = { 'name' , 'job_parameters' , 'job_type' } def __init__ ( self , job_type : str , job_id : str , request_time : datetime , status_code : str , user_id : str , name : Optional [ str ] = None , job_parameters : Optional [ dict ] = None , files : Optional [ List ] = None , logs : Optional [ List ] = None , browse_images : Optional [ List ] = None , thumbnail_images : Optional [ List ] = None , expiration_time : Optional [ datetime ] = None , processing_times : Optional [ List [ float ]] = None , ): self . job_id = job_id self . job_type = job_type self . request_time = request_time self . status_code = status_code self . user_id = user_id self . name = name self . job_parameters = job_parameters self . files = files self . logs = logs self . browse_images = browse_images self . thumbnail_images = thumbnail_images self . expiration_time = expiration_time self . processing_times = processing_times def __repr__ ( self ): return f 'Job.from_dict( { self . to_dict () } )' def __str__ ( self ): return f 'HyP3 { self . job_type } job { self . job_id } ' def __eq__ ( self , other ): return self . __dict__ == other . __dict__ @staticmethod def from_dict ( input_dict : dict ): expiration_time = parse_date ( input_dict [ 'expiration_time' ]) if input_dict . get ( 'expiration_time' ) else None return Job ( job_type = input_dict [ 'job_type' ], job_id = input_dict [ 'job_id' ], request_time = parse_date ( input_dict [ 'request_time' ]), status_code = input_dict [ 'status_code' ], user_id = input_dict [ 'user_id' ], name = input_dict . get ( 'name' ), job_parameters = input_dict . get ( 'job_parameters' ), files = input_dict . get ( 'files' ), logs = input_dict . get ( 'logs' ), browse_images = input_dict . get ( 'browse_images' ), thumbnail_images = input_dict . get ( 'thumbnail_images' ), expiration_time = expiration_time , processing_times = input_dict . get ( 'processing_times' ), ) def to_dict ( self , for_resubmit : bool = False ): job_dict = {} if for_resubmit : keys_to_process = Job . _attributes_for_resubmit else : keys_to_process = vars ( self ) . keys () for key in keys_to_process : value = self . __getattribute__ ( key ) if value is not None : if isinstance ( value , datetime ): job_dict [ key ] = value . isoformat ( timespec = 'seconds' ) else : job_dict [ key ] = value return job_dict def succeeded ( self ) -> bool : return self . status_code == 'SUCCEEDED' def failed ( self ) -> bool : return self . status_code == 'FAILED' def complete ( self ) -> bool : return self . succeeded () or self . failed () # TODO may want to update this to check if status code is actually RUNNING, because currently this also returns # true if status is PENDING def running ( self ) -> bool : return not self . complete () def expired ( self ) -> bool : return self . expiration_time is not None and datetime . now ( tz . UTC ) >= self . expiration_time def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" location = Path ( location ) if not self . succeeded (): raise HyP3SDKError ( f 'Only succeeded jobs can be downloaded; job is { self . status_code } .' ) if self . expired (): raise HyP3SDKError ( f 'Expired jobs cannot be downloaded; ' f 'job expired { self . expiration_time . isoformat ( timespec = \"seconds\" ) } .' ) if create : location . mkdir ( parents = True , exist_ok = True ) elif not location . is_dir (): raise NotADirectoryError ( str ( location )) downloaded_files = [] for file in self . files : download_url = file [ 'url' ] filename = location / file [ 'filename' ] try : downloaded_files . append ( download_file ( download_url , filename , chunk_size = 10485760 )) except HTTPError : raise HyP3SDKError ( f 'Unable to download file: { download_url } ' ) return downloaded_files download_files ( location = '.' , create = True ) \u00b6 Parameters: Name Type Description Default location Union [ Path , str ] Directory location to put files into '.' create bool Create location if it does not point to an existing directory True Returns: list of Path objects to downloaded files Source code in hyp3_sdk/jobs.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" location = Path ( location ) if not self . succeeded (): raise HyP3SDKError ( f 'Only succeeded jobs can be downloaded; job is { self . status_code } .' ) if self . expired (): raise HyP3SDKError ( f 'Expired jobs cannot be downloaded; ' f 'job expired { self . expiration_time . isoformat ( timespec = \"seconds\" ) } .' ) if create : location . mkdir ( parents = True , exist_ok = True ) elif not location . is_dir (): raise NotADirectoryError ( str ( location )) downloaded_files = [] for file in self . files : download_url = file [ 'url' ] filename = location / file [ 'filename' ] try : downloaded_files . append ( download_file ( download_url , filename , chunk_size = 10485760 )) except HTTPError : raise HyP3SDKError ( f 'Unable to download file: { download_url } ' ) return downloaded_files util \u00b6 Extra utilities for working with HyP3 chunk ( itr , n = 200 ) \u00b6 Split a sequence into small chunks Parameters: Name Type Description Default itr Sequence [ Any ] A sequence object to chunk required n int Size of the chunks to return 200 Source code in hyp3_sdk/util.py 43 44 45 46 47 48 49 50 51 52 53 54 def chunk ( itr : Sequence [ Any ], n : int = 200 ) -> Generator [ Sequence [ Any ], None , None ]: \"\"\"Split a sequence into small chunks Args: itr: A sequence object to chunk n: Size of the chunks to return \"\"\" if not isinstance ( n , int ) or n < 1 : raise ValueError ( f 'n must be a positive integer: { n } ' ) for i in range ( 0 , len ( itr ), n ): yield itr [ i : i + n ] download_file ( url , filepath , chunk_size = None , retries = 2 , backoff_factor = 1 ) \u00b6 Download a file Args: url: URL of the file to download filepath: Location to place file into chunk_size: Size to chunk the download into retries: Number of retries to attempt backoff_factor: Factor for calculating time between retries Returns: download_path: The path to the downloaded file Source code in hyp3_sdk/util.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 def download_file ( url : str , filepath : Union [ Path , str ], chunk_size = None , retries = 2 , backoff_factor = 1 ) -> Path : \"\"\"Download a file Args: url: URL of the file to download filepath: Location to place file into chunk_size: Size to chunk the download into retries: Number of retries to attempt backoff_factor: Factor for calculating time between retries Returns: download_path: The path to the downloaded file \"\"\" filepath = Path ( filepath ) session = requests . Session () retry_strategy = Retry ( total = retries , backoff_factor = backoff_factor , status_forcelist = [ 429 , 500 , 502 , 503 , 504 ], ) session . mount ( 'https://' , HTTPAdapter ( max_retries = retry_strategy )) session . mount ( 'http://' , HTTPAdapter ( max_retries = retry_strategy )) stream = False if chunk_size is None else True with session . get ( url , stream = stream ) as s : s . raise_for_status () tqdm = get_tqdm_progress_bar () with tqdm . wrapattr ( open ( filepath , \"wb\" ), 'write' , miniters = 1 , desc = filepath . name , total = int ( s . headers . get ( 'content-length' , 0 ))) as f : for chunk in s . iter_content ( chunk_size = chunk_size ): if chunk : f . write ( chunk ) session . close () return filepath extract_zipped_product ( zip_file , delete = True ) \u00b6 Extract a zipped HyP3 product Extract a zipped HyP3 product to the same directory as the zipped HyP3 product, optionally deleting zip file afterward. Parameters: Name Type Description Default zip_file Union [ str , Path ] Zipped HyP3 product to extract required delete bool Delete zip_file after it has been extracted True Returns: Type Description Path Path to the HyP3 product folder containing the product files Source code in hyp3_sdk/util.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def extract_zipped_product ( zip_file : Union [ str , Path ], delete : bool = True ) -> Path : \"\"\"Extract a zipped HyP3 product Extract a zipped HyP3 product to the same directory as the zipped HyP3 product, optionally deleting `zip file` afterward. Args: zip_file: Zipped HyP3 product to extract delete: Delete `zip_file` after it has been extracted Returns: Path to the HyP3 product folder containing the product files \"\"\" zip_file = Path ( zip_file ) with ZipFile ( zip_file ) as z : z . extractall ( path = zip_file . parent ) if delete : zip_file . unlink () return zip_file . parent / zip_file . stem get_authenticated_session ( username , password ) \u00b6 Log into HyP3 using credentials for urs.earthdata.nasa.gov from either the provided credentials or a .netrc file. Returns: Type Description Session An authenticated HyP3 Session Source code in hyp3_sdk/util.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def get_authenticated_session ( username : str , password : str ) -> requests . Session : \"\"\"Log into HyP3 using credentials for `urs.earthdata.nasa.gov` from either the provided credentials or a `.netrc` file. Returns: An authenticated HyP3 Session \"\"\" s = requests . Session () if username is not None and password is not None : response = s . get ( AUTH_URL , auth = ( username , password )) auth_error_message = ( 'Was not able to authenticate with credentials provided \\n ' 'This could be due to invalid credentials or a connection error.' ) else : response = s . get ( AUTH_URL ) auth_error_message = ( 'Was not able to authenticate with .netrc file and no credentials provided \\n ' 'This could be due to invalid credentials in .netrc or a connection error.' ) parsed_url = urllib . parse . urlparse ( response . url ) query_params = urllib . parse . parse_qs ( parsed_url . query ) error_msg = query_params . get ( 'error_msg' ) resolution_url = query_params . get ( 'resolution_url' ) if error_msg is not None and resolution_url is not None : raise AuthenticationError ( f ' { error_msg [ 0 ] } : { resolution_url [ 0 ] } ' ) if error_msg is not None and 'Please update your profile' in error_msg [ 0 ]: raise AuthenticationError ( f ' { error_msg [ 0 ] } : { PROFILE_URL } ' ) try : response . raise_for_status () except requests . HTTPError : raise AuthenticationError ( auth_error_message ) return s","title":"API Reference"},{"location":"using/sdk_api/#hyp3_sdk-v300-api-reference","text":"","title":"hyp3_sdk v3.0.0 API Reference"},{"location":"using/sdk_api/#hyp3_sdk","text":"A python wrapper around the HyP3 API","title":"hyp3_sdk"},{"location":"using/sdk_api/#hyp3_sdk.Batch","text":"Source code in 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 class Batch : def __init__ ( self , jobs : Optional [ List [ Job ]] = None ): if jobs is None : jobs = [] self . jobs = jobs def __add__ ( self , other : Union [ Job , 'Batch' ]): if isinstance ( other , Batch ): return Batch ( self . jobs + other . jobs ) elif isinstance ( other , Job ): return Batch ( self . jobs + [ other ]) else : raise TypeError ( f \"unsupported operand type(s) for +: ' { type ( self ) } ' and ' { type ( other ) } '\" ) def __iadd__ ( self , other : Union [ Job , 'Batch' ]): if isinstance ( other , Batch ): self . jobs += other . jobs elif isinstance ( other , Job ): self . jobs += [ other ] else : raise TypeError ( f \"unsupported operand type(s) for +=: ' { type ( self ) } ' and ' { type ( other ) } '\" ) return self def __iter__ ( self ): return iter ( self . jobs ) def __len__ ( self ): return len ( self . jobs ) def __contains__ ( self , job : Job ): return job in self . jobs def __eq__ ( self , other : 'Batch' ): return self . jobs == other . jobs def __delitem__ ( self , job : int ): self . jobs . pop ( job ) return self def __getitem__ ( self , index : int ): if isinstance ( index , slice ): return Batch ( self . jobs [ index ]) return self . jobs [ index ] def __setitem__ ( self , index : int , job : Job ): self . jobs [ index ] = job return self def __repr__ ( self ): reprs = \", \" . join ([ job . __repr__ () for job in self . jobs ]) return f 'Batch([ { reprs } ])' def __str__ ( self ): count = self . _count_statuses () return f ' { len ( self ) } HyP3 Jobs: ' \\ f ' { count [ \"SUCCEEDED\" ] } succeeded, ' \\ f ' { count [ \"FAILED\" ] } failed, ' \\ f ' { count [ \"RUNNING\" ] } running, ' \\ f ' { count [ \"PENDING\" ] } pending.' def _count_statuses ( self ): return Counter ([ job . status_code for job in self . jobs ]) def complete ( self ) -> bool : \"\"\" Returns: True if all jobs are complete, otherwise returns False \"\"\" for job in self . jobs : if not job . complete (): return False return True def succeeded ( self ) -> bool : \"\"\" Returns: True if all jobs have succeeded, otherwise returns False \"\"\" for job in self . jobs : if not job . succeeded (): return False return True def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" downloaded_files = [] tqdm = get_tqdm_progress_bar () for job in tqdm ( self . jobs ): try : downloaded_files . extend ( job . download_files ( location , create )) except HyP3SDKError as e : print ( f 'Warning: { e } Skipping download for { job } .' ) return downloaded_files def any_expired ( self ) -> bool : \"\"\"Check succeeded jobs for expiration\"\"\" for job in self . jobs : try : if job . expired (): return True except HyP3SDKError : continue return False def filter_jobs ( self , succeeded : bool = True , running : bool = True , failed : bool = False , include_expired : bool = True , ) -> 'Batch' : \"\"\"Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Args: succeeded: Include all succeeded jobs running: Include all running jobs failed: Include all failed jobs include_expired: Include expired jobs in the result Returns: batch: A batch object containing jobs matching all the selected statuses \"\"\" filtered_jobs = [] for job in self . jobs : if job . succeeded () and succeeded : if include_expired or not job . expired (): filtered_jobs . append ( job ) elif job . running () and running : filtered_jobs . append ( job ) elif job . failed () and failed : filtered_jobs . append ( job ) return Batch ( filtered_jobs )","title":"Batch"},{"location":"using/sdk_api/#hyp3_sdk.Batch.any_expired","text":"Check succeeded jobs for expiration Source code in 241 242 243 244 245 246 247 248 249 def any_expired ( self ) -> bool : \"\"\"Check succeeded jobs for expiration\"\"\" for job in self . jobs : try : if job . expired (): return True except HyP3SDKError : continue return False","title":"any_expired()"},{"location":"using/sdk_api/#hyp3_sdk.Batch.complete","text":"Returns: True if all jobs are complete, otherwise returns False Source code in 206 207 208 209 210 211 212 213 def complete ( self ) -> bool : \"\"\" Returns: True if all jobs are complete, otherwise returns False \"\"\" for job in self . jobs : if not job . complete (): return False return True","title":"complete()"},{"location":"using/sdk_api/#hyp3_sdk.Batch.download_files","text":"Parameters: Name Type Description Default location Union [ Path , str ] Directory location to put files into '.' create bool Create location if it does not point to an existing directory True Returns: list of Path objects to downloaded files Source code in 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" downloaded_files = [] tqdm = get_tqdm_progress_bar () for job in tqdm ( self . jobs ): try : downloaded_files . extend ( job . download_files ( location , create )) except HyP3SDKError as e : print ( f 'Warning: { e } Skipping download for { job } .' ) return downloaded_files","title":"download_files()"},{"location":"using/sdk_api/#hyp3_sdk.Batch.filter_jobs","text":"Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Parameters: Name Type Description Default succeeded bool Include all succeeded jobs True running bool Include all running jobs True failed bool Include all failed jobs False include_expired bool Include expired jobs in the result True Returns: Name Type Description batch Batch A batch object containing jobs matching all the selected statuses Source code in 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 def filter_jobs ( self , succeeded : bool = True , running : bool = True , failed : bool = False , include_expired : bool = True , ) -> 'Batch' : \"\"\"Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Args: succeeded: Include all succeeded jobs running: Include all running jobs failed: Include all failed jobs include_expired: Include expired jobs in the result Returns: batch: A batch object containing jobs matching all the selected statuses \"\"\" filtered_jobs = [] for job in self . jobs : if job . succeeded () and succeeded : if include_expired or not job . expired (): filtered_jobs . append ( job ) elif job . running () and running : filtered_jobs . append ( job ) elif job . failed () and failed : filtered_jobs . append ( job ) return Batch ( filtered_jobs )","title":"filter_jobs()"},{"location":"using/sdk_api/#hyp3_sdk.Batch.succeeded","text":"Returns: True if all jobs have succeeded, otherwise returns False Source code in 215 216 217 218 219 220 221 222 def succeeded ( self ) -> bool : \"\"\" Returns: True if all jobs have succeeded, otherwise returns False \"\"\" for job in self . jobs : if not job . succeeded (): return False return True","title":"succeeded()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3","text":"A python wrapper around the HyP3 API. Warning: All jobs submitted to HyP3 are publicly visible. For more information, see https://hyp3-docs.asf.alaska.edu/#public-visibility-of-jobs Source code in 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 class HyP3 : \"\"\"A python wrapper around the HyP3 API. Warning: All jobs submitted to HyP3 are publicly visible. For more information, see https://hyp3-docs.asf.alaska.edu/#public-visibility-of-jobs \"\"\" def __init__ ( self , api_url : str = PROD_API , username : Optional [ str ] = None , password : Optional [ str ] = None , prompt : bool = False ): \"\"\"If username and password are not provided, attempts to use credentials from a `.netrc` file. Args: api_url: Address of the HyP3 API username: Username for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. password: Password for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. prompt: Prompt for username and/or password interactively when they are not provided as keyword parameters \"\"\" self . url = api_url if username is None and prompt : username = input ( 'NASA Earthdata Login username: ' ) if password is None and prompt : password = getpass ( 'NASA Earthdata Login password: ' ) self . session = hyp3_sdk . util . get_authenticated_session ( username , password ) self . session . headers . update ({ 'User-Agent' : f ' { hyp3_sdk . __name__ } / { hyp3_sdk . __version__ } ' }) def find_jobs ( self , start : Optional [ datetime ] = None , end : Optional [ datetime ] = None , status_code : Optional [ str ] = None , name : Optional [ str ] = None , job_type : Optional [ str ] = None , user_id : Optional [ str ] = None ) -> Batch : \"\"\"Gets a Batch of jobs from HyP3 matching the provided search criteria Args: start: only jobs submitted after given time end: only jobs submitted before given time status_code: only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) name: only jobs with this name job_type: only jobs with this job_type user_id: only jobs submitted by this user (defaults to the current user) Returns: A Batch object containing the found jobs \"\"\" params = {} for param_name in ( 'start' , 'end' , 'status_code' , 'name' , 'job_type' , 'user_id' ): param_value = locals () . get ( param_name ) if param_value is not None : if isinstance ( param_value , datetime ): if param_value . tzinfo is None : param_value = param_value . replace ( tzinfo = timezone . utc ) param_value = param_value . isoformat ( timespec = 'seconds' ) params [ param_name ] = param_value response = self . session . get ( urljoin ( self . url , '/jobs' ), params = params ) _raise_for_hyp3_status ( response ) jobs = [ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]] while 'next' in response . json (): next_url = response . json ()[ 'next' ] response = self . session . get ( next_url ) _raise_for_hyp3_status ( response ) jobs . extend ([ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]]) return Batch ( jobs ) def get_job_by_id ( self , job_id : str ) -> Job : \"\"\"Get job by job ID Args: job_id: A job ID Returns: A Job object \"\"\" response = self . session . get ( urljoin ( self . url , f '/jobs/ { job_id } ' )) _raise_for_hyp3_status ( response ) return Job . from_dict ( response . json ()) @singledispatchmethod def watch ( self , job_or_batch : Union [ Batch , Job ], timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Union [ Batch , Job ]: \"\"\"Watch jobs until they complete Args: job_or_batch: A Batch or Job object of jobs to watch timeout: How long to wait until exiting in seconds interval: How often to check for updates in seconds Returns: A Batch or Job object with refreshed watched jobs \"\"\" raise NotImplementedError ( f 'Cannot watch { type ( job_or_batch ) } type object' ) @watch . register def _watch_batch ( self , batch : Batch , timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Batch : tqdm = hyp3_sdk . util . get_tqdm_progress_bar () iterations_until_timeout = math . ceil ( timeout / interval ) bar_format = ' {l_bar}{bar} | {n_fmt} / {total_fmt} [ {postfix[0]} ]' with tqdm ( total = len ( batch ), bar_format = bar_format , postfix = [ f 'timeout in { timeout } s' ]) as progress_bar : for ii in range ( iterations_until_timeout ): batch = self . refresh ( batch ) counts = batch . _count_statuses () complete = counts [ 'SUCCEEDED' ] + counts [ 'FAILED' ] progress_bar . postfix = [ f 'timeout in { timeout - ii * interval } s' ] # to control n/total manually; update is n += value progress_bar . n = complete progress_bar . update ( 0 ) if batch . complete (): return batch time . sleep ( interval ) raise HyP3Error ( f 'Timeout occurred while waiting for { batch } ' ) @watch . register def _watch_job ( self , job : Job , timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Job : tqdm = hyp3_sdk . util . get_tqdm_progress_bar () iterations_until_timeout = math . ceil ( timeout / interval ) bar_format = ' {n_fmt} / {total_fmt} [ {postfix[0]} ]' with tqdm ( total = 1 , bar_format = bar_format , postfix = [ f 'timeout in { timeout } s' ]) as progress_bar : for ii in range ( iterations_until_timeout ): job = self . refresh ( job ) progress_bar . postfix = [ f 'timeout in { timeout - ii * interval } s' ] progress_bar . update ( int ( job . complete ())) if job . complete (): return job time . sleep ( interval ) raise HyP3Error ( f 'Timeout occurred while waiting for { job } ' ) @singledispatchmethod def refresh ( self , job_or_batch : Union [ Batch , Job ]) -> Union [ Batch , Job ]: \"\"\"Refresh each jobs' information Args: job_or_batch: A Batch of Job object to refresh Returns: A Batch or Job object with refreshed information \"\"\" raise NotImplementedError ( f 'Cannot refresh { type ( job_or_batch ) } type object' ) @refresh . register def _refresh_batch ( self , batch : Batch ): jobs = [] for job in batch . jobs : jobs . append ( self . refresh ( job )) return Batch ( jobs ) @refresh . register def _refresh_job ( self , job : Job ): return self . get_job_by_id ( job . job_id ) def submit_prepared_jobs ( self , prepared_jobs : Union [ dict , List [ dict ]]) -> Batch : \"\"\"Submit a prepared job dictionary, or list of prepared job dictionaries Args: prepared_jobs: A prepared job dictionary, or list of prepared job dictionaries Returns: A Batch object containing the submitted job(s) \"\"\" if isinstance ( prepared_jobs , dict ): payload = { 'jobs' : [ prepared_jobs ]} else : payload = { 'jobs' : prepared_jobs } response = self . session . post ( urljoin ( self . url , '/jobs' ), json = payload ) _raise_for_hyp3_status ( response ) batch = Batch () for job in response . json ()[ 'jobs' ]: batch += Job . from_dict ( job ) return batch def submit_autorift_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> Batch : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A Batch object containing the autoRIFT job \"\"\" job_dict = self . prepare_autorift_job ( granule1 , granule2 , name = name ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_autorift_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> dict : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A dictionary containing the prepared autoRIFT job \"\"\" job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ]}, 'job_type' : 'AUTORIFT' , } if name is not None : job_dict [ 'name' ] = name return job_dict def submit_rtc_job ( self , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> Batch : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A Batch object containing the RTC job \"\"\" arguments = locals () arguments . pop ( 'self' ) job_dict = self . prepare_rtc_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_rtc_job ( cls , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> dict : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A dictionary containing the prepared RTC job \"\"\" job_parameters = locals () . copy () for key in [ 'granule' , 'name' , 'cls' ]: job_parameters . pop ( key , None ) job_dict = { 'job_parameters' : { 'granules' : [ granule ], ** job_parameters }, 'job_type' : 'RTC_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict def submit_insar_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> Batch : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A Batch object containing the InSAR job \"\"\" arguments = locals () . copy () arguments . pop ( 'self' ) job_dict = self . prepare_insar_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_insar_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> dict : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A dictionary containing the prepared InSAR job \"\"\" if include_los_displacement : warnings . warn ( 'The include_los_displacement parameter has been deprecated in favor of ' 'include_displacement_maps, and will be removed in a future release.' , FutureWarning ) job_parameters = locals () . copy () for key in [ 'cls' , 'granule1' , 'granule2' , 'name' ]: job_parameters . pop ( key ) job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ], ** job_parameters }, 'job_type' : 'INSAR_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict def my_info ( self ) -> dict : \"\"\" Returns: Your user information \"\"\" response = self . session . get ( urljoin ( self . url , '/user' )) _raise_for_hyp3_status ( response ) return response . json () def check_quota ( self ) -> Optional [ int ]: \"\"\" Returns: The number of jobs left in your quota, or None if you have no quota \"\"\" info = self . my_info () return info [ 'quota' ][ 'remaining' ]","title":"HyP3"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.__init__","text":"If username and password are not provided, attempts to use credentials from a .netrc file. Parameters: Name Type Description Default api_url str Address of the HyP3 API PROD_API username Optional [ str ] Username for authenticating to urs.earthdata.nasa.gov . Both username and password must be provided if either is provided. None password Optional [ str ] Password for authenticating to urs.earthdata.nasa.gov . Both username and password must be provided if either is provided. None prompt bool Prompt for username and/or password interactively when they are not provided as keyword parameters False Source code in 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def __init__ ( self , api_url : str = PROD_API , username : Optional [ str ] = None , password : Optional [ str ] = None , prompt : bool = False ): \"\"\"If username and password are not provided, attempts to use credentials from a `.netrc` file. Args: api_url: Address of the HyP3 API username: Username for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. password: Password for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. prompt: Prompt for username and/or password interactively when they are not provided as keyword parameters \"\"\" self . url = api_url if username is None and prompt : username = input ( 'NASA Earthdata Login username: ' ) if password is None and prompt : password = getpass ( 'NASA Earthdata Login password: ' ) self . session = hyp3_sdk . util . get_authenticated_session ( username , password ) self . session . headers . update ({ 'User-Agent' : f ' { hyp3_sdk . __name__ } / { hyp3_sdk . __version__ } ' })","title":"__init__()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.check_quota","text":"Returns: Type Description Optional [ int ] The number of jobs left in your quota, or None if you have no quota Source code in 423 424 425 426 427 428 429 def check_quota ( self ) -> Optional [ int ]: \"\"\" Returns: The number of jobs left in your quota, or None if you have no quota \"\"\" info = self . my_info () return info [ 'quota' ][ 'remaining' ]","title":"check_quota()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.find_jobs","text":"Gets a Batch of jobs from HyP3 matching the provided search criteria Parameters: Name Type Description Default start Optional [ datetime ] only jobs submitted after given time None end Optional [ datetime ] only jobs submitted before given time None status_code Optional [ str ] only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) None name Optional [ str ] only jobs with this name None job_type Optional [ str ] only jobs with this job_type None user_id Optional [ str ] only jobs submitted by this user (defaults to the current user) None Returns: Type Description Batch A Batch object containing the found jobs Source code in 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def find_jobs ( self , start : Optional [ datetime ] = None , end : Optional [ datetime ] = None , status_code : Optional [ str ] = None , name : Optional [ str ] = None , job_type : Optional [ str ] = None , user_id : Optional [ str ] = None ) -> Batch : \"\"\"Gets a Batch of jobs from HyP3 matching the provided search criteria Args: start: only jobs submitted after given time end: only jobs submitted before given time status_code: only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) name: only jobs with this name job_type: only jobs with this job_type user_id: only jobs submitted by this user (defaults to the current user) Returns: A Batch object containing the found jobs \"\"\" params = {} for param_name in ( 'start' , 'end' , 'status_code' , 'name' , 'job_type' , 'user_id' ): param_value = locals () . get ( param_name ) if param_value is not None : if isinstance ( param_value , datetime ): if param_value . tzinfo is None : param_value = param_value . replace ( tzinfo = timezone . utc ) param_value = param_value . isoformat ( timespec = 'seconds' ) params [ param_name ] = param_value response = self . session . get ( urljoin ( self . url , '/jobs' ), params = params ) _raise_for_hyp3_status ( response ) jobs = [ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]] while 'next' in response . json (): next_url = response . json ()[ 'next' ] response = self . session . get ( next_url ) _raise_for_hyp3_status ( response ) jobs . extend ([ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]]) return Batch ( jobs )","title":"find_jobs()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.get_job_by_id","text":"Get job by job ID Parameters: Name Type Description Default job_id str A job ID required Returns: Type Description Job A Job object Source code in 92 93 94 95 96 97 98 99 100 101 102 103 104 def get_job_by_id ( self , job_id : str ) -> Job : \"\"\"Get job by job ID Args: job_id: A job ID Returns: A Job object \"\"\" response = self . session . get ( urljoin ( self . url , f '/jobs/ { job_id } ' )) _raise_for_hyp3_status ( response ) return Job . from_dict ( response . json ())","title":"get_job_by_id()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.my_info","text":"Returns: Type Description dict Your user information Source code in 414 415 416 417 418 419 420 421 def my_info ( self ) -> dict : \"\"\" Returns: Your user information \"\"\" response = self . session . get ( urljoin ( self . url , '/user' )) _raise_for_hyp3_status ( response ) return response . json ()","title":"my_info()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.prepare_autorift_job","text":"Submit an autoRIFT job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None Returns: Type Description dict A dictionary containing the prepared autoRIFT job Source code in 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 @classmethod def prepare_autorift_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> dict : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A dictionary containing the prepared autoRIFT job \"\"\" job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ]}, 'job_type' : 'AUTORIFT' , } if name is not None : job_dict [ 'name' ] = name return job_dict","title":"prepare_autorift_job()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.prepare_insar_job","text":"Submit an InSAR job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None include_look_vectors bool Include the look vector theta and phi files in the product package False include_los_displacement bool Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of include_displacement_maps , and will be removed in a future release. False include_inc_map bool Include the local and ellipsoidal incidence angle maps in the product package False looks Literal ['20x4', '10x2'] Number of looks to take in range and azimuth '20x4' include_dem bool Include the digital elevation model GeoTIFF in the product package False include_wrapped_phase bool Include the wrapped phase GeoTIFF in the product package False apply_water_mask bool Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping False include_displacement_maps bool Include displacement maps (line-of-sight and vertical) in the product package False Returns: A dictionary containing the prepared InSAR job Source code in 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 @classmethod def prepare_insar_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> dict : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A dictionary containing the prepared InSAR job \"\"\" if include_los_displacement : warnings . warn ( 'The include_los_displacement parameter has been deprecated in favor of ' 'include_displacement_maps, and will be removed in a future release.' , FutureWarning ) job_parameters = locals () . copy () for key in [ 'cls' , 'granule1' , 'granule2' , 'name' ]: job_parameters . pop ( key ) job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ], ** job_parameters }, 'job_type' : 'INSAR_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict","title":"prepare_insar_job()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.prepare_rtc_job","text":"Submit an RTC job Parameters: Name Type Description Default granule str The granule (scene) to use required name Optional [ str ] A name for the job None dem_matching bool Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files False include_dem bool Include the DEM file in the product package False include_inc_map bool Include the local incidence angle map in the product package False include_rgb bool Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) False include_scattering_area bool Include the scattering area in the product package False radiometry Literal ['sigma0', 'gamma0'] Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) 'gamma0' resolution Literal [10, 20, 30] Desired output pixel spacing in meters 30 scale Literal ['amplitude', 'decibel', 'power'] Scale of output image; power, decibel or amplitude 'power' speckle_filter bool Apply an Enhanced Lee speckle filter False dem_name Literal ['copernicus', 'legacy'] Name of the DEM to use for processing. copernicus will use the Copernicus GLO-30 Public DEM, while legacy will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. 'copernicus' Returns: Type Description dict A dictionary containing the prepared RTC job Source code in 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 @classmethod def prepare_rtc_job ( cls , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> dict : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A dictionary containing the prepared RTC job \"\"\" job_parameters = locals () . copy () for key in [ 'granule' , 'name' , 'cls' ]: job_parameters . pop ( key , None ) job_dict = { 'job_parameters' : { 'granules' : [ granule ], ** job_parameters }, 'job_type' : 'RTC_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict","title":"prepare_rtc_job()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.refresh","text":"Refresh each jobs' information Parameters: Name Type Description Default job_or_batch Union [ Batch , Job ] A Batch of Job object to refresh required Returns: Type Description Union [ Batch , Job ] A Batch or Job object with refreshed information Source code in 159 160 161 162 163 164 165 166 167 168 169 @singledispatchmethod def refresh ( self , job_or_batch : Union [ Batch , Job ]) -> Union [ Batch , Job ]: \"\"\"Refresh each jobs' information Args: job_or_batch: A Batch of Job object to refresh Returns: A Batch or Job object with refreshed information \"\"\" raise NotImplementedError ( f 'Cannot refresh { type ( job_or_batch ) } type object' )","title":"refresh()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.submit_autorift_job","text":"Submit an autoRIFT job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None Returns: Type Description Batch A Batch object containing the autoRIFT job Source code in 204 205 206 207 208 209 210 211 212 213 214 215 216 def submit_autorift_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> Batch : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A Batch object containing the autoRIFT job \"\"\" job_dict = self . prepare_autorift_job ( granule1 , granule2 , name = name ) return self . submit_prepared_jobs ( prepared_jobs = job_dict )","title":"submit_autorift_job()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.submit_insar_job","text":"Submit an InSAR job Parameters: Name Type Description Default granule1 str The first granule (scene) to use required granule2 str The second granule (scene) to use required name Optional [ str ] A name for the job None include_look_vectors bool Include the look vector theta and phi files in the product package False include_los_displacement bool Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of include_displacement_maps , and will be removed in a future release. False include_inc_map bool Include the local and ellipsoidal incidence angle maps in the product package False looks Literal ['20x4', '10x2'] Number of looks to take in range and azimuth '20x4' include_dem bool Include the digital elevation model GeoTIFF in the product package False include_wrapped_phase bool Include the wrapped phase GeoTIFF in the product package False apply_water_mask bool Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping False include_displacement_maps bool Include displacement maps (line-of-sight and vertical) in the product package False Returns: Type Description Batch A Batch object containing the InSAR job Source code in 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 def submit_insar_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> Batch : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A Batch object containing the InSAR job \"\"\" arguments = locals () . copy () arguments . pop ( 'self' ) job_dict = self . prepare_insar_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict )","title":"submit_insar_job()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.submit_prepared_jobs","text":"Submit a prepared job dictionary, or list of prepared job dictionaries Parameters: Name Type Description Default prepared_jobs Union [ dict , List [ dict ]] A prepared job dictionary, or list of prepared job dictionaries required Returns: Type Description Batch A Batch object containing the submitted job(s) Source code in 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 def submit_prepared_jobs ( self , prepared_jobs : Union [ dict , List [ dict ]]) -> Batch : \"\"\"Submit a prepared job dictionary, or list of prepared job dictionaries Args: prepared_jobs: A prepared job dictionary, or list of prepared job dictionaries Returns: A Batch object containing the submitted job(s) \"\"\" if isinstance ( prepared_jobs , dict ): payload = { 'jobs' : [ prepared_jobs ]} else : payload = { 'jobs' : prepared_jobs } response = self . session . post ( urljoin ( self . url , '/jobs' ), json = payload ) _raise_for_hyp3_status ( response ) batch = Batch () for job in response . json ()[ 'jobs' ]: batch += Job . from_dict ( job ) return batch","title":"submit_prepared_jobs()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.submit_rtc_job","text":"Submit an RTC job Parameters: Name Type Description Default granule str The granule (scene) to use required name Optional [ str ] A name for the job None dem_matching bool Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files False include_dem bool Include the DEM file in the product package False include_inc_map bool Include the local incidence angle map in the product package False include_rgb bool Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) False include_scattering_area bool Include the scattering area in the product package False radiometry Literal ['sigma0', 'gamma0'] Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) 'gamma0' resolution Literal [10, 20, 30] Desired output pixel spacing in meters 30 scale Literal ['amplitude', 'decibel', 'power'] Scale of output image; power, decibel or amplitude 'power' speckle_filter bool Apply an Enhanced Lee speckle filter False dem_name Literal ['copernicus', 'legacy'] Name of the DEM to use for processing. copernicus will use the Copernicus GLO-30 Public DEM, while legacy will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. 'copernicus' Returns: Type Description Batch A Batch object containing the RTC job Source code in 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 def submit_rtc_job ( self , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> Batch : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A Batch object containing the RTC job \"\"\" arguments = locals () arguments . pop ( 'self' ) job_dict = self . prepare_rtc_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict )","title":"submit_rtc_job()"},{"location":"using/sdk_api/#hyp3_sdk.HyP3.watch","text":"Watch jobs until they complete Parameters: Name Type Description Default job_or_batch Union [ Batch , Job ] A Batch or Job object of jobs to watch required timeout int How long to wait until exiting in seconds 10800 interval Union [ int , float ] How often to check for updates in seconds 60 Returns: Type Description Union [ Batch , Job ] A Batch or Job object with refreshed watched jobs Source code in 106 107 108 109 110 111 112 113 114 115 116 117 118 119 @singledispatchmethod def watch ( self , job_or_batch : Union [ Batch , Job ], timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Union [ Batch , Job ]: \"\"\"Watch jobs until they complete Args: job_or_batch: A Batch or Job object of jobs to watch timeout: How long to wait until exiting in seconds interval: How often to check for updates in seconds Returns: A Batch or Job object with refreshed watched jobs \"\"\" raise NotImplementedError ( f 'Cannot watch { type ( job_or_batch ) } type object' )","title":"watch()"},{"location":"using/sdk_api/#hyp3_sdk.Job","text":"Source code in 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 class Job : _attributes_for_resubmit = { 'name' , 'job_parameters' , 'job_type' } def __init__ ( self , job_type : str , job_id : str , request_time : datetime , status_code : str , user_id : str , name : Optional [ str ] = None , job_parameters : Optional [ dict ] = None , files : Optional [ List ] = None , logs : Optional [ List ] = None , browse_images : Optional [ List ] = None , thumbnail_images : Optional [ List ] = None , expiration_time : Optional [ datetime ] = None , processing_times : Optional [ List [ float ]] = None , ): self . job_id = job_id self . job_type = job_type self . request_time = request_time self . status_code = status_code self . user_id = user_id self . name = name self . job_parameters = job_parameters self . files = files self . logs = logs self . browse_images = browse_images self . thumbnail_images = thumbnail_images self . expiration_time = expiration_time self . processing_times = processing_times def __repr__ ( self ): return f 'Job.from_dict( { self . to_dict () } )' def __str__ ( self ): return f 'HyP3 { self . job_type } job { self . job_id } ' def __eq__ ( self , other ): return self . __dict__ == other . __dict__ @staticmethod def from_dict ( input_dict : dict ): expiration_time = parse_date ( input_dict [ 'expiration_time' ]) if input_dict . get ( 'expiration_time' ) else None return Job ( job_type = input_dict [ 'job_type' ], job_id = input_dict [ 'job_id' ], request_time = parse_date ( input_dict [ 'request_time' ]), status_code = input_dict [ 'status_code' ], user_id = input_dict [ 'user_id' ], name = input_dict . get ( 'name' ), job_parameters = input_dict . get ( 'job_parameters' ), files = input_dict . get ( 'files' ), logs = input_dict . get ( 'logs' ), browse_images = input_dict . get ( 'browse_images' ), thumbnail_images = input_dict . get ( 'thumbnail_images' ), expiration_time = expiration_time , processing_times = input_dict . get ( 'processing_times' ), ) def to_dict ( self , for_resubmit : bool = False ): job_dict = {} if for_resubmit : keys_to_process = Job . _attributes_for_resubmit else : keys_to_process = vars ( self ) . keys () for key in keys_to_process : value = self . __getattribute__ ( key ) if value is not None : if isinstance ( value , datetime ): job_dict [ key ] = value . isoformat ( timespec = 'seconds' ) else : job_dict [ key ] = value return job_dict def succeeded ( self ) -> bool : return self . status_code == 'SUCCEEDED' def failed ( self ) -> bool : return self . status_code == 'FAILED' def complete ( self ) -> bool : return self . succeeded () or self . failed () # TODO may want to update this to check if status code is actually RUNNING, because currently this also returns # true if status is PENDING def running ( self ) -> bool : return not self . complete () def expired ( self ) -> bool : return self . expiration_time is not None and datetime . now ( tz . UTC ) >= self . expiration_time def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" location = Path ( location ) if not self . succeeded (): raise HyP3SDKError ( f 'Only succeeded jobs can be downloaded; job is { self . status_code } .' ) if self . expired (): raise HyP3SDKError ( f 'Expired jobs cannot be downloaded; ' f 'job expired { self . expiration_time . isoformat ( timespec = \"seconds\" ) } .' ) if create : location . mkdir ( parents = True , exist_ok = True ) elif not location . is_dir (): raise NotADirectoryError ( str ( location )) downloaded_files = [] for file in self . files : download_url = file [ 'url' ] filename = location / file [ 'filename' ] try : downloaded_files . append ( download_file ( download_url , filename , chunk_size = 10485760 )) except HTTPError : raise HyP3SDKError ( f 'Unable to download file: { download_url } ' ) return downloaded_files","title":"Job"},{"location":"using/sdk_api/#hyp3_sdk.Job.download_files","text":"Parameters: Name Type Description Default location Union [ Path , str ] Directory location to put files into '.' create bool Create location if it does not point to an existing directory True Returns: list of Path objects to downloaded files Source code in 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" location = Path ( location ) if not self . succeeded (): raise HyP3SDKError ( f 'Only succeeded jobs can be downloaded; job is { self . status_code } .' ) if self . expired (): raise HyP3SDKError ( f 'Expired jobs cannot be downloaded; ' f 'job expired { self . expiration_time . isoformat ( timespec = \"seconds\" ) } .' ) if create : location . mkdir ( parents = True , exist_ok = True ) elif not location . is_dir (): raise NotADirectoryError ( str ( location )) downloaded_files = [] for file in self . files : download_url = file [ 'url' ] filename = location / file [ 'filename' ] try : downloaded_files . append ( download_file ( download_url , filename , chunk_size = 10485760 )) except HTTPError : raise HyP3SDKError ( f 'Unable to download file: { download_url } ' ) return downloaded_files","title":"download_files()"},{"location":"using/sdk_api/#hyp3_sdk.exceptions","text":"Errors and exceptions to raise when the SDK runs into problems","title":"exceptions"},{"location":"using/sdk_api/#hyp3_sdk.exceptions.ASFSearchError","text":"Bases: HyP3SDKError Raise for errors when using the ASF Search module Source code in hyp3_sdk/exceptions.py 15 16 class ASFSearchError ( HyP3SDKError ): \"\"\"Raise for errors when using the ASF Search module\"\"\"","title":"ASFSearchError"},{"location":"using/sdk_api/#hyp3_sdk.exceptions.AuthenticationError","text":"Bases: HyP3SDKError Raise when authentication does not succeed Source code in hyp3_sdk/exceptions.py 23 24 class AuthenticationError ( HyP3SDKError ): \"\"\"Raise when authentication does not succeed\"\"\"","title":"AuthenticationError"},{"location":"using/sdk_api/#hyp3_sdk.exceptions.HyP3Error","text":"Bases: HyP3SDKError Raise for errors when using the HyP3 module Source code in hyp3_sdk/exceptions.py 11 12 class HyP3Error ( HyP3SDKError ): \"\"\"Raise for errors when using the HyP3 module\"\"\"","title":"HyP3Error"},{"location":"using/sdk_api/#hyp3_sdk.exceptions.HyP3SDKError","text":"Bases: Exception Base Exception for the HyP3 SDK Source code in hyp3_sdk/exceptions.py 7 8 class HyP3SDKError ( Exception ): \"\"\"Base Exception for the HyP3 SDK\"\"\"","title":"HyP3SDKError"},{"location":"using/sdk_api/#hyp3_sdk.exceptions.ServerError","text":"Bases: HyP3SDKError Raise when the HyP3 SDK encounters a server error Source code in hyp3_sdk/exceptions.py 19 20 class ServerError ( HyP3SDKError ): \"\"\"Raise when the HyP3 SDK encounters a server error\"\"\"","title":"ServerError"},{"location":"using/sdk_api/#hyp3_sdk.hyp3","text":"","title":"hyp3"},{"location":"using/sdk_api/#hyp3_sdk.hyp3.HyP3","text":"A python wrapper around the HyP3 API. Warning: All jobs submitted to HyP3 are publicly visible. For more information, see https://hyp3-docs.asf.alaska.edu/#public-visibility-of-jobs Source code in hyp3_sdk/hyp3.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 class HyP3 : \"\"\"A python wrapper around the HyP3 API. Warning: All jobs submitted to HyP3 are publicly visible. For more information, see https://hyp3-docs.asf.alaska.edu/#public-visibility-of-jobs \"\"\" def __init__ ( self , api_url : str = PROD_API , username : Optional [ str ] = None , password : Optional [ str ] = None , prompt : bool = False ): \"\"\"If username and password are not provided, attempts to use credentials from a `.netrc` file. Args: api_url: Address of the HyP3 API username: Username for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. password: Password for authenticating to `urs.earthdata.nasa.gov`. Both username and password must be provided if either is provided. prompt: Prompt for username and/or password interactively when they are not provided as keyword parameters \"\"\" self . url = api_url if username is None and prompt : username = input ( 'NASA Earthdata Login username: ' ) if password is None and prompt : password = getpass ( 'NASA Earthdata Login password: ' ) self . session = hyp3_sdk . util . get_authenticated_session ( username , password ) self . session . headers . update ({ 'User-Agent' : f ' { hyp3_sdk . __name__ } / { hyp3_sdk . __version__ } ' }) def find_jobs ( self , start : Optional [ datetime ] = None , end : Optional [ datetime ] = None , status_code : Optional [ str ] = None , name : Optional [ str ] = None , job_type : Optional [ str ] = None , user_id : Optional [ str ] = None ) -> Batch : \"\"\"Gets a Batch of jobs from HyP3 matching the provided search criteria Args: start: only jobs submitted after given time end: only jobs submitted before given time status_code: only jobs matching this status (SUCCEEDED, FAILED, RUNNING, PENDING) name: only jobs with this name job_type: only jobs with this job_type user_id: only jobs submitted by this user (defaults to the current user) Returns: A Batch object containing the found jobs \"\"\" params = {} for param_name in ( 'start' , 'end' , 'status_code' , 'name' , 'job_type' , 'user_id' ): param_value = locals () . get ( param_name ) if param_value is not None : if isinstance ( param_value , datetime ): if param_value . tzinfo is None : param_value = param_value . replace ( tzinfo = timezone . utc ) param_value = param_value . isoformat ( timespec = 'seconds' ) params [ param_name ] = param_value response = self . session . get ( urljoin ( self . url , '/jobs' ), params = params ) _raise_for_hyp3_status ( response ) jobs = [ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]] while 'next' in response . json (): next_url = response . json ()[ 'next' ] response = self . session . get ( next_url ) _raise_for_hyp3_status ( response ) jobs . extend ([ Job . from_dict ( job ) for job in response . json ()[ 'jobs' ]]) return Batch ( jobs ) def get_job_by_id ( self , job_id : str ) -> Job : \"\"\"Get job by job ID Args: job_id: A job ID Returns: A Job object \"\"\" response = self . session . get ( urljoin ( self . url , f '/jobs/ { job_id } ' )) _raise_for_hyp3_status ( response ) return Job . from_dict ( response . json ()) @singledispatchmethod def watch ( self , job_or_batch : Union [ Batch , Job ], timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Union [ Batch , Job ]: \"\"\"Watch jobs until they complete Args: job_or_batch: A Batch or Job object of jobs to watch timeout: How long to wait until exiting in seconds interval: How often to check for updates in seconds Returns: A Batch or Job object with refreshed watched jobs \"\"\" raise NotImplementedError ( f 'Cannot watch { type ( job_or_batch ) } type object' ) @watch . register def _watch_batch ( self , batch : Batch , timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Batch : tqdm = hyp3_sdk . util . get_tqdm_progress_bar () iterations_until_timeout = math . ceil ( timeout / interval ) bar_format = ' {l_bar}{bar} | {n_fmt} / {total_fmt} [ {postfix[0]} ]' with tqdm ( total = len ( batch ), bar_format = bar_format , postfix = [ f 'timeout in { timeout } s' ]) as progress_bar : for ii in range ( iterations_until_timeout ): batch = self . refresh ( batch ) counts = batch . _count_statuses () complete = counts [ 'SUCCEEDED' ] + counts [ 'FAILED' ] progress_bar . postfix = [ f 'timeout in { timeout - ii * interval } s' ] # to control n/total manually; update is n += value progress_bar . n = complete progress_bar . update ( 0 ) if batch . complete (): return batch time . sleep ( interval ) raise HyP3Error ( f 'Timeout occurred while waiting for { batch } ' ) @watch . register def _watch_job ( self , job : Job , timeout : int = 10800 , interval : Union [ int , float ] = 60 ) -> Job : tqdm = hyp3_sdk . util . get_tqdm_progress_bar () iterations_until_timeout = math . ceil ( timeout / interval ) bar_format = ' {n_fmt} / {total_fmt} [ {postfix[0]} ]' with tqdm ( total = 1 , bar_format = bar_format , postfix = [ f 'timeout in { timeout } s' ]) as progress_bar : for ii in range ( iterations_until_timeout ): job = self . refresh ( job ) progress_bar . postfix = [ f 'timeout in { timeout - ii * interval } s' ] progress_bar . update ( int ( job . complete ())) if job . complete (): return job time . sleep ( interval ) raise HyP3Error ( f 'Timeout occurred while waiting for { job } ' ) @singledispatchmethod def refresh ( self , job_or_batch : Union [ Batch , Job ]) -> Union [ Batch , Job ]: \"\"\"Refresh each jobs' information Args: job_or_batch: A Batch of Job object to refresh Returns: A Batch or Job object with refreshed information \"\"\" raise NotImplementedError ( f 'Cannot refresh { type ( job_or_batch ) } type object' ) @refresh . register def _refresh_batch ( self , batch : Batch ): jobs = [] for job in batch . jobs : jobs . append ( self . refresh ( job )) return Batch ( jobs ) @refresh . register def _refresh_job ( self , job : Job ): return self . get_job_by_id ( job . job_id ) def submit_prepared_jobs ( self , prepared_jobs : Union [ dict , List [ dict ]]) -> Batch : \"\"\"Submit a prepared job dictionary, or list of prepared job dictionaries Args: prepared_jobs: A prepared job dictionary, or list of prepared job dictionaries Returns: A Batch object containing the submitted job(s) \"\"\" if isinstance ( prepared_jobs , dict ): payload = { 'jobs' : [ prepared_jobs ]} else : payload = { 'jobs' : prepared_jobs } response = self . session . post ( urljoin ( self . url , '/jobs' ), json = payload ) _raise_for_hyp3_status ( response ) batch = Batch () for job in response . json ()[ 'jobs' ]: batch += Job . from_dict ( job ) return batch def submit_autorift_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> Batch : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A Batch object containing the autoRIFT job \"\"\" job_dict = self . prepare_autorift_job ( granule1 , granule2 , name = name ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_autorift_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None ) -> dict : \"\"\"Submit an autoRIFT job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job Returns: A dictionary containing the prepared autoRIFT job \"\"\" job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ]}, 'job_type' : 'AUTORIFT' , } if name is not None : job_dict [ 'name' ] = name return job_dict def submit_rtc_job ( self , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> Batch : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A Batch object containing the RTC job \"\"\" arguments = locals () arguments . pop ( 'self' ) job_dict = self . prepare_rtc_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_rtc_job ( cls , granule : str , name : Optional [ str ] = None , dem_matching : bool = False , include_dem : bool = False , include_inc_map : bool = False , include_rgb : bool = False , include_scattering_area : bool = False , radiometry : Literal [ 'sigma0' , 'gamma0' ] = 'gamma0' , resolution : Literal [ 10 , 20 , 30 ] = 30 , scale : Literal [ 'amplitude' , 'decibel' , 'power' ] = 'power' , speckle_filter : bool = False , dem_name : Literal [ 'copernicus' , 'legacy' ] = 'copernicus' ) -> dict : \"\"\"Submit an RTC job Args: granule: The granule (scene) to use name: A name for the job dem_matching: Coregisters SAR data to the DEM, rather than using dead reckoning based on orbit files include_dem: Include the DEM file in the product package include_inc_map: Include the local incidence angle map in the product package include_rgb: Include a false-color RGB decomposition in the product package for dual-pol granules (ignored for single-pol granules) include_scattering_area: Include the scattering area in the product package radiometry: Backscatter coefficient normalization, either by ground area (sigma0) or illuminated area projected into the look direction (gamma0) resolution: Desired output pixel spacing in meters scale: Scale of output image; power, decibel or amplitude speckle_filter: Apply an Enhanced Lee speckle filter dem_name: Name of the DEM to use for processing. `copernicus` will use the Copernicus GLO-30 Public DEM, while `legacy` will use the DEM with the best coverage from ASF's legacy SRTM/NED datasets. Returns: A dictionary containing the prepared RTC job \"\"\" job_parameters = locals () . copy () for key in [ 'granule' , 'name' , 'cls' ]: job_parameters . pop ( key , None ) job_dict = { 'job_parameters' : { 'granules' : [ granule ], ** job_parameters }, 'job_type' : 'RTC_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict def submit_insar_job ( self , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> Batch : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A Batch object containing the InSAR job \"\"\" arguments = locals () . copy () arguments . pop ( 'self' ) job_dict = self . prepare_insar_job ( ** arguments ) return self . submit_prepared_jobs ( prepared_jobs = job_dict ) @classmethod def prepare_insar_job ( cls , granule1 : str , granule2 : str , name : Optional [ str ] = None , include_look_vectors : bool = False , include_los_displacement : bool = False , include_inc_map : bool = False , looks : Literal [ '20x4' , '10x2' ] = '20x4' , include_dem : bool = False , include_wrapped_phase : bool = False , apply_water_mask : bool = False , include_displacement_maps : bool = False ) -> dict : \"\"\"Submit an InSAR job Args: granule1: The first granule (scene) to use granule2: The second granule (scene) to use name: A name for the job include_look_vectors: Include the look vector theta and phi files in the product package include_los_displacement: Include a GeoTIFF in the product package containing displacement values along the Line-Of-Sight (LOS). This parameter has been deprecated in favor of `include_displacement_maps`, and will be removed in a future release. include_inc_map: Include the local and ellipsoidal incidence angle maps in the product package looks: Number of looks to take in range and azimuth include_dem: Include the digital elevation model GeoTIFF in the product package include_wrapped_phase: Include the wrapped phase GeoTIFF in the product package apply_water_mask: Sets pixels over coastal waters and large inland waterbodies as invalid for phase unwrapping include_displacement_maps: Include displacement maps (line-of-sight and vertical) in the product package Returns: A dictionary containing the prepared InSAR job \"\"\" if include_los_displacement : warnings . warn ( 'The include_los_displacement parameter has been deprecated in favor of ' 'include_displacement_maps, and will be removed in a future release.' , FutureWarning ) job_parameters = locals () . copy () for key in [ 'cls' , 'granule1' , 'granule2' , 'name' ]: job_parameters . pop ( key ) job_dict = { 'job_parameters' : { 'granules' : [ granule1 , granule2 ], ** job_parameters }, 'job_type' : 'INSAR_GAMMA' , } if name is not None : job_dict [ 'name' ] = name return job_dict def my_info ( self ) -> dict : \"\"\" Returns: Your user information \"\"\" response = self . session . get ( urljoin ( self . url , '/user' )) _raise_for_hyp3_status ( response ) return response . json () def check_quota ( self ) -> Optional [ int ]: \"\"\" Returns: The number of jobs left in your quota, or None if you have no quota \"\"\" info = self . my_info () return info [ 'quota' ][ 'remaining' ]","title":"HyP3"},{"location":"using/sdk_api/#hyp3_sdk.jobs","text":"","title":"jobs"},{"location":"using/sdk_api/#hyp3_sdk.jobs.Batch","text":"Source code in hyp3_sdk/jobs.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 class Batch : def __init__ ( self , jobs : Optional [ List [ Job ]] = None ): if jobs is None : jobs = [] self . jobs = jobs def __add__ ( self , other : Union [ Job , 'Batch' ]): if isinstance ( other , Batch ): return Batch ( self . jobs + other . jobs ) elif isinstance ( other , Job ): return Batch ( self . jobs + [ other ]) else : raise TypeError ( f \"unsupported operand type(s) for +: ' { type ( self ) } ' and ' { type ( other ) } '\" ) def __iadd__ ( self , other : Union [ Job , 'Batch' ]): if isinstance ( other , Batch ): self . jobs += other . jobs elif isinstance ( other , Job ): self . jobs += [ other ] else : raise TypeError ( f \"unsupported operand type(s) for +=: ' { type ( self ) } ' and ' { type ( other ) } '\" ) return self def __iter__ ( self ): return iter ( self . jobs ) def __len__ ( self ): return len ( self . jobs ) def __contains__ ( self , job : Job ): return job in self . jobs def __eq__ ( self , other : 'Batch' ): return self . jobs == other . jobs def __delitem__ ( self , job : int ): self . jobs . pop ( job ) return self def __getitem__ ( self , index : int ): if isinstance ( index , slice ): return Batch ( self . jobs [ index ]) return self . jobs [ index ] def __setitem__ ( self , index : int , job : Job ): self . jobs [ index ] = job return self def __repr__ ( self ): reprs = \", \" . join ([ job . __repr__ () for job in self . jobs ]) return f 'Batch([ { reprs } ])' def __str__ ( self ): count = self . _count_statuses () return f ' { len ( self ) } HyP3 Jobs: ' \\ f ' { count [ \"SUCCEEDED\" ] } succeeded, ' \\ f ' { count [ \"FAILED\" ] } failed, ' \\ f ' { count [ \"RUNNING\" ] } running, ' \\ f ' { count [ \"PENDING\" ] } pending.' def _count_statuses ( self ): return Counter ([ job . status_code for job in self . jobs ]) def complete ( self ) -> bool : \"\"\" Returns: True if all jobs are complete, otherwise returns False \"\"\" for job in self . jobs : if not job . complete (): return False return True def succeeded ( self ) -> bool : \"\"\" Returns: True if all jobs have succeeded, otherwise returns False \"\"\" for job in self . jobs : if not job . succeeded (): return False return True def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" downloaded_files = [] tqdm = get_tqdm_progress_bar () for job in tqdm ( self . jobs ): try : downloaded_files . extend ( job . download_files ( location , create )) except HyP3SDKError as e : print ( f 'Warning: { e } Skipping download for { job } .' ) return downloaded_files def any_expired ( self ) -> bool : \"\"\"Check succeeded jobs for expiration\"\"\" for job in self . jobs : try : if job . expired (): return True except HyP3SDKError : continue return False def filter_jobs ( self , succeeded : bool = True , running : bool = True , failed : bool = False , include_expired : bool = True , ) -> 'Batch' : \"\"\"Filter jobs by status. By default, only succeeded and still running jobs will be in the returned batch. Args: succeeded: Include all succeeded jobs running: Include all running jobs failed: Include all failed jobs include_expired: Include expired jobs in the result Returns: batch: A batch object containing jobs matching all the selected statuses \"\"\" filtered_jobs = [] for job in self . jobs : if job . succeeded () and succeeded : if include_expired or not job . expired (): filtered_jobs . append ( job ) elif job . running () and running : filtered_jobs . append ( job ) elif job . failed () and failed : filtered_jobs . append ( job ) return Batch ( filtered_jobs )","title":"Batch"},{"location":"using/sdk_api/#hyp3_sdk.jobs.Job","text":"Source code in hyp3_sdk/jobs.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 class Job : _attributes_for_resubmit = { 'name' , 'job_parameters' , 'job_type' } def __init__ ( self , job_type : str , job_id : str , request_time : datetime , status_code : str , user_id : str , name : Optional [ str ] = None , job_parameters : Optional [ dict ] = None , files : Optional [ List ] = None , logs : Optional [ List ] = None , browse_images : Optional [ List ] = None , thumbnail_images : Optional [ List ] = None , expiration_time : Optional [ datetime ] = None , processing_times : Optional [ List [ float ]] = None , ): self . job_id = job_id self . job_type = job_type self . request_time = request_time self . status_code = status_code self . user_id = user_id self . name = name self . job_parameters = job_parameters self . files = files self . logs = logs self . browse_images = browse_images self . thumbnail_images = thumbnail_images self . expiration_time = expiration_time self . processing_times = processing_times def __repr__ ( self ): return f 'Job.from_dict( { self . to_dict () } )' def __str__ ( self ): return f 'HyP3 { self . job_type } job { self . job_id } ' def __eq__ ( self , other ): return self . __dict__ == other . __dict__ @staticmethod def from_dict ( input_dict : dict ): expiration_time = parse_date ( input_dict [ 'expiration_time' ]) if input_dict . get ( 'expiration_time' ) else None return Job ( job_type = input_dict [ 'job_type' ], job_id = input_dict [ 'job_id' ], request_time = parse_date ( input_dict [ 'request_time' ]), status_code = input_dict [ 'status_code' ], user_id = input_dict [ 'user_id' ], name = input_dict . get ( 'name' ), job_parameters = input_dict . get ( 'job_parameters' ), files = input_dict . get ( 'files' ), logs = input_dict . get ( 'logs' ), browse_images = input_dict . get ( 'browse_images' ), thumbnail_images = input_dict . get ( 'thumbnail_images' ), expiration_time = expiration_time , processing_times = input_dict . get ( 'processing_times' ), ) def to_dict ( self , for_resubmit : bool = False ): job_dict = {} if for_resubmit : keys_to_process = Job . _attributes_for_resubmit else : keys_to_process = vars ( self ) . keys () for key in keys_to_process : value = self . __getattribute__ ( key ) if value is not None : if isinstance ( value , datetime ): job_dict [ key ] = value . isoformat ( timespec = 'seconds' ) else : job_dict [ key ] = value return job_dict def succeeded ( self ) -> bool : return self . status_code == 'SUCCEEDED' def failed ( self ) -> bool : return self . status_code == 'FAILED' def complete ( self ) -> bool : return self . succeeded () or self . failed () # TODO may want to update this to check if status code is actually RUNNING, because currently this also returns # true if status is PENDING def running ( self ) -> bool : return not self . complete () def expired ( self ) -> bool : return self . expiration_time is not None and datetime . now ( tz . UTC ) >= self . expiration_time def download_files ( self , location : Union [ Path , str ] = '.' , create : bool = True ) -> List [ Path ]: \"\"\" Args: location: Directory location to put files into create: Create `location` if it does not point to an existing directory Returns: list of Path objects to downloaded files \"\"\" location = Path ( location ) if not self . succeeded (): raise HyP3SDKError ( f 'Only succeeded jobs can be downloaded; job is { self . status_code } .' ) if self . expired (): raise HyP3SDKError ( f 'Expired jobs cannot be downloaded; ' f 'job expired { self . expiration_time . isoformat ( timespec = \"seconds\" ) } .' ) if create : location . mkdir ( parents = True , exist_ok = True ) elif not location . is_dir (): raise NotADirectoryError ( str ( location )) downloaded_files = [] for file in self . files : download_url = file [ 'url' ] filename = location / file [ 'filename' ] try : downloaded_files . append ( download_file ( download_url , filename , chunk_size = 10485760 )) except HTTPError : raise HyP3SDKError ( f 'Unable to download file: { download_url } ' ) return downloaded_files","title":"Job"},{"location":"using/sdk_api/#hyp3_sdk.util","text":"Extra utilities for working with HyP3","title":"util"},{"location":"using/sdk_api/#hyp3_sdk.util.chunk","text":"Split a sequence into small chunks Parameters: Name Type Description Default itr Sequence [ Any ] A sequence object to chunk required n int Size of the chunks to return 200 Source code in hyp3_sdk/util.py 43 44 45 46 47 48 49 50 51 52 53 54 def chunk ( itr : Sequence [ Any ], n : int = 200 ) -> Generator [ Sequence [ Any ], None , None ]: \"\"\"Split a sequence into small chunks Args: itr: A sequence object to chunk n: Size of the chunks to return \"\"\" if not isinstance ( n , int ) or n < 1 : raise ValueError ( f 'n must be a positive integer: { n } ' ) for i in range ( 0 , len ( itr ), n ): yield itr [ i : i + n ]","title":"chunk()"},{"location":"using/sdk_api/#hyp3_sdk.util.download_file","text":"Download a file Args: url: URL of the file to download filepath: Location to place file into chunk_size: Size to chunk the download into retries: Number of retries to attempt backoff_factor: Factor for calculating time between retries Returns: download_path: The path to the downloaded file Source code in hyp3_sdk/util.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 def download_file ( url : str , filepath : Union [ Path , str ], chunk_size = None , retries = 2 , backoff_factor = 1 ) -> Path : \"\"\"Download a file Args: url: URL of the file to download filepath: Location to place file into chunk_size: Size to chunk the download into retries: Number of retries to attempt backoff_factor: Factor for calculating time between retries Returns: download_path: The path to the downloaded file \"\"\" filepath = Path ( filepath ) session = requests . Session () retry_strategy = Retry ( total = retries , backoff_factor = backoff_factor , status_forcelist = [ 429 , 500 , 502 , 503 , 504 ], ) session . mount ( 'https://' , HTTPAdapter ( max_retries = retry_strategy )) session . mount ( 'http://' , HTTPAdapter ( max_retries = retry_strategy )) stream = False if chunk_size is None else True with session . get ( url , stream = stream ) as s : s . raise_for_status () tqdm = get_tqdm_progress_bar () with tqdm . wrapattr ( open ( filepath , \"wb\" ), 'write' , miniters = 1 , desc = filepath . name , total = int ( s . headers . get ( 'content-length' , 0 ))) as f : for chunk in s . iter_content ( chunk_size = chunk_size ): if chunk : f . write ( chunk ) session . close () return filepath","title":"download_file()"},{"location":"using/sdk_api/#hyp3_sdk.util.extract_zipped_product","text":"Extract a zipped HyP3 product Extract a zipped HyP3 product to the same directory as the zipped HyP3 product, optionally deleting zip file afterward. Parameters: Name Type Description Default zip_file Union [ str , Path ] Zipped HyP3 product to extract required delete bool Delete zip_file after it has been extracted True Returns: Type Description Path Path to the HyP3 product folder containing the product files Source code in hyp3_sdk/util.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def extract_zipped_product ( zip_file : Union [ str , Path ], delete : bool = True ) -> Path : \"\"\"Extract a zipped HyP3 product Extract a zipped HyP3 product to the same directory as the zipped HyP3 product, optionally deleting `zip file` afterward. Args: zip_file: Zipped HyP3 product to extract delete: Delete `zip_file` after it has been extracted Returns: Path to the HyP3 product folder containing the product files \"\"\" zip_file = Path ( zip_file ) with ZipFile ( zip_file ) as z : z . extractall ( path = zip_file . parent ) if delete : zip_file . unlink () return zip_file . parent / zip_file . stem","title":"extract_zipped_product()"},{"location":"using/sdk_api/#hyp3_sdk.util.get_authenticated_session","text":"Log into HyP3 using credentials for urs.earthdata.nasa.gov from either the provided credentials or a .netrc file. Returns: Type Description Session An authenticated HyP3 Session Source code in hyp3_sdk/util.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def get_authenticated_session ( username : str , password : str ) -> requests . Session : \"\"\"Log into HyP3 using credentials for `urs.earthdata.nasa.gov` from either the provided credentials or a `.netrc` file. Returns: An authenticated HyP3 Session \"\"\" s = requests . Session () if username is not None and password is not None : response = s . get ( AUTH_URL , auth = ( username , password )) auth_error_message = ( 'Was not able to authenticate with credentials provided \\n ' 'This could be due to invalid credentials or a connection error.' ) else : response = s . get ( AUTH_URL ) auth_error_message = ( 'Was not able to authenticate with .netrc file and no credentials provided \\n ' 'This could be due to invalid credentials in .netrc or a connection error.' ) parsed_url = urllib . parse . urlparse ( response . url ) query_params = urllib . parse . parse_qs ( parsed_url . query ) error_msg = query_params . get ( 'error_msg' ) resolution_url = query_params . get ( 'resolution_url' ) if error_msg is not None and resolution_url is not None : raise AuthenticationError ( f ' { error_msg [ 0 ] } : { resolution_url [ 0 ] } ' ) if error_msg is not None and 'Please update your profile' in error_msg [ 0 ]: raise AuthenticationError ( f ' { error_msg [ 0 ] } : { PROFILE_URL } ' ) try : response . raise_for_status () except requests . HTTPError : raise AuthenticationError ( auth_error_message ) return s","title":"get_authenticated_session()"},{"location":"using/subscriptions/","text":"Subscriptions in HyP3 \u00b6 The Subscriptions feature of HyP3 has been removed in favor of a more flexible approach. You can follow these tutorials to achieve subscription-like functionality using Jupyter notebooks.","title":"Subscriptions"},{"location":"using/subscriptions/#subscriptions-in-hyp3","text":"The Subscriptions feature of HyP3 has been removed in favor of a more flexible approach. You can follow these tutorials to achieve subscription-like functionality using Jupyter notebooks.","title":"Subscriptions in HyP3"},{"location":"using/vertex/","text":"On Demand Sentinel-1 Processing in Vertex \u00b6 The Alaska Satellite Facility offers On Demand processing of Sentinel-1 datasets to Radiometric Terrain Correction (RTC) or Interferometric SAR (InSAR) products through Vertex , ASF's Data Search web portal. You can submit scenes to be processed into higher-level products, avoiding the cost and complexity of performing such processing yourself. On Demand Sentinel-1 products are generated using ASF's HyP3 processing platform, leveraging GAMMA Software. Products are distributed as UTM-projected GeoTIFFs. To learn more about the finished products, refer to the Product Guides: ASF Sentinel-1 RTC Product Guide ASF Sentinel-1 InSAR Product Guide Getting Started \u00b6 To request On Demand products, visit ASF Data Search - Vertex . Select your scenes - RTC processing is available for Sentinel-1 GRD-H and SLC scenes with a beam mode of IW. InSAR processing requires pairs of IW SLC scenes. Use the Geographic Search in Vertex to find individual scenes to submit for RTC processing, or reference scenes to use for generating InSAR pairs. For InSAR, once you find a reference scene, use either the Baseline or SBAS Search to find scene pairs to submit for processing. Submit your request - After selecting your scenes, access the On Demand queue to submit your processing request. You may process up to 1000 jobs per month. Monitor your request - The On Demand Products search type displays your running and completed requests. New requests are typically available for download within an hour, but wait time will depend on processing load. Download your data - Finished On Demand products can be downloaded after an On Demand Products search either directly or via your download queue . On Demand products are retained and available to download for two weeks after processing. Tutorials \u00b6 Refer to our step-by-step tutorials for ordering and accessing RTC and InSAR products in Vertex.","title":"Vertex"},{"location":"using/vertex/#on-demand-sentinel-1-processing-in-vertex","text":"The Alaska Satellite Facility offers On Demand processing of Sentinel-1 datasets to Radiometric Terrain Correction (RTC) or Interferometric SAR (InSAR) products through Vertex , ASF's Data Search web portal. You can submit scenes to be processed into higher-level products, avoiding the cost and complexity of performing such processing yourself. On Demand Sentinel-1 products are generated using ASF's HyP3 processing platform, leveraging GAMMA Software. Products are distributed as UTM-projected GeoTIFFs. To learn more about the finished products, refer to the Product Guides: ASF Sentinel-1 RTC Product Guide ASF Sentinel-1 InSAR Product Guide","title":"On Demand Sentinel-1 Processing in Vertex"},{"location":"using/vertex/#getting-started","text":"To request On Demand products, visit ASF Data Search - Vertex . Select your scenes - RTC processing is available for Sentinel-1 GRD-H and SLC scenes with a beam mode of IW. InSAR processing requires pairs of IW SLC scenes. Use the Geographic Search in Vertex to find individual scenes to submit for RTC processing, or reference scenes to use for generating InSAR pairs. For InSAR, once you find a reference scene, use either the Baseline or SBAS Search to find scene pairs to submit for processing. Submit your request - After selecting your scenes, access the On Demand queue to submit your processing request. You may process up to 1000 jobs per month. Monitor your request - The On Demand Products search type displays your running and completed requests. New requests are typically available for download within an hour, but wait time will depend on processing load. Download your data - Finished On Demand products can be downloaded after an On Demand Products search either directly or via your download queue . On Demand products are retained and available to download for two weeks after processing.","title":"Getting Started"},{"location":"using/vertex/#tutorials","text":"Refer to our step-by-step tutorials for ordering and accessing RTC and InSAR products in Vertex.","title":"Tutorials"}]}