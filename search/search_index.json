{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ASF HyP3 \u00b6 Alaska Satellite Facility's Hybrid Pluggable Processing Pipeline HyP3 is a system that addresses many of the issues that people face when processing Synthetic Aperture Radar (SAR) imagery: Most SAR datasets require at least some processing to remove distortions before they are analysis-ready SAR processing is computing-intensive Software for SAR processing is complicated to use and/or prohibitively expensive Producing analysis-ready SAR data has a steep learning curve that acts as a barrier to entry HyP3 solves these problems by providing a free service where people can request SAR processing on-demand. These processing requests are picked up by automated systems, which handle the complexity of SAR processing on behalf of the user. HyP3 doesn't require users to have a lot of knowledge of SAR processing before getting started; users only need to submit the input data, and set a few optional parameters if desired. With HyP3, analysis-ready products are just a few clicks away. How it Works \u00b6 HyP3 is made up of multiple parts, but they fall into roughly two categories: Orchestration and Plugins. The Orchestration of HyP3 runs HyP3 plugins in the cloud and makes it easy for users to request processing, monitor their requests, and download finished products without needing to manage any of the plugins. HyP3 Orchestration can be deployed independently. Plugins are the workhorses of HyP3. They marshal the input data through complicated SAR processing code to generate an output product. Plugins are container-based and can also be used independently. Contact Us \u00b6 Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? open an issue General questions? Suggstions? Or just want to talk to the team? chat with us on gitter","title":"Home"},{"location":"#asf-hyp3","text":"Alaska Satellite Facility's Hybrid Pluggable Processing Pipeline HyP3 is a system that addresses many of the issues that people face when processing Synthetic Aperture Radar (SAR) imagery: Most SAR datasets require at least some processing to remove distortions before they are analysis-ready SAR processing is computing-intensive Software for SAR processing is complicated to use and/or prohibitively expensive Producing analysis-ready SAR data has a steep learning curve that acts as a barrier to entry HyP3 solves these problems by providing a free service where people can request SAR processing on-demand. These processing requests are picked up by automated systems, which handle the complexity of SAR processing on behalf of the user. HyP3 doesn't require users to have a lot of knowledge of SAR processing before getting started; users only need to submit the input data, and set a few optional parameters if desired. With HyP3, analysis-ready products are just a few clicks away.","title":"ASF HyP3"},{"location":"#how-it-works","text":"HyP3 is made up of multiple parts, but they fall into roughly two categories: Orchestration and Plugins. The Orchestration of HyP3 runs HyP3 plugins in the cloud and makes it easy for users to request processing, monitor their requests, and download finished products without needing to manage any of the plugins. HyP3 Orchestration can be deployed independently. Plugins are the workhorses of HyP3. They marshal the input data through complicated SAR processing code to generate an output product. Plugins are container-based and can also be used independently.","title":"How it Works"},{"location":"#contact-us","text":"Want to talk about HyP3? We would love to hear from you! Found a bug? Want to request a feature? open an issue General questions? Suggstions? Or just want to talk to the team? chat with us on gitter","title":"Contact Us"},{"location":"api/","text":"HyP3 API \u00b6","title":"API"},{"location":"api/#hyp3-api","text":"","title":"HyP3 API"},{"location":"contributing/","text":"Contributing \u00b6","title":"Contributing"},{"location":"contributing/#contributing","text":"","title":"Contributing"},{"location":"getting_started/","text":"Getting started \u00b6 Using Vertex \u00b6 Using the SDK \u00b6 Using the API \u00b6","title":"Getting started"},{"location":"getting_started/#getting-started","text":"","title":"Getting started"},{"location":"getting_started/#using-vertex","text":"","title":"Using Vertex"},{"location":"getting_started/#using-the-sdk","text":"","title":"Using the SDK"},{"location":"getting_started/#using-the-api","text":"","title":"Using the API"},{"location":"gis_tools/","text":"GIS Tools \u00b6","title":"GIS Tools"},{"location":"gis_tools/#gis-tools","text":"","title":"GIS Tools"},{"location":"hyp3lib/","text":"HyP3lib \u00b6","title":"hyp3lib"},{"location":"hyp3lib/#hyp3lib","text":"","title":"HyP3lib"},{"location":"plugins/","text":"Plugins \u00b6 Plugins are the science backbone of HyP3; they do all of the data processing and product generation. Plugins can be added to HyP3 to generate new science products, or support different tools/software/algorithms/options/etc that are not currently supported by HyP3. How plugins work \u00b6 At their most basic level, HyP3 plugins are Docker containers with an interface (entrypoint) HyP3 understands. Plugins handle the entire processing workflow for a single product, including: Marshaling the required input data performing any needed transformations and computations on the data creating the final product uploading the product to an AWS S3 bucket for distribution By encapsulating the entire workflow for generating a single product, HyP3 can arbitrarily scale to meet user need. Developing a plugin \u00b6 To create a new HyP3 plugin, we recommend starting from a Minimal Working Example (MWE) of generating the product you're plugin will generate. Importantly, the MWE should be entirely self contained, and include all the necessary data to generate the product. Once a MWE is developed, it's important to define your plugin's interface -- this is where HyP3 connects the product generation and users. When designing the interface, you may find it helpful to ask yourself: what options do I want to provide to users? what's the minimal set information I need to gather from users? is this information easily input by users? is this information serializable? For example, can the information be written in a JSON file? could I define this information more simply? Once a MWE is developed and an interface is defined, you can use our HyP3 plugin cookiecuter to help you build a plugin that conforms to the plugin requirements. Plugin requirements \u00b6 In order to be supported by HyP3, a plugin must meet a few requirements: the plugin must be a Docker image that is hosted in a repository where HyP3 will be able to pull it he plugin's entrypoint must minimally accept the following arguments --bucket BUCKET-NAME where BUCKET-NAME is the name of an AWS S3 bucket that output products will be uploaded to --bucket-prefix BUCKET-PREFIX where BUCKET-PREFIX is a string appended to the key of any file uploaded to AWS S3 (this is effectively a subfolder in AWS S3) --username USER where USER is the username used to authenticate to EarthData Login --password PASSWORD where PASSWORD is the password used to authenticate to EarthData Login any necessary user input should be able to be provided through entrypoint arguments when uploading files to the S3 Bucket products files must be tagged with filetype: product if you wish to upload thumbnails or browse images, they must be tagged filetype: thumbnail or filetype: browse respectively Note: the aws subpackage of hyp3lib provides helper functions for tagging and uploading files Add the plugin to HyP3 \u00b6 Once the plugin itself is created, it can be added to the HyP3 system by... TBD.","title":"Overview"},{"location":"plugins/#plugins","text":"Plugins are the science backbone of HyP3; they do all of the data processing and product generation. Plugins can be added to HyP3 to generate new science products, or support different tools/software/algorithms/options/etc that are not currently supported by HyP3.","title":"Plugins"},{"location":"plugins/#how-plugins-work","text":"At their most basic level, HyP3 plugins are Docker containers with an interface (entrypoint) HyP3 understands. Plugins handle the entire processing workflow for a single product, including: Marshaling the required input data performing any needed transformations and computations on the data creating the final product uploading the product to an AWS S3 bucket for distribution By encapsulating the entire workflow for generating a single product, HyP3 can arbitrarily scale to meet user need.","title":"How plugins work"},{"location":"plugins/#developing-a-plugin","text":"To create a new HyP3 plugin, we recommend starting from a Minimal Working Example (MWE) of generating the product you're plugin will generate. Importantly, the MWE should be entirely self contained, and include all the necessary data to generate the product. Once a MWE is developed, it's important to define your plugin's interface -- this is where HyP3 connects the product generation and users. When designing the interface, you may find it helpful to ask yourself: what options do I want to provide to users? what's the minimal set information I need to gather from users? is this information easily input by users? is this information serializable? For example, can the information be written in a JSON file? could I define this information more simply? Once a MWE is developed and an interface is defined, you can use our HyP3 plugin cookiecuter to help you build a plugin that conforms to the plugin requirements.","title":"Developing a plugin"},{"location":"plugins/#plugin-requirements","text":"In order to be supported by HyP3, a plugin must meet a few requirements: the plugin must be a Docker image that is hosted in a repository where HyP3 will be able to pull it he plugin's entrypoint must minimally accept the following arguments --bucket BUCKET-NAME where BUCKET-NAME is the name of an AWS S3 bucket that output products will be uploaded to --bucket-prefix BUCKET-PREFIX where BUCKET-PREFIX is a string appended to the key of any file uploaded to AWS S3 (this is effectively a subfolder in AWS S3) --username USER where USER is the username used to authenticate to EarthData Login --password PASSWORD where PASSWORD is the password used to authenticate to EarthData Login any necessary user input should be able to be provided through entrypoint arguments when uploading files to the S3 Bucket products files must be tagged with filetype: product if you wish to upload thumbnails or browse images, they must be tagged filetype: thumbnail or filetype: browse respectively Note: the aws subpackage of hyp3lib provides helper functions for tagging and uploading files","title":"Plugin requirements"},{"location":"plugins/#add-the-plugin-to-hyp3","text":"Once the plugin itself is created, it can be added to the HyP3 system by... TBD.","title":"Add the plugin to HyP3"},{"location":"products/","text":"Available HyP3 Products \u00b6 RTC \u00b6 InSAR (SDK + API only) \u00b6 autoRIFT (SDK + API only) \u00b6 Product usage guidelines \u00b6","title":"Overview"},{"location":"products/#available-hyp3-products","text":"","title":"Available HyP3 Products"},{"location":"products/#rtc","text":"","title":"RTC"},{"location":"products/#insar-sdk-api-only","text":"","title":"InSAR (SDK + API only)"},{"location":"products/#autorift-sdk-api-only","text":"","title":"autoRIFT (SDK + API only)"},{"location":"products/#product-usage-guidelines","text":"","title":"Product usage guidelines"},{"location":"sdk/","text":"HyP3 SDK \u00b6","title":"SDK"},{"location":"sdk/#hyp3-sdk","text":"","title":"HyP3 SDK"},{"location":"software/","text":"HyP3 Sotware \u00b6","title":"HyP3 Sotware"},{"location":"software/#hyp3-sotware","text":"","title":"HyP3 Sotware"},{"location":"vertex/","text":"HyP3 in Vertex \u00b6","title":"Vertex"},{"location":"vertex/#hyp3-in-vertex","text":"","title":"HyP3 in Vertex"},{"location":"guides/rtc_atbd/","text":"RTC Algorithm Theoretical Basis \u00b6","title":"RTC ATBD"},{"location":"guides/rtc_atbd/#rtc-algorithm-theoretical-basis","text":"","title":"RTC Algorithm Theoretical Basis"},{"location":"guides/rtc_user/","text":"RTC Users Guide \u00b6","title":"RTC Users Guide"},{"location":"guides/rtc_user/#rtc-users-guide","text":"","title":"RTC Users Guide"},{"location":"plugins/autoRIFT/","text":"HyP3 autoRIFT Plugin \u00b6","title":"HyP3 autoRIFT"},{"location":"plugins/autoRIFT/#hyp3-autorift-plugin","text":"","title":"HyP3 autoRIFT Plugin"},{"location":"plugins/gamma/","text":"HyP3 GAMMA Plugin \u00b6","title":"HyP3 GAMMA"},{"location":"plugins/gamma/#hyp3-gamma-plugin","text":"","title":"HyP3 GAMMA Plugin"}]}